{
    "Which of these versions of the Old Testament typically contains the most books?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "catholic"
            ],
            "lines": [
                [
                    0.16796536796536796,
                    0.9,
                    0.6199770378874856,
                    0.5750273822562979,
                    0.3873239436619718,
                    0.28238038277511956,
                    0.553757225433526,
                    0.7068965517241379,
                    0.6904761904761905,
                    -1.0
                ],
                [
                    0.39675324675324675,
                    0.1,
                    0.33951123503362307,
                    0.3888280394304491,
                    0.5308775731310943,
                    0.2269554568238779,
                    0.3884393063583815,
                    0.28160919540229884,
                    0.30158730158730157,
                    -1.0
                ],
                [
                    0.43528138528138527,
                    0.0,
                    0.04051172707889126,
                    0.03614457831325301,
                    0.0817984832069339,
                    0.4906641604010026,
                    0.057803468208092484,
                    0.011494252873563218,
                    0.007936507936507936,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "catholic": 0.5426448980200109,
                "protestant": 0.328284594946697,
                "eastern orthodox": 0.12907050703329218
            },
            "question": "which of these versions of the old testament typically contains the most books?",
            "rate_limited": false,
            "answers": [
                "catholic",
                "protestant",
                "eastern orthodox"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "catholic": 0.6991455827382256,
                "protestant": 0.25799192018441885,
                "eastern orthodox": 0.32653976206731194
            },
            "integer_answers": {
                "catholic": 6,
                "protestant": 1,
                "eastern orthodox": 2
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    2100000.0,
                    1420000.0,
                    132000.0
                ],
                "wikipedia_search": [
                    1.411901913875598,
                    1.1347772841193895,
                    2.453320802005013
                ],
                "answer_relation_to_question": [
                    0.8398268398268398,
                    1.9837662337662336,
                    2.1764069264069263
                ],
                "question_related_to_answer": [
                    1.8,
                    0.2,
                    0.0
                ],
                "result_count_noun_chunks": [
                    14300000.0,
                    19600000.0,
                    3020000.0
                ],
                "word_count_noun_chunks": [
                    123.0,
                    49.0,
                    2.0
                ],
                "word_count_raw": [
                    87.0,
                    38.0,
                    1.0
                ],
                "result_count": [
                    3780000.0,
                    2070000.0,
                    247000.0
                ],
                "word_count_appended": [
                    479.0,
                    336.0,
                    50.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "The material that forms images in an Etch A Sketch is also the main component in which item?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "soda cans"
            ],
            "lines": [
                [
                    0.3648786717752235,
                    0,
                    0.04285714285714286,
                    0.02912621359223301,
                    0.9999453267303371,
                    0.5069444444444444,
                    0.22727272727272727,
                    0.3333333333333333,
                    0.3333333333333333,
                    -1.0
                ],
                [
                    0.49061302681992336,
                    0,
                    0.4857142857142857,
                    0.4174757281553398,
                    2.8775405085765094e-05,
                    0.23333333333333334,
                    0.2727272727272727,
                    0.3333333333333333,
                    0.3333333333333333,
                    -1.0
                ],
                [
                    0.14450830140485313,
                    0,
                    0.4714285714285714,
                    0.5533980582524272,
                    2.5897864577188586e-05,
                    0.25972222222222224,
                    0.5,
                    0.3333333333333333,
                    0.3333333333333333,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "zinc supplement tablets": 0.35471139916734684,
                "soda cans": 0.32446871472991473,
                "u.s. nickels": 0.3208198861027384
            },
            "question": "the material that forms images in an etch a sketch is also the main component in which item?",
            "rate_limited": false,
            "answers": [
                "zinc supplement tablets",
                "u.s. nickels",
                "soda cans"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "zinc supplement tablets": 0.16536304755231743,
                "soda cans": 0.4228964758789131,
                "u.s. nickels": 0.41799704009977895
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    3.0,
                    43.0,
                    57.0
                ],
                "wikipedia_search": [
                    3.548611111111111,
                    1.6333333333333333,
                    1.8180555555555555
                ],
                "answer_relation_to_question": [
                    2.189272030651341,
                    2.94367816091954,
                    0.8670498084291188
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    1390000.0,
                    40.0,
                    36.0
                ],
                "word_count_noun_chunks": [
                    1.0,
                    1.0,
                    1.0
                ],
                "word_count_raw": [
                    1.0,
                    1.0,
                    1.0
                ],
                "result_count": [
                    3.0,
                    34.0,
                    33.0
                ],
                "word_count_appended": [
                    5.0,
                    6.0,
                    11.0
                ]
            },
            "integer_answers": {
                "zinc supplement tablets": 4,
                "soda cans": 2,
                "u.s. nickels": 2
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Who was NOT a wife of Henry VIII?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "catherine of york"
            ],
            "lines": [
                [
                    0.29185814185814185,
                    0,
                    0.24418177524729096,
                    0.24418177524729096,
                    0.2506764056771906,
                    0.4230769230769231,
                    0.26530612244897955,
                    0.13636363636363635,
                    0.275,
                    0.0
                ],
                [
                    0.37053191906133087,
                    0,
                    0.499975219887061,
                    0.499975219887061,
                    0.49996636110235326,
                    0.3205128205128205,
                    0.46811224489795916,
                    0.5,
                    0.5,
                    0.0
                ],
                [
                    0.3376099390805273,
                    0,
                    0.25584300486564804,
                    0.25584300486564804,
                    0.24935723322045616,
                    0.2564102564102564,
                    0.26658163265306123,
                    0.36363636363636365,
                    0.22499999999999998,
                    0.0
                ]
            ],
            "fraction_answers": {
                "catherine of york": 0.08523155366285355,
                "catherine parr": 0.46733880502013664,
                "catherine howard": 0.44742964131700974
            },
            "question": "who was not a wife of henry viii?",
            "rate_limited": false,
            "answers": [
                "catherine parr",
                "catherine of york",
                "catherine howard"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "catherine of york": 0.4821604552640873,
                "catherine parr": 0.1593742341271244,
                "catherine howard": 0.07369058792155742
            },
            "integer_answers": {
                "catherine of york": 0,
                "catherine parr": 5,
                "catherine howard": 3
            },
            "categorical_data": {
                "question_type": 0
            },
            "data": {
                "result_count_important_words": [
                    351000.0,
                    34.0,
                    335000.0
                ],
                "wikipedia_search": [
                    0.46153846153846156,
                    1.0769230769230769,
                    1.4615384615384617
                ],
                "answer_relation_to_question": [
                    1.248851148851149,
                    0.776808485632015,
                    0.9743403655168361
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    378000.0,
                    51.0,
                    380000.0
                ],
                "word_count_noun_chunks": [
                    8.0,
                    0.0,
                    3.0
                ],
                "word_count_raw": [
                    27.0,
                    0.0,
                    33.0
                ],
                "word_count_appended": [
                    184.0,
                    25.0,
                    183.0
                ],
                "result_count": [
                    351000.0,
                    34.0,
                    335000.0
                ]
            },
            "negative_question": true
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "How many U.S. state names are only four letters long?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "50 states"
            ],
            "lines": [
                [
                    0.23222055256373095,
                    0.0,
                    0.11380753138075314,
                    0.12268314210061783,
                    0.1991404011461318,
                    0.3599468488990129,
                    0.2222222222222222,
                    0.0,
                    0,
                    5.0
                ],
                [
                    0.529533249935163,
                    1.0,
                    0.6794979079497908,
                    0.6707855251544572,
                    0.5429799426934098,
                    0.5162743609212858,
                    0.5694444444444444,
                    1.0,
                    0,
                    5.0
                ],
                [
                    0.23824619750110604,
                    0.0,
                    0.20669456066945607,
                    0.20653133274492497,
                    0.25787965616045844,
                    0.12377879017970134,
                    0.20833333333333334,
                    0.0,
                    0,
                    5.0
                ]
            ],
            "fraction_answers": {
                "12 states": 0.1562525872890586,
                "50 states": 0.6885644288873188,
                "3 states": 0.15518298382362253
            },
            "question": "how many u.s. state names are only four letters long?",
            "rate_limited": false,
            "answers": [
                "12 states",
                "50 states",
                "3 states"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "12 states": 0.22764022674726658,
                "50 states": 0.5878166274964689,
                "3 states": 0.3257094473940358
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 5
            },
            "data": {
                "result_count_important_words": [
                    1390000.0,
                    7600000.0,
                    2340000.0
                ],
                "wikipedia_search": [
                    1.0798405466970387,
                    1.5488230827638572,
                    0.371336370539104
                ],
                "answer_relation_to_question": [
                    0.9288822102549238,
                    2.118132999740652,
                    0.9529847900044242
                ],
                "question_related_to_answer": [
                    0.0,
                    1.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    1390000.0,
                    3790000.0,
                    1800000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    6.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_appended": [
                    32.0,
                    82.0,
                    30.0
                ],
                "result_count": [
                    1360000.0,
                    8120000.0,
                    2470000.0
                ]
            },
            "integer_answers": {
                "12 states": 0,
                "50 states": 8,
                "3 states": 0
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "What play has the stage direction, \u201cEnter a Messenger, with two heads and a hand\u201d?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "titus andronicus"
            ],
            "lines": [
                [
                    0.29962250796272266,
                    1.0,
                    0.03278688524590164,
                    0.049558390578999016,
                    0.17135123880907766,
                    0.22264552781439853,
                    0.0375,
                    0.0,
                    0.0,
                    1.0
                ],
                [
                    0.36170421925995827,
                    0.0,
                    0.819672131147541,
                    0.021426234870788353,
                    0.40807828440557986,
                    0.7545288609212119,
                    0.6125,
                    0.9545454545454546,
                    1.0,
                    1.0
                ],
                [
                    0.338673272777319,
                    0.0,
                    0.14754098360655737,
                    0.9290153745502127,
                    0.4205704767853425,
                    0.022825611264389683,
                    0.35,
                    0.045454545454545456,
                    0.0,
                    1.0
                ]
            ],
            "fraction_answers": {
                "oedipus rex": 0.20149606115678884,
                "agamemnon": 0.25045336271537405,
                "titus andronicus": 0.5480505761278371
            },
            "question": "what play has the stage direction, \u201center a messenger, with two heads and a hand\u201d?",
            "rate_limited": false,
            "answers": [
                "oedipus rex",
                "titus andronicus",
                "agamemnon"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "oedipus rex": 0.3144803593550802,
                "agamemnon": 0.24808650435365515,
                "titus andronicus": 0.7895931591183605
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    30300.0,
                    13100.0,
                    568000.0
                ],
                "wikipedia_search": [
                    1.5585186947007896,
                    5.281702026448483,
                    0.1597792788507278
                ],
                "answer_relation_to_question": [
                    2.0973575557390585,
                    2.531929534819708,
                    2.370712909441233
                ],
                "question_related_to_answer": [
                    1.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    823.0,
                    1960.0,
                    2020.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    21.0,
                    1.0
                ],
                "word_count_raw": [
                    0.0,
                    25.0,
                    0.0
                ],
                "result_count": [
                    2.0,
                    50.0,
                    9.0
                ],
                "word_count_appended": [
                    3.0,
                    49.0,
                    28.0
                ]
            },
            "integer_answers": {
                "oedipus rex": 1,
                "agamemnon": 2,
                "titus andronicus": 6
            }
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Which of these actors was a high school cheerleader?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "michael douglas"
            ],
            "lines": [
                [
                    0.4338624338624338,
                    0,
                    0.12205882352941176,
                    0.19736842105263158,
                    0.13691376701966718,
                    0.36481481481481487,
                    0.45390070921985815,
                    0.0,
                    0,
                    -1.0
                ],
                [
                    0.291005291005291,
                    0,
                    0.7941176470588235,
                    0.7177033492822966,
                    0.7715582450832073,
                    0.10555555555555556,
                    0.2765957446808511,
                    1.0,
                    0,
                    -1.0
                ],
                [
                    0.2751322751322751,
                    0,
                    0.0838235294117647,
                    0.08492822966507177,
                    0.09152798789712557,
                    0.5296296296296297,
                    0.2695035460992908,
                    0.0,
                    0,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "john travolta": 0.1906493139764511,
                "george clooney": 0.2441312813569739,
                "michael douglas": 0.565219404666575
            },
            "question": "which of these actors was a high school cheerleader?",
            "rate_limited": false,
            "answers": [
                "george clooney",
                "michael douglas",
                "john travolta"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "john travolta": 0.1293001324021399,
                "george clooney": 0.45972835457349825,
                "michael douglas": 0.6877827298850057
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    330000.0,
                    1200000.0,
                    142000.0
                ],
                "wikipedia_search": [
                    1.0944444444444446,
                    0.31666666666666665,
                    1.588888888888889
                ],
                "answer_relation_to_question": [
                    1.3015873015873014,
                    0.873015873015873,
                    0.8253968253968254
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    181000.0,
                    1020000.0,
                    121000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    1.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_appended": [
                    64.0,
                    39.0,
                    38.0
                ],
                "result_count": [
                    166000.0,
                    1080000.0,
                    114000.0
                ]
            },
            "integer_answers": {
                "john travolta": 1,
                "george clooney": 2,
                "michael douglas": 4
            }
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Wrestling legend Ric Flair entered the ring to the same music used in what classic film?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "back to the future"
            ],
            "lines": [
                [
                    0.23353446823219068,
                    0,
                    0.21830985915492956,
                    0.19553072625698323,
                    0.19736842105263158,
                    0.732760827637417,
                    0.16129032258064516,
                    0,
                    0,
                    1.0
                ],
                [
                    0.5408843300682166,
                    0,
                    0.352112676056338,
                    0.33519553072625696,
                    0.4407894736842105,
                    0.0445646010268299,
                    0.3870967741935484,
                    0,
                    0,
                    1.0
                ],
                [
                    0.22558120169959273,
                    0,
                    0.4295774647887324,
                    0.4692737430167598,
                    0.3618421052631579,
                    0.22267457133575316,
                    0.45161290322580644,
                    0,
                    0,
                    1.0
                ]
            ],
            "fraction_answers": {
                "star wars: episode iv": 0.2897991041524662,
                "back to the future": 0.36009366488830036,
                "2001: a space odyssey": 0.3501072309592334
            },
            "question": "wrestling legend ric flair entered the ring to the same music used in what classic film?",
            "rate_limited": false,
            "answers": [
                "star wars: episode iv",
                "2001: a space odyssey",
                "back to the future"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "star wars: episode iv": 0.39617404375123716,
                "back to the future": 0.482274950557362,
                "2001: a space odyssey": 0.39230773328234453
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    35.0,
                    60.0,
                    84.0
                ],
                "wikipedia_search": [
                    5.129325793461918,
                    0.31195220718780925,
                    1.5587219993502717
                ],
                "answer_relation_to_question": [
                    1.401206809393144,
                    3.2453059804092996,
                    1.3534872101975564
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    30.0,
                    67.0,
                    55.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_appended": [
                    5.0,
                    12.0,
                    14.0
                ],
                "result_count": [
                    31.0,
                    50.0,
                    61.0
                ]
            },
            "integer_answers": {
                "star wars: episode iv": 1,
                "back to the future": 3,
                "2001: a space odyssey": 2
            }
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "The man famously known as the Science Guy holds a patent for which of these items?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "mechanical pencil"
            ],
            "lines": [
                [
                    0.28050682261208576,
                    0,
                    0.0054167394723047355,
                    0.012051868802440885,
                    0.0024067388688327317,
                    0.23822222222222225,
                    0.15476190476190477,
                    0,
                    0,
                    -1.0
                ],
                [
                    0.5710526315789474,
                    0,
                    0.9872444522103792,
                    0.9748283752860412,
                    0.9940877936483022,
                    0.7137777777777778,
                    0.5,
                    0,
                    0,
                    -1.0
                ],
                [
                    0.14844054580896685,
                    0,
                    0.007338808317316093,
                    0.013119755911517926,
                    0.0035054674828650656,
                    0.048,
                    0.34523809523809523,
                    0,
                    0,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "pulse rate monitor": 0.11556104945663186,
                "mechanical pencil": 0.7901651717502413,
                "ballet shoe": 0.09427377879312686
            },
            "question": "the man famously known as the science guy holds a patent for which of these items?",
            "rate_limited": false,
            "answers": [
                "pulse rate monitor",
                "mechanical pencil",
                "ballet shoe"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "pulse rate monitor": -0.03294221618047498,
                "mechanical pencil": 0.31945850038889456,
                "ballet shoe": 0.18121040699394747
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    79.0,
                    6390.0,
                    86.0
                ],
                "wikipedia_search": [
                    1.1911111111111112,
                    3.568888888888889,
                    0.24
                ],
                "answer_relation_to_question": [
                    1.6830409356725147,
                    3.426315789473684,
                    0.8906432748538011
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    46.0,
                    19000.0,
                    67.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_appended": [
                    13.0,
                    42.0,
                    29.0
                ],
                "result_count": [
                    62.0,
                    11300.0,
                    84.0
                ]
            },
            "integer_answers": {
                "pulse rate monitor": 0,
                "mechanical pencil": 6,
                "ballet shoe": 0
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "What advertising mascot wears epaulettes?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "cap'n crunch"
            ],
            "lines": [
                [
                    0.17305236270753513,
                    0.0,
                    0.0891089108910891,
                    0.08737864077669903,
                    0.08108108108108109,
                    0.08333333333333333,
                    0.15294117647058825,
                    0.0,
                    0.0,
                    1.0
                ],
                [
                    0.44061302681992337,
                    1.0,
                    0.594059405940594,
                    0.5825242718446602,
                    0.6216216216216216,
                    0.21794871794871795,
                    0.36470588235294116,
                    0.0,
                    0.0,
                    1.0
                ],
                [
                    0.38633461047254153,
                    0.0,
                    0.31683168316831684,
                    0.3300970873786408,
                    0.2972972972972973,
                    0.6987179487179488,
                    0.4823529411764706,
                    1.0,
                    1.0,
                    1.0
                ]
            ],
            "fraction_answers": {
                "sun-maid raisin girl": 0.07409950058448066,
                "cap'n crunch": 0.5012923964679128,
                "mr. peanut": 0.4246081029476065
            },
            "question": "what advertising mascot wears epaulettes?",
            "rate_limited": false,
            "answers": [
                "sun-maid raisin girl",
                "mr. peanut",
                "cap'n crunch"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "sun-maid raisin girl": 0.023709926552545967,
                "cap'n crunch": 0.8458093115450728,
                "mr. peanut": 0.28402594807290155
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    9.0,
                    60.0,
                    34.0
                ],
                "wikipedia_search": [
                    0.25,
                    0.6538461538461539,
                    2.0961538461538463
                ],
                "answer_relation_to_question": [
                    0.5191570881226054,
                    1.3218390804597702,
                    1.1590038314176245
                ],
                "question_related_to_answer": [
                    0.0,
                    1.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    9.0,
                    69.0,
                    33.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    7.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    3.0
                ],
                "result_count": [
                    9.0,
                    60.0,
                    32.0
                ],
                "word_count_appended": [
                    13.0,
                    31.0,
                    41.0
                ]
            },
            "integer_answers": {
                "sun-maid raisin girl": 0,
                "cap'n crunch": 4,
                "mr. peanut": 5
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which alum from \u201cThe Hills\u201d founded a wildly popular millennial skincare line?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "emily weiss"
            ],
            "lines": [
                [
                    0.4439934082856043,
                    0.5294117647058824,
                    0.10227272727272728,
                    0.22818791946308725,
                    0.21153846153846154,
                    0.3932291666666667,
                    0.21428571428571427,
                    0.5,
                    0,
                    -1.0
                ],
                [
                    0.2882266402683826,
                    0.29411764705882354,
                    0.6363636363636364,
                    0.5100671140939598,
                    0.4807692307692308,
                    0.5166495901639344,
                    0.5714285714285714,
                    0.0,
                    0,
                    -1.0
                ],
                [
                    0.26777995144601313,
                    0.17647058823529413,
                    0.26136363636363635,
                    0.26174496644295303,
                    0.3076923076923077,
                    0.0901212431693989,
                    0.21428571428571427,
                    0.5,
                    0,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "emily weiss": 0.327864895277268,
                "whitney port": 0.2599323009544147,
                "lauren conrad": 0.41220280376831736
            },
            "question": "which alum from \u201cthe hills\u201d founded a wildly popular millennial skincare line?",
            "rate_limited": false,
            "answers": [
                "emily weiss",
                "lauren conrad",
                "whitney port"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "emily weiss": 0.3954131045604065,
                "whitney port": 0.13001210333625615,
                "lauren conrad": 0.24688190994676637
            },
            "integer_answers": {
                "emily weiss": 3,
                "whitney port": 0,
                "lauren conrad": 5
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    34.0,
                    76.0,
                    39.0
                ],
                "wikipedia_search": [
                    1.5729166666666667,
                    2.0665983606557377,
                    0.3604849726775956
                ],
                "answer_relation_to_question": [
                    3.10795385799923,
                    2.017586481878678,
                    1.874459660122092
                ],
                "question_related_to_answer": [
                    1.0588235294117647,
                    0.5882352941176471,
                    0.35294117647058826
                ],
                "result_count_noun_chunks": [
                    33.0,
                    75.0,
                    48.0
                ],
                "word_count_noun_chunks": [
                    1.0,
                    0.0,
                    1.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_appended": [
                    9.0,
                    24.0,
                    9.0
                ],
                "result_count": [
                    9.0,
                    56.0,
                    23.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which color is NOT represented in the original electronic Simon game?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "orange"
            ],
            "lines": [
                [
                    0.2772686832740213,
                    0.2698412698412699,
                    0.3234244946492271,
                    0.3260095011876485,
                    0.32136824324324326,
                    0.3572197484054904,
                    0.3125,
                    0.25,
                    0.14285714285714285,
                    -1.0
                ],
                [
                    0.4104537366548043,
                    0.47619047619047616,
                    0.34780023781212843,
                    0.34679334916864607,
                    0.35050675675675674,
                    0.4315209564118391,
                    0.35042134831460675,
                    0.5,
                    0.5,
                    -1.0
                ],
                [
                    0.3122775800711744,
                    0.25396825396825395,
                    0.3287752675386445,
                    0.3271971496437055,
                    0.328125,
                    0.21125929518267056,
                    0.33707865168539325,
                    0.25,
                    0.35714285714285715,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "blue": 0.4265579814537681,
                "orange": 0.17473625304238719,
                "green": 0.3987057655038446
            },
            "question": "which color is not represented in the original electronic simon game?",
            "rate_limited": false,
            "answers": [
                "blue",
                "orange",
                "green"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "blue": 0.08174050240823144,
                "orange": 0.3218975514717602,
                "green": 0.3149795321171053
            },
            "negative_question": true,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    2930000.0,
                    2580000.0,
                    2910000.0
                ],
                "wikipedia_search": [
                    1.1422420127560768,
                    0.5478323487052876,
                    2.3099256385386355
                ],
                "answer_relation_to_question": [
                    2.2273131672597866,
                    0.8954626334519573,
                    1.8772241992882561
                ],
                "question_related_to_answer": [
                    0.9206349206349206,
                    0.09523809523809523,
                    0.9841269841269842
                ],
                "result_count_noun_chunks": [
                    8460000.0,
                    7080000.0,
                    8140000.0
                ],
                "word_count_noun_chunks": [
                    5.0,
                    0.0,
                    5.0
                ],
                "word_count_raw": [
                    5.0,
                    0.0,
                    2.0
                ],
                "word_count_appended": [
                    267.0,
                    213.0,
                    232.0
                ],
                "result_count": [
                    2970000.0,
                    2560000.0,
                    2880000.0
                ]
            },
            "integer_answers": {
                "blue": 7,
                "orange": 0,
                "green": 2
            }
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "What car brand is sung about by Will Smith, Charli XCX and Janis Joplin?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "porsche"
            ],
            "lines": [
                [
                    0.5681637875879718,
                    0.16666666666666666,
                    0.38451339167329623,
                    0.33850814085573644,
                    0.3819444444444444,
                    0.0045045045045045045,
                    0.28870292887029286,
                    0.0,
                    0,
                    1.0
                ],
                [
                    0.2240818937939859,
                    0.1,
                    0.38451339167329623,
                    0.36993563044301403,
                    0.3872863247863248,
                    0.5995995995995996,
                    0.2928870292887029,
                    0.1111111111111111,
                    0,
                    1.0
                ],
                [
                    0.20775431861804225,
                    0.7333333333333334,
                    0.2309732166534076,
                    0.29155622870124953,
                    0.23076923076923078,
                    0.3958958958958959,
                    0.41841004184100417,
                    0.8888888888888888,
                    0,
                    1.0
                ]
            ],
            "fraction_answers": {
                "porsche": 0.4246976443376316,
                "rolls-royce": 0.26662548307536416,
                "mercedes-benz": 0.3086768725870043
            },
            "question": "what car brand is sung about by will smith, charli xcx and janis joplin?",
            "rate_limited": false,
            "answers": [
                "rolls-royce",
                "mercedes-benz",
                "porsche"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "porsche": 0.5578316826252063,
                "rolls-royce": 0.3700221281293052,
                "mercedes-benz": 0.20462856844151675
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    8940.0,
                    9770.0,
                    7700.0
                ],
                "wikipedia_search": [
                    0.018018018018018018,
                    2.3983983983983985,
                    1.5835835835835836
                ],
                "answer_relation_to_question": [
                    1.7044913627639156,
                    0.6722456813819577,
                    0.6232629558541267
                ],
                "question_related_to_answer": [
                    0.3333333333333333,
                    0.2,
                    1.4666666666666668
                ],
                "result_count_noun_chunks": [
                    14300.0,
                    14500.0,
                    8640.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    2.0,
                    16.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_appended": [
                    69.0,
                    70.0,
                    100.0
                ],
                "result_count": [
                    14500.0,
                    14500.0,
                    8710.0
                ]
            },
            "integer_answers": {
                "porsche": 3,
                "rolls-royce": 2,
                "mercedes-benz": 3
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which person is most likely to use a Reuleaux triangle at work?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "banksy"
            ],
            "lines": [
                [
                    0.3248865278541044,
                    0,
                    0.06666666666666667,
                    0.0738255033557047,
                    0.09523809523809523,
                    0.02611754966887417,
                    0.06349206349206349,
                    0,
                    0,
                    -1.0
                ],
                [
                    0.18266471270684498,
                    0,
                    0.37333333333333335,
                    0.348993288590604,
                    0.3869047619047619,
                    0.15378565970453387,
                    0.06349206349206349,
                    0,
                    0,
                    -1.0
                ],
                [
                    0.4924487594390507,
                    0,
                    0.56,
                    0.5771812080536913,
                    0.5178571428571429,
                    0.820096790626592,
                    0.873015873015873,
                    0,
                    0,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "banksy": 0.6400999623320582,
                "adam levine": 0.25152896995535695,
                "greta gerwig": 0.10837106771258474
            },
            "question": "which person is most likely to use a reuleaux triangle at work?",
            "rate_limited": false,
            "answers": [
                "greta gerwig",
                "adam levine",
                "banksy"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "banksy": 0.36706575951900866,
                "adam levine": 0.18431236916145102,
                "greta gerwig": 0.05356267474457463
            },
            "integer_answers": {
                "banksy": 6,
                "adam levine": 0,
                "greta gerwig": 0
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    11.0,
                    52.0,
                    86.0
                ],
                "wikipedia_search": [
                    0.07835264900662252,
                    0.46135697911360163,
                    2.460290371879776
                ],
                "answer_relation_to_question": [
                    1.2995461114164173,
                    0.7306588508273798,
                    1.9697950377562026
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    16.0,
                    65.0,
                    87.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_appended": [
                    4.0,
                    4.0,
                    55.0
                ],
                "result_count": [
                    10.0,
                    56.0,
                    84.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Which of these songs was written by the man nicknamed \u201cSlowhand\u201d?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "lay down sally"
            ],
            "lines": [
                [
                    0.40758113590263695,
                    0,
                    0.9992889674654573,
                    0.9992931828706525,
                    0.6094570928196147,
                    0.2256383712905452,
                    0.7105263157894737,
                    0,
                    1.0,
                    -1.0
                ],
                [
                    0.39038474121572986,
                    0,
                    0.00041316755385591023,
                    0.0003899680713641571,
                    0.2031523642732049,
                    0.6922015182884748,
                    0.18421052631578946,
                    0,
                    0.0,
                    -1.0
                ],
                [
                    0.2020341228816332,
                    0,
                    0.000297864980686819,
                    0.0003168490579833776,
                    0.18739054290718038,
                    0.08216011042097998,
                    0.10526315789473684,
                    0,
                    0.0,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "lay down sally": 0.7073978665911972,
                "lover lay down": 0.08249466402045723,
                "lay lady lay": 0.2101074693883456
            },
            "question": "which of these songs was written by the man nicknamed \u201cslowhand\u201d?",
            "rate_limited": false,
            "answers": [
                "lay down sally",
                "lay lady lay",
                "lover lay down"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "lay down sally": 0.27445008086721523,
                "lover lay down": 0.057495577368836655,
                "lay lady lay": 0.1973856680992111
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    123000.0,
                    48.0,
                    39.0
                ],
                "wikipedia_search": [
                    0.6769151138716356,
                    2.0766045548654244,
                    0.24648033126293994
                ],
                "answer_relation_to_question": [
                    1.6303245436105478,
                    1.5615389648629194,
                    0.8081364915265328
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    348000.0,
                    116000.0,
                    107000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    3.0,
                    0.0,
                    0.0
                ],
                "result_count": [
                    104000.0,
                    43.0,
                    31.0
                ],
                "word_count_appended": [
                    54.0,
                    14.0,
                    8.0
                ]
            },
            "integer_answers": {
                "lay down sally": 6,
                "lover lay down": 0,
                "lay lady lay": 1
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which of these quantities is the largest?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "dozen"
            ],
            "lines": [
                [
                    1.0,
                    0,
                    0.6233845741122573,
                    0.9195973277345323,
                    0.6479866557369234,
                    0,
                    0.762,
                    0,
                    0,
                    -1.0
                ],
                [
                    0.0,
                    0,
                    5.1590447512738545e-06,
                    1.1811341824113259e-06,
                    1.1049711547280057e-06,
                    0,
                    0.01,
                    0,
                    0,
                    -1.0
                ],
                [
                    0.0,
                    0,
                    0.37661026684299137,
                    0.08040149113128525,
                    0.3520122392919219,
                    0,
                    0.228,
                    0,
                    0,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "two half-dozens": 0.0020014890300176823,
                "baker's dozen": 0.2074047994532397,
                "dozen": 0.7905937115167426
            },
            "question": "which of these quantities is the largest?",
            "rate_limited": false,
            "answers": [
                "dozen",
                "two half-dozens",
                "baker's dozen"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "two half-dozens": 0.04263767858701587,
                "baker's dozen": 0.15864861954569776,
                "dozen": 0.38588895803027023
            },
            "integer_answers": {
                "two half-dozens": 0,
                "baker's dozen": 0,
                "dozen": 5
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    10900000.0,
                    14.0,
                    953000.0
                ],
                "wikipedia_search": [
                    0.0,
                    0.0,
                    0.0
                ],
                "answer_relation_to_question": [
                    2.0,
                    0.0,
                    0.0
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    8210000.0,
                    14.0,
                    4460000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count": [
                    1450000.0,
                    12.0,
                    876000.0
                ],
                "word_count_appended": [
                    381.0,
                    5.0,
                    114.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "The actor who played Don Draper provides the voice for what car company\u2019s ads?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "mercedes-benz"
            ],
            "lines": [
                [
                    0.34437070738479836,
                    0.29411764705882354,
                    0.16610850636302746,
                    0.14613180515759314,
                    0.13280610853558766,
                    0.626183970856102,
                    0.3401360544217687,
                    0.5142857142857142,
                    0.7,
                    1.0
                ],
                [
                    0.31626186293817177,
                    0.6764705882352942,
                    0.3750837240455459,
                    0.4713467048710602,
                    0.4949550040905372,
                    0.3315033014571949,
                    0.30612244897959184,
                    0.08571428571428572,
                    0.3,
                    1.0
                ],
                [
                    0.3393674296770299,
                    0.029411764705882353,
                    0.45880776959142666,
                    0.3825214899713467,
                    0.3722388873738751,
                    0.0423127276867031,
                    0.35374149659863946,
                    0.4,
                    0.0,
                    1.0
                ]
            ],
            "fraction_answers": {
                "jaguar": 0.26426684062276695,
                "bmw": 0.3730508800368535,
                "mercedes-benz": 0.36268227934037944
            },
            "question": "the actor who played don draper provides the voice for what car company\u2019s ads?",
            "rate_limited": false,
            "answers": [
                "mercedes-benz",
                "bmw",
                "jaguar"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "jaguar": 0.14666478419438997,
                "bmw": 0.24656007621426154,
                "mercedes-benz": 0.41886136448089295
            },
            "integer_answers": {
                "jaguar": 2,
                "bmw": 3,
                "mercedes-benz": 4
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    1020000.0,
                    3290000.0,
                    2670000.0
                ],
                "wikipedia_search": [
                    3.7571038251366122,
                    1.9890198087431696,
                    0.2538763661202186
                ],
                "answer_relation_to_question": [
                    2.06622424430879,
                    1.8975711776290307,
                    2.036204578062179
                ],
                "question_related_to_answer": [
                    0.5882352941176471,
                    1.3529411764705883,
                    0.058823529411764705
                ],
                "result_count_noun_chunks": [
                    974000.0,
                    3630000.0,
                    2730000.0
                ],
                "word_count_noun_chunks": [
                    18.0,
                    3.0,
                    14.0
                ],
                "word_count_raw": [
                    7.0,
                    3.0,
                    0.0
                ],
                "word_count_appended": [
                    200.0,
                    180.0,
                    208.0
                ],
                "result_count": [
                    992000.0,
                    2240000.0,
                    2740000.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which of these substances expands when it freezes?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "dihydrogen monoxide"
            ],
            "lines": [
                [
                    0.3333333333333333,
                    0,
                    0.23549480326371644,
                    0.4315352697095436,
                    0.41284066700947625,
                    0.0,
                    0.2894736842105263,
                    0,
                    0,
                    2.0
                ],
                [
                    0.0,
                    0,
                    0.7623389464626719,
                    0.5408022130013831,
                    0.5428634393594358,
                    1.0,
                    0.37593984962406013,
                    0,
                    0,
                    2.0
                ],
                [
                    0.6666666666666666,
                    0,
                    0.0021662502736117507,
                    0.027662517289073305,
                    0.04429589363108793,
                    0.0,
                    0.33458646616541354,
                    0,
                    0,
                    2.0
                ]
            ],
            "fraction_answers": {
                "sodium chloride": 0.28377962625443265,
                "carbon dioxide": 0.5369907414079252,
                "dihydrogen monoxide": 0.1792296323376422
            },
            "question": "which of these substances expands when it freezes?",
            "rate_limited": false,
            "answers": [
                "sodium chloride",
                "carbon dioxide",
                "dihydrogen monoxide"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "sodium chloride": 0.1449772909261016,
                "carbon dioxide": 0.26547685598092663,
                "dihydrogen monoxide": 0.34348293843811994
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 2
            },
            "data": {
                "result_count_important_words": [
                    312000.0,
                    391000.0,
                    20000.0
                ],
                "wikipedia_search": [
                    0.0,
                    1.0,
                    0.0
                ],
                "answer_relation_to_question": [
                    0.3333333333333333,
                    0.0,
                    0.6666666666666666
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    5620000.0,
                    7390000.0,
                    603000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_appended": [
                    77.0,
                    100.0,
                    89.0
                ],
                "result_count": [
                    312000.0,
                    1010000.0,
                    2870.0
                ]
            },
            "integer_answers": {
                "sodium chloride": 0,
                "carbon dioxide": 5,
                "dihydrogen monoxide": 1
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which U.S. president's wife was NOT born in North America?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "rutherford b. hayes"
            ],
            "lines": [
                [
                    0.2879362253031793,
                    0.0,
                    0.1718249733191035,
                    0.17509920634920634,
                    0.17532467532467533,
                    0.34878386668759187,
                    0.3203517587939699,
                    0.0,
                    0.0,
                    -1.0
                ],
                [
                    0.3374047170102592,
                    0.5,
                    0.42702774813233724,
                    0.4254712301587302,
                    0.42364117364117365,
                    0.39652199759360457,
                    0.3718592964824121,
                    0.5,
                    0.5,
                    -1.0
                ],
                [
                    0.3746590576865615,
                    0.5,
                    0.40114727854855925,
                    0.3994295634920635,
                    0.401034151034151,
                    0.25469413571880367,
                    0.3077889447236181,
                    0.5,
                    0.5,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "martin van buren": 0.19138819306583177,
                "john quincy adams": 0.6712620653827275,
                "rutherford b. hayes": 0.13734974155144072
            },
            "question": "which u.s. president's wife was not born in north america?",
            "rate_limited": false,
            "answers": [
                "john quincy adams",
                "rutherford b. hayes",
                "martin van buren"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "martin van buren": 0.20192091572393622,
                "john quincy adams": 0.15985372078405508,
                "rutherford b. hayes": 0.23587463818014778
            },
            "negative_question": true,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    262000.0,
                    60100.0,
                    81100.0
                ],
                "wikipedia_search": [
                    1.5121613331240817,
                    1.034780024063955,
                    2.4530586428119636
                ],
                "answer_relation_to_question": [
                    2.544765296361849,
                    1.9511433958768896,
                    1.5040913077612617
                ],
                "question_related_to_answer": [
                    1.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    270000.0,
                    63500.0,
                    82300.0
                ],
                "word_count_noun_chunks": [
                    5.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    6.0,
                    0.0,
                    0.0
                ],
                "result_count": [
                    246000.0,
                    54700.0,
                    74100.0
                ],
                "word_count_appended": [
                    143.0,
                    102.0,
                    153.0
                ]
            },
            "integer_answers": {
                "martin van buren": 2,
                "john quincy adams": 7,
                "rutherford b. hayes": 0
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Who was the president of the Screen Actors Guild before its merger with AFTRA?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "ken howard"
            ],
            "lines": [
                [
                    0.4382814143996358,
                    0,
                    0.00297359805364491,
                    0.2362076011442583,
                    0.1422213230831479,
                    0.3790243902439025,
                    0.335149863760218,
                    0.21212121212121213,
                    0.16666666666666666,
                    0.0
                ],
                [
                    0.07322710361156,
                    0,
                    0.0028234163337638543,
                    0.04863097670617082,
                    0.3843819542787781,
                    0.10941734417344173,
                    0.2098092643051771,
                    0.0,
                    0.07142857142857142,
                    0.0
                ],
                [
                    0.4884914819888042,
                    0,
                    0.9942029856125912,
                    0.7151614221495709,
                    0.47339672263807403,
                    0.5115582655826558,
                    0.4550408719346049,
                    0.7878787878787878,
                    0.7619047619047619,
                    0.0
                ]
            ],
            "fraction_answers": {
                "gabrielle carteris": 0.23908075868408576,
                "ken howard": 0.6484544124612314,
                "melissa gilbert": 0.11246482885468287
            },
            "question": "who was the president of the screen actors guild before its merger with aftra?",
            "rate_limited": false,
            "answers": [
                "gabrielle carteris",
                "melissa gilbert",
                "ken howard"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "gabrielle carteris": 0.5156175438791175,
                "ken howard": 0.762211865418733,
                "melissa gilbert": 0.020762146140049426
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 0
            },
            "data": {
                "result_count_important_words": [
                    5780.0,
                    1190.0,
                    17500.0
                ],
                "wikipedia_search": [
                    2.274146341463415,
                    0.6565040650406504,
                    3.069349593495935
                ],
                "answer_relation_to_question": [
                    2.6296884863978147,
                    0.43936262166936,
                    2.9309488919328253
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    7030.0,
                    19000.0,
                    23400.0
                ],
                "word_count_noun_chunks": [
                    7.0,
                    0.0,
                    26.0
                ],
                "word_count_raw": [
                    7.0,
                    3.0,
                    32.0
                ],
                "word_count_appended": [
                    123.0,
                    77.0,
                    167.0
                ],
                "result_count": [
                    99.0,
                    94.0,
                    33100.0
                ]
            },
            "integer_answers": {
                "gabrielle carteris": 0,
                "ken howard": 8,
                "melissa gilbert": 0
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Jean Valjean, the protagonist of \u201cLes Mis\u00e9rables,\u201d is identified by what prisoner number?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "24601"
            ],
            "lines": [
                [
                    0.003703703703703704,
                    0.3333333333333333,
                    0.004243551712001609,
                    0.03425414364640884,
                    0.0026620918125887364,
                    0.07152317880794704,
                    0.21122994652406418,
                    0.0,
                    0.0,
                    1.0
                ],
                [
                    0.7999999999999999,
                    0.6666666666666666,
                    0.9955251646638845,
                    0.9613259668508287,
                    0.9968054898248935,
                    0.8211920529801325,
                    0.6470588235294118,
                    1.0,
                    1.0,
                    1.0
                ],
                [
                    0.1962962962962963,
                    0.0,
                    0.00023128362411383176,
                    0.004419889502762431,
                    0.0005324183625177473,
                    0.10728476821192054,
                    0.14171122994652408,
                    0.0,
                    0.0,
                    1.0
                ]
            ],
            "fraction_answers": {
                "y2k": 0.07343888328222747,
                "24601": 0.8765082405017575,
                "867-5309": 0.050052876216014994
            },
            "question": "jean valjean, the protagonist of \u201cles mis\u00e9rables,\u201d is identified by what prisoner number?",
            "rate_limited": false,
            "answers": [
                "y2k",
                "24601",
                "867-5309"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "y2k": 0.24765291777933804,
                "24601": 0.8495853036087938,
                "867-5309": 0.12920167442983518
            },
            "integer_answers": {
                "y2k": 0,
                "24601": 9,
                "867-5309": 0
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    93.0,
                    2610.0,
                    12.0
                ],
                "wikipedia_search": [
                    0.3576158940397351,
                    4.105960264900662,
                    0.5364238410596026
                ],
                "answer_relation_to_question": [
                    0.022222222222222223,
                    4.8,
                    1.1777777777777778
                ],
                "question_related_to_answer": [
                    1.0,
                    2.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    90.0,
                    33700.0,
                    18.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    31.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    17.0,
                    0.0
                ],
                "word_count_appended": [
                    79.0,
                    242.0,
                    53.0
                ],
                "result_count": [
                    844.0,
                    198000.0,
                    46.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "What is the grammatically correct way to announce people have arrived?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "there here"
            ],
            "lines": [
                [
                    0.3301282051282051,
                    0,
                    0.04230463216316392,
                    0.053326785775943096,
                    0.8633327903567356,
                    0.0,
                    0.5833333333333334,
                    0,
                    0,
                    1.0
                ],
                [
                    0.42692307692307696,
                    0,
                    0.9547650928567271,
                    0.9437690144519426,
                    0.09692132269099202,
                    0.5,
                    0.10416666666666667,
                    0,
                    0,
                    1.0
                ],
                [
                    0.24294871794871792,
                    0,
                    0.0029302749801090604,
                    0.002904199772114311,
                    0.03974588695227236,
                    0.5,
                    0.3125,
                    0,
                    0,
                    1.0
                ]
            ],
            "fraction_answers": {
                "their here": 0.18350484660886893,
                "there here": 0.5044241955982343,
                "they're here": 0.3120709577928969
            },
            "question": "what is the grammatically correct way to announce people have arrived?",
            "rate_limited": false,
            "answers": [
                "they're here",
                "there here",
                "their here"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "their here": 0.306445403313073,
                "there here": 0.31426554385522765,
                "they're here": 0.2928181533989288
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    139000.0,
                    2460000.0,
                    7570.0
                ],
                "wikipedia_search": [
                    0.0,
                    2.0,
                    2.0
                ],
                "answer_relation_to_question": [
                    1.3205128205128205,
                    1.7076923076923078,
                    0.9717948717948717
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    2120000.0,
                    238000.0,
                    97600.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count": [
                    109000.0,
                    2460000.0,
                    7550.0
                ],
                "word_count_appended": [
                    28.0,
                    5.0,
                    15.0
                ]
            },
            "integer_answers": {
                "their here": 0,
                "there here": 4,
                "they're here": 2
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which of these is NOT a Slavic language?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "hungarian"
            ],
            "lines": [
                [
                    0.33048128342245986,
                    0.14583333333333331,
                    0.46011038635223284,
                    0.46759358288770053,
                    0.39486072969792074,
                    0.1857976653696498,
                    0.32418952618453867,
                    0.14583333333333331,
                    0.16666666666666669,
                    -1.0
                ],
                [
                    0.26844919786096255,
                    0.35416666666666663,
                    0.41169091821374815,
                    0.11925133689839573,
                    0.2783444488034523,
                    0.43093385214007784,
                    0.3482959268495428,
                    0.35416666666666663,
                    0.33333333333333337,
                    -1.0
                ],
                [
                    0.40106951871657753,
                    0.5,
                    0.12819869543401907,
                    0.41315508021390374,
                    0.32679482149862693,
                    0.38326848249027234,
                    0.32751454696591853,
                    0.5,
                    0.5,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "bulgarian": 0.4174741095004809,
                "hungarian": 0.2266664121512626,
                "serbian": 0.3558594783482565
            },
            "question": "which of these is not a slavic language?",
            "rate_limited": false,
            "answers": [
                "bulgarian",
                "serbian",
                "hungarian"
            ],
            "ml_answers": {
                "bulgarian": 0.05908179865171631,
                "hungarian": 0.6671287971032448,
                "serbian": 0.2542927001506167
            },
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "integer_answers": {
                "bulgarian": 5,
                "hungarian": 1,
                "serbian": 3
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    303000.0,
                    3560000.0,
                    812000.0
                ],
                "wikipedia_search": [
                    1.2568093385214008,
                    0.27626459143968873,
                    0.4669260700389105
                ],
                "answer_relation_to_question": [
                    0.6780748663101605,
                    0.9262032085561498,
                    0.39572192513368987
                ],
                "question_related_to_answer": [
                    0.7083333333333334,
                    0.2916666666666667,
                    0.0
                ],
                "result_count_noun_chunks": [
                    536000.0,
                    1130000.0,
                    883000.0
                ],
                "word_count_noun_chunks": [
                    17.0,
                    7.0,
                    0.0
                ],
                "word_count_raw": [
                    22.0,
                    11.0,
                    0.0
                ],
                "result_count": [
                    795000.0,
                    1760000.0,
                    7410000.0
                ],
                "word_count_appended": [
                    423.0,
                    365.0,
                    415.0
                ]
            },
            "negative_question": true
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Basketball is NOT a major theme of which of these 90s movies?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "eddie"
            ],
            "lines": [
                [
                    0.3153100420706054,
                    0,
                    0.47970772774203796,
                    0.47071858182969295,
                    0.47970772774203796,
                    0.28125,
                    0.389030612244898,
                    0.0,
                    0.0,
                    -1.0
                ],
                [
                    0.1976861167002012,
                    0,
                    0.45711222301644033,
                    0.3616650838873061,
                    0.45711222301644033,
                    0.28125,
                    0.423469387755102,
                    0.5,
                    0.5,
                    -1.0
                ],
                [
                    0.4870038412291933,
                    0,
                    0.06318004924152171,
                    0.16761633428300093,
                    0.06318004924152171,
                    0.4375,
                    0.1875,
                    0.5,
                    0.5,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "white men can't jump": 0.39606882709268193,
                "point break": 0.2054262414061275,
                "eddie": 0.3985049315011906
            },
            "question": "basketball is not a major theme of which of these 90s movies?",
            "rate_limited": false,
            "answers": [
                "white men can't jump",
                "point break",
                "eddie"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "white men can't jump": 0.22005925793271844,
                "point break": 0.28804555674340987,
                "eddie": 0.44253296665959263
            },
            "negative_question": true,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    92500.0,
                    437000.0,
                    1050000.0
                ],
                "wikipedia_search": [
                    1.75,
                    1.75,
                    0.5
                ],
                "answer_relation_to_question": [
                    1.8468995792939455,
                    3.023138832997988,
                    0.1299615877080666
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    51100.0,
                    108000.0,
                    1100000.0
                ],
                "word_count_noun_chunks": [
                    1.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    1.0,
                    0.0,
                    0.0
                ],
                "result_count": [
                    51100.0,
                    108000.0,
                    1100000.0
                ],
                "word_count_appended": [
                    87.0,
                    60.0,
                    245.0
                ]
            },
            "integer_answers": {
                "white men can't jump": 3,
                "point break": 1,
                "eddie": 4
            }
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "What generation of the iPod was the first to offer video?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "u2 special edition"
            ],
            "lines": [
                [
                    0.23139922555352035,
                    1.0,
                    0.5032822757111597,
                    0.4056603773584906,
                    0.42430086788813887,
                    0.5,
                    0.25,
                    0.0,
                    0.0,
                    1.0
                ],
                [
                    0.5104017004801369,
                    0.0,
                    0.24070021881838075,
                    0.16123499142367068,
                    0.3153326904532305,
                    0.5,
                    0.5111111111111111,
                    1.0,
                    1.0,
                    1.0
                ],
                [
                    0.2581990739663428,
                    0.0,
                    0.25601750547045954,
                    0.43310463121783876,
                    0.26036644165863065,
                    0.0,
                    0.2388888888888889,
                    0.0,
                    0.0,
                    1.0
                ]
            ],
            "fraction_answers": {
                "third generation": 0.36829363850125657,
                "u2 special edition": 0.4709756346985033,
                "fifth generation": 0.1607307268002401
            },
            "question": "what generation of the ipod was the first to offer video?",
            "rate_limited": false,
            "answers": [
                "third generation",
                "u2 special edition",
                "fifth generation"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "third generation": 0.19782196968824578,
                "u2 special edition": 0.8458093115450728,
                "fifth generation": 0.2209778977877666
            },
            "integer_answers": {
                "third generation": 4,
                "u2 special edition": 4,
                "fifth generation": 1
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    946000.0,
                    376000.0,
                    1010000.0
                ],
                "wikipedia_search": [
                    1.5,
                    1.5,
                    0.0
                ],
                "answer_relation_to_question": [
                    0.9255969022140814,
                    2.0416068019205476,
                    1.0327962958653711
                ],
                "question_related_to_answer": [
                    1.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    440000.0,
                    327000.0,
                    270000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    2.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    2.0,
                    0.0
                ],
                "result_count": [
                    230000.0,
                    110000.0,
                    117000.0
                ],
                "word_count_appended": [
                    45.0,
                    92.0,
                    43.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which of these actresses is NOT mentioned in Madonna\u2019s song \u201cVogue\u201d?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "audrey hepburn"
            ],
            "lines": [
                [
                    0.3202777777777778,
                    0,
                    2.8491023489451983e-05,
                    0.34423751243684975,
                    0.43136439267886856,
                    0.5000000000000001,
                    0.3230088495575221,
                    0.5,
                    0.25,
                    -1.0
                ],
                [
                    0.3036111111111111,
                    0,
                    0.4999873168992208,
                    0.4998889135747612,
                    0.09650582362728788,
                    0.14871794871794872,
                    0.3805309734513274,
                    0.5,
                    0.5,
                    -1.0
                ],
                [
                    0.3761111111111111,
                    0,
                    0.4999841920772897,
                    0.15587357398838908,
                    0.4721297836938436,
                    0.3512820512820513,
                    0.29646017699115046,
                    0.0,
                    0.25,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "jean harlow": 0.3327707441313731,
                "audrey hepburn": 0.2676894781545857,
                "rita hayworth": 0.39953977771404126
            },
            "question": "which of these actresses is not mentioned in madonna\u2019s song \u201cvogue\u201d?",
            "rate_limited": false,
            "answers": [
                "jean harlow",
                "audrey hepburn",
                "rita hayworth"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "integer_answers": {
                "jean harlow": 2,
                "audrey hepburn": 3,
                "rita hayworth": 3
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    129000.0,
                    92.0,
                    285000.0
                ],
                "wikipedia_search": [
                    0.0,
                    2.1076923076923078,
                    0.8923076923076922
                ],
                "answer_relation_to_question": [
                    1.0783333333333331,
                    1.1783333333333332,
                    0.7433333333333333
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    330000.0,
                    1940000.0,
                    134000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    1.0
                ],
                "word_count_raw": [
                    1.0,
                    0.0,
                    1.0
                ],
                "word_count_appended": [
                    40.0,
                    27.0,
                    46.0
                ],
                "result_count": [
                    2720000.0,
                    69.0,
                    86.0
                ]
            },
            "ml_answers": {
                "jean harlow": 0.24802816106436743,
                "audrey hepburn": 0.3254923240052805,
                "rita hayworth": 0.040498744679735785
            }
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Which of these is NOT a step in the famous Korean 10-step skin care regime?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "spelunking"
            ],
            "lines": [
                [
                    0.3056199921119276,
                    0.10869565217391303,
                    0.19799101242400213,
                    0.0487615239364656,
                    0.1659240436553756,
                    0.4184626436781609,
                    0.2820284697508897,
                    0.11363636363636365,
                    0.07692307692307693,
                    -1.0
                ],
                [
                    0.20889899115705568,
                    0.391304347826087,
                    0.30604017975152,
                    0.4529323558813729,
                    0.3350499965548417,
                    0.3315373563218391,
                    0.33362989323843417,
                    0.38636363636363635,
                    0.4230769230769231,
                    -1.0
                ],
                [
                    0.48548101673101673,
                    0.5,
                    0.49596880782447794,
                    0.4983061201821615,
                    0.4990259597897827,
                    0.25,
                    0.38434163701067614,
                    0.5,
                    0.5,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "moisturizing": 0.29581473773961997,
                "spelunking": 0.08597254632486333,
                "cleansing": 0.6182127159355165
            },
            "question": "which of these is not a step in the famous korean 10-step skin care regime?",
            "rate_limited": false,
            "answers": [
                "cleansing",
                "moisturizing",
                "spelunking"
            ],
            "ml_answers": {
                "moisturizing": 0.19424912212594717,
                "spelunking": 0.5731085165346053,
                "cleansing": 0.09873160289029585
            },
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "integer_answers": {
                "moisturizing": 1,
                "spelunking": 1,
                "cleansing": 7
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    3250000.0,
                    339000.0,
                    12200.0
                ],
                "wikipedia_search": [
                    0.6522988505747127,
                    1.3477011494252873,
                    2.0
                ],
                "answer_relation_to_question": [
                    1.5550400631045793,
                    2.3288080707435546,
                    0.11615186615186615
                ],
                "question_related_to_answer": [
                    0.782608695652174,
                    0.21739130434782608,
                    0.0
                ],
                "result_count_noun_chunks": [
                    3200000.0,
                    1580000.0,
                    9330.0
                ],
                "word_count_noun_chunks": [
                    17.0,
                    5.0,
                    0.0
                ],
                "word_count_raw": [
                    22.0,
                    4.0,
                    0.0
                ],
                "result_count": [
                    914000.0,
                    587000.0,
                    12200.0
                ],
                "word_count_appended": [
                    245.0,
                    187.0,
                    130.0
                ]
            },
            "negative_question": true
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Napa cabbage is named after what?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "city in california"
            ],
            "question": "napa cabbage is named after what?",
            "answers": [
                "city in california",
                "scientist edward napa",
                "japanese for \u201cvegetable\u201d"
            ],
            "integer_answers": {
                "city in california": 2,
                "scientist edward napa": 3,
                "japanese for \u201cvegetable\u201d": 1
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    52.0,
                    2310000.0,
                    22.0
                ],
                "wikipedia_search": [
                    0.0,
                    0.0,
                    1.0
                ],
                "answer_relation_to_question": [
                    1.0,
                    0.0,
                    1.0
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    27.0,
                    98.0,
                    20.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_appended": [
                    27.0,
                    7.0,
                    0.0
                ],
                "result_count": [
                    47.0,
                    134000.0,
                    13.0
                ]
            },
            "negative_question": false,
            "fraction_answers": {
                "city in california": 0.24678294050005567,
                "scientist edward napa": 0.4802108045845283,
                "japanese for \u201cvegetable\u201d": 0.2730062549154161
            },
            "lines": [
                [
                    0.5,
                    0,
                    0.0003505892883783381,
                    2.2510101408006842e-05,
                    0.18620689655172415,
                    0.0,
                    0.7941176470588235,
                    0,
                    0,
                    1.0
                ],
                [
                    0.0,
                    0,
                    0.9995524392063255,
                    0.9999679663941502,
                    0.6758620689655173,
                    0.0,
                    0.20588235294117646,
                    0,
                    0,
                    1.0
                ],
                [
                    0.5,
                    0,
                    9.697150529613606e-05,
                    9.523504441849049e-06,
                    0.13793103448275862,
                    1.0,
                    0.0,
                    0,
                    0,
                    1.0
                ]
            ],
            "rate_limited": false,
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "city in california": 0.44240863974129724,
                "scientist edward napa": 0.09652112460728125,
                "japanese for \u201cvegetable\u201d": 0.41602334698808935
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Lonnie Lynn's only Academy Award win was in what category?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "best original song"
            ],
            "lines": [
                [
                    0.33493642287437353,
                    0.0,
                    0.04962406015037594,
                    0.060267248431960734,
                    0.05141129032258065,
                    0.3178261827799001,
                    0.2695035460992908,
                    0.0,
                    0.0,
                    1.0
                ],
                [
                    0.32059623038347523,
                    0.0,
                    0.0443609022556391,
                    0.053449686392146166,
                    0.04536290322580645,
                    0.25884373731861243,
                    0.19858156028368795,
                    0.0625,
                    0.0625,
                    1.0
                ],
                [
                    0.34446734674215124,
                    1.0,
                    0.9060150375939849,
                    0.8862830651758931,
                    0.9032258064516129,
                    0.4233300799014875,
                    0.5319148936170213,
                    0.9375,
                    0.9375,
                    1.0
                ]
            ],
            "fraction_answers": {
                "best adapted screenplay": 0.1203965278509424,
                "best original song": 0.7633595810535723,
                "best cinematography": 0.11624389109548527
            },
            "question": "lonnie lynn's only academy award win was in what category?",
            "rate_limited": false,
            "answers": [
                "best adapted screenplay",
                "best cinematography",
                "best original song"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "best adapted screenplay": 0.03924348162093191,
                "best original song": 0.7658397746676754,
                "best cinematography": 0.02895929519623356
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    2210.0,
                    1960.0,
                    32500.0
                ],
                "wikipedia_search": [
                    1.2713047311196004,
                    1.0353749492744497,
                    1.69332031960595
                ],
                "answer_relation_to_question": [
                    1.3397456914974941,
                    1.282384921533901,
                    1.377869386968605
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    1.0
                ],
                "result_count_noun_chunks": [
                    2550.0,
                    2250.0,
                    44800.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    1.0,
                    15.0
                ],
                "word_count_raw": [
                    0.0,
                    1.0,
                    15.0
                ],
                "result_count": [
                    2640.0,
                    2360.0,
                    48200.0
                ],
                "word_count_appended": [
                    38.0,
                    28.0,
                    75.0
                ]
            },
            "integer_answers": {
                "best adapted screenplay": 0,
                "best original song": 9,
                "best cinematography": 0
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which of these products was featured on \u201cShark Tank\u201d?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "scrub daddy"
            ],
            "lines": [
                [
                    0.008771929824561403,
                    0.0,
                    0.44746436857805766,
                    0.977651571590793,
                    0.3483660130718954,
                    0.03125,
                    0.18181818181818182,
                    0.0,
                    0.0,
                    -1.0
                ],
                [
                    0.8415570175438596,
                    1.0,
                    0.5510440835266821,
                    0.022248247728008944,
                    0.2823529411764706,
                    0.84375,
                    0.7445887445887446,
                    1.0,
                    1.0,
                    -1.0
                ],
                [
                    0.14967105263157893,
                    0.0,
                    0.0014915478952601923,
                    0.00010018068119812027,
                    0.369281045751634,
                    0.125,
                    0.0735930735930736,
                    0.0,
                    0.0,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "scrub daddy": 0.6983934482848629,
                "sticky buddy": 0.0799041000614161,
                "instant pot": 0.22170245165372104
            },
            "question": "which of these products was featured on \u201cshark tank\u201d?",
            "rate_limited": false,
            "answers": [
                "instant pot",
                "scrub daddy",
                "sticky buddy"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "scrub daddy": 0.8555938027464317,
                "sticky buddy": 0.022583839428766014,
                "instant pot": 0.2229383750557589
            },
            "integer_answers": {
                "scrub daddy": 7,
                "sticky buddy": 1,
                "instant pot": 1
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    7690000.0,
                    175000.0,
                    788.0
                ],
                "wikipedia_search": [
                    0.125,
                    3.375,
                    0.5
                ],
                "answer_relation_to_question": [
                    0.03508771929824561,
                    3.3662280701754383,
                    0.5986842105263157
                ],
                "question_related_to_answer": [
                    0.0,
                    1.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    53300.0,
                    43200.0,
                    56500.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    4.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    4.0,
                    0.0
                ],
                "result_count": [
                    10800.0,
                    13300.0,
                    36.0
                ],
                "word_count_appended": [
                    42.0,
                    172.0,
                    17.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "What are the first words spoken by God in the King James Bible?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "let there be light"
            ],
            "lines": [
                [
                    0.21023299151942756,
                    1.0,
                    0.9984001896071577,
                    0.9993489955114954,
                    0.5795366032295941,
                    0.5000000000000001,
                    0.8303571428571429,
                    1.0,
                    1.0,
                    1.0
                ],
                [
                    0.3626607339199644,
                    0.0,
                    0.0003555134206316288,
                    0.0001370535765272908,
                    0.00019763535115151657,
                    0.33333333333333337,
                    0.044642857142857144,
                    0.0,
                    0.0,
                    1.0
                ],
                [
                    0.427106274560608,
                    0.0,
                    0.001244296972210701,
                    0.0005139509119773404,
                    0.4202657614192543,
                    0.16666666666666669,
                    0.125,
                    0.0,
                    0.0,
                    1.0
                ]
            ],
            "fraction_answers": {
                "hello, my children": 0.08236968074938504,
                "let there be light": 0.7908751025249798,
                "this is my gift": 0.12675521672563525
            },
            "question": "what are the first words spoken by god in the king james bible?",
            "rate_limited": false,
            "answers": [
                "let there be light",
                "hello, my children",
                "this is my gift"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "hello, my children": 0.01179601232313996,
                "let there be light": 0.7424369595924116,
                "this is my gift": 0.17740201457616578
            },
            "integer_answers": {
                "hello, my children": 0,
                "let there be light": 8,
                "this is my gift": 1
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    87500.0,
                    12.0,
                    45.0
                ],
                "wikipedia_search": [
                    1.0,
                    0.6666666666666666,
                    0.3333333333333333
                ],
                "answer_relation_to_question": [
                    1.2613979491165654,
                    2.1759644035197865,
                    2.562637647363648
                ],
                "question_related_to_answer": [
                    1.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    99700.0,
                    34.0,
                    72300.0
                ],
                "word_count_noun_chunks": [
                    2.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    6.0,
                    0.0,
                    0.0
                ],
                "word_count_appended": [
                    93.0,
                    5.0,
                    14.0
                ],
                "result_count": [
                    33700.0,
                    12.0,
                    42.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which of these grape varieties is typically white?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "riesling"
            ],
            "lines": [
                [
                    0.6315876517218799,
                    0.3225806451612903,
                    0.4405850091407678,
                    0.1564625850340136,
                    0.7748037834574361,
                    0.6459912896036657,
                    0.33785310734463275,
                    0.3225806451612903,
                    0.47619047619047616,
                    -1.0
                ],
                [
                    0.3103194344805083,
                    0.3870967741935484,
                    0.27239488117001825,
                    0.10495626822157435,
                    0.19541155162004428,
                    0.35400871039633436,
                    0.3446327683615819,
                    0.3870967741935484,
                    0.2857142857142857,
                    -1.0
                ],
                [
                    0.0580929137976118,
                    0.2903225806451613,
                    0.2870201096892139,
                    0.738581146744412,
                    0.029784664922519622,
                    0.0,
                    0.31751412429378534,
                    0.2903225806451613,
                    0.23809523809523808,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "riesling": 0.45651502142393924,
                "concord": 0.24997037320367813,
                "merlot": 0.29351460537238266
            },
            "question": "which of these grape varieties is typically white?",
            "rate_limited": false,
            "answers": [
                "riesling",
                "merlot",
                "concord"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "riesling": 0.38278901413860045,
                "concord": 0.25173717865705036,
                "merlot": 0.12491593384006287
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    322000.0,
                    216000.0,
                    1520000.0
                ],
                "wikipedia_search": [
                    2.583965158414663,
                    1.4160348415853374,
                    0.0
                ],
                "answer_relation_to_question": [
                    1.8947629551656395,
                    0.9309583034415249,
                    0.17427874139283536
                ],
                "question_related_to_answer": [
                    0.3225806451612903,
                    0.3870967741935484,
                    0.2903225806451613
                ],
                "result_count_noun_chunks": [
                    3850000.0,
                    971000.0,
                    148000.0
                ],
                "word_count_noun_chunks": [
                    10.0,
                    12.0,
                    9.0
                ],
                "word_count_raw": [
                    10.0,
                    6.0,
                    5.0
                ],
                "result_count": [
                    241000.0,
                    149000.0,
                    157000.0
                ],
                "word_count_appended": [
                    299.0,
                    305.0,
                    281.0
                ]
            },
            "integer_answers": {
                "riesling": 5,
                "concord": 1,
                "merlot": 3
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "The inventor of the Erector Set made another toy that contained what?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "uranium ore"
            ],
            "lines": [
                [
                    0.2114129409545369,
                    0,
                    0.37662337662337664,
                    0.43617021276595747,
                    0.48148148148148145,
                    0.2516666666666667,
                    0.6666666666666666,
                    0,
                    0,
                    1.0
                ],
                [
                    0.27198641765704584,
                    0,
                    0.5909090909090909,
                    0.4787234042553192,
                    0.39814814814814814,
                    0.12666666666666668,
                    0.2708333333333333,
                    0,
                    0,
                    1.0
                ],
                [
                    0.5166006413884173,
                    0,
                    0.032467532467532464,
                    0.0851063829787234,
                    0.12037037037037036,
                    0.6216666666666667,
                    0.0625,
                    0,
                    0,
                    1.0
                ]
            ],
            "fraction_answers": {
                "asbestos powder": 0.23978526564528502,
                "uranium ore": 0.40400355752644757,
                "live ants": 0.35621117682826736
            },
            "question": "the inventor of the erector set made another toy that contained what?",
            "rate_limited": false,
            "answers": [
                "uranium ore",
                "live ants",
                "asbestos powder"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "asbestos powder": 0.32653976206731194,
                "uranium ore": 0.34338151103909653,
                "live ants": 0.19707270152653103
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    41.0,
                    45.0,
                    8.0
                ],
                "wikipedia_search": [
                    0.5033333333333334,
                    0.25333333333333335,
                    1.2433333333333334
                ],
                "answer_relation_to_question": [
                    0.6342388228636107,
                    0.8159592529711375,
                    1.5498019241652519
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    52.0,
                    43.0,
                    13.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count": [
                    58.0,
                    91.0,
                    5.0
                ],
                "word_count_appended": [
                    32.0,
                    13.0,
                    3.0
                ]
            },
            "integer_answers": {
                "asbestos powder": 2,
                "uranium ore": 2,
                "live ants": 2
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which of these outfits can be defined as a \u201cCanadian tuxedo\u201d?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "jean jacket / jeans"
            ],
            "lines": [
                [
                    0.0,
                    0,
                    0.0,
                    0.8715596330275229,
                    0.3332218133154901,
                    0.0,
                    0.3,
                    0,
                    0,
                    -1.0
                ],
                [
                    0.8125,
                    0,
                    0.0,
                    0.0,
                    0.3288725326196052,
                    0.1111111111111111,
                    0.3,
                    0,
                    0,
                    -1.0
                ],
                [
                    0.1875,
                    0,
                    1.0,
                    0.12844036697247707,
                    0.33790565406490464,
                    0.8888888888888888,
                    0.4,
                    0,
                    0,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "jean jacket / jeans": 0.49045581832104507,
                "wool sweater / slacks": 0.2507969077238355,
                "cotton t-shirt / shorts": 0.2587472739551194
            },
            "question": "which of these outfits can be defined as a \u201ccanadian tuxedo\u201d?",
            "rate_limited": false,
            "answers": [
                "wool sweater / slacks",
                "cotton t-shirt / shorts",
                "jean jacket / jeans"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "jean jacket / jeans": 0.40598914485714815,
                "wool sweater / slacks": 0.24193280590940164,
                "cotton t-shirt / shorts": 0.33177420190831414
            },
            "integer_answers": {
                "jean jacket / jeans": 4,
                "wool sweater / slacks": 1,
                "cotton t-shirt / shorts": 1
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    95.0,
                    0,
                    14.0
                ],
                "wikipedia_search": [
                    0.0,
                    0.3333333333333333,
                    2.6666666666666665
                ],
                "answer_relation_to_question": [
                    0.0,
                    1.625,
                    0.375
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    996000.0,
                    983000.0,
                    1010000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_appended": [
                    3.0,
                    3.0,
                    4.0
                ],
                "result_count": [
                    0,
                    0,
                    12.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which of these creatures is most likely to bark?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "dog"
            ],
            "lines": [
                [
                    0.0,
                    0.2,
                    0.041474654377880185,
                    0.011907000062668422,
                    0.11873608017817372,
                    0.038461538461538464,
                    0.2,
                    0.2,
                    0.04240282685512368,
                    -1.0
                ],
                [
                    0.4166666666666667,
                    0.0,
                    0.5407066052227343,
                    0.06060036347684402,
                    0.11567371937639198,
                    0.2692307692307692,
                    0.1616822429906542,
                    0.0,
                    0.0,
                    -1.0
                ],
                [
                    0.5833333333333334,
                    0.8,
                    0.41781874039938555,
                    0.9274926364604875,
                    0.7655902004454342,
                    0.6923076923076923,
                    0.6383177570093458,
                    0.8,
                    0.9575971731448764,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "blue whale": 0.17384004077378445,
                "mime": 0.0947757888817094,
                "dog": 0.7313841703445062
            },
            "question": "which of these creatures is most likely to bark?",
            "rate_limited": false,
            "answers": [
                "mime",
                "blue whale",
                "dog"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "blue whale": 0.10439729256184124,
                "mime": -0.00028137963962622634,
                "dog": 0.7259077482969769
            },
            "integer_answers": {
                "blue whale": 1,
                "mime": 0,
                "dog": 8
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    190000.0,
                    967000.0,
                    14800000.0
                ],
                "wikipedia_search": [
                    0.07692307692307693,
                    0.5384615384615384,
                    1.3846153846153846
                ],
                "answer_relation_to_question": [
                    0.0,
                    1.25,
                    1.75
                ],
                "question_related_to_answer": [
                    0.2,
                    0.0,
                    0.8
                ],
                "result_count_noun_chunks": [
                    853000.0,
                    831000.0,
                    5500000.0
                ],
                "word_count_noun_chunks": [
                    2.0,
                    0.0,
                    8.0
                ],
                "word_count_raw": [
                    12.0,
                    0.0,
                    271.0
                ],
                "word_count_appended": [
                    214.0,
                    173.0,
                    683.0
                ],
                "result_count": [
                    135000.0,
                    1760000.0,
                    1360000.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which of these phrases, written backwards, is a hip hop group?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "beat chefs"
            ],
            "lines": [
                [
                    0.4055168408826946,
                    0,
                    0.009174311926605505,
                    0.008907159986296678,
                    2.86418631481729e-05,
                    0.45426458424560895,
                    0.38235294117647056,
                    0,
                    0,
                    -1.0
                ],
                [
                    0.5406310491676346,
                    0,
                    0.001058574453069866,
                    0.0010277492291880781,
                    1.859208660495434e-05,
                    0.0,
                    0.29411764705882354,
                    0,
                    0,
                    -1.0
                ],
                [
                    0.053852109949670934,
                    0,
                    0.9897671136203247,
                    0.9900650907845152,
                    0.9999527660502469,
                    0.545735415754391,
                    0.3235294117647059,
                    0,
                    0,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "beat chefs": 0.13947560199922018,
                "drummers ear": 0.2100407466801374,
                "blues rhythm": 0.6504836513206426
            },
            "question": "which of these phrases, written backwards, is a hip hop group?",
            "rate_limited": false,
            "answers": [
                "drummers ear",
                "beat chefs",
                "blues rhythm"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "beat chefs": 0.31028596693360755,
                "drummers ear": 0.2684576588312587,
                "blues rhythm": 0.2177126687512109
            },
            "integer_answers": {
                "beat chefs": 1,
                "drummers ear": 1,
                "blues rhythm": 4
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    52.0,
                    6.0,
                    5780.0
                ],
                "wikipedia_search": [
                    1.8170583369824358,
                    0.0,
                    2.182941663017564
                ],
                "answer_relation_to_question": [
                    2.433101045296167,
                    3.243786295005807,
                    0.32311265969802555
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    57.0,
                    37.0,
                    1990000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_appended": [
                    13.0,
                    10.0,
                    11.0
                ],
                "result_count": [
                    52.0,
                    6.0,
                    5610.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which of these is a French territory?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "french guiana"
            ],
            "lines": [
                [
                    0.6971754481260185,
                    1.0,
                    0.9989284578821147,
                    0.9980816417172721,
                    0.9980816507733354,
                    0.48484848484848486,
                    0.6554307116104869,
                    1.0,
                    0,
                    -1.0
                ],
                [
                    0.18902770233568714,
                    0.0,
                    0.0010558418670738264,
                    0.001914502058203131,
                    0.001914502075574307,
                    0.18181818181818182,
                    0.2808988764044944,
                    0.0,
                    0,
                    -1.0
                ],
                [
                    0.1137968495382944,
                    0.0,
                    1.5700250811506714e-05,
                    3.856224524816733e-06,
                    3.8471510902535835e-06,
                    0.3333333333333333,
                    0.06367041198501873,
                    0.0,
                    0,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "french guiana": 0.8540682993697142,
                "french stewart": 0.08207870081990182,
                "french cyprus": 0.06385299981038413
            },
            "question": "which of these is a french territory?",
            "rate_limited": false,
            "answers": [
                "french guiana",
                "french stewart",
                "french cyprus"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "french guiana": 0.701314570421798,
                "french stewart": 0.1057164600035586,
                "french cyprus": -0.012332653280036188
            },
            "integer_answers": {
                "french guiana": 8,
                "french stewart": 0,
                "french cyprus": 0
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    110000000.0,
                    211000.0,
                    425.0
                ],
                "wikipedia_search": [
                    0.9696969696969697,
                    0.36363636363636365,
                    0.6666666666666666
                ],
                "answer_relation_to_question": [
                    1.394350896252037,
                    0.3780554046713743,
                    0.2275936990765888
                ],
                "question_related_to_answer": [
                    1.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    110000000.0,
                    211000.0,
                    424.0
                ],
                "word_count_noun_chunks": [
                    8.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count": [
                    5090000.0,
                    5380.0,
                    80.0
                ],
                "word_count_appended": [
                    175.0,
                    75.0,
                    17.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "What makeup item often contains dried cochineal bugs as an ingredient?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "lipstick"
            ],
            "lines": [
                [
                    0.5328698282591725,
                    0.21739130434782608,
                    0.1223091976516634,
                    0.38224078445614673,
                    0.3778292639458207,
                    0.1989795918367347,
                    0.26164383561643834,
                    0.0,
                    0.01818181818181818,
                    1.0
                ],
                [
                    0.260221506635441,
                    0.06521739130434782,
                    0.07534246575342465,
                    0.05211548937715635,
                    0.05186241311709143,
                    0.07312925170068027,
                    0.21095890410958903,
                    0.0,
                    0.0,
                    1.0
                ],
                [
                    0.2069086651053864,
                    0.717391304347826,
                    0.8023483365949119,
                    0.5656437261666969,
                    0.5703083229370879,
                    0.7278911564625851,
                    0.5273972602739726,
                    1.0,
                    0.9818181818181818,
                    1.0
                ]
            ],
            "fraction_answers": {
                "mascara": 0.23460506936618009,
                "eyeliner": 0.0876497135553034,
                "lipstick": 0.6777452170785164
            },
            "question": "what makeup item often contains dried cochineal bugs as an ingredient?",
            "rate_limited": false,
            "answers": [
                "mascara",
                "eyeliner",
                "lipstick"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "mascara": 0.2714793437528347,
                "eyeliner": 0.051988583608302254,
                "lipstick": 0.697475292409257
            },
            "integer_answers": {
                "mascara": 1,
                "eyeliner": 0,
                "lipstick": 8
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    42100.0,
                    5740.0,
                    62300.0
                ],
                "wikipedia_search": [
                    1.3928571428571428,
                    0.5119047619047619,
                    5.095238095238096
                ],
                "answer_relation_to_question": [
                    2.13147931303669,
                    1.040886026541764,
                    0.8276346604215457
                ],
                "question_related_to_answer": [
                    0.43478260869565216,
                    0.13043478260869565,
                    1.434782608695652
                ],
                "result_count_noun_chunks": [
                    42400.0,
                    5820.0,
                    64000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    78.0
                ],
                "word_count_raw": [
                    1.0,
                    0.0,
                    54.0
                ],
                "result_count": [
                    5000.0,
                    3080.0,
                    32800.0
                ],
                "word_count_appended": [
                    191.0,
                    154.0,
                    385.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "What term describes a person from the state between New York and Rhode Island?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "hoosier"
            ],
            "lines": [
                [
                    0.32146126587718366,
                    0.0,
                    0.0812879804277484,
                    0.02106858008633258,
                    0.5052138064829036,
                    0.28334892787524363,
                    0.26552462526766596,
                    0,
                    0,
                    1.0
                ],
                [
                    0.44233847738340676,
                    0.5,
                    0.000980867447602512,
                    0.009833909836768531,
                    0.005739228841645784,
                    0.0659337231968811,
                    0.291220556745182,
                    0,
                    0,
                    1.0
                ],
                [
                    0.2362002567394095,
                    0.5,
                    0.9177311521246491,
                    0.9690975100768989,
                    0.48904696467545067,
                    0.6507173489278752,
                    0.44325481798715205,
                    0,
                    0,
                    1.0
                ]
            ],
            "fraction_answers": {
                "hoosier": 0.6008640072187765,
                "nutmegger": 0.1880066804930695,
                "cheesehead": 0.21112931228815396
            },
            "question": "what term describes a person from the state between new york and rhode island?",
            "rate_limited": false,
            "answers": [
                "cheesehead",
                "nutmegger",
                "hoosier"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "integer_answers": {
                "hoosier": 4,
                "nutmegger": 2,
                "cheesehead": 1
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    7370.0,
                    3440.0,
                    339000.0
                ],
                "wikipedia_search": [
                    1.4167446393762182,
                    0.32966861598440544,
                    3.2535867446393762
                ],
                "answer_relation_to_question": [
                    1.928767595263102,
                    2.6540308643004407,
                    1.417201540436457
                ],
                "question_related_to_answer": [
                    0.0,
                    0.5,
                    0.5
                ],
                "result_count_noun_chunks": [
                    250000.0,
                    2840.0,
                    242000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count": [
                    72100.0,
                    870.0,
                    814000.0
                ],
                "word_count_appended": [
                    124.0,
                    136.0,
                    207.0
                ]
            },
            "ml_answers": {
                "hoosier": 0.3890460035900414,
                "nutmegger": 0.3116048895037006,
                "cheesehead": 0.14274382989666312
            }
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Where in the home does the Maillard reaction typically occur?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "kitchen"
            ],
            "lines": [
                [
                    0.6091370558375635,
                    0.9545454545454546,
                    0.7824212893553223,
                    0.782934833567745,
                    0.24301592069690597,
                    0.7032784793978824,
                    0.4798061389337641,
                    1.0,
                    1.0,
                    3.0
                ],
                [
                    0.1548223350253807,
                    0.0,
                    0.04188530734632684,
                    0.04172526957337084,
                    0.3244217482727546,
                    0.12590891695369308,
                    0.24394184168012925,
                    0.0,
                    0.0,
                    3.0
                ],
                [
                    0.23604060913705585,
                    0.045454545454545456,
                    0.17569340329835081,
                    0.1753398968588842,
                    0.4325623310303394,
                    0.17081260364842454,
                    0.2762520193861066,
                    0.0,
                    0.0,
                    3.0
                ]
            ],
            "fraction_answers": {
                "bathroom": 0.16801726764596744,
                "kitchen": 0.7283487969260709,
                "bedroom": 0.1036339354279617
            },
            "question": "where in the home does the maillard reaction typically occur?",
            "rate_limited": false,
            "answers": [
                "kitchen",
                "bedroom",
                "bathroom"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "bathroom": 0.03703837621890173,
                "kitchen": 0.8106808554225736,
                "bedroom": 0.08549559461417787
            },
            "integer_answers": {
                "bathroom": 1,
                "kitchen": 8,
                "bedroom": 0
            },
            "categorical_data": {
                "question_type": 3
            },
            "data": {
                "result_count_important_words": [
                    167000.0,
                    8900.0,
                    37400.0
                ],
                "wikipedia_search": [
                    2.109835438193647,
                    0.3777267508610792,
                    0.5124378109452736
                ],
                "answer_relation_to_question": [
                    1.218274111675127,
                    0.3096446700507614,
                    0.4720812182741117
                ],
                "question_related_to_answer": [
                    1.9090909090909092,
                    0.0,
                    0.09090909090909091
                ],
                "result_count_noun_chunks": [
                    80900.0,
                    108000.0,
                    144000.0
                ],
                "word_count_noun_chunks": [
                    5.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    25.0,
                    0.0,
                    0.0
                ],
                "result_count": [
                    167000.0,
                    8940.0,
                    37500.0
                ],
                "word_count_appended": [
                    297.0,
                    151.0,
                    171.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Who is the director of \u201cTyler Perry\u2019s Madea\u2019s Family Reunion\u201d?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "tyler perry"
            ],
            "lines": [
                [
                    0.8676670923797362,
                    1.0,
                    0.999771044798901,
                    0.643510054844607,
                    0.9998041620713468,
                    0.6392543859649122,
                    0.8576051779935275,
                    0.9953703703703703,
                    0.9960159362549801,
                    0.0
                ],
                [
                    0.10185185185185186,
                    0.0,
                    0.00012974128062275813,
                    0.15173674588665448,
                    0.00010994410029650549,
                    0.15021929824561403,
                    0.06472491909385113,
                    0.0,
                    0.0,
                    0.0
                ],
                [
                    0.03048105576841209,
                    0.0,
                    9.921392047622682e-05,
                    0.20475319926873858,
                    8.589382835664491e-05,
                    0.21052631578947367,
                    0.07766990291262135,
                    0.004629629629629629,
                    0.00398406374501992,
                    0.0
                ]
            ],
            "fraction_answers": {
                "george lucas": 0.0520858333843212,
                "abraham lincoln": 0.05913658609585869,
                "tyler perry": 0.8887775805198201
            },
            "question": "who is the director of \u201ctyler perry\u2019s madea\u2019s family reunion\u201d?",
            "rate_limited": false,
            "answers": [
                "tyler perry",
                "george lucas",
                "abraham lincoln"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "george lucas": 0.11267780074242316,
                "abraham lincoln": 0.20249808970717417,
                "tyler perry": 0.78698680653103
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 0
            },
            "data": {
                "result_count_important_words": [
                    704000.0,
                    166000.0,
                    224000.0
                ],
                "wikipedia_search": [
                    3.8355263157894735,
                    0.9013157894736842,
                    1.263157894736842
                ],
                "answer_relation_to_question": [
                    5.206002554278417,
                    0.6111111111111112,
                    0.18288633461047255
                ],
                "question_related_to_answer": [
                    2.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    291000.0,
                    32.0,
                    25.0
                ],
                "word_count_noun_chunks": [
                    215.0,
                    0.0,
                    1.0
                ],
                "word_count_raw": [
                    250.0,
                    0.0,
                    1.0
                ],
                "result_count": [
                    262000.0,
                    34.0,
                    26.0
                ],
                "word_count_appended": [
                    265.0,
                    20.0,
                    24.0
                ]
            },
            "integer_answers": {
                "george lucas": 0,
                "abraham lincoln": 0,
                "tyler perry": 9
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "The first person to lead an expedition to the South Pole came from what country?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "norway"
            ],
            "lines": [
                [
                    0.2654186795491143,
                    0.5,
                    0.30592859482476253,
                    0.27116402116402116,
                    0.2671118530884808,
                    0.3841568718276065,
                    0.28774193548387095,
                    0.75,
                    0.5,
                    1.0
                ],
                [
                    0.37765700483091785,
                    0.25,
                    0.169996724533246,
                    0.21428571428571427,
                    0.1986644407345576,
                    0.3842689900612428,
                    0.37290322580645163,
                    0.0,
                    0.0,
                    1.0
                ],
                [
                    0.35692431561996774,
                    0.25,
                    0.5240746806419915,
                    0.5145502645502645,
                    0.5342237061769616,
                    0.23157413811115066,
                    0.3393548387096774,
                    0.25,
                    0.5,
                    1.0
                ]
            ],
            "fraction_answers": {
                "canada": 0.38896688264555707,
                "iceland": 0.21864178891690336,
                "norway": 0.39239132843753954
            },
            "question": "the first person to lead an expedition to the south pole came from what country?",
            "rate_limited": false,
            "answers": [
                "norway",
                "iceland",
                "canada"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "canada": 0.04613101782090126,
                "iceland": 0.5302966466085257,
                "norway": 0.7152410960333827
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    205000.0,
                    162000.0,
                    389000.0
                ],
                "wikipedia_search": [
                    2.6890981027932455,
                    2.6898829304286997,
                    1.6210189667780546
                ],
                "answer_relation_to_question": [
                    1.592512077294686,
                    2.2659420289855072,
                    2.1415458937198064
                ],
                "question_related_to_answer": [
                    2.0,
                    1.0,
                    1.0
                ],
                "result_count_noun_chunks": [
                    160000.0,
                    119000.0,
                    320000.0
                ],
                "word_count_noun_chunks": [
                    6.0,
                    0.0,
                    2.0
                ],
                "word_count_raw": [
                    6.0,
                    0.0,
                    6.0
                ],
                "word_count_appended": [
                    223.0,
                    289.0,
                    263.0
                ],
                "result_count": [
                    93400.0,
                    51900.0,
                    160000.0
                ]
            },
            "integer_answers": {
                "canada": 3,
                "iceland": 3,
                "norway": 3
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which of these modes of transportation has only one wheel?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "bus"
            ],
            "lines": [
                [
                    0.09649122807017545,
                    0.0,
                    0.26395173453996984,
                    0.029922639030798424,
                    0.27245949926362295,
                    0.09574468085106383,
                    0.10409356725146199,
                    0.0,
                    0.0,
                    -1.0
                ],
                [
                    0.3842105263157895,
                    0.7894736842105262,
                    0.5113122171945701,
                    0.9560648080572179,
                    0.5036818851251841,
                    0.5425531914893617,
                    0.408187134502924,
                    0.8,
                    0.6153846153846154,
                    -1.0
                ],
                [
                    0.5192982456140351,
                    0.21052631578947367,
                    0.22473604826546004,
                    0.014012552911983653,
                    0.22385861561119294,
                    0.3617021276595745,
                    0.48771929824561405,
                    0.2,
                    0.38461538461538464,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "unicycle": 0.2918298431903021,
                "bus": 0.6123186735866877,
                "monster truck": 0.09585148322301028
            },
            "question": "which of these modes of transportation has only one wheel?",
            "rate_limited": false,
            "answers": [
                "monster truck",
                "bus",
                "unicycle"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "unicycle": 0.48230718729060723,
                "bus": 0.7646349270100038,
                "monster truck": 0.09145938021610697
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    1230000.0,
                    39300000.0,
                    576000.0
                ],
                "wikipedia_search": [
                    0.19148936170212766,
                    1.0851063829787233,
                    0.723404255319149
                ],
                "answer_relation_to_question": [
                    0.19298245614035087,
                    0.7684210526315789,
                    1.03859649122807
                ],
                "question_related_to_answer": [
                    0.0,
                    2.3684210526315788,
                    0.631578947368421
                ],
                "result_count_noun_chunks": [
                    1850000.0,
                    3420000.0,
                    1520000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    24.0,
                    6.0
                ],
                "word_count_raw": [
                    0.0,
                    32.0,
                    20.0
                ],
                "word_count_appended": [
                    89.0,
                    349.0,
                    417.0
                ],
                "result_count": [
                    1750000.0,
                    3390000.0,
                    1490000.0
                ]
            },
            "integer_answers": {
                "unicycle": 2,
                "bus": 7,
                "monster truck": 0
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Who defeated Napoleon at the Battle of Waterloo?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "the duke of wellington"
            ],
            "lines": [
                [
                    0.0,
                    0.0,
                    0.008507436772961398,
                    0.0003525329803880337,
                    0.0002141768260674195,
                    0.0375,
                    0.13392857142857142,
                    0.0,
                    0.0,
                    0.0
                ],
                [
                    0.9675069380203515,
                    1.0,
                    0.978065860292841,
                    0.9833814716087255,
                    0.9826936725446307,
                    0.9625,
                    0.4330357142857143,
                    1.0,
                    1.0,
                    0.0
                ],
                [
                    0.03249306197964847,
                    0.0,
                    0.01342670293419758,
                    0.016265995410886466,
                    0.01709215062930191,
                    0.0,
                    0.4330357142857143,
                    0.0,
                    0.0,
                    0.0
                ]
            ],
            "fraction_answers": {
                "jack skellington": 0.02005585755644314,
                "the duke of wellington": 0.9230204063058071,
                "beef wellington": 0.05692373613774985
            },
            "question": "who defeated napoleon at the battle of waterloo?",
            "rate_limited": false,
            "answers": [
                "jack skellington",
                "the duke of wellington",
                "beef wellington"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "jack skellington": 0.050910684471782285,
                "the duke of wellington": 0.7805340618580214,
                "beef wellington": 0.39949612400255147
            },
            "integer_answers": {
                "jack skellington": 0,
                "the duke of wellington": 9,
                "beef wellington": 0
            },
            "categorical_data": {
                "question_type": 0
            },
            "data": {
                "result_count_important_words": [
                    57.0,
                    159000.0,
                    2630.0
                ],
                "wikipedia_search": [
                    0.15,
                    3.85,
                    0.0
                ],
                "answer_relation_to_question": [
                    0.0,
                    3.870027752081406,
                    0.12997224791859388
                ],
                "question_related_to_answer": [
                    0.0,
                    1.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    51.0,
                    234000.0,
                    4070.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    14.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    14.0,
                    0.0
                ],
                "word_count_appended": [
                    30.0,
                    97.0,
                    97.0
                ],
                "result_count": [
                    1470.0,
                    169000.0,
                    2320.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Made famous in a documentary, where is the \u201cGrey Gardens\u201d home located?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "east hampton, ny"
            ],
            "lines": [
                [
                    0.18822695035460996,
                    0,
                    0.17486338797814208,
                    0.000793203130508355,
                    0.7587799538133941,
                    0.3482142857142857,
                    0.15151515151515152,
                    0.0,
                    0.0,
                    3.0
                ],
                [
                    0.6990354609929078,
                    0,
                    0.4426229508196721,
                    0.001533526052316153,
                    0.22103589958911915,
                    0.38125,
                    0.6363636363636364,
                    1.0,
                    1.0,
                    3.0
                ],
                [
                    0.11273758865248226,
                    0,
                    0.3825136612021858,
                    0.9976732708171755,
                    0.02018414659748673,
                    0.27053571428571427,
                    0.21212121212121213,
                    0.0,
                    0.0,
                    3.0
                ]
            ],
            "fraction_answers": {
                "east hampton, ny": 0.5477301842272064,
                "savannah, ga": 0.2494706992095321,
                "cape cod, ma": 0.20279911656326144
            },
            "question": "made famous in a documentary, where is the \u201cgrey gardens\u201d home located?",
            "rate_limited": false,
            "answers": [
                "cape cod, ma",
                "east hampton, ny",
                "savannah, ga"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "east hampton, ny": 0.7185959807138422,
                "savannah, ga": 0.2695400796271284,
                "cape cod, ma": 0.09887545740375486
            },
            "integer_answers": {
                "east hampton, ny": 6,
                "savannah, ga": 1,
                "cape cod, ma": 1
            },
            "categorical_data": {
                "question_type": 3
            },
            "data": {
                "result_count_important_words": [
                    45.0,
                    87.0,
                    56600.0
                ],
                "wikipedia_search": [
                    1.3928571428571428,
                    1.525,
                    1.082142857142857
                ],
                "answer_relation_to_question": [
                    0.9411347517730497,
                    3.495177304964539,
                    0.5636879432624113
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    253000.0,
                    73700.0,
                    6730.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    1.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    1.0,
                    0.0
                ],
                "word_count_appended": [
                    5.0,
                    21.0,
                    7.0
                ],
                "result_count": [
                    32.0,
                    81.0,
                    70.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Which of these is NOT a machine used for printing?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "spirit duplicator"
            ],
            "lines": [
                [
                    0.48748569794050345,
                    0,
                    0.49166549936965964,
                    0.4941260684660407,
                    0.4918746031372734,
                    0.5,
                    0.3362760834670947,
                    0,
                    0,
                    -1.0
                ],
                [
                    0.34196224256292906,
                    0,
                    0.10778820563104075,
                    0.09577245357699271,
                    0.08138331647891629,
                    0.30978260869565216,
                    0.2712680577849117,
                    0,
                    0,
                    -1.0
                ],
                [
                    0.1705520594965675,
                    0,
                    0.4005462949992996,
                    0.4101014779569666,
                    0.4267420803838104,
                    0.19021739130434784,
                    0.3924558587479936,
                    0,
                    0,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "spirit duplicator": 0.33646161237033817,
                "hydraulophone": 0.0661906825398094,
                "hectograph": 0.5973477050898525
            },
            "question": "which of these is not a machine used for printing?",
            "rate_limited": false,
            "answers": [
                "hydraulophone",
                "hectograph",
                "spirit duplicator"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "spirit duplicator": 0.45896440897021007,
                "hydraulophone": 0.35161817125166295,
                "hectograph": 0.20651973939038976
            },
            "integer_answers": {
                "spirit duplicator": 2,
                "hydraulophone": 0,
                "hectograph": 4
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    2790.0,
                    192000.0,
                    42700.0
                ],
                "wikipedia_search": [
                    0.0,
                    0.7608695652173914,
                    1.2391304347826086
                ],
                "answer_relation_to_question": [
                    0.05005720823798627,
                    0.6321510297482837,
                    1.31779176201373
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    6910.0,
                    356000.0,
                    62300.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count": [
                    2380.0,
                    112000.0,
                    28400.0
                ],
                "word_count_appended": [
                    204.0,
                    285.0,
                    134.0
                ]
            },
            "negative_question": true
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Dominique Ansel is credited with creating what food craze?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "cronut"
            ],
            "lines": [
                [
                    0.17876910367616689,
                    0.0,
                    0.25882352941176473,
                    0.0007509451551090165,
                    0.04188991719434973,
                    0.0,
                    0.052123552123552123,
                    0.0,
                    0.0,
                    1.0
                ],
                [
                    0.2730555442079606,
                    0.0,
                    0.2529411764705882,
                    0.0023046247863690505,
                    0.19581100828056502,
                    0.24393939393939396,
                    0.05019305019305019,
                    0.0,
                    0.010752688172043012,
                    1.0
                ],
                [
                    0.5481753521158725,
                    1.0,
                    0.48823529411764705,
                    0.996944430058522,
                    0.7622990745250853,
                    0.7560606060606061,
                    0.8976833976833977,
                    1.0,
                    0.989247311827957,
                    1.0
                ]
            ],
            "fraction_answers": {
                "ramen burger": 0.11433305400555221,
                "cronut": 0.8265161629321208,
                "rainbow bagel": 0.05915078306232694
            },
            "question": "dominique ansel is credited with creating what food craze?",
            "rate_limited": false,
            "answers": [
                "rainbow bagel",
                "ramen burger",
                "cronut"
            ],
            "ml_answers": {
                "ramen burger": 0.13884801396978141,
                "cronut": 0.9415694225506144,
                "rainbow bagel": 0.07327937179845792
            },
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "integer_answers": {
                "ramen burger": 0,
                "cronut": 9,
                "rainbow bagel": 0
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    29.0,
                    89.0,
                    38500.0
                ],
                "wikipedia_search": [
                    0.0,
                    0.9757575757575758,
                    3.0242424242424244
                ],
                "answer_relation_to_question": [
                    0.8938455183808344,
                    1.3652777210398028,
                    2.7408767605793627
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    1.0
                ],
                "result_count_noun_chunks": [
                    17200.0,
                    80400.0,
                    313000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    167.0
                ],
                "word_count_raw": [
                    0.0,
                    3.0,
                    276.0
                ],
                "word_count_appended": [
                    27.0,
                    26.0,
                    465.0
                ],
                "result_count": [
                    44.0,
                    43.0,
                    83.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which person is most famous for being a children\u2019s book writer?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "dr. seuss"
            ],
            "lines": [
                [
                    0.33577964519140996,
                    0.0,
                    0.43696162881754114,
                    0.5351378197169109,
                    0.5861377312235346,
                    0.42870234186222983,
                    0.24881516587677724,
                    0.0,
                    0.0,
                    -1.0
                ],
                [
                    0.5782259570494864,
                    1.0,
                    0.5309318715740016,
                    0.3575862925254532,
                    0.358814352574103,
                    0.34343663124324664,
                    0.3862559241706161,
                    1.0,
                    1.0,
                    -1.0
                ],
                [
                    0.08599439775910364,
                    0.0,
                    0.03210649960845732,
                    0.10727588775763595,
                    0.05504791620236238,
                    0.2278610268945235,
                    0.36492890995260663,
                    0.0,
                    0.0,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "tiger woods": 0.09702384868607661,
                "paris hilton": 0.28572603696537824,
                "dr. seuss": 0.6172501143485453
            },
            "question": "which person is most famous for being a children\u2019s book writer?",
            "rate_limited": false,
            "answers": [
                "paris hilton",
                "dr. seuss",
                "tiger woods"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "tiger woods": 0.152739600431999,
                "paris hilton": 0.24843651296556607,
                "dr. seuss": 0.7326763491018434
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    4310000.0,
                    2880000.0,
                    864000.0
                ],
                "wikipedia_search": [
                    2.143511709311149,
                    1.7171831562162332,
                    1.1393051344726175
                ],
                "answer_relation_to_question": [
                    1.6788982259570497,
                    2.8911297852474322,
                    0.42997198879551823
                ],
                "question_related_to_answer": [
                    0.0,
                    1.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    2630000.0,
                    1610000.0,
                    247000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    1.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    4.0,
                    0.0
                ],
                "word_count_appended": [
                    105.0,
                    163.0,
                    154.0
                ],
                "result_count": [
                    2790000.0,
                    3390000.0,
                    205000.0
                ]
            },
            "integer_answers": {
                "tiger woods": 0,
                "paris hilton": 3,
                "dr. seuss": 6
            }
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "How does the second verse of \u201cThe Star-Spangled Banner\u201d begin?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "on the shore"
            ],
            "lines": [
                [
                    0.17803030303030304,
                    0,
                    0.0018029831175217178,
                    0.009341199606686333,
                    0.003978779840848806,
                    0.5833333333333334,
                    0.036585365853658534,
                    0.0,
                    0.0,
                    5.0
                ],
                [
                    0.3248106060606061,
                    0,
                    0.8178987051303065,
                    0.8884674813878354,
                    0.746684350132626,
                    0.06250000000000001,
                    0.4878048780487805,
                    0.6666666666666666,
                    1.0,
                    5.0
                ],
                [
                    0.49715909090909094,
                    0,
                    0.18029831175217179,
                    0.1021913190054783,
                    0.2493368700265252,
                    0.3541666666666667,
                    0.47560975609756095,
                    0.3333333333333333,
                    0.0,
                    5.0
                ]
            ],
            "fraction_answers": {
                "on the shore": 0.6243540859283527,
                "where the foe": 0.2740119184738534,
                "travels far": 0.10163399559779399
            },
            "question": "how does the second verse of \u201cthe star-spangled banner\u201d begin?",
            "rate_limited": false,
            "answers": [
                "travels far",
                "on the shore",
                "where the foe"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "on the shore": 0.4880685000514079,
                "where the foe": 0.264516454835266,
                "travels far": 0.18500354614158251
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 5
            },
            "data": {
                "result_count_important_words": [
                    2660.0,
                    253000.0,
                    29100.0
                ],
                "wikipedia_search": [
                    2.333333333333333,
                    0.25,
                    1.4166666666666665
                ],
                "answer_relation_to_question": [
                    0.7121212121212122,
                    1.2992424242424243,
                    1.9886363636363638
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    30.0,
                    5630.0,
                    1880.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    6.0,
                    3.0
                ],
                "word_count_raw": [
                    0.0,
                    2.0,
                    0.0
                ],
                "result_count": [
                    11.0,
                    4990.0,
                    1100.0
                ],
                "word_count_appended": [
                    3.0,
                    40.0,
                    39.0
                ]
            },
            "integer_answers": {
                "on the shore": 6,
                "where the foe": 1,
                "travels far": 1
            }
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Which of these substances is both artificially made and found in nature?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "nylon"
            ],
            "lines": [
                [
                    0.6923076923076923,
                    0,
                    0.018898931799506986,
                    0.3484848484848485,
                    0.41849148418491483,
                    0.2833333333333333,
                    0.29187071498530853,
                    0,
                    0.0,
                    -1.0
                ],
                [
                    0.15384615384615385,
                    0,
                    0.027937551355792935,
                    0.32196969696969696,
                    0.2664233576642336,
                    0.09999999999999999,
                    0.3006856023506366,
                    0,
                    1.0,
                    -1.0
                ],
                [
                    0.15384615384615385,
                    0,
                    0.9531635168447001,
                    0.32954545454545453,
                    0.3150851581508516,
                    0.6166666666666667,
                    0.40744368266405484,
                    0,
                    0.0,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "latex": 0.3965358046739831,
                "teflon": 0.2933410007279435,
                "nylon": 0.31012319459807347
            },
            "question": "which of these substances is both artificially made and found in nature?",
            "rate_limited": false,
            "answers": [
                "teflon",
                "nylon",
                "latex"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "latex": 0.37798013893372423,
                "teflon": 0.2991302657910774,
                "nylon": 0.4049886187767909
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    1840000.0,
                    1700000.0,
                    1740000.0
                ],
                "wikipedia_search": [
                    0.85,
                    0.3,
                    1.85
                ],
                "answer_relation_to_question": [
                    0.6923076923076923,
                    0.15384615384615385,
                    0.15384615384615385
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    3440000.0,
                    2190000.0,
                    2590000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    4.0,
                    0.0
                ],
                "word_count_appended": [
                    298.0,
                    307.0,
                    416.0
                ],
                "result_count": [
                    2300000.0,
                    3400000.0,
                    116000000.0
                ]
            },
            "integer_answers": {
                "latex": 3,
                "teflon": 3,
                "nylon": 1
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Every U.S. state that starts with which of these letters has a Democratic governor?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "c"
            ],
            "lines": [
                [
                    0.34090909090909094,
                    0.2556702905034518,
                    0.33450143357757245,
                    0.327710843373494,
                    0.3208502024291498,
                    0.18421052631578946,
                    0.27911342141361634,
                    0.23289246693502014,
                    0.25828662930344276,
                    -1.0
                ],
                [
                    0.2159090909090909,
                    0.4488352263377898,
                    0.3536158012105766,
                    0.3530120481927711,
                    0.3643724696356275,
                    0.5,
                    0.4272615695617645,
                    0.4637312084120595,
                    0.44067253803042433,
                    -1.0
                ],
                [
                    0.4431818181818182,
                    0.2954944831587583,
                    0.31188276521185093,
                    0.3192771084337349,
                    0.3147773279352227,
                    0.3157894736842105,
                    0.2936250090246192,
                    0.3033763246529204,
                    0.3010408326661329,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "c": 0.39637888358778933,
                "w": 0.2815716560845142,
                "v": 0.32204946032769644
            },
            "question": "every u.s. state that starts with which of these letters has a democratic governor?",
            "rate_limited": false,
            "answers": [
                "w",
                "c",
                "v"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "c": 0.4465521324967589,
                "w": 0.07900200036251359,
                "v": 0.25907576580452696
            },
            "integer_answers": {
                "c": 8,
                "w": 0,
                "v": 1
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    2720000.0,
                    2930000.0,
                    2650000.0
                ],
                "wikipedia_search": [
                    0.3684210526315789,
                    1.0,
                    0.631578947368421
                ],
                "answer_relation_to_question": [
                    1.3636363636363638,
                    0.8636363636363636,
                    1.7727272727272727
                ],
                "question_related_to_answer": [
                    1.0226811620138072,
                    1.7953409053511593,
                    1.1819779326350333
                ],
                "result_count_noun_chunks": [
                    6340000.0,
                    7200000.0,
                    6220000.0
                ],
                "word_count_noun_chunks": [
                    2835.0,
                    5645.0,
                    3693.0
                ],
                "word_count_raw": [
                    3226.0,
                    5504.0,
                    3760.0
                ],
                "result_count": [
                    10500000.0,
                    11100000.0,
                    9790000.0
                ],
                "word_count_appended": [
                    3866.0,
                    5918.0,
                    4067.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "What does a rattlesnake typically do when it feels threatened?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "rattles its tail"
            ],
            "lines": [
                [
                    0.6222222222222222,
                    0,
                    2.1046784949598083e-05,
                    0.0001195076285702904,
                    0.0009255494909477799,
                    0.5,
                    0.6756756756756757,
                    0,
                    0,
                    1.0
                ],
                [
                    0.2333333333333333,
                    0,
                    0.20430781487658628,
                    0.4182766999960164,
                    0.35118980684560624,
                    0.0,
                    0.16216216216216217,
                    0,
                    0,
                    1.0
                ],
                [
                    0.14444444444444446,
                    0,
                    0.7956711383384641,
                    0.5816037923754133,
                    0.647884643663446,
                    0.5,
                    0.16216216216216217,
                    0,
                    0,
                    1.0
                ]
            ],
            "fraction_answers": {
                "sends an angry email": 0.4719610301639883,
                "eats its feelings": 0.2282116362022841,
                "rattles its tail": 0.29982733363372754
            },
            "question": "what does a rattlesnake typically do when it feels threatened?",
            "rate_limited": false,
            "answers": [
                "rattles its tail",
                "eats its feelings",
                "sends an angry email"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "sends an angry email": 0.2978992012000608,
                "eats its feelings": 0.2898814504567614,
                "rattles its tail": 0.3497680011388568
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    30.0,
                    105000.0,
                    146000.0
                ],
                "wikipedia_search": [
                    1.0,
                    0.0,
                    1.0
                ],
                "answer_relation_to_question": [
                    1.8666666666666667,
                    0.7,
                    0.43333333333333335
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    1070.0,
                    406000.0,
                    749000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_appended": [
                    25.0,
                    6.0,
                    6.0
                ],
                "result_count": [
                    41.0,
                    398000.0,
                    1550000.0
                ]
            },
            "integer_answers": {
                "sends an angry email": 3,
                "eats its feelings": 0,
                "rattles its tail": 3
            }
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Which of these was a name the ancient Greeks gave the planet Venus?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "phosphorus"
            ],
            "lines": [
                [
                    0.1111111111111111,
                    0,
                    0.00011720064643145536,
                    0.0014639171531329635,
                    0.00018384456558619025,
                    0.14285714285714288,
                    0.14748784440842788,
                    0.0,
                    0.0,
                    -1.0
                ],
                [
                    0.2222222222222222,
                    0,
                    0.978464112409398,
                    0.7568090220671956,
                    0.969414401998944,
                    0.634920634920635,
                    0.5672609400324149,
                    1.0,
                    1.0,
                    -1.0
                ],
                [
                    0.6666666666666666,
                    0,
                    0.021418686944170557,
                    0.24172706077967143,
                    0.03040175343546984,
                    0.22222222222222224,
                    0.2852512155591572,
                    0.0,
                    0.0,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "antimony": 0.18346095070091975,
                "flourine": 0.05040263259272906,
                "phosphorus": 0.7661364167063512
            },
            "question": "which of these was a name the ancient greeks gave the planet venus?",
            "rate_limited": false,
            "answers": [
                "flourine",
                "phosphorus",
                "antimony"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "antimony": 0.28243582064057904,
                "flourine": 0.03281978926902148,
                "phosphorus": 0.8011367709037928
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    648.0,
                    335000.0,
                    107000.0
                ],
                "wikipedia_search": [
                    0.42857142857142855,
                    1.9047619047619047,
                    0.6666666666666666
                ],
                "answer_relation_to_question": [
                    0.3333333333333333,
                    0.6666666666666666,
                    2.0
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    641.0,
                    3380000.0,
                    106000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    4.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    5.0,
                    0.0
                ],
                "result_count": [
                    545.0,
                    4550000.0,
                    99600.0
                ],
                "word_count_appended": [
                    91.0,
                    350.0,
                    176.0
                ]
            },
            "integer_answers": {
                "antimony": 1,
                "flourine": 0,
                "phosphorus": 7
            }
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Which of these film composers most recently won an Oscar?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "hans zimmer"
            ],
            "lines": [
                [
                    0.299860478293466,
                    0.25,
                    0.2910521140609636,
                    0.2879746835443038,
                    0.31179138321995464,
                    0.6345354645354646,
                    0.37343358395989973,
                    0.25,
                    0.125,
                    -1.0
                ],
                [
                    0.2882902907580255,
                    0.625,
                    0.07964601769911504,
                    0.5253164556962026,
                    0.47619047619047616,
                    0.23106617520410624,
                    0.3483709273182957,
                    0.5,
                    0.875,
                    -1.0
                ],
                [
                    0.41184923094850856,
                    0.125,
                    0.6293018682399213,
                    0.18670886075949367,
                    0.21201814058956917,
                    0.13439836026042923,
                    0.2781954887218045,
                    0.25,
                    0.0,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "ennio morricone": 0.31373863417933917,
                "danny elfman": 0.24749688327996966,
                "hans zimmer": 0.4387644825406913
            },
            "question": "which of these film composers most recently won an oscar?",
            "rate_limited": false,
            "answers": [
                "ennio morricone",
                "hans zimmer",
                "danny elfman"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "integer_answers": {
                "ennio morricone": 2,
                "danny elfman": 2,
                "hans zimmer": 5
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    182000.0,
                    332000.0,
                    118000.0
                ],
                "wikipedia_search": [
                    3.172677322677323,
                    1.1553308760205312,
                    0.6719918013021462
                ],
                "answer_relation_to_question": [
                    1.49930239146733,
                    1.4414514537901275,
                    2.0592461547425427
                ],
                "question_related_to_answer": [
                    0.25,
                    0.625,
                    0.125
                ],
                "result_count_noun_chunks": [
                    110000.0,
                    168000.0,
                    74800.0
                ],
                "word_count_noun_chunks": [
                    2.0,
                    4.0,
                    2.0
                ],
                "word_count_raw": [
                    1.0,
                    7.0,
                    0.0
                ],
                "word_count_appended": [
                    149.0,
                    139.0,
                    111.0
                ],
                "result_count": [
                    592000.0,
                    162000.0,
                    1280000.0
                ]
            },
            "ml_answers": {
                "ennio morricone": 0.27853960367673,
                "danny elfman": 0.23049209714717983,
                "hans zimmer": 0.4657117638361685
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which of these figure skating jumps was invented the most recently?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "lutz"
            ],
            "lines": [
                [
                    0.06727201370058512,
                    0.203125,
                    0.17478991596638654,
                    0.22204888195527822,
                    0.2365415986949429,
                    0.013447286636385369,
                    0.32650273224043713,
                    0.203125,
                    0.21739130434782608,
                    -1.0
                ],
                [
                    0.8034465534465535,
                    0.28125,
                    0.426890756302521,
                    0.3764950598023921,
                    0.11908646003262642,
                    0.9759144154912742,
                    0.29918032786885246,
                    0.28125,
                    0.17391304347826086,
                    -1.0
                ],
                [
                    0.1292814328528614,
                    0.515625,
                    0.3983193277310924,
                    0.4014560582423297,
                    0.6443719412724307,
                    0.010638297872340425,
                    0.3743169398907104,
                    0.515625,
                    0.6086956521739131,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "salchow": 0.4152696240469423,
                "lutz": 0.1849159703935379,
                "axel": 0.39981440555951975
            },
            "question": "which of these figure skating jumps was invented the most recently?",
            "rate_limited": false,
            "answers": [
                "lutz",
                "salchow",
                "axel"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "salchow": 0.3454691374288383,
                "lutz": 0.3853554360766397,
                "axel": 0.3350837769763451
            },
            "integer_answers": {
                "salchow": 3,
                "lutz": 0,
                "axel": 6
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    42700.0,
                    72400.0,
                    77200.0
                ],
                "wikipedia_search": [
                    0.053789146545541476,
                    3.903657661965097,
                    0.0425531914893617
                ],
                "answer_relation_to_question": [
                    0.33636006850292566,
                    4.017232767232768,
                    0.6464071642643071
                ],
                "question_related_to_answer": [
                    0.203125,
                    0.28125,
                    0.515625
                ],
                "result_count_noun_chunks": [
                    116000.0,
                    58400.0,
                    316000.0
                ],
                "word_count_noun_chunks": [
                    13.0,
                    18.0,
                    33.0
                ],
                "word_count_raw": [
                    10.0,
                    8.0,
                    28.0
                ],
                "word_count_appended": [
                    239.0,
                    219.0,
                    274.0
                ],
                "result_count": [
                    104000.0,
                    254000.0,
                    237000.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Romaine, Iceberg and Butterhead are all varieties of what?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "lettuce"
            ],
            "lines": [
                [
                    1.0,
                    1.0,
                    0.9902927233049891,
                    0.9993056772242662,
                    0.9975004088116429,
                    0.9895833333333334,
                    0.9803063457330415,
                    1.0,
                    1.0,
                    1.0
                ],
                [
                    0.0,
                    0.0,
                    0.009496576115584318,
                    0.0005969878071729383,
                    0.002149181208680823,
                    0.0,
                    0.006564551422319475,
                    0.0,
                    0.0,
                    1.0
                ],
                [
                    0.0,
                    0.0,
                    0.00021070057942659343,
                    9.733496856080515e-05,
                    0.00035040997967622115,
                    0.010416666666666666,
                    0.01312910284463895,
                    0.0,
                    0.0,
                    1.0
                ]
            ],
            "fraction_answers": {
                "lettuce": 0.9952209431563637,
                "race cars": 0.002689357226552137,
                "disney dwarfs": 0.002089699617084173
            },
            "question": "romaine, iceberg and butterhead are all varieties of what?",
            "rate_limited": false,
            "answers": [
                "lettuce",
                "disney dwarfs",
                "race cars"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "lettuce": 0.8619448566740576,
                "race cars": 0.14659438314098944,
                "disney dwarfs": 0.13176299244555
            },
            "integer_answers": {
                "lettuce": 9,
                "race cars": 0,
                "disney dwarfs": 0
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    154000.0,
                    92.0,
                    15.0
                ],
                "wikipedia_search": [
                    3.9583333333333335,
                    0.0,
                    0.041666666666666664
                ],
                "answer_relation_to_question": [
                    4.0,
                    0.0,
                    0.0
                ],
                "question_related_to_answer": [
                    4.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    42700.0,
                    92.0,
                    15.0
                ],
                "word_count_noun_chunks": [
                    688.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    669.0,
                    0.0,
                    0.0
                ],
                "word_count_appended": [
                    896.0,
                    6.0,
                    12.0
                ],
                "result_count": [
                    65800.0,
                    631.0,
                    14.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "What is the correct pronunciation of the performer who sings \u201cSmooth Operator\u201d?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "shah-day"
            ],
            "lines": [
                [
                    0.6666666666666666,
                    0,
                    0.7835051546391752,
                    0.609375,
                    0.4353768059351816,
                    0.0,
                    0.7473118279569892,
                    1.0,
                    1.0,
                    1.0
                ],
                [
                    0.0,
                    0,
                    0.14432989690721648,
                    0.234375,
                    0.0023428348301444747,
                    0.0,
                    0.12903225806451613,
                    0.0,
                    0.0,
                    1.0
                ],
                [
                    0.3333333333333333,
                    0,
                    0.07216494845360824,
                    0.15625,
                    0.562280359234674,
                    1.0,
                    0.12365591397849462,
                    0.0,
                    0.0,
                    1.0
                ]
            ],
            "fraction_answers": {
                "say-dee": 0.28096056937501374,
                "sayd": 0.06375999872523465,
                "shah-day": 0.6552794318997516
            },
            "question": "what is the correct pronunciation of the performer who sings \u201csmooth operator\u201d?",
            "rate_limited": false,
            "answers": [
                "shah-day",
                "sayd",
                "say-dee"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "say-dee": 0.08991929256304505,
                "sayd": 0.07809040416021872,
                "shah-day": 0.8149610446941572
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    39.0,
                    15.0,
                    10.0
                ],
                "wikipedia_search": [
                    0.0,
                    0.0,
                    1.0
                ],
                "answer_relation_to_question": [
                    2.0,
                    0.0,
                    1.0
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    2230.0,
                    12.0,
                    2880.0
                ],
                "word_count_noun_chunks": [
                    1.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    2.0,
                    0.0,
                    0.0
                ],
                "word_count_appended": [
                    139.0,
                    24.0,
                    23.0
                ],
                "result_count": [
                    76.0,
                    14.0,
                    7.0
                ]
            },
            "integer_answers": {
                "say-dee": 2,
                "sayd": 0,
                "shah-day": 6
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which of these are you most likely to find in a toolbox?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "hammerhead shark"
            ],
            "lines": [
                [
                    0.16228070175438597,
                    1.0,
                    0.9424443934877321,
                    0.7309417040358744,
                    0.9702228357325972,
                    0.05555555555555555,
                    0.8063725490196079,
                    0,
                    1.0,
                    -1.0
                ],
                [
                    0.21052631578947367,
                    0.0,
                    0.03210272873194221,
                    0.11547085201793722,
                    0.01735357917570499,
                    0.8888888888888888,
                    0.12009803921568628,
                    0,
                    0.0,
                    -1.0
                ],
                [
                    0.6271929824561404,
                    0.0,
                    0.025452877780325612,
                    0.15358744394618834,
                    0.01242358509169789,
                    0.05555555555555555,
                    0.07352941176470588,
                    0,
                    0.0,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "hammerhead shark": 0.11846773207432672,
                "hammer": 0.7084772174482191,
                "mc hammer": 0.17305505047745415
            },
            "question": "which of these are you most likely to find in a toolbox?",
            "rate_limited": false,
            "answers": [
                "hammer",
                "mc hammer",
                "hammerhead shark"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "hammerhead shark": 0.2842036975563787,
                "hammer": 0.2511400656531113,
                "mc hammer": 0.09883380436337162
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    652000.0,
                    103000.0,
                    137000.0
                ],
                "wikipedia_search": [
                    0.1111111111111111,
                    1.7777777777777777,
                    0.1111111111111111
                ],
                "answer_relation_to_question": [
                    0.32456140350877194,
                    0.42105263157894735,
                    1.2543859649122808
                ],
                "question_related_to_answer": [
                    1.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    9840000.0,
                    176000.0,
                    126000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    1.0,
                    0.0,
                    0.0
                ],
                "result_count": [
                    4110000.0,
                    140000.0,
                    111000.0
                ],
                "word_count_appended": [
                    329.0,
                    49.0,
                    30.0
                ]
            },
            "integer_answers": {
                "hammerhead shark": 1,
                "hammer": 6,
                "mc hammer": 1
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which of these is usually found on the ocean floor?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "sea cucumber"
            ],
            "lines": [
                [
                    0.058333333333333334,
                    0,
                    0.7539041464728056,
                    0.7750247770069376,
                    0.6999825874978234,
                    0.28108974358974365,
                    0.3720316622691293,
                    0,
                    0,
                    -1.0
                ],
                [
                    0.05952380952380952,
                    0,
                    0.07027463651050081,
                    0.06937561942517344,
                    0.06146613268326659,
                    0.03541666666666667,
                    0.13984168865435356,
                    0,
                    0,
                    -1.0
                ],
                [
                    0.8821428571428571,
                    0,
                    0.1758212170166936,
                    0.155599603567889,
                    0.23855127981890997,
                    0.6834935897435898,
                    0.48812664907651715,
                    0,
                    0,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "sweet potato": 0.4900610416949622,
                "cherry tomato": 0.07264975891062843,
                "sea cucumber": 0.43728919939440947
            },
            "question": "which of these is usually found on the ocean floor?",
            "rate_limited": false,
            "answers": [
                "sweet potato",
                "cherry tomato",
                "sea cucumber"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "sweet potato": 0.1604047290800984,
                "cherry tomato": 0.15829628240597554,
                "sea cucumber": 0.4580233413097764
            },
            "integer_answers": {
                "sweet potato": 3,
                "cherry tomato": 0,
                "sea cucumber": 3
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    391000.0,
                    35000.0,
                    78500.0
                ],
                "wikipedia_search": [
                    1.1243589743589744,
                    0.14166666666666666,
                    2.7339743589743586
                ],
                "answer_relation_to_question": [
                    0.23333333333333334,
                    0.23809523809523808,
                    3.5285714285714285
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    402000.0,
                    35300.0,
                    137000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_appended": [
                    141.0,
                    53.0,
                    185.0
                ],
                "result_count": [
                    280000.0,
                    26100.0,
                    65300.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "The '90s band The Lightning Seeds took their name from which song?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "raspberry beret"
            ],
            "lines": [
                [
                    0.13056238056238056,
                    1.0,
                    0.04715307475396366,
                    0.009853806141624483,
                    0.011671041289335283,
                    0.241156116068292,
                    0.38461538461538464,
                    1.0,
                    1.0,
                    -1.0
                ],
                [
                    0.23266448266448267,
                    0.0,
                    0.9523987376048105,
                    0.9897407053755565,
                    0.9879221672300406,
                    0.4220824843673154,
                    0.3384615384615385,
                    0.0,
                    0.0,
                    -1.0
                ],
                [
                    0.6367731367731367,
                    0.0,
                    0.0004481876412257932,
                    0.0004054884828190606,
                    0.00040679148062413434,
                    0.33676139956439266,
                    0.27692307692307694,
                    0.0,
                    0.0,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "when doves cry": 0.13907978676280836,
                "raspberry beret": 0.4250013114923312,
                "purple rain": 0.4359189017448604
            },
            "question": "the '90s band the lightning seeds took their name from which song?",
            "rate_limited": false,
            "answers": [
                "raspberry beret",
                "purple rain",
                "when doves cry"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "when doves cry": 0.22228482282707057,
                "raspberry beret": 0.7571438977925797,
                "purple rain": 0.40815427217767464
            },
            "integer_answers": {
                "when doves cry": 1,
                "raspberry beret": 4,
                "purple rain": 4
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    2260.0,
                    227000.0,
                    93.0
                ],
                "wikipedia_search": [
                    0.964624464273168,
                    1.6883299374692615,
                    1.3470455982575706
                ],
                "answer_relation_to_question": [
                    0.5222495222495223,
                    0.9306579306579307,
                    2.547092547092547
                ],
                "question_related_to_answer": [
                    1.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    2410.0,
                    204000.0,
                    84.0
                ],
                "word_count_noun_chunks": [
                    3.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    3.0,
                    0.0,
                    0.0
                ],
                "word_count_appended": [
                    25.0,
                    22.0,
                    18.0
                ],
                "result_count": [
                    10100.0,
                    204000.0,
                    96.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which Las Vegas hotel features a replica of the Rialto Bridge?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "the venetian"
            ],
            "lines": [
                [
                    0.41242494662012075,
                    0.25,
                    0.14291736930860033,
                    0.015925155925155924,
                    0.19751381215469613,
                    0.1981892595339231,
                    0.528023598820059,
                    0.025,
                    0.013333333333333334,
                    -1.0
                ],
                [
                    0.19169159988034315,
                    0.625,
                    0.32166947723440137,
                    0.9792099792099792,
                    0.7983425414364641,
                    0.0324301175737756,
                    0.3746312684365782,
                    0.9125,
                    0.9733333333333334,
                    -1.0
                ],
                [
                    0.39588345349953613,
                    0.125,
                    0.5354131534569984,
                    0.004864864864864865,
                    0.004143646408839779,
                    0.7693806228923012,
                    0.09734513274336283,
                    0.0625,
                    0.013333333333333334,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "caesars palace": 0.22309602302213738,
                "luxor": 0.19814749729954317,
                "the venetian": 0.5787564796783194
            },
            "question": "which las vegas hotel features a replica of the rialto bridge?",
            "rate_limited": false,
            "answers": [
                "luxor",
                "the venetian",
                "caesars palace"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "caesars palace": 0.3350681285243192,
                "luxor": 0.47029288995907054,
                "the venetian": 0.6840696234786783
            },
            "integer_answers": {
                "caesars palace": 2,
                "luxor": 2,
                "the venetian": 5
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    7660.0,
                    471000.0,
                    2340.0
                ],
                "wikipedia_search": [
                    1.1891355572035387,
                    0.19458070544265357,
                    4.6162837373538075
                ],
                "answer_relation_to_question": [
                    2.0621247331006036,
                    0.9584579994017157,
                    1.9794172674976807
                ],
                "question_related_to_answer": [
                    0.5,
                    1.25,
                    0.25
                ],
                "result_count_noun_chunks": [
                    143000.0,
                    578000.0,
                    3000.0
                ],
                "word_count_noun_chunks": [
                    2.0,
                    73.0,
                    5.0
                ],
                "word_count_raw": [
                    1.0,
                    73.0,
                    1.0
                ],
                "result_count": [
                    3390.0,
                    7630.0,
                    12700.0
                ],
                "word_count_appended": [
                    179.0,
                    127.0,
                    33.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "What TV series derived from a nearly 20-year-old Michael Crichton screenplay?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "er"
            ],
            "lines": [
                [
                    0.2566890319046967,
                    0.0,
                    0.0004017609715838821,
                    0.03571428571428571,
                    0.022745735174654752,
                    0.022727272727272728,
                    0.009759271307742356,
                    0.0,
                    0.0,
                    1.0
                ],
                [
                    0.20895294171345108,
                    0.0,
                    0.0012464271106367426,
                    0.052336028751123094,
                    0.015976171134578932,
                    0.30612627286125815,
                    0.07221860767729343,
                    0.0,
                    0.0,
                    1.0
                ],
                [
                    0.5343580263818521,
                    1.0,
                    0.9983518119177793,
                    0.9119496855345912,
                    0.9612780936907663,
                    0.6711464544114691,
                    0.9180221210149642,
                    1.0,
                    1.0,
                    1.0
                ]
            ],
            "fraction_answers": {
                "numb3rs": 0.07298404991648239,
                "the expanse": 0.03867081753335957,
                "er": 0.888345132550158
            },
            "question": "what tv series derived from a nearly 20-year-old michael crichton screenplay?",
            "rate_limited": false,
            "answers": [
                "the expanse",
                "numb3rs",
                "er"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "numb3rs": 0.1946603642743781,
                "the expanse": 0.1608661031535915,
                "er": 0.8619448566740576
            },
            "integer_answers": {
                "numb3rs": 0,
                "the expanse": 0,
                "er": 9
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    1590.0,
                    2330.0,
                    40600.0
                ],
                "wikipedia_search": [
                    0.09090909090909091,
                    1.2245050914450326,
                    2.6845858176458766
                ],
                "answer_relation_to_question": [
                    1.2834451595234835,
                    1.0447647085672553,
                    2.671790131909261
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    2.0
                ],
                "result_count_noun_chunks": [
                    3360.0,
                    2360.0,
                    142000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    1016.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    1147.0
                ],
                "word_count_appended": [
                    15.0,
                    111.0,
                    1411.0
                ],
                "result_count": [
                    3320.0,
                    10300.0,
                    8250000.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which of these video games was NOT produced by FromSoftware?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "beyond: two souls"
            ],
            "lines": [
                [
                    0.24198977412981554,
                    0.05851063829787234,
                    0.010091897108807868,
                    0.11291038154392191,
                    0.11868563021088768,
                    0.3576882323610072,
                    0.22451456310679613,
                    0.06944444444444442,
                    0.08620689655172414,
                    -1.0
                ],
                [
                    0.3799029269734897,
                    0.5,
                    0.4964961604632621,
                    0.46029281277728484,
                    0.45843550760176555,
                    0.4148591373722264,
                    0.4526699029126214,
                    0.5,
                    0.5,
                    -1.0
                ],
                [
                    0.3781072988966948,
                    0.44148936170212766,
                    0.49341194242793,
                    0.42679680567879325,
                    0.4228788621873467,
                    0.22745263026676638,
                    0.3228155339805825,
                    0.4305555555555556,
                    0.41379310344827586,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "dark souls": 0.7155461204988273,
                "beyond: two souls": 0.0749652337554111,
                "demon's souls": 0.20948864574576162
            },
            "question": "which of these video games was not produced by fromsoftware?",
            "rate_limited": false,
            "answers": [
                "dark souls",
                "beyond: two souls",
                "demon's souls"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "dark souls": 0.14756591634641025,
                "beyond: two souls": 0.2709999234592075,
                "demon's souls": 0.13852419068723817
            },
            "integer_answers": {
                "dark souls": 8,
                "beyond: two souls": 0,
                "demon's souls": 1
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    698000.0,
                    71600.0,
                    132000.0
                ],
                "wikipedia_search": [
                    0.8538706058339567,
                    0.5108451757666417,
                    1.6352842183994016
                ],
                "answer_relation_to_question": [
                    2.0640818069614757,
                    0.9607765842120823,
                    0.9751416088264417
                ],
                "question_related_to_answer": [
                    0.8829787234042553,
                    0.0,
                    0.11702127659574468
                ],
                "result_count_noun_chunks": [
                    311000.0,
                    33900.0,
                    62900.0
                ],
                "word_count_noun_chunks": [
                    62.0,
                    0.0,
                    10.0
                ],
                "word_count_raw": [
                    72.0,
                    0.0,
                    15.0
                ],
                "result_count": [
                    4670000.0,
                    33400.0,
                    62800.0
                ],
                "word_count_appended": [
                    227.0,
                    39.0,
                    146.0
                ]
            },
            "negative_question": true
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Which of these athletes has a notably obscured glabella?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "michael phelps"
            ],
            "lines": [
                [
                    0.875,
                    1.0,
                    0.6111111111111112,
                    0.5416666666666666,
                    0.5652173913043478,
                    0.45,
                    0.42857142857142855,
                    0,
                    0,
                    -1.0
                ],
                [
                    0.0,
                    0.0,
                    0.2222222222222222,
                    0.2916666666666667,
                    0.30434782608695654,
                    0.0,
                    0.2857142857142857,
                    0,
                    0,
                    -1.0
                ],
                [
                    0.125,
                    0.0,
                    0.16666666666666666,
                    0.16666666666666666,
                    0.13043478260869565,
                    0.55,
                    0.2857142857142857,
                    0,
                    0,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "michael strahan": 0.15770728581287588,
                "michael phelps": 0.638795228236222,
                "anthony davis": 0.20349748595090209
            },
            "question": "which of these athletes has a notably obscured glabella?",
            "rate_limited": false,
            "answers": [
                "michael phelps",
                "michael strahan",
                "anthony davis"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "michael strahan": 0.1553127892132356,
                "michael phelps": 0.3759114880554262,
                "anthony davis": 0.3405695038570539
            },
            "integer_answers": {
                "michael strahan": 0,
                "michael phelps": 6,
                "anthony davis": 1
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    13.0,
                    7.0,
                    4.0
                ],
                "wikipedia_search": [
                    0.9,
                    0.0,
                    1.1
                ],
                "answer_relation_to_question": [
                    0.875,
                    0.0,
                    0.125
                ],
                "question_related_to_answer": [
                    1.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    13.0,
                    7.0,
                    3.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_appended": [
                    6.0,
                    4.0,
                    4.0
                ],
                "result_count": [
                    22.0,
                    8.0,
                    6.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which of these is NOT a marsupial?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "quintana roo"
            ],
            "lines": [
                [
                    0.5,
                    0.5,
                    0.491544322616614,
                    0.45533839444354707,
                    0.4557174887892377,
                    0.5,
                    0.47,
                    0.5,
                    0.5,
                    -1.0
                ],
                [
                    0.2164179104477612,
                    0.46875,
                    0.4614383943504925,
                    0.4589727023098046,
                    0.45507687379884687,
                    0.5,
                    0.28833333333333333,
                    0.46875,
                    0.4230769230769231,
                    -1.0
                ],
                [
                    0.28358208955223885,
                    0.03125,
                    0.04701728303289349,
                    0.08568890324664835,
                    0.08920563741191545,
                    0.0,
                    0.24166666666666664,
                    0.03125,
                    0.07692307692307693,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "cuscus": 0.1687075250406308,
                "quintana roo": 0.028311065366800274,
                "wombat": 0.802981409592569
            },
            "question": "which of these is not a marsupial?",
            "rate_limited": false,
            "answers": [
                "quintana roo",
                "cuscus",
                "wombat"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "cuscus": 0.2718638728920135,
                "quintana roo": 0.6484675813992543,
                "wombat": 0.08717557882638176
            },
            "integer_answers": {
                "cuscus": 1,
                "quintana roo": 0,
                "wombat": 8
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    55300.0,
                    50800.0,
                    513000.0
                ],
                "wikipedia_search": [
                    0.0,
                    0.0,
                    1.0
                ],
                "answer_relation_to_question": [
                    0.0,
                    0.5671641791044776,
                    0.43283582089552236
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0625,
                    0.9375
                ],
                "result_count_noun_chunks": [
                    55300.0,
                    56100.0,
                    513000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    1.0,
                    15.0
                ],
                "word_count_raw": [
                    0.0,
                    2.0,
                    11.0
                ],
                "word_count_appended": [
                    72.0,
                    508.0,
                    620.0
                ],
                "result_count": [
                    36400.0,
                    166000.0,
                    1950000.0
                ]
            },
            "negative_question": true
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which of these is NOT the title of a current TV show?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "chicage fire"
            ],
            "lines": [
                [
                    0.26557890901886916,
                    0,
                    0.40657059110893995,
                    0.4356243949661181,
                    0.28478057889822594,
                    0.36738147822985545,
                    0.17824074074074076,
                    0,
                    0,
                    -1.0
                ],
                [
                    0.2924089491948847,
                    0,
                    0.2044455300439668,
                    0.20571151984511132,
                    0.2647058823529412,
                    0.3006615407830119,
                    0.49537037037037035,
                    0,
                    0,
                    -1.0
                ],
                [
                    0.44201214178624615,
                    0,
                    0.38898387884709335,
                    0.3586640851887706,
                    0.4505135387488329,
                    0.33195698098713267,
                    0.3263888888888889,
                    0,
                    0,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "chicago med": 0.3539411023457502,
                "chicago police": 0.23382682851767847,
                "chicage fire": 0.41223206913657123
            },
            "question": "which of these is not the title of a current tv show?",
            "rate_limited": false,
            "answers": [
                "chicago med",
                "chicage fire",
                "chicago police"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "chicago med": 0.30562897892258606,
                "chicago police": 0.45964631982040627,
                "chicage fire": 0.4911968641701461
            },
            "integer_answers": {
                "chicago med": 2,
                "chicago police": 0,
                "chicage fire": 4
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    66500.0,
                    304000.0,
                    146000.0
                ],
                "wikipedia_search": [
                    0.7957111306208675,
                    1.1960307553019287,
                    1.0082581140772038
                ],
                "answer_relation_to_question": [
                    1.4065265458867853,
                    1.2455463048306916,
                    0.3479271492825231
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    461000.0,
                    504000.0,
                    106000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_appended": [
                    139.0,
                    2.0,
                    75.0
                ],
                "result_count": [
                    76500.0,
                    242000.0,
                    90900.0
                ]
            },
            "negative_question": true
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which of these things is NOT found inside an atom?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "proton"
            ],
            "lines": [
                [
                    0.34671800513384676,
                    0.21875,
                    0.2762809718547029,
                    0.27774234693877553,
                    0.25655430711610483,
                    0.32073643410852715,
                    0.318859649122807,
                    0.21551724137931033,
                    0.1923076923076923,
                    -1.0
                ],
                [
                    0.3055555555555556,
                    0.5,
                    0.46788549434688476,
                    0.4492984693877551,
                    0.4541198501872659,
                    0.29761904761904767,
                    0.3649122807017544,
                    0.5,
                    0.5,
                    -1.0
                ],
                [
                    0.34772643931059777,
                    0.28125,
                    0.25583353379841234,
                    0.2729591836734694,
                    0.2893258426966292,
                    0.38164451827242524,
                    0.31622807017543864,
                    0.28448275862068967,
                    0.3076923076923077,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "wonton": 0.14680206715594146,
                "proton": 0.46145185600849636,
                "neutron": 0.3917460768355623
            },
            "question": "which of these things is not found inside an atom?",
            "rate_limited": false,
            "answers": [
                "proton",
                "wonton",
                "neutron"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "wonton": 0.24448788663100535,
                "proton": 0.43964996991703714,
                "neutron": 0.2215807125122044
            },
            "integer_answers": {
                "wonton": 2,
                "proton": 4,
                "neutron": 3
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    697000.0,
                    159000.0,
                    712000.0
                ],
                "wikipedia_search": [
                    1.0755813953488373,
                    1.2142857142857142,
                    0.7101328903654485
                ],
                "answer_relation_to_question": [
                    0.9196919691969196,
                    1.1666666666666667,
                    0.9136413641364136
                ],
                "question_related_to_answer": [
                    0.5625,
                    0.0,
                    0.4375
                ],
                "result_count_noun_chunks": [
                    208000.0,
                    39200.0,
                    180000.0
                ],
                "word_count_noun_chunks": [
                    33.0,
                    0.0,
                    25.0
                ],
                "word_count_raw": [
                    72.0,
                    0.0,
                    45.0
                ],
                "word_count_appended": [
                    413.0,
                    308.0,
                    419.0
                ],
                "result_count": [
                    186000.0,
                    26700.0,
                    203000.0
                ]
            },
            "negative_question": true
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "What actor famously yelled \"Not the bees! Not the bees!\" in a 2006 film?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "macauley culkin"
            ],
            "lines": [
                [
                    0.09728984096072701,
                    0.0,
                    0.1111111111111111,
                    0.4512723335138062,
                    0.22972972972972971,
                    0.3038935430478885,
                    0.26666666666666666,
                    0.0,
                    0.0,
                    1.0
                ],
                [
                    0.4186140863356053,
                    0.5,
                    0.5,
                    0.49973950618545115,
                    0.4899480761549727,
                    0.3826627183370782,
                    0.45,
                    0.5,
                    0.5,
                    1.0
                ],
                [
                    0.4840960727036676,
                    0.5,
                    0.3888888888888889,
                    0.048988160300742656,
                    0.2803221941152976,
                    0.3134437386150333,
                    0.2833333333333333,
                    0.5,
                    0.5,
                    1.0
                ]
            ],
            "fraction_answers": {
                "macauley culkin": 0.0575634695526428,
                "nicolas cage": 0.6755637277711268,
                "oprah winfrey": 0.26687280267623037
            },
            "question": "what actor famously yelled \"not the bees! not the bees!\" in a 2006 film?",
            "rate_limited": false,
            "answers": [
                "nicolas cage",
                "macauley culkin",
                "oprah winfrey"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "macauley culkin": 0.7400780518271077,
                "nicolas cage": 0.10349017719581588,
                "oprah winfrey": 0.7263995178063906
            },
            "integer_answers": {
                "macauley culkin": 0,
                "nicolas cage": 8,
                "oprah winfrey": 1
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    9540.0,
                    51.0,
                    88300.0
                ],
                "wikipedia_search": [
                    1.176638741712669,
                    0.7040236899775306,
                    1.1193375683098006
                ],
                "answer_relation_to_question": [
                    3.221681272314184,
                    0.6510873093151575,
                    0.12723141837065888
                ],
                "question_related_to_answer": [
                    3.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    406000.0,
                    15100.0,
                    330000.0
                ],
                "word_count_noun_chunks": [
                    13.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    3.0,
                    0.0,
                    0.0
                ],
                "word_count_appended": [
                    14.0,
                    3.0,
                    13.0
                ],
                "result_count": [
                    14.0,
                    0,
                    4.0
                ]
            },
            "negative_question": true
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Mardi Gras is celebrated right before what other observance?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "lent"
            ],
            "lines": [
                [
                    0.5021104095521214,
                    1.0,
                    0.5832793259883344,
                    0.7564365459102301,
                    0.25012607160867373,
                    0.4016225749559083,
                    0.458133971291866,
                    1.0,
                    1.0,
                    1.0
                ],
                [
                    0.2990442964892022,
                    0.0,
                    0.1510045366169799,
                    0.20186830713146503,
                    0.25769036812909735,
                    0.28557319223985894,
                    0.291866028708134,
                    0.0,
                    0.0,
                    1.0
                ],
                [
                    0.19884529395867623,
                    0.0,
                    0.2657161373946857,
                    0.041695146958304855,
                    0.4921835602622289,
                    0.3128042328042328,
                    0.25,
                    0.0,
                    0.0,
                    1.0
                ]
            ],
            "fraction_answers": {
                "kwanzaa": 0.16522741436830418,
                "ramadan": 0.17347159681979207,
                "lent": 0.6613009888119037
            },
            "question": "mardi gras is celebrated right before what other observance?",
            "rate_limited": false,
            "answers": [
                "lent",
                "kwanzaa",
                "ramadan"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "kwanzaa": 0.2440215324284052,
                "ramadan": 0.1797351040967209,
                "lent": 0.7460616653060692
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    166000.0,
                    44300.0,
                    9150.0
                ],
                "wikipedia_search": [
                    1.2048677248677249,
                    0.8567195767195768,
                    0.9384126984126984
                ],
                "answer_relation_to_question": [
                    2.5105520477606076,
                    1.4952214824460115,
                    0.9942264697933814
                ],
                "question_related_to_answer": [
                    2.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    49600.0,
                    51100.0,
                    97600.0
                ],
                "word_count_noun_chunks": [
                    65.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    111.0,
                    0.0,
                    0.0
                ],
                "word_count_appended": [
                    383.0,
                    244.0,
                    209.0
                ],
                "result_count": [
                    180000.0,
                    46600.0,
                    82000.0
                ]
            },
            "integer_answers": {
                "kwanzaa": 0,
                "ramadan": 1,
                "lent": 8
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "In which state is happy hour currently banned?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "illinois"
            ],
            "lines": [
                [
                    0.6364314679643147,
                    0.8333333333333334,
                    0.744043043812452,
                    0.5276653171390013,
                    0.18694362017804153,
                    0.39244089834515367,
                    0.4819277108433735,
                    1.0,
                    0.9272727272727272,
                    -1.0
                ],
                [
                    0.2043471208434712,
                    0.16666666666666669,
                    0.2167563412759416,
                    0.4426450742240216,
                    0.5717111770524234,
                    0.2851418439716312,
                    0.42606790799561883,
                    0.0,
                    0.01818181818181818,
                    -1.0
                ],
                [
                    0.1592214111922141,
                    0.0,
                    0.03920061491160646,
                    0.029689608636977057,
                    0.2413452027695351,
                    0.32241725768321516,
                    0.09200438116100766,
                    0.0,
                    0.05454545454545454,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "arizona": 0.25905755002351033,
                "illinois": 0.636673124320933,
                "rhode island": 0.1042693256555567
            },
            "question": "in which state is happy hour currently banned?",
            "rate_limited": false,
            "answers": [
                "illinois",
                "arizona",
                "rhode island"
            ],
            "ml_answers": {
                "arizona": 0.17163254260246813,
                "illinois": 0.7513087165518144,
                "rhode island": 0.07675048207005011
            },
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "integer_answers": {
                "arizona": 1,
                "illinois": 8,
                "rhode island": 0
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    3910000.0,
                    3280000.0,
                    220000.0
                ],
                "wikipedia_search": [
                    1.5697635933806147,
                    1.140567375886525,
                    1.2896690307328607
                ],
                "answer_relation_to_question": [
                    1.909294403892944,
                    0.6130413625304136,
                    0.47766423357664234
                ],
                "question_related_to_answer": [
                    1.6666666666666665,
                    0.3333333333333333,
                    0.0
                ],
                "result_count_noun_chunks": [
                    1890000.0,
                    5780000.0,
                    2440000.0
                ],
                "word_count_noun_chunks": [
                    25.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    51.0,
                    1.0,
                    3.0
                ],
                "result_count": [
                    4840000.0,
                    1410000.0,
                    255000.0
                ],
                "word_count_appended": [
                    440.0,
                    389.0,
                    84.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "In baking, yeast helps bread rise, but scientifically yeast is what?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "fungus"
            ],
            "lines": [
                [
                    0.6,
                    0.5897435897435898,
                    0.654296875,
                    0.6555772994129159,
                    0.028700205474912175,
                    0.8807241145950824,
                    0.34221598877980364,
                    0.47368421052631576,
                    0.6206896551724138,
                    1.0
                ],
                [
                    0.2,
                    0.1282051282051282,
                    0.1748046875,
                    0.17465753424657535,
                    0.9345794392523364,
                    0.06468531468531469,
                    0.3141654978962132,
                    0.42105263157894735,
                    0.2413793103448276,
                    1.0
                ],
                [
                    0.2,
                    0.28205128205128205,
                    0.1708984375,
                    0.1697651663405088,
                    0.03672035527275137,
                    0.05459057071960298,
                    0.3436185133239832,
                    0.10526315789473684,
                    0.13793103448275862,
                    1.0
                ]
            ],
            "fraction_answers": {
                "fungus": 0.5384035487450037,
                "plant": 0.2948366159677047,
                "bacteria": 0.16675983528729155
            },
            "question": "in baking, yeast helps bread rise, but scientifically yeast is what?",
            "rate_limited": false,
            "answers": [
                "fungus",
                "plant",
                "bacteria"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "fungus": 0.4871279847872557,
                "plant": 0.12043041705231264,
                "bacteria": 0.42769739117448546
            },
            "integer_answers": {
                "fungus": 7,
                "plant": 1,
                "bacteria": 1
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    1340000.0,
                    357000.0,
                    347000.0
                ],
                "wikipedia_search": [
                    3.5228964583803295,
                    0.25874125874125875,
                    0.21836228287841192
                ],
                "answer_relation_to_question": [
                    3.0,
                    1.0,
                    1.0
                ],
                "question_related_to_answer": [
                    1.1794871794871795,
                    0.2564102564102564,
                    0.5641025641025641
                ],
                "result_count_noun_chunks": [
                    433000.0,
                    14100000.0,
                    554000.0
                ],
                "word_count_noun_chunks": [
                    9.0,
                    8.0,
                    2.0
                ],
                "word_count_raw": [
                    18.0,
                    7.0,
                    4.0
                ],
                "result_count": [
                    1340000.0,
                    358000.0,
                    350000.0
                ],
                "word_count_appended": [
                    244.0,
                    224.0,
                    245.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which of these is classified as a neurological condition or disorder?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "multiple sclerosis"
            ],
            "lines": [
                [
                    0.1705711656875929,
                    0.0,
                    0.0037150818032435523,
                    0.6709677419354839,
                    0.004195029286053507,
                    0.28756674294431733,
                    0.5116279069767442,
                    0.0,
                    0.0,
                    -1.0
                ],
                [
                    0.24269233491400666,
                    0.0,
                    0.031792526970065016,
                    0.1235483870967742,
                    0.022241570365679912,
                    0.20404271548436306,
                    0.24086378737541528,
                    0.0,
                    0.0,
                    -1.0
                ],
                [
                    0.5867364993984004,
                    1.0,
                    0.9644923912266914,
                    0.20548387096774193,
                    0.9735634003482666,
                    0.5083905415713196,
                    0.24750830564784054,
                    1.0,
                    1.0,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "halitosis": 0.18318262984815947,
                "cystic fibrosis": 0.09613125802292269,
                "multiple sclerosis": 0.7206861121289179
            },
            "question": "which of these is classified as a neurological condition or disorder?",
            "rate_limited": false,
            "answers": [
                "halitosis",
                "cystic fibrosis",
                "multiple sclerosis"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "halitosis": 0.27025185182956235,
                "cystic fibrosis": 0.2184196510504762,
                "multiple sclerosis": 0.7058080813396413
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    2080000.0,
                    383000.0,
                    637000.0
                ],
                "wikipedia_search": [
                    0.8627002288329519,
                    0.6121281464530892,
                    1.5251716247139586
                ],
                "answer_relation_to_question": [
                    0.5117134970627787,
                    0.72807700474202,
                    1.7602094981952012
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    1.0
                ],
                "result_count_noun_chunks": [
                    106000.0,
                    562000.0,
                    24600000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    3.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    7.0
                ],
                "result_count": [
                    93600.0,
                    801000.0,
                    24300000.0
                ],
                "word_count_appended": [
                    308.0,
                    145.0,
                    149.0
                ]
            },
            "integer_answers": {
                "halitosis": 2,
                "cystic fibrosis": 0,
                "multiple sclerosis": 7
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which of these Uranus moons is NOT named after a Shakespearean character?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "oberon"
            ],
            "lines": [
                [
                    0.46963283403073985,
                    0.10060975609756095,
                    0.11502305385200769,
                    0.11872360394181136,
                    0.11499087550629811,
                    0.47074468085106386,
                    0.28504043126684636,
                    0.17924528301886794,
                    0.21311475409836067,
                    -1.0
                ],
                [
                    0.2127291839333724,
                    0.4024390243902439,
                    0.3963695778683021,
                    0.393633661817613,
                    0.396069791249388,
                    0.20186170212765955,
                    0.3335579514824798,
                    0.34905660377358494,
                    0.29508196721311475,
                    -1.0
                ],
                [
                    0.31763798203588783,
                    0.4969512195121951,
                    0.48860736827969026,
                    0.48764273424057564,
                    0.4889393332443139,
                    0.3273936170212766,
                    0.38140161725067384,
                    0.4716981132075472,
                    0.4918032786885246,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "oberon": 0.5406388282969874,
                "trinculo": 0.12176105255984782,
                "umbriel": 0.3376001191431648
            },
            "question": "which of these uranus moons is not named after a shakespearean character?",
            "rate_limited": false,
            "answers": [
                "oberon",
                "umbriel",
                "trinculo"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "oberon": 0.3076069747897771,
                "trinculo": 0.04287767128149946,
                "umbriel": 0.15105628240894703
            },
            "negative_question": true,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    19500.0,
                    5440.0,
                    632.0
                ],
                "wikipedia_search": [
                    0.23404255319148937,
                    2.3851063829787233,
                    1.380851063829787
                ],
                "answer_relation_to_question": [
                    0.3036716596926021,
                    2.872708160666276,
                    1.823620179641122
                ],
                "question_related_to_answer": [
                    1.5975609756097562,
                    0.3902439024390244,
                    0.012195121951219513
                ],
                "result_count_noun_chunks": [
                    17300.0,
                    4670.0,
                    497.0
                ],
                "word_count_noun_chunks": [
                    34.0,
                    16.0,
                    3.0
                ],
                "word_count_raw": [
                    35.0,
                    25.0,
                    1.0
                ],
                "result_count": [
                    17200.0,
                    4630.0,
                    509.0
                ],
                "word_count_appended": [
                    319.0,
                    247.0,
                    176.0
                ]
            },
            "integer_answers": {
                "oberon": 7,
                "trinculo": 0,
                "umbriel": 2
            }
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Which of these knots is typically used to add another line to a rope?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "bowline"
            ],
            "lines": [
                [
                    0.5062403237974451,
                    1.0,
                    0.5233494363929146,
                    0.40652557319223986,
                    0.91324200913242,
                    0.5455273736757995,
                    0.6045081967213115,
                    0.8636363636363636,
                    0.9285714285714286,
                    -1.0
                ],
                [
                    0.3729278149497799,
                    0.0,
                    0.29549114331723025,
                    0.37213403880070545,
                    0.049502837878205946,
                    0.39576091075341446,
                    0.1680327868852459,
                    0.13636363636363635,
                    0.07142857142857142,
                    -1.0
                ],
                [
                    0.12083186125277497,
                    0.0,
                    0.18115942028985507,
                    0.22134038800705466,
                    0.03725515298937396,
                    0.058711715570786034,
                    0.22745901639344263,
                    0.0,
                    0.0,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "grantchester": 0.09408417272258747,
                "rolling hitch": 0.20684908226408774,
                "bowline": 0.6990667450133247
            },
            "question": "which of these knots is typically used to add another line to a rope?",
            "rate_limited": false,
            "answers": [
                "bowline",
                "rolling hitch",
                "grantchester"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "grantchester": 0.27279739929894453,
                "rolling hitch": 0.25189385447718005,
                "bowline": 0.8555938027464317
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    46100.0,
                    42200.0,
                    25100.0
                ],
                "wikipedia_search": [
                    2.182109494703198,
                    1.5830436430136579,
                    0.23484686228314414
                ],
                "answer_relation_to_question": [
                    2.0249612951897804,
                    1.4917112597991196,
                    0.48332744501109987
                ],
                "question_related_to_answer": [
                    1.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    214000.0,
                    11600.0,
                    8730.0
                ],
                "word_count_noun_chunks": [
                    19.0,
                    3.0,
                    0.0
                ],
                "word_count_raw": [
                    13.0,
                    1.0,
                    0.0
                ],
                "word_count_appended": [
                    295.0,
                    82.0,
                    111.0
                ],
                "result_count": [
                    65000.0,
                    36700.0,
                    22500.0
                ]
            },
            "integer_answers": {
                "grantchester": 0,
                "rolling hitch": 0,
                "bowline": 9
            }
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Which of these celebrities is known for having aviophobia?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "john madden"
            ],
            "lines": [
                [
                    0.39345238095238094,
                    0.5,
                    0.4444444444444444,
                    0.42543859649122806,
                    0.43,
                    0.8344907407407408,
                    0.4567901234567901,
                    0.125,
                    0.25,
                    -1.0
                ],
                [
                    0.27619047619047615,
                    0.25,
                    0.24444444444444444,
                    0.2982456140350877,
                    0.29,
                    0.07423941798941798,
                    0.37037037037037035,
                    0.5,
                    0.5,
                    -1.0
                ],
                [
                    0.33035714285714285,
                    0.25,
                    0.3111111111111111,
                    0.27631578947368424,
                    0.28,
                    0.09126984126984126,
                    0.1728395061728395,
                    0.375,
                    0.25,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "angelina jolie": 0.4288462540095094,
                "john travolta": 0.25965482120940214,
                "john madden": 0.31149892478108854
            },
            "question": "which of these celebrities is known for having aviophobia?",
            "rate_limited": false,
            "answers": [
                "angelina jolie",
                "john madden",
                "john travolta"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "angelina jolie": 0.19940461732341627,
                "john travolta": 0.1789613869503611,
                "john madden": 0.2809090157825442
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    97.0,
                    68.0,
                    63.0
                ],
                "wikipedia_search": [
                    2.5034722222222223,
                    0.22271825396825395,
                    0.2738095238095238
                ],
                "answer_relation_to_question": [
                    1.1803571428571429,
                    0.8285714285714285,
                    0.9910714285714286
                ],
                "question_related_to_answer": [
                    1.0,
                    0.5,
                    0.5
                ],
                "result_count_noun_chunks": [
                    86.0,
                    58.0,
                    56.0
                ],
                "word_count_noun_chunks": [
                    1.0,
                    4.0,
                    3.0
                ],
                "word_count_raw": [
                    1.0,
                    2.0,
                    1.0
                ],
                "result_count": [
                    80.0,
                    44.0,
                    56.0
                ],
                "word_count_appended": [
                    37.0,
                    30.0,
                    14.0
                ]
            },
            "integer_answers": {
                "angelina jolie": 7,
                "john travolta": 0,
                "john madden": 2
            }
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "By definition, an Anglophile would be most interested in which of these things?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "geometry"
            ],
            "lines": [
                [
                    0.7000000000000001,
                    0.0,
                    0.40993087621568103,
                    0.08552655579290414,
                    0.4094778007821486,
                    0.26666666666666666,
                    0.7212389380530974,
                    0,
                    0,
                    -1.0
                ],
                [
                    0.20000000000000004,
                    1.0,
                    0.5894491380347378,
                    0.9120130357063237,
                    0.5898320680929376,
                    0.7333333333333334,
                    0.2345132743362832,
                    0,
                    0,
                    -1.0
                ],
                [
                    0.10000000000000002,
                    0.0,
                    0.0006199857495812783,
                    0.002460408500772171,
                    0.0006901311249137336,
                    0.0,
                    0.04424778761061947,
                    0,
                    0,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "geometry": 0.37040583393007115,
                "downton abbey": 0.6084486927862308,
                "trout fishing": 0.021145473283698094
            },
            "question": "by definition, an anglophile would be most interested in which of these things?",
            "rate_limited": false,
            "answers": [
                "geometry",
                "downton abbey",
                "trout fishing"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "geometry": 0.559926762646282,
                "downton abbey": 0.1793896560789853,
                "trout fishing": 0.08288375692225236
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    211000.0,
                    2250000.0,
                    6070.0
                ],
                "wikipedia_search": [
                    0.8,
                    2.2,
                    0.0
                ],
                "answer_relation_to_question": [
                    1.4,
                    0.4,
                    0.2
                ],
                "question_related_to_answer": [
                    0.0,
                    1.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    44500.0,
                    64100.0,
                    75.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count": [
                    44300.0,
                    63700.0,
                    67.0
                ],
                "word_count_appended": [
                    163.0,
                    53.0,
                    10.0
                ]
            },
            "integer_answers": {
                "geometry": 2,
                "downton abbey": 5,
                "trout fishing": 0
            }
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Who wrote a #1 hit song for the Monkees?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "neil diamond"
            ],
            "lines": [
                [
                    0.24110499169507824,
                    0.0,
                    0.3333333333333333,
                    0.2693689071318625,
                    0.3333333333333333,
                    0.5366170441366657,
                    0,
                    0,
                    0,
                    0.0
                ],
                [
                    0.46952387627324543,
                    1.0,
                    0.3333333333333333,
                    0.5618265777321704,
                    0.3333333333333333,
                    0.2946559946743365,
                    0,
                    0,
                    0,
                    0.0
                ],
                [
                    0.2893711320316763,
                    0.0,
                    0.3333333333333333,
                    0.16880451513596717,
                    0.3333333333333333,
                    0.16872696118899783,
                    0,
                    0,
                    0,
                    0.0
                ]
            ],
            "fraction_answers": {
                "neil diamond": 0.4987788525577365,
                "james taylor": 0.28562626827171217,
                "jackson browne": 0.2155948791705513
            },
            "question": "who wrote a #1 hit song for the monkees?",
            "rate_limited": false,
            "answers": [
                "james taylor",
                "neil diamond",
                "jackson browne"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "neil diamond": 0.3943668628553823,
                "james taylor": 0.31691140669578943,
                "jackson browne": 0.05325269578113871
            },
            "integer_answers": {
                "neil diamond": 3,
                "james taylor": 3,
                "jackson browne": 0
            },
            "categorical_data": {
                "question_type": 0
            },
            "data": {
                "result_count_important_words": [
                    105000.0,
                    219000.0,
                    65800.0
                ],
                "wikipedia_search": [
                    2.1464681765466627,
                    1.178623978697346,
                    0.6749078447559913
                ],
                "answer_relation_to_question": [
                    0.9644199667803129,
                    1.8780955050929817,
                    1.1574845281267052
                ],
                "question_related_to_answer": [
                    0.0,
                    1.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    12480000000.0,
                    12480000000.0,
                    12480000000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count": [
                    72900000.0,
                    72900000.0,
                    72900000.0
                ],
                "word_count_appended": [
                    0.0,
                    0.0,
                    0.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Anne of Green Gables literally means Anne of what?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "green walls"
            ],
            "lines": [
                [
                    0.4763071895424837,
                    0,
                    0.5256410256410257,
                    0.5636363636363636,
                    0.22758696636362524,
                    0.08333333333333333,
                    0.4473684210526316,
                    0,
                    0,
                    1.0
                ],
                [
                    0.35749299719887956,
                    0,
                    0.038461538461538464,
                    0.05454545454545454,
                    0.000330368176979456,
                    0.430952380952381,
                    0.07894736842105263,
                    0,
                    0,
                    1.0
                ],
                [
                    0.16619981325863678,
                    0,
                    0.4358974358974359,
                    0.38181818181818183,
                    0.7720826654593953,
                    0.4857142857142857,
                    0.47368421052631576,
                    0,
                    0,
                    1.0
                ]
            ],
            "fraction_answers": {
                "green pastures": 0.38731221659491055,
                "green walls": 0.45256609877904186,
                "green jars": 0.1601216846260476
            },
            "question": "anne of green gables literally means anne of what?",
            "rate_limited": false,
            "answers": [
                "green pastures",
                "green jars",
                "green walls"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "green pastures": 0.36493826436422533,
                "green walls": 0.4047704360316481,
                "green jars": 0.37876754007329616
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    62.0,
                    6.0,
                    42.0
                ],
                "wikipedia_search": [
                    0.3333333333333333,
                    1.723809523809524,
                    1.9428571428571428
                ],
                "answer_relation_to_question": [
                    1.9052287581699345,
                    1.429971988795518,
                    0.664799253034547
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    18600.0,
                    27.0,
                    63100.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count": [
                    41.0,
                    3.0,
                    34.0
                ],
                "word_count_appended": [
                    17.0,
                    3.0,
                    18.0
                ]
            },
            "integer_answers": {
                "green pastures": 3,
                "green walls": 3,
                "green jars": 0
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "What Japanese word means \u201cempty orchestra\u201d?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "karaoke"
            ],
            "lines": [
                [
                    0.21336996336996336,
                    0.0,
                    0.05077262693156733,
                    0.34825425246195163,
                    0.1239356669820246,
                    0.15625,
                    0.18890074706510138,
                    0.0,
                    0.0,
                    1.0
                ],
                [
                    0.3126831501831502,
                    0.3926767676767677,
                    0.052980132450331126,
                    0.30214861235452106,
                    0.37748344370860926,
                    0.4270833333333333,
                    0.21664887940234792,
                    0.018050541516245487,
                    0.01607717041800643,
                    1.0
                ],
                [
                    0.47394688644688643,
                    0.6073232323232323,
                    0.8962472406181016,
                    0.3495971351835273,
                    0.4985808893093661,
                    0.4166666666666667,
                    0.5944503735325507,
                    0.9819494584837545,
                    0.9839228295819936,
                    1.0
                ]
            ],
            "fraction_answers": {
                "sake": 0.12016480631228982,
                "anime": 0.2350924478937014,
                "karaoke": 0.6447427457940089
            },
            "question": "what japanese word means \u201cempty orchestra\u201d?",
            "rate_limited": false,
            "answers": [
                "sake",
                "anime",
                "karaoke"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "sake": 0.0856926431189189,
                "anime": -0.012867514499257927,
                "karaoke": 0.6955055229748484
            },
            "integer_answers": {
                "sake": 0,
                "anime": 1,
                "karaoke": 8
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    778000.0,
                    675000.0,
                    781000.0
                ],
                "wikipedia_search": [
                    0.625,
                    1.7083333333333333,
                    1.6666666666666667
                ],
                "answer_relation_to_question": [
                    0.8534798534798534,
                    1.2507326007326007,
                    1.8957875457875457
                ],
                "question_related_to_answer": [
                    0.0,
                    0.7853535353535354,
                    1.2146464646464645
                ],
                "result_count_noun_chunks": [
                    13100.0,
                    39900.0,
                    52700.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    5.0,
                    272.0
                ],
                "word_count_raw": [
                    0.0,
                    5.0,
                    306.0
                ],
                "word_count_appended": [
                    177.0,
                    203.0,
                    557.0
                ],
                "result_count": [
                    1150.0,
                    1200.0,
                    20300.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "What is Telluride, Colorado named after?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "an element"
            ],
            "lines": [
                [
                    0.3333333333333333,
                    0,
                    0.9125025704297759,
                    0.9974330108860288,
                    0.8655101660138034,
                    0,
                    0.5405405405405406,
                    0,
                    0,
                    1.0
                ],
                [
                    0.0,
                    0,
                    0.0873946123791898,
                    0.002549618089624399,
                    0.08860287259839582,
                    0,
                    0.36936936936936937,
                    0,
                    0,
                    1.0
                ],
                [
                    0.6666666666666666,
                    0,
                    0.00010281719103434094,
                    1.737102434689151e-05,
                    0.04588696138780078,
                    0,
                    0.09009009009009009,
                    0,
                    0,
                    1.0
                ]
            ],
            "fraction_answers": {
                "a european city": 0.16055278127198777,
                "an element": 0.7298639242406963,
                "a governor": 0.1095832944873159
            },
            "question": "what is telluride, colorado named after?",
            "rate_limited": false,
            "answers": [
                "an element",
                "a governor",
                "a european city"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "a european city": 0.2375792738706015,
                "an element": 0.30976866078618326,
                "a governor": 0.23786244307385773
            },
            "integer_answers": {
                "a european city": 1,
                "an element": 4,
                "a governor": 0
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    1780000.0,
                    4550.0,
                    31.0
                ],
                "wikipedia_search": [
                    0.0,
                    0.0,
                    0.0
                ],
                "answer_relation_to_question": [
                    0.3333333333333333,
                    0.0,
                    0.6666666666666666
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    46400000.0,
                    4750000.0,
                    2460000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count": [
                    213000.0,
                    20400.0,
                    24.0
                ],
                "word_count_appended": [
                    60.0,
                    41.0,
                    10.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which of these is NOT a suit in a traditional Tarot deck?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "gloves"
            ],
            "lines": [
                [
                    0.46153846153846156,
                    0.5,
                    0.40610802624936904,
                    0.42345132743362834,
                    0.4235190097259063,
                    0.24043062200956938,
                    0.3979695431472081,
                    0.5,
                    0.5,
                    -1.0
                ],
                [
                    0.1291208791208791,
                    0.25,
                    0.284452296819788,
                    0.2831858407079646,
                    0.2833775419982316,
                    0.3181818181818182,
                    0.2939086294416243,
                    0.20370370370370372,
                    0.2556818181818182,
                    -1.0
                ],
                [
                    0.40934065934065933,
                    0.25,
                    0.309439676930843,
                    0.29336283185840706,
                    0.2931034482758621,
                    0.44138755980861244,
                    0.3081218274111675,
                    0.2962962962962963,
                    0.24431818181818182,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "gloves": 0.14377400219907943,
                "cups": 0.3676954485022157,
                "swords": 0.488530549298705
            },
            "question": "which of these is not a suit in a traditional tarot deck?",
            "rate_limited": false,
            "answers": [
                "gloves",
                "swords",
                "cups"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "integer_answers": {
                "gloves": 1,
                "cups": 1,
                "swords": 7
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    173000.0,
                    490000.0,
                    467000.0
                ],
                "wikipedia_search": [
                    1.0382775119617225,
                    0.7272727272727273,
                    0.23444976076555024
                ],
                "answer_relation_to_question": [
                    0.3076923076923077,
                    2.967032967032967,
                    0.7252747252747253
                ],
                "question_related_to_answer": [
                    0.0,
                    0.5,
                    0.5
                ],
                "result_count_noun_chunks": [
                    173000.0,
                    490000.0,
                    468000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    48.0,
                    33.0
                ],
                "word_count_raw": [
                    0.0,
                    43.0,
                    45.0
                ],
                "word_count_appended": [
                    201.0,
                    406.0,
                    378.0
                ],
                "result_count": [
                    372000.0,
                    854000.0,
                    755000.0
                ]
            },
            "ml_answers": {
                "gloves": 0.3223717915563635,
                "cups": 0.23098745962403897,
                "swords": 0.060992825403332326
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Table tennis is also known as what?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "ping-pong"
            ],
            "lines": [
                [
                    0.6692424242424243,
                    1.0,
                    0.9982249744998893,
                    0.9871547239391901,
                    0.9869875324213928,
                    0.20198170731707318,
                    0.48034188034188036,
                    1.0,
                    1.0,
                    1.0
                ],
                [
                    0.1409090909090909,
                    0.0,
                    0.0017077071877808023,
                    0.012763212592345084,
                    0.012773953907981625,
                    0.6676829268292683,
                    0.294017094017094,
                    0.0,
                    0.0,
                    1.0
                ],
                [
                    0.18984848484848485,
                    0.0,
                    6.73183123299099e-05,
                    8.206346846484378e-05,
                    0.0002385136706255944,
                    0.13033536585365854,
                    0.22564102564102564,
                    0.0,
                    0.0,
                    1.0
                ]
            ],
            "fraction_answers": {
                "hunky-dory": 0.1255393317159512,
                "argle-bargle": 0.060690307977176595,
                "ping-pong": 0.8137703603068721
            },
            "question": "table tennis is also known as what?",
            "rate_limited": false,
            "answers": [
                "ping-pong",
                "hunky-dory",
                "argle-bargle"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "integer_answers": {
                "hunky-dory": 1,
                "argle-bargle": 0,
                "ping-pong": 8
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    9900000.0,
                    128000.0,
                    823.0
                ],
                "wikipedia_search": [
                    0.40396341463414637,
                    1.3353658536585367,
                    0.2606707317073171
                ],
                "answer_relation_to_question": [
                    2.007727272727273,
                    0.42272727272727273,
                    0.5695454545454546
                ],
                "question_related_to_answer": [
                    1.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    9890000.0,
                    128000.0,
                    2390.0
                ],
                "word_count_noun_chunks": [
                    28.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    81.0,
                    0.0,
                    0.0
                ],
                "result_count": [
                    12100000.0,
                    20700.0,
                    816.0
                ],
                "word_count_appended": [
                    281.0,
                    172.0,
                    132.0
                ]
            },
            "ml_answers": {
                "hunky-dory": 0.27800644087555876,
                "argle-bargle": 0.19237638622136471,
                "ping-pong": 0.7465257644179569
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which of these countries is closest to the International Date Line?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "japan"
            ],
            "lines": [
                [
                    0.3289099942244652,
                    0.9285714285714286,
                    0.41735918744228995,
                    0.41779226828132277,
                    0.19096209912536444,
                    0.32236730863275115,
                    0.30149253731343284,
                    0.5,
                    0.6666666666666666,
                    -1.0
                ],
                [
                    0.36500742628461774,
                    0.07142857142857142,
                    0.25346260387811637,
                    0.3223102002794597,
                    0.35276967930029157,
                    0.3777416673453997,
                    0.3582089552238806,
                    0.0,
                    0.0,
                    -1.0
                ],
                [
                    0.30608257949091716,
                    0.0,
                    0.32917820867959374,
                    0.2598975314392175,
                    0.45626822157434405,
                    0.29989102402184914,
                    0.3402985074626866,
                    0.5,
                    0.3333333333333333,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "brazil": 0.23343656708225968,
                "japan": 0.4526801655841913,
                "spain": 0.313883267333549
            },
            "question": "which of these countries is closest to the international date line?",
            "rate_limited": false,
            "answers": [
                "japan",
                "brazil",
                "spain"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "brazil": 0.17578819221765493,
                "japan": 0.38264521645263716,
                "spain": 0.1309059223551702
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    8970000.0,
                    6920000.0,
                    5580000.0
                ],
                "wikipedia_search": [
                    1.2894692345310046,
                    1.5109666693815988,
                    1.1995640960873966
                ],
                "answer_relation_to_question": [
                    1.3156399768978606,
                    1.4600297051384707,
                    1.2243303179636684
                ],
                "question_related_to_answer": [
                    1.8571428571428572,
                    0.14285714285714285,
                    0.0
                ],
                "result_count_noun_chunks": [
                    2620000.0,
                    4840000.0,
                    6260000.0
                ],
                "word_count_noun_chunks": [
                    1.0,
                    0.0,
                    1.0
                ],
                "word_count_raw": [
                    2.0,
                    0.0,
                    1.0
                ],
                "result_count": [
                    9040000.0,
                    5490000.0,
                    7130000.0
                ],
                "word_count_appended": [
                    303.0,
                    360.0,
                    342.0
                ]
            },
            "integer_answers": {
                "brazil": 3,
                "japan": 5,
                "spain": 1
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which of these is NOT a name of one of the Florida Keys?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "turtle key"
            ],
            "lines": [
                [
                    0.2493413088371431,
                    0,
                    0.49972206781545303,
                    0.4726151162066172,
                    0.4999917564083173,
                    0.33333333333333337,
                    0.41785714285714287,
                    0,
                    0.0,
                    -1.0
                ],
                [
                    0.4686973343777446,
                    0,
                    0.0011848687867528906,
                    0.3638544457598604,
                    0.48387123366424784,
                    0.5,
                    0.375,
                    0,
                    0.5,
                    -1.0
                ],
                [
                    0.2819613567851124,
                    0,
                    0.4990930633977941,
                    0.16353043803352235,
                    0.016137009927434887,
                    0.16666666666666669,
                    0.20714285714285713,
                    0,
                    0.5,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "pigeon key": 0.4758481737276036,
                "turtle key": 0.23068346211754123,
                "fat deer key": 0.29346836415485517
            },
            "question": "which of these is not a name of one of the florida keys?",
            "rate_limited": false,
            "answers": [
                "fat deer key",
                "turtle key",
                "pigeon key"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "pigeon key": 0.10873968224718703,
                "turtle key": 0.3209637273351029,
                "fat deer key": 0.17896388305234442
            },
            "negative_question": true,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    8790.0,
                    43700.0,
                    108000.0
                ],
                "wikipedia_search": [
                    0.3333333333333333,
                    0.0,
                    0.6666666666666666
                ],
                "answer_relation_to_question": [
                    1.0026347646514278,
                    0.1252106624890218,
                    0.8721545728595504
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    23.0,
                    45000.0,
                    1350000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    1.0,
                    0.0,
                    0.0
                ],
                "result_count": [
                    19.0,
                    34100.0,
                    62.0
                ],
                "word_count_appended": [
                    23.0,
                    35.0,
                    82.0
                ]
            },
            "integer_answers": {
                "pigeon key": 4,
                "turtle key": 1,
                "fat deer key": 2
            }
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "The '70s sitcom \u201cThree's Company\u201d was about three people who were what?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "roommates"
            ],
            "lines": [
                [
                    0.11111111111111112,
                    1.0,
                    0.9998641488928135,
                    0.9104840706208274,
                    0.9991532599491956,
                    0.28205128205128205,
                    0.9555555555555556,
                    1.0,
                    1.0,
                    1.0
                ],
                [
                    0.7222222222222223,
                    0.0,
                    0.0,
                    2.046031619372646e-06,
                    0.0,
                    0.3333333333333333,
                    0.017777777777777778,
                    0.0,
                    0.0,
                    1.0
                ],
                [
                    0.16666666666666669,
                    0.0,
                    0.00013585110718652356,
                    0.08951388334755325,
                    0.000846740050804403,
                    0.3846153846153846,
                    0.02666666666666667,
                    0.0,
                    0.0,
                    1.0
                ]
            ],
            "fraction_answers": {
                "roommates": 0.8064688253534205,
                "trivia show hosts": 0.11925948659610586,
                "panda bears": 0.07427168805047357
            },
            "question": "the '70s sitcom \u201cthree's company\u201d was about three people who were what?",
            "rate_limited": false,
            "answers": [
                "roommates",
                "trivia show hosts",
                "panda bears"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "roommates": 0.809898584861037,
                "trivia show hosts": 0.24063075673707268,
                "panda bears": 0.04313332308763948
            },
            "integer_answers": {
                "roommates": 7,
                "trivia show hosts": 1,
                "panda bears": 1
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    1780000.0,
                    4.0,
                    175000.0
                ],
                "wikipedia_search": [
                    0.8461538461538461,
                    1.0,
                    1.1538461538461537
                ],
                "answer_relation_to_question": [
                    0.2222222222222222,
                    1.4444444444444444,
                    0.3333333333333333
                ],
                "question_related_to_answer": [
                    1.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    76700.0,
                    0,
                    65.0
                ],
                "word_count_noun_chunks": [
                    1.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    6.0,
                    0.0,
                    0.0
                ],
                "word_count_appended": [
                    215.0,
                    4.0,
                    6.0
                ],
                "result_count": [
                    184000.0,
                    0,
                    25.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "How did Mason jars get their name?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "named after inventor"
            ],
            "lines": [
                [
                    0.0,
                    0,
                    4.678337950268098e-06,
                    4.2338504813686386e-06,
                    4.74774912181478e-06,
                    0.0,
                    0.42105263157894735,
                    0,
                    0,
                    5.0
                ],
                [
                    0.36068187392690704,
                    0,
                    0.999994736869806,
                    0.9999951613137356,
                    0.9999946587822379,
                    0.0,
                    0.3157894736842105,
                    0,
                    0,
                    5.0
                ],
                [
                    0.6393181260730929,
                    0,
                    5.847922437835123e-07,
                    6.048357830526627e-07,
                    5.934686402268475e-07,
                    1.0,
                    0.2631578947368421,
                    0,
                    0,
                    5.0
                ]
            ],
            "fraction_answers": {
                "named after inventor": 0.07017771525275014,
                "invented in mason, al": 0.6127426507628162,
                "masons used them": 0.3170796339844337
            },
            "question": "how did mason jars get their name?",
            "rate_limited": false,
            "answers": [
                "named after inventor",
                "invented in mason, al",
                "masons used them"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "named after inventor": 0.43008628337026744,
                "invented in mason, al": 0.27188067361542534,
                "masons used them": 0.3167018395935789
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 5
            },
            "data": {
                "result_count_important_words": [
                    21.0,
                    4960000.0,
                    3.0
                ],
                "wikipedia_search": [
                    0.0,
                    0.0,
                    1.0
                ],
                "answer_relation_to_question": [
                    0.0,
                    0.7213637478538141,
                    1.2786362521461858
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    16.0,
                    3370000.0,
                    2.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count": [
                    16.0,
                    3420000.0,
                    2.0
                ],
                "word_count_appended": [
                    8.0,
                    6.0,
                    5.0
                ]
            },
            "integer_answers": {
                "named after inventor": 1,
                "invented in mason, al": 3,
                "masons used them": 2
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which two countries have almost perfectly identical flags?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "indonesia / monaco"
            ],
            "lines": [
                [
                    0.04090909090909091,
                    0,
                    0.2463768115942029,
                    0.40248810830589093,
                    0.288135593220339,
                    0.00315955766192733,
                    0.17647058823529413,
                    0,
                    0,
                    -1.0
                ],
                [
                    0.10372960372960373,
                    0,
                    0.4057971014492754,
                    0.5744603000365899,
                    0.4067796610169492,
                    0.00315955766192733,
                    0.17647058823529413,
                    0,
                    0,
                    -1.0
                ],
                [
                    0.8553613053613054,
                    0,
                    0.34782608695652173,
                    0.02305159165751921,
                    0.3050847457627119,
                    0.9936808846761452,
                    0.6470588235294118,
                    0,
                    0,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "luxembourg / russia": 0.2783994686882733,
                "indonesia / monaco": 0.5286772396572691,
                "armenia / romania": 0.19292329165445754
            },
            "question": "which two countries have almost perfectly identical flags?",
            "rate_limited": false,
            "answers": [
                "armenia / romania",
                "luxembourg / russia",
                "indonesia / monaco"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "luxembourg / russia": 0.2870694713601506,
                "indonesia / monaco": 0.6064841120665064,
                "armenia / romania": 0.1923411580135829
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    1100.0,
                    1570.0,
                    63.0
                ],
                "wikipedia_search": [
                    0.009478672985781991,
                    0.009478672985781991,
                    2.9810426540284363
                ],
                "answer_relation_to_question": [
                    0.16363636363636364,
                    0.4149184149184149,
                    3.4214452214452216
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    17.0,
                    24.0,
                    18.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count": [
                    17.0,
                    28.0,
                    24.0
                ],
                "word_count_appended": [
                    3.0,
                    3.0,
                    11.0
                ]
            },
            "integer_answers": {
                "luxembourg / russia": 3,
                "indonesia / monaco": 3,
                "armenia / romania": 0
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Catherine O'Hara and Eugene Levy do NOT kiss in which Christopher Guest film?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "waiting for guffman"
            ],
            "lines": [
                [
                    0.3972450993561563,
                    0.16249999999999998,
                    0.05953617168570441,
                    0.008291554184342464,
                    0.40131578947368424,
                    0.4393939393939394,
                    0.3545751633986928,
                    0.2763157894736842,
                    0.3802083333333333,
                    -1.0
                ],
                [
                    0.3071831488338027,
                    0.4083333333333333,
                    0.47758740048459675,
                    0.4958252988816043,
                    0.33755060728744946,
                    0.0896464646464647,
                    0.26143790849673204,
                    0.368421052631579,
                    0.171875,
                    -1.0
                ],
                [
                    0.295571751810041,
                    0.4291666666666667,
                    0.46287642782969884,
                    0.4958831469340532,
                    0.2611336032388664,
                    0.47095959595959597,
                    0.3839869281045752,
                    0.35526315789473684,
                    0.4479166666666667,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "a mighty wind": 0.351586618978764,
                "best in show": 0.44902625771121396,
                "waiting for guffman": 0.19938712331002206
            },
            "question": "catherine o'hara and eugene levy do not kiss in which christopher guest film?",
            "rate_limited": false,
            "answers": [
                "best in show",
                "a mighty wind",
                "waiting for guffman"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "a mighty wind": 0.2082474349278349,
                "best in show": 0.22730363353532532,
                "waiting for guffman": 0.4539941511028691
            },
            "negative_question": true,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    510000.0,
                    4330.0,
                    4270.0
                ],
                "wikipedia_search": [
                    0.36363636363636365,
                    2.462121212121212,
                    0.17424242424242425
                ],
                "answer_relation_to_question": [
                    1.644078410301499,
                    3.0850696186591566,
                    3.2708519710393444
                ],
                "question_related_to_answer": [
                    1.35,
                    0.3666666666666667,
                    0.2833333333333333
                ],
                "result_count_noun_chunks": [
                    39000.0,
                    64200.0,
                    94400.0
                ],
                "word_count_noun_chunks": [
                    34.0,
                    20.0,
                    22.0
                ],
                "word_count_raw": [
                    23.0,
                    63.0,
                    10.0
                ],
                "word_count_appended": [
                    89.0,
                    146.0,
                    71.0
                ],
                "result_count": [
                    509000.0,
                    25900.0,
                    42900.0
                ]
            },
            "integer_answers": {
                "a mighty wind": 3,
                "best in show": 4,
                "waiting for guffman": 2
            }
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "What SportsCenter anchor shares their last name with Linus & Lucy from \u201cPeanuts\u201d?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "scott van pelt"
            ],
            "lines": [
                [
                    0.347307024075453,
                    0.9824561403508771,
                    0.3326612903225806,
                    0.46511627906976744,
                    0.0032258064516129032,
                    0.2833333333333333,
                    0.25,
                    0.5,
                    0.25,
                    1.0
                ],
                [
                    0.34482501861504095,
                    0.0,
                    0.3346774193548387,
                    0.3372093023255814,
                    0.24946236559139784,
                    0.20833333333333331,
                    0.5,
                    0.0,
                    0.5,
                    1.0
                ],
                [
                    0.30786795730950606,
                    0.017543859649122806,
                    0.3326612903225806,
                    0.19767441860465115,
                    0.7473118279569892,
                    0.5083333333333333,
                    0.25,
                    0.5,
                    0.25,
                    1.0
                ]
            ],
            "fraction_answers": {
                "jemele hill": 0.3793444304004027,
                "kenny mayne": 0.34571029857513147,
                "scott van pelt": 0.2749452710244658
            },
            "question": "what sportscenter anchor shares their last name with linus & lucy from \u201cpeanuts\u201d?",
            "rate_limited": false,
            "answers": [
                "jemele hill",
                "scott van pelt",
                "kenny mayne"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "jemele hill": 0.32285822700162875,
                "kenny mayne": 0.3793213722674965,
                "scott van pelt": 0.5200559231216004
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    40.0,
                    29.0,
                    17.0
                ],
                "wikipedia_search": [
                    0.5666666666666667,
                    0.41666666666666663,
                    1.0166666666666666
                ],
                "answer_relation_to_question": [
                    1.041921072226359,
                    1.0344750558451228,
                    0.9236038719285182
                ],
                "question_related_to_answer": [
                    0.9824561403508771,
                    0.0,
                    0.017543859649122806
                ],
                "result_count_noun_chunks": [
                    60.0,
                    4640.0,
                    13900.0
                ],
                "word_count_noun_chunks": [
                    1.0,
                    0.0,
                    1.0
                ],
                "word_count_raw": [
                    1.0,
                    2.0,
                    1.0
                ],
                "word_count_appended": [
                    1.0,
                    2.0,
                    1.0
                ],
                "result_count": [
                    165000.0,
                    166000.0,
                    165000.0
                ]
            },
            "integer_answers": {
                "jemele hill": 4,
                "kenny mayne": 2,
                "scott van pelt": 3
            }
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "How do you let someone on Tinder know you're interested?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "swipe right"
            ],
            "lines": [
                [
                    0.4988902340597256,
                    1.0,
                    0.9995139977808956,
                    0.09387348955514578,
                    0.4965144684316101,
                    0.9128571428571428,
                    0.8317757009345794,
                    1.0,
                    1.0,
                    5.0
                ],
                [
                    0.17347098914895526,
                    0.0,
                    0.0,
                    0.9060832470105376,
                    0.5031346613440316,
                    0.06469387755102039,
                    0.028037383177570093,
                    0.0,
                    0.0,
                    5.0
                ],
                [
                    0.32763877679131914,
                    0.0,
                    0.0004860022191044721,
                    4.326343431671936e-05,
                    0.0003508702243583378,
                    0.02244897959183673,
                    0.14018691588785046,
                    0.0,
                    0.0,
                    5.0
                ]
            ],
            "fraction_answers": {
                "draw circle around face": 0.18615779535912388,
                "shake phone": 0.0545727564609762,
                "swipe right": 0.7592694481798999
            },
            "question": "how do you let someone on tinder know you're interested?",
            "rate_limited": false,
            "answers": [
                "swipe right",
                "draw circle around face",
                "shake phone"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "draw circle around face": 0.10221654275047937,
                "shake phone": 0.05913656897019091,
                "swipe right": 0.7482547022502726
            },
            "integer_answers": {
                "draw circle around face": 2,
                "shake phone": 0,
                "swipe right": 7
            },
            "categorical_data": {
                "question_type": 5
            },
            "data": {
                "result_count_important_words": [
                    115000.0,
                    1110000.0,
                    53.0
                ],
                "wikipedia_search": [
                    4.564285714285715,
                    0.32346938775510203,
                    0.11224489795918367
                ],
                "answer_relation_to_question": [
                    1.9955609362389024,
                    0.693883956595821,
                    1.3105551071652766
                ],
                "question_related_to_answer": [
                    1.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    2250000.0,
                    2280000.0,
                    1590.0
                ],
                "word_count_noun_chunks": [
                    15.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    7.0,
                    0.0,
                    0.0
                ],
                "word_count_appended": [
                    89.0,
                    3.0,
                    15.0
                ],
                "result_count": [
                    109000.0,
                    0,
                    53.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "In computing, what unit is half a byte?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "nibble"
            ],
            "lines": [
                [
                    0.32858987173080123,
                    0.920863309352518,
                    0.47767857142857145,
                    0.4778761061946903,
                    0.4778761061946903,
                    1.0,
                    0.6757679180887372,
                    0.8531073446327684,
                    0.8546511627906976,
                    1.0
                ],
                [
                    0.2506226053639847,
                    0.0,
                    0.0,
                    0.0,
                    0.0,
                    0.0,
                    0.01820250284414107,
                    0.0,
                    0.0,
                    1.0
                ],
                [
                    0.4207875229052141,
                    0.07913669064748201,
                    0.5223214285714286,
                    0.5221238938053098,
                    0.5221238938053098,
                    0.0,
                    0.30602957906712175,
                    0.14689265536723164,
                    0.14534883720930233,
                    1.0
                ]
            ],
            "fraction_answers": {
                "demibyte": 0.029869456467569524,
                "nibble": 0.6740455989348305,
                "octet": 0.2960849445976
            },
            "question": "in computing, what unit is half a byte?",
            "rate_limited": false,
            "answers": [
                "nibble",
                "demibyte",
                "octet"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "demibyte": 0.12888472877862642,
                "nibble": 0.8082877177883135,
                "octet": 0.14993493655752596
            },
            "integer_answers": {
                "demibyte": 0,
                "nibble": 5,
                "octet": 4
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    1080000.0,
                    0,
                    1180000.0
                ],
                "wikipedia_search": [
                    4.0,
                    0.0,
                    0.0
                ],
                "answer_relation_to_question": [
                    1.314359486923205,
                    1.0024904214559387,
                    1.6831500916208564
                ],
                "question_related_to_answer": [
                    0.920863309352518,
                    0.0,
                    0.07913669064748201
                ],
                "result_count_noun_chunks": [
                    1080000.0,
                    0,
                    1180000.0
                ],
                "word_count_noun_chunks": [
                    151.0,
                    0.0,
                    26.0
                ],
                "word_count_raw": [
                    147.0,
                    0.0,
                    25.0
                ],
                "result_count": [
                    1070000.0,
                    0,
                    1170000.0
                ],
                "word_count_appended": [
                    594.0,
                    16.0,
                    269.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Blue spruce, red cedar & white pine are all kinds of what?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "evergreen trees"
            ],
            "question": "blue spruce, red cedar & white pine are all kinds of what?",
            "answers": [
                "colgate flavors",
                "marvel supervillains",
                "evergreen trees"
            ],
            "integer_answers": {
                "marvel supervillains": 0,
                "evergreen trees": 8,
                "colgate flavors": 1
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    56.0,
                    54.0,
                    61800.0
                ],
                "wikipedia_search": [
                    1.8795107033639145,
                    0.5881753312945974,
                    4.532313965341489
                ],
                "answer_relation_to_question": [
                    1.9330637915543576,
                    0.4148547469302186,
                    4.652081461515424
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    1.0
                ],
                "result_count_noun_chunks": [
                    5830.0,
                    86.0,
                    108000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    2.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    12.0
                ],
                "result_count": [
                    1280000.0,
                    1280000.0,
                    1280000.0
                ],
                "word_count_appended": [
                    0.0,
                    0.0,
                    12.0
                ]
            },
            "negative_question": false,
            "fraction_answers": {
                "marvel supervillains": 0.05313894673714992,
                "evergreen trees": 0.8435200052093491,
                "colgate flavors": 0.10334104805350099
            },
            "lines": [
                [
                    0.27615197022205107,
                    0.0,
                    0.3333333333333333,
                    0.0009045388467129704,
                    0.05117806102742371,
                    0.26850152905198776,
                    0.0,
                    0.0,
                    0.0,
                    1.0
                ],
                [
                    0.05926496384717409,
                    0.0,
                    0.3333333333333333,
                    0.0008722338879017929,
                    0.0007549422381403841,
                    0.08402504732779963,
                    0.0,
                    0.0,
                    0.0,
                    1.0
                ],
                [
                    0.6645830659307749,
                    1.0,
                    0.3333333333333333,
                    0.9982232272653853,
                    0.948066996734436,
                    0.6474734236202127,
                    1.0,
                    1.0,
                    1.0,
                    1.0
                ]
            ],
            "rate_limited": false,
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "marvel supervillains": 0.11777747549552335,
                "evergreen trees": 0.8765202048096833,
                "colgate flavors": 0.11889273667484884
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which of these sharks is NOT a Lamniforme?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "great white shark"
            ],
            "lines": [
                [
                    0.34917355371900827,
                    0.39285714285714285,
                    0.4687369737390579,
                    0.48334617689870707,
                    0.44762534323197395,
                    0.4612794612794613,
                    0.2871536523929471,
                    0,
                    0,
                    -1.0
                ],
                [
                    0.25413223140495866,
                    0.19047619047619047,
                    0.056362770201869805,
                    0.08087164997003166,
                    0.09524051662768229,
                    0.14814814814814814,
                    0.3073047858942065,
                    0,
                    0,
                    -1.0
                ],
                [
                    0.39669421487603307,
                    0.4166666666666667,
                    0.4749002560590722,
                    0.4357821731312612,
                    0.45713414014034376,
                    0.39057239057239057,
                    0.40554156171284633,
                    0,
                    0,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "goblin shark": 0.174236484537629,
                "great white shark": 0.6764182020791178,
                "hammerhead shark": 0.14934531338325316
            },
            "question": "which of these sharks is not a lamniforme?",
            "rate_limited": false,
            "answers": [
                "goblin shark",
                "great white shark",
                "hammerhead shark"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "goblin shark": 0.18600006800633248,
                "great white shark": 0.3484115016849499,
                "hammerhead shark": 0.2865123437969751
            },
            "integer_answers": {
                "goblin shark": 1,
                "great white shark": 6,
                "hammerhead shark": 0
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    38900.0,
                    979000.0,
                    150000.0
                ],
                "wikipedia_search": [
                    0.07744107744107744,
                    0.7037037037037037,
                    0.21885521885521886
                ],
                "answer_relation_to_question": [
                    0.6033057851239669,
                    0.9834710743801652,
                    0.4132231404958678
                ],
                "question_related_to_answer": [
                    0.42857142857142855,
                    1.2380952380952381,
                    0.3333333333333333
                ],
                "result_count_noun_chunks": [
                    103000.0,
                    796000.0,
                    84300.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count": [
                    105000.0,
                    1490000.0,
                    84300.0
                ],
                "word_count_appended": [
                    169.0,
                    153.0,
                    75.0
                ]
            },
            "negative_question": true
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which of these restaurant brands has its original location in Europe?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "benihana"
            ],
            "lines": [
                [
                    0.38476190476190475,
                    0,
                    0.22570532915360503,
                    0.29411764705882354,
                    0.23076923076923078,
                    0.6653508771929825,
                    0.784394250513347,
                    0.5,
                    0.5,
                    -1.0
                ],
                [
                    0.40194805194805194,
                    0,
                    0.6426332288401254,
                    0.54437564499484,
                    0.6354515050167224,
                    0.2655701754385965,
                    0.1293634496919918,
                    0.0,
                    0.0,
                    -1.0
                ],
                [
                    0.21329004329004325,
                    0,
                    0.13166144200626959,
                    0.16150670794633643,
                    0.13377926421404682,
                    0.06907894736842105,
                    0.08624229979466119,
                    0.5,
                    0.5,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "mr. chow": 0.22444483807747231,
                "benihana": 0.4481374049312367,
                "p.f. chang's": 0.32741775699129105
            },
            "question": "which of these restaurant brands has its original location in europe?",
            "rate_limited": false,
            "answers": [
                "benihana",
                "p.f. chang's",
                "mr. chow"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "mr. chow": 0.33911197366348717,
                "benihana": 0.7236155582364037,
                "p.f. chang's": 0.255095813793804
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    114000.0,
                    211000.0,
                    62600.0
                ],
                "wikipedia_search": [
                    2.66140350877193,
                    1.062280701754386,
                    0.2763157894736842
                ],
                "answer_relation_to_question": [
                    1.9238095238095239,
                    2.00974025974026,
                    1.0664502164502163
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    138000.0,
                    380000.0,
                    80000.0
                ],
                "word_count_noun_chunks": [
                    1.0,
                    0.0,
                    1.0
                ],
                "word_count_raw": [
                    1.0,
                    0.0,
                    1.0
                ],
                "word_count_appended": [
                    382.0,
                    63.0,
                    42.0
                ],
                "result_count": [
                    144000.0,
                    410000.0,
                    84000.0
                ]
            },
            "integer_answers": {
                "mr. chow": 0,
                "benihana": 4,
                "p.f. chang's": 4
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "In which of these movies is the title NOT spoken by any character?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "inception"
            ],
            "lines": [
                [
                    0.16231228020150174,
                    0.0,
                    0.3942523574315222,
                    0.35758196721311475,
                    0.26528599605522685,
                    0.10225247408658128,
                    0.3239171374764595,
                    0,
                    0.5,
                    -1.0
                ],
                [
                    0.42130025662959797,
                    0.5,
                    0.3616973506960036,
                    0.3206967213114754,
                    0.34812623274161736,
                    0.42356714037803106,
                    0.3187382297551789,
                    0,
                    0.5,
                    -1.0
                ],
                [
                    0.4163874631689003,
                    0.5,
                    0.24405029187247418,
                    0.32172131147540983,
                    0.3865877712031558,
                    0.47418038553538766,
                    0.3573446327683616,
                    0,
                    0.0,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "inception": 0.47359944688389843,
                "speed": 0.32493203599407766,
                "gravity": 0.20146851712202393
            },
            "question": "in which of these movies is the title not spoken by any character?",
            "rate_limited": false,
            "answers": [
                "inception",
                "gravity",
                "speed"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "inception": 0.4089078364288809,
                "speed": 0.3082833435851161,
                "gravity": 0.339525313052209
            },
            "integer_answers": {
                "inception": 4,
                "speed": 2,
                "gravity": 2
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    1390000.0,
                    1750000.0,
                    1740000.0
                ],
                "wikipedia_search": [
                    2.386485155480512,
                    0.4585971577318137,
                    0.15491768678767412
                ],
                "answer_relation_to_question": [
                    2.0261263187909897,
                    0.4721984602224123,
                    0.5016752209865982
                ],
                "question_related_to_answer": [
                    1.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    4760000.0,
                    3080000.0,
                    2300000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    1.0
                ],
                "word_count_appended": [
                    374.0,
                    385.0,
                    303.0
                ],
                "result_count": [
                    4710000.0,
                    6160000.0,
                    11400000.0
                ]
            },
            "negative_question": true
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Which player won Rookie of the Year in their sport most recently?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "mike trout"
            ],
            "lines": [
                [
                    0.45293709673369986,
                    0,
                    0.18332779807372965,
                    4.853900035870321e-05,
                    0.363855421686747,
                    0.39216705261113155,
                    0.33053221288515405,
                    0.6666666666666666,
                    1.0,
                    -1.0
                ],
                [
                    0.18570853348452768,
                    0,
                    0.07273331119229492,
                    4.805361035511618e-05,
                    0.06265060240963856,
                    0.16188290419375945,
                    0.33613445378151263,
                    0.0,
                    0.0,
                    -1.0
                ],
                [
                    0.36135436978177243,
                    0,
                    0.7439388907339755,
                    0.9999034073892862,
                    0.5734939759036145,
                    0.445950043195109,
                    0.3333333333333333,
                    0.3333333333333333,
                    0.0,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "mike trout": 0.42369184845718594,
                "von miller": 0.10239473233401104,
                "blake griffin": 0.47391341920880303
            },
            "question": "which player won rookie of the year in their sport most recently?",
            "rate_limited": false,
            "answers": [
                "mike trout",
                "von miller",
                "blake griffin"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "mike trout": 0.7881616193217316,
                "von miller": 0.380473110039019,
                "blake griffin": 0.09264539230592654
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    100.0,
                    99.0,
                    2060000.0
                ],
                "wikipedia_search": [
                    1.9608352630556578,
                    0.8094145209687973,
                    2.229750215975545
                ],
                "answer_relation_to_question": [
                    2.717622580402199,
                    1.1142512009071661,
                    2.1681262186906345
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    1510000.0,
                    260000.0,
                    2380000.0
                ],
                "word_count_noun_chunks": [
                    2.0,
                    0.0,
                    1.0
                ],
                "word_count_raw": [
                    1.0,
                    0.0,
                    0.0
                ],
                "word_count_appended": [
                    118.0,
                    120.0,
                    119.0
                ],
                "result_count": [
                    552000.0,
                    219000.0,
                    2240000.0
                ]
            },
            "integer_answers": {
                "mike trout": 3,
                "von miller": 1,
                "blake griffin": 4
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "What form of transportation counts Jay-Z as a prominent investor?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "aviation"
            ],
            "lines": [
                [
                    0.3548049846530563,
                    0.3333333333333333,
                    0.5171498057193973,
                    0.2290564893724526,
                    0.2189066603007878,
                    0.16511018786127168,
                    0.48118279569892475,
                    0.3333333333333333,
                    0.3333333333333333,
                    1.0
                ],
                [
                    0.24183135913560533,
                    0.3333333333333333,
                    0.00763145388980516,
                    0.019772964597298482,
                    0.5777035091907377,
                    0.4782153179190752,
                    0.1478494623655914,
                    0.3333333333333333,
                    0.3333333333333333,
                    1.0
                ],
                [
                    0.4033636562113383,
                    0.3333333333333333,
                    0.47521874039079753,
                    0.7511705460302489,
                    0.2033898305084746,
                    0.35667449421965314,
                    0.3709677419354839,
                    0.3333333333333333,
                    0.3333333333333333,
                    1.0
                ]
            ],
            "fraction_answers": {
                "boats": 0.39564277881066623,
                "aviation": 0.3295789915117656,
                "e-bikes": 0.27477822967756815
            },
            "question": "what form of transportation counts jay-z as a prominent investor?",
            "rate_limited": false,
            "answers": [
                "aviation",
                "e-bikes",
                "boats"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "boats": 0.2357987414669482,
                "aviation": 0.42007607721604934,
                "e-bikes": 0.19242001519090624
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    680000.0,
                    58700.0,
                    2230000.0
                ],
                "wikipedia_search": [
                    0.6604407514450867,
                    1.9128612716763007,
                    1.4266979768786126
                ],
                "answer_relation_to_question": [
                    1.7740249232652816,
                    1.2091567956780267,
                    2.0168182810566915
                ],
                "question_related_to_answer": [
                    0.3333333333333333,
                    0.3333333333333333,
                    0.3333333333333333
                ],
                "result_count_noun_chunks": [
                    917000.0,
                    2420000.0,
                    852000.0
                ],
                "word_count_noun_chunks": [
                    1.0,
                    1.0,
                    1.0
                ],
                "word_count_raw": [
                    1.0,
                    1.0,
                    1.0
                ],
                "word_count_appended": [
                    179.0,
                    55.0,
                    138.0
                ],
                "result_count": [
                    1850000.0,
                    27300.0,
                    1700000.0
                ]
            },
            "integer_answers": {
                "boats": 2,
                "aviation": 5,
                "e-bikes": 2
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which of these has NEVER been named Pantone\u2019s Color of the Year?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "chili pepper"
            ],
            "lines": [
                [
                    0.41827681388012616,
                    0,
                    0.41647511626663813,
                    0.23442622950819675,
                    0.21483345315121016,
                    0.3277777777777778,
                    0.18006993006993008,
                    0,
                    0.33333333333333337,
                    -1.0
                ],
                [
                    0.32762223974763405,
                    0,
                    0.08571657668252525,
                    0.37868852459016394,
                    0.4876587586867961,
                    0.40416666666666673,
                    0.40209790209790214,
                    0,
                    0.33333333333333337,
                    -1.0
                ],
                [
                    0.2541009463722398,
                    0,
                    0.49780830705083656,
                    0.38688524590163936,
                    0.29750778816199375,
                    0.26805555555555555,
                    0.41783216783216787,
                    0,
                    0.33333333333333337,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "chili pepper": 0.2984219016549239,
                "cucumber": 0.3928020988607964,
                "sand dollar": 0.3087759994842796
            },
            "question": "which of these has never been named pantone\u2019s color of the year?",
            "rate_limited": false,
            "answers": [
                "cucumber",
                "sand dollar",
                "chili pepper"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "chili pepper": 0.5256373647601252,
                "cucumber": 0.3106587234167477,
                "sand dollar": 0.13279622410373706
            },
            "integer_answers": {
                "chili pepper": 2,
                "cucumber": 4,
                "sand dollar": 1
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    324000.0,
                    148000.0,
                    138000.0
                ],
                "wikipedia_search": [
                    1.0333333333333334,
                    0.575,
                    1.3916666666666668
                ],
                "answer_relation_to_question": [
                    0.4903391167192429,
                    1.0342665615141957,
                    1.4753943217665615
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    23800000.0,
                    1030000.0,
                    16900000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    1.0,
                    1.0,
                    1.0
                ],
                "result_count": [
                    3750000.0,
                    18600000.0,
                    98400.0
                ],
                "word_count_appended": [
                    183.0,
                    56.0,
                    47.0
                ]
            },
            "negative_question": true
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "What book that heavily influenced \u201cThe Matrix\u201d makes a cameo in the movie?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "neuromancer"
            ],
            "lines": [
                [
                    0.6334712976914811,
                    0,
                    0.5910890536998828,
                    0.18765679879578526,
                    0.1489795918367347,
                    0.8431818181818183,
                    0.9585987261146497,
                    0,
                    0.9444444444444444,
                    1.0
                ],
                [
                    0.17162511841410924,
                    0,
                    0.36469079350917305,
                    0.772704465629704,
                    0.7448979591836735,
                    0.030303030303030304,
                    0.0,
                    0,
                    0.05555555555555555,
                    1.0
                ],
                [
                    0.1949035838944096,
                    0,
                    0.04422015279094407,
                    0.03963873557451079,
                    0.10612244897959183,
                    0.1265151515151515,
                    0.041401273885350316,
                    0,
                    0.0,
                    1.0
                ]
            ],
            "fraction_answers": {
                "simulacra & simulation": 0.3056824175136065,
                "neuromancer": 0.615345961537828,
                "gravity's rainbow": 0.07897162094856545
            },
            "question": "what book that heavily influenced \u201cthe matrix\u201d makes a cameo in the movie?",
            "rate_limited": false,
            "answers": [
                "neuromancer",
                "simulacra & simulation",
                "gravity's rainbow"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "integer_answers": {
                "simulacra & simulation": 2,
                "neuromancer": 5,
                "gravity's rainbow": 0
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    374.0,
                    1540.0,
                    79.0
                ],
                "wikipedia_search": [
                    5.0590909090909095,
                    0.18181818181818182,
                    0.759090909090909
                ],
                "answer_relation_to_question": [
                    3.167356488457406,
                    0.8581255920705462,
                    0.9745179194720479
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    4380.0,
                    21900.0,
                    3120.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    17.0,
                    1.0,
                    0.0
                ],
                "word_count_appended": [
                    301.0,
                    0.0,
                    13.0
                ],
                "result_count": [
                    10600.0,
                    6540.0,
                    793.0
                ]
            },
            "ml_answers": {
                "simulacra & simulation": 0.3806877056326973,
                "neuromancer": 0.5700448870783654,
                "gravity's rainbow": 0.32128363580232494
            }
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Which of these things was created by a person who chose to remain anonymous?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "bitcoin"
            ],
            "lines": [
                [
                    0.4381699346405229,
                    1.0,
                    0.9237875288683602,
                    0.8178676564699859,
                    0.9696554871092858,
                    0.8973684210526316,
                    0.7551984877126654,
                    0,
                    1.0,
                    0.0
                ],
                [
                    0.19764705882352943,
                    0.0,
                    0.0395908940943583,
                    0.06092410085754512,
                    0.0070727812000912615,
                    0.08947368421052632,
                    0.18714555765595464,
                    0,
                    0.0,
                    0.0
                ],
                [
                    0.3641830065359477,
                    0.0,
                    0.03662157703728142,
                    0.12120824267246896,
                    0.02327173169062286,
                    0.013157894736842105,
                    0.057655954631379965,
                    0,
                    0.0,
                    0.0
                ]
            ],
            "fraction_answers": {
                "hoverboards": 0.07273175960525063,
                "fidget spinners": 0.07701230091306788,
                "bitcoin": 0.8502559394816815
            },
            "question": "which of these things was created by a person who chose to remain anonymous?",
            "rate_limited": false,
            "answers": [
                "bitcoin",
                "hoverboards",
                "fidget spinners"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "hoverboards": 0.03194210688779602,
                "fidget spinners": 0.05356267474457463,
                "bitcoin": 0.4520942984021817
            },
            "integer_answers": {
                "hoverboards": 0,
                "fidget spinners": 0,
                "bitcoin": 8
            },
            "categorical_data": {
                "question_type": 0
            },
            "data": {
                "result_count_important_words": [
                    639000.0,
                    47600.0,
                    94700.0
                ],
                "wikipedia_search": [
                    3.5894736842105264,
                    0.35789473684210527,
                    0.05263157894736842
                ],
                "answer_relation_to_question": [
                    2.1908496732026146,
                    0.9882352941176471,
                    1.8209150326797385
                ],
                "question_related_to_answer": [
                    1.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    17000000.0,
                    124000.0,
                    408000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    26.0,
                    0.0,
                    0.0
                ],
                "result_count": [
                    280000.0,
                    12000.0,
                    11100.0
                ],
                "word_count_appended": [
                    799.0,
                    198.0,
                    61.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "In which town were a President, Governor, Senator, NFL owner and late night host all born?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "muncie, in"
            ],
            "lines": [
                [
                    0.24213394095502278,
                    1.0,
                    0.8066705448904402,
                    0.8127062706270627,
                    0.7924182694222116,
                    0.38285929032272115,
                    0.2777777777777778,
                    0,
                    0,
                    -1.0
                ],
                [
                    0.33259238161283927,
                    0.0,
                    0.02036067481093659,
                    0.004125412541254125,
                    0.01764026599769044,
                    0.17637664562531583,
                    0.2777777777777778,
                    0,
                    0,
                    -1.0
                ],
                [
                    0.4252736774321379,
                    0.0,
                    0.17296878029862323,
                    0.18316831683168316,
                    0.18994146458009795,
                    0.44076406405196294,
                    0.4444444444444444,
                    0,
                    0,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "muncie, in": 0.2652229639484214,
                "hope, ar": 0.11841045119511628,
                "brookline, ma": 0.6163665848564623
            },
            "question": "in which town were a president, governor, senator, nfl owner and late night host all born?",
            "rate_limited": false,
            "answers": [
                "brookline, ma",
                "hope, ar",
                "muncie, in"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "muncie, in": 0.46671865342803165,
                "hope, ar": 0.03585784507664164,
                "brookline, ma": 0.3580825833393603
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    19700.0,
                    100.0,
                    4440.0
                ],
                "wikipedia_search": [
                    3.062874322581769,
                    1.4110131650025266,
                    3.5261125124157036
                ],
                "answer_relation_to_question": [
                    1.6949375866851595,
                    2.328146671289875,
                    2.9769157420249654
                ],
                "question_related_to_answer": [
                    1.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    19900.0,
                    443.0,
                    4770.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count": [
                    20800.0,
                    525.0,
                    4460.0
                ],
                "word_count_appended": [
                    5.0,
                    5.0,
                    8.0
                ]
            },
            "integer_answers": {
                "muncie, in": 3,
                "hope, ar": 0,
                "brookline, ma": 4
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Though it now conveys something different, which of these words originally meant \u201cparrot\u201d?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "popinjay"
            ],
            "lines": [
                [
                    0.175,
                    0,
                    0.33698030634573306,
                    0.4845702626880898,
                    0.36561119293078054,
                    0.0,
                    0.3522167487684729,
                    0,
                    0.0,
                    -1.0
                ],
                [
                    0.2625,
                    0,
                    0.2363238512035011,
                    0.3238969650599337,
                    0.5596465390279823,
                    0.041666666666666664,
                    0.3522167487684729,
                    0,
                    0.0,
                    -1.0
                ],
                [
                    0.5625,
                    0,
                    0.42669584245076586,
                    0.19153277225197654,
                    0.07474226804123711,
                    0.9583333333333334,
                    0.2955665024630542,
                    0,
                    1.0,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "thespian": 0.25375011010379384,
                "popinjay": 0.5013386740771953,
                "warble": 0.2449112158190109
            },
            "question": "though it now conveys something different, which of these words originally meant \u201cparrot\u201d?",
            "rate_limited": false,
            "answers": [
                "warble",
                "thespian",
                "popinjay"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "thespian": 0.1978556038818435,
                "popinjay": 0.4960865118874735,
                "warble": 0.36935179316077926
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    19000.0,
                    12700.0,
                    7510.0
                ],
                "wikipedia_search": [
                    0.0,
                    0.125,
                    2.875
                ],
                "answer_relation_to_question": [
                    0.7,
                    1.05,
                    2.25
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    993000.0,
                    1520000.0,
                    203000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    1.0
                ],
                "result_count": [
                    15400.0,
                    10800.0,
                    19500.0
                ],
                "word_count_appended": [
                    143.0,
                    143.0,
                    120.0
                ]
            },
            "integer_answers": {
                "thespian": 1,
                "popinjay": 4,
                "warble": 2
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "What gargantuan fruit is the subject of a Roald Dahl children's book?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "peach"
            ],
            "lines": [
                [
                    0.2267543859649123,
                    0.0,
                    0.00429000429000429,
                    0.001254930082466834,
                    0.004308487720809996,
                    0.18108318034175963,
                    0.22868217054263565,
                    0.0,
                    0.0,
                    1.0
                ],
                [
                    0.13157894736842107,
                    0.0,
                    0.004719004719004719,
                    0.003764790247400502,
                    0.004739336492890996,
                    0.33319799463352634,
                    0.10852713178294573,
                    0.1,
                    0.25,
                    1.0
                ],
                [
                    0.6416666666666667,
                    1.0,
                    0.990990990990991,
                    0.9949802796701327,
                    0.990952175786299,
                    0.48571882502471403,
                    0.6627906976744186,
                    0.9,
                    0.75,
                    1.0
                ]
            ],
            "fraction_answers": {
                "loquat": 0.10405857836046549,
                "dragonfruit": 0.07181923988250986,
                "peach": 0.8241221817570247
            },
            "question": "what gargantuan fruit is the subject of a roald dahl children's book?",
            "rate_limited": false,
            "answers": [
                "dragonfruit",
                "loquat",
                "peach"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "loquat": -0.009990208201806891,
                "dragonfruit": 0.21237290196265532,
                "peach": 0.7757043878522208
            },
            "integer_answers": {
                "loquat": 0,
                "dragonfruit": 0,
                "peach": 9
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    14.0,
                    42.0,
                    11100.0
                ],
                "wikipedia_search": [
                    0.7243327213670385,
                    1.3327919785341054,
                    1.9428753000988561
                ],
                "answer_relation_to_question": [
                    0.9070175438596491,
                    0.5263157894736842,
                    2.5666666666666664
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    1.0
                ],
                "result_count_noun_chunks": [
                    10.0,
                    11.0,
                    2300.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    1.0,
                    9.0
                ],
                "word_count_raw": [
                    0.0,
                    1.0,
                    3.0
                ],
                "word_count_appended": [
                    59.0,
                    28.0,
                    171.0
                ],
                "result_count": [
                    10.0,
                    11.0,
                    2310.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "The only person who owns more U.S. land than Ted Turner made his fortune in what business?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "cable tv"
            ],
            "lines": [
                [
                    0.1757201646090535,
                    0,
                    0.08937378568225975,
                    0.7625924281329034,
                    0.11817764867757223,
                    0.33905134292231065,
                    0.873015873015873,
                    0,
                    0,
                    1.0
                ],
                [
                    0.6186507936507936,
                    0,
                    0.06620833956060379,
                    0.01731760526671429,
                    0.8377923864852469,
                    0.3952115626309175,
                    0.07936507936507936,
                    0,
                    0,
                    1.0
                ],
                [
                    0.2056290417401528,
                    0,
                    0.8444178747571365,
                    0.22008996660038227,
                    0.04402996483718086,
                    0.26573709444677185,
                    0.047619047619047616,
                    0,
                    0,
                    1.0
                ]
            ],
            "fraction_answers": {
                "pharmaceuticals": 0.39298854050666215,
                "cable tv": 0.33575762782655927,
                "fast food": 0.27125383166677863
            },
            "question": "the only person who owns more u.s. land than ted turner made his fortune in what business?",
            "rate_limited": false,
            "answers": [
                "pharmaceuticals",
                "cable tv",
                "fast food"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "pharmaceuticals": 0.3551750327836073,
                "cable tv": 0.39214243134969123,
                "fast food": 0.2530003092813469
            },
            "integer_answers": {
                "pharmaceuticals": 2,
                "cable tv": 3,
                "fast food": 1
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    3950000.0,
                    89700.0,
                    1140000.0
                ],
                "wikipedia_search": [
                    1.6952567146115534,
                    1.9760578131545874,
                    1.3286854722338592
                ],
                "answer_relation_to_question": [
                    1.0543209876543211,
                    3.711904761904762,
                    1.233774250440917
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    773000.0,
                    5480000.0,
                    288000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count": [
                    598000.0,
                    443000.0,
                    5650000.0
                ],
                "word_count_appended": [
                    165.0,
                    15.0,
                    9.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Which game is an example of combinatorics?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "sudoku"
            ],
            "lines": [
                [
                    0.6178343949044586,
                    1.0,
                    0.11927788523533205,
                    0.18909780103809953,
                    0.11511254019292605,
                    0.14516129032258066,
                    0.30745658835546474,
                    0,
                    0,
                    -1.0
                ],
                [
                    0.14225053078556263,
                    0.0,
                    0.3984526112185687,
                    0.005405871077512869,
                    0.40385852090032154,
                    0.3544142614601019,
                    0.06230847803881512,
                    0,
                    0,
                    -1.0
                ],
                [
                    0.23991507430997877,
                    0.0,
                    0.48226950354609927,
                    0.8054963278843876,
                    0.4810289389067524,
                    0.5004244482173175,
                    0.6302349336057201,
                    0,
                    0,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "sudoku": 0.4484813180671794,
                "risk": 0.3562772142926945,
                "crossword puzzles": 0.1952414676401261
            },
            "question": "which game is an example of combinatorics?",
            "rate_limited": false,
            "answers": [
                "risk",
                "crossword puzzles",
                "sudoku"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "sudoku": 0.401538216027624,
                "risk": 0.38547777529941,
                "crossword puzzles": 0.10941329100674109
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    878000.0,
                    25100.0,
                    3740000.0
                ],
                "wikipedia_search": [
                    0.2903225806451613,
                    0.7088285229202038,
                    1.000848896434635
                ],
                "answer_relation_to_question": [
                    1.2356687898089171,
                    0.28450106157112526,
                    0.47983014861995754
                ],
                "question_related_to_answer": [
                    1.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    895000.0,
                    3140000.0,
                    3740000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_appended": [
                    301.0,
                    61.0,
                    617.0
                ],
                "result_count": [
                    925000.0,
                    3090000.0,
                    3740000.0
                ]
            },
            "integer_answers": {
                "sudoku": 5,
                "risk": 2,
                "crossword puzzles": 0
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which of these mammals averages the largest litter?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "naked mole rat"
            ],
            "lines": [
                [
                    0.24113475177304966,
                    1.0,
                    0.6655029456687759,
                    0.6834532374100719,
                    0.23533921042545036,
                    0.7863247863247863,
                    0.1597222222222222,
                    1.0,
                    0,
                    -1.0
                ],
                [
                    0.05460992907801419,
                    0.0,
                    0.0006545930613135501,
                    0.12524525833878353,
                    0.3008815638175546,
                    0.1111111111111111,
                    0.06944444444444445,
                    0.0,
                    0,
                    -1.0
                ],
                [
                    0.7042553191489361,
                    0.0,
                    0.3338424612699105,
                    0.19130150425114453,
                    0.46377922575699504,
                    0.10256410256410257,
                    0.7708333333333334,
                    0.0,
                    0,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "naked mole rat": 0.5964346442280445,
                "burmese cat": 0.08274336248140268,
                "jackrabbit": 0.3208219932905528
            },
            "question": "which of these mammals averages the largest litter?",
            "rate_limited": false,
            "answers": [
                "naked mole rat",
                "burmese cat",
                "jackrabbit"
            ],
            "ml_answers": {
                "naked mole rat": 0.49400493639916554,
                "burmese cat": 0.07707318115507075,
                "jackrabbit": 0.25732266641381224
            },
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "integer_answers": {
                "naked mole rat": 5,
                "burmese cat": 0,
                "jackrabbit": 3
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    209000.0,
                    38300.0,
                    58500.0
                ],
                "wikipedia_search": [
                    2.358974358974359,
                    0.3333333333333333,
                    0.3076923076923077
                ],
                "answer_relation_to_question": [
                    0.723404255319149,
                    0.16382978723404257,
                    2.1127659574468085
                ],
                "question_related_to_answer": [
                    1.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    61400.0,
                    78500.0,
                    121000.0
                ],
                "word_count_noun_chunks": [
                    1.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_appended": [
                    69.0,
                    30.0,
                    333.0
                ],
                "result_count": [
                    30500.0,
                    30.0,
                    15300.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Queen Victoria is credited with starting what fashion trend?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "white wedding dress"
            ],
            "lines": [
                [
                    0.18015576155111038,
                    0,
                    0.3855421686746988,
                    0.2753623188405797,
                    0.6540977298961139,
                    0.5936507936507937,
                    0.21839080459770116,
                    0,
                    0.0,
                    1.0
                ],
                [
                    0.28204224715852627,
                    0,
                    0.2289156626506024,
                    0.427536231884058,
                    0.28703347441323585,
                    0.11904761904761905,
                    0.3333333333333333,
                    0,
                    0.0,
                    1.0
                ],
                [
                    0.5378019912903634,
                    0,
                    0.3855421686746988,
                    0.2971014492753623,
                    0.05886879569065025,
                    0.2873015873015873,
                    0.4482758620689655,
                    0,
                    1.0,
                    1.0
                ]
            ],
            "fraction_answers": {
                "white wedding dress": 0.43069883632880396,
                "mini dress": 0.32959993960157113,
                "little black dress": 0.239701224069625
            },
            "question": "queen victoria is credited with starting what fashion trend?",
            "rate_limited": false,
            "answers": [
                "mini dress",
                "little black dress",
                "white wedding dress"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "white wedding dress": 0.5596171095508692,
                "mini dress": 0.4034112988446457,
                "little black dress": 0.3439821307948527
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    38.0,
                    59.0,
                    41.0
                ],
                "wikipedia_search": [
                    2.3746031746031746,
                    0.4761904761904762,
                    1.1492063492063491
                ],
                "answer_relation_to_question": [
                    1.0809345693066623,
                    1.6922534829511575,
                    3.2268119477421804
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    17000000.0,
                    7460000.0,
                    1530000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    5.0
                ],
                "result_count": [
                    32.0,
                    19.0,
                    32.0
                ],
                "word_count_appended": [
                    19.0,
                    29.0,
                    39.0
                ]
            },
            "integer_answers": {
                "white wedding dress": 3,
                "mini dress": 3,
                "little black dress": 1
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Who is the only actor to appear as both a student and a guest on \u201cInside the Actors Studio\u201d?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "bradley cooper"
            ],
            "lines": [
                [
                    0.341727120712252,
                    0.0,
                    0.24299065420560748,
                    0.08266129032258064,
                    0.4563053097345133,
                    0.288332481689661,
                    0.22641509433962265,
                    0.0,
                    0.0,
                    0.0
                ],
                [
                    0.4012387279492626,
                    0.0,
                    0.308411214953271,
                    0.03574046920821115,
                    0.06526548672566372,
                    0.12284321239993186,
                    0.1509433962264151,
                    0.0,
                    0.0,
                    0.0
                ],
                [
                    0.2570341513384854,
                    1.0,
                    0.4485981308411215,
                    0.8815982404692082,
                    0.478429203539823,
                    0.5888243059104071,
                    0.6226415094339622,
                    1.0,
                    1.0,
                    0.0
                ]
            ],
            "fraction_answers": {
                "tobey maguire": 0.12049361194030614,
                "bradley cooper": 0.6974583935036675,
                "ryan gosling": 0.18204799455602635
            },
            "question": "who is the only actor to appear as both a student and a guest on \u201cinside the actors studio\u201d?",
            "rate_limited": false,
            "answers": [
                "ryan gosling",
                "tobey maguire",
                "bradley cooper"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "tobey maguire": 0.04854265680319761,
                "bradley cooper": 0.8259239319215143,
                "ryan gosling": 0.01882780922660829
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 0
            },
            "data": {
                "result_count_important_words": [
                    45100.0,
                    19500.0,
                    481000.0
                ],
                "wikipedia_search": [
                    1.7299948901379663,
                    0.7370592743995912,
                    3.5329458354624426
                ],
                "answer_relation_to_question": [
                    1.70863560356126,
                    2.006193639746313,
                    1.285170756692427
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    1.0
                ],
                "result_count_noun_chunks": [
                    165000.0,
                    23600.0,
                    173000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    2.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    4.0
                ],
                "word_count_appended": [
                    12.0,
                    8.0,
                    33.0
                ],
                "result_count": [
                    26.0,
                    33.0,
                    48.0
                ]
            },
            "integer_answers": {
                "tobey maguire": 1,
                "bradley cooper": 8,
                "ryan gosling": 0
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "According to the old saying, what kind of animal can NOT change its spots?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "tiger"
            ],
            "lines": [
                [
                    0.3210337869209615,
                    0.49395770392749244,
                    0.3627300613496932,
                    0.36510791366906475,
                    0.3591654247391952,
                    0.4863121874177415,
                    0.35564853556485354,
                    0.4734848484848485,
                    0.4764705882352941,
                    1.0
                ],
                [
                    0.27289635344119434,
                    0.01057401812688824,
                    0.3197852760736196,
                    0.3732014388489209,
                    0.3181818181818182,
                    0.3476472195281712,
                    0.301673640167364,
                    0.08333333333333331,
                    0.03529411764705881,
                    1.0
                ],
                [
                    0.4060698596378442,
                    0.4954682779456193,
                    0.3174846625766871,
                    0.2616906474820144,
                    0.32265275707898655,
                    0.1660405930540873,
                    0.3426778242677824,
                    0.4431818181818182,
                    0.48823529411764705,
                    1.0
                ]
            ],
            "fraction_answers": {
                "tiger": 0.2792218368127808,
                "leopard": 0.5416472854781403,
                "zebra": 0.17913087770907896
            },
            "question": "according to the old saying, what kind of animal can not change its spots?",
            "rate_limited": false,
            "answers": [
                "zebra",
                "leopard",
                "tiger"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "integer_answers": {
                "tiger": 3,
                "leopard": 6,
                "zebra": 0
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    1500000.0,
                    1410000.0,
                    2650000.0
                ],
                "wikipedia_search": [
                    0.16425375098710188,
                    1.8282333656619458,
                    4.007512883350953
                ],
                "answer_relation_to_question": [
                    2.1475945569484622,
                    2.7252437587056684,
                    1.1271616843458694
                ],
                "question_related_to_answer": [
                    0.012084592145015106,
                    0.9788519637462235,
                    0.00906344410876133
                ],
                "result_count_noun_chunks": [
                    1890000.0,
                    2440000.0,
                    2380000.0
                ],
                "word_count_noun_chunks": [
                    7.0,
                    110.0,
                    15.0
                ],
                "word_count_raw": [
                    4.0,
                    79.0,
                    2.0
                ],
                "word_count_appended": [
                    345.0,
                    474.0,
                    376.0
                ],
                "result_count": [
                    1790000.0,
                    2350000.0,
                    2380000.0
                ]
            },
            "ml_answers": {
                "tiger": 0.30053340032922093,
                "leopard": 0.04697352058477283,
                "zebra": 0.20631073778618506
            }
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Which of these astronomical objects orbits the Earth?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "moon"
            ],
            "lines": [
                [
                    0.439453125,
                    0.46535714285714286,
                    0.2717391304347826,
                    0.28377525252525254,
                    0.25601750547045954,
                    0.40514200711569137,
                    0.48777777777777775,
                    0.4583333333333333,
                    0.3583815028901734,
                    -1.0
                ],
                [
                    0.435546875,
                    0.06,
                    0.2080745341614907,
                    0.1764520202020202,
                    0.20021881838074398,
                    0.3276821862348178,
                    0.09111111111111111,
                    0.058333333333333334,
                    0.028901734104046242,
                    -1.0
                ],
                [
                    0.125,
                    0.47464285714285714,
                    0.5201863354037267,
                    0.5397727272727273,
                    0.5437636761487965,
                    0.26717580664949087,
                    0.4211111111111111,
                    0.48333333333333334,
                    0.6127167630057804,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "sun": 0.44307806778531367,
                "milky way": 0.17625784583639592,
                "moon": 0.3806640863782903
            },
            "question": "which of these astronomical objects orbits the earth?",
            "rate_limited": false,
            "answers": [
                "moon",
                "milky way",
                "sun"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "sun": 0.39783522462138615,
                "milky way": 0.2901900798721622,
                "moon": 0.5151328732135535
            },
            "integer_answers": {
                "sun": 6,
                "milky way": 0,
                "moon": 3
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    899000.0,
                    559000.0,
                    1710000.0
                ],
                "wikipedia_search": [
                    1.6205680284627655,
                    1.3107287449392713,
                    1.0687032265979635
                ],
                "answer_relation_to_question": [
                    1.7578125,
                    1.7421875,
                    0.5
                ],
                "question_related_to_answer": [
                    0.9307142857142857,
                    0.12,
                    0.9492857142857143
                ],
                "result_count_noun_chunks": [
                    2340000.0,
                    1830000.0,
                    4970000.0
                ],
                "word_count_noun_chunks": [
                    55.0,
                    7.0,
                    58.0
                ],
                "word_count_raw": [
                    62.0,
                    5.0,
                    106.0
                ],
                "word_count_appended": [
                    439.0,
                    82.0,
                    379.0
                ],
                "result_count": [
                    1750000.0,
                    1340000.0,
                    3350000.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "What soda is named for a medical condition?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "pepsi"
            ],
            "lines": [
                [
                    0.3303030303030303,
                    0.0,
                    0.003528523090613715,
                    0.06156559073832707,
                    0.13214717567801001,
                    0.024390243902439025,
                    0.28404255319148936,
                    0.0,
                    0.0,
                    1.0
                ],
                [
                    0.5363636363636364,
                    1.0,
                    0.17901304829213274,
                    0.25070919267039793,
                    0.7030575228882363,
                    0.8048780487804879,
                    0.44468085106382976,
                    1.0,
                    1.0,
                    1.0
                ],
                [
                    0.13333333333333333,
                    0.0,
                    0.8174584286172536,
                    0.6877252165912751,
                    0.16479530143375368,
                    0.17073170731707318,
                    0.2712765957446808,
                    0.0,
                    0.0,
                    1.0
                ]
            ],
            "fraction_answers": {
                "fanta": 0.24948006478193,
                "pepsi": 0.6576335888954135,
                "faygo": 0.09288634632265663
            },
            "question": "what soda is named for a medical condition?",
            "rate_limited": false,
            "answers": [
                "faygo",
                "pepsi",
                "fanta"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "fanta": 0.14695464852209425,
                "pepsi": 0.7372655593451748,
                "faygo": 0.12459155259117405
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    80300.0,
                    327000.0,
                    897000.0
                ],
                "wikipedia_search": [
                    0.04878048780487805,
                    1.6097560975609757,
                    0.34146341463414637
                ],
                "answer_relation_to_question": [
                    0.990909090909091,
                    1.6090909090909091,
                    0.4
                ],
                "question_related_to_answer": [
                    0.0,
                    1.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    76500.0,
                    407000.0,
                    95400.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    5.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    14.0,
                    0.0
                ],
                "result_count": [
                    6820.0,
                    346000.0,
                    1580000.0
                ],
                "word_count_appended": [
                    267.0,
                    418.0,
                    255.0
                ]
            },
            "integer_answers": {
                "fanta": 2,
                "pepsi": 7,
                "faygo": 0
            }
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Which of these is NOT a geometric shape?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "tarragon"
            ],
            "lines": [
                [
                    0.43,
                    0.33333333333333337,
                    0.3096514745308311,
                    0.48234862385321103,
                    0.48251081149834646,
                    0.35,
                    0.33271719038817005,
                    0.33333333333333337,
                    0.4166666666666667,
                    -1.0
                ],
                [
                    0.5,
                    0.5,
                    0.4772117962466488,
                    0.49471559633027523,
                    0.4944670567285678,
                    0.4,
                    0.39695009242144175,
                    0.5,
                    0.5,
                    -1.0
                ],
                [
                    0.07,
                    0.16666666666666669,
                    0.21313672922252008,
                    0.022935779816513735,
                    0.023022131773085708,
                    0.25,
                    0.2703327171903882,
                    0.16666666666666669,
                    0.08333333333333331,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "hexagon": 0.7186457722957389,
                "octagon": 0.2287641258658018,
                "tarragon": 0.052590101838459205
            },
            "question": "which of these is not a geometric shape?",
            "rate_limited": false,
            "answers": [
                "octagon",
                "tarragon",
                "hexagon"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "hexagon": 0.09121762494691688,
                "octagon": 0.19659898032181736,
                "tarragon": 0.2843900494562984
            },
            "integer_answers": {
                "hexagon": 9,
                "octagon": 0,
                "tarragon": 0
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    481000.0,
                    144000.0,
                    13000000.0
                ],
                "wikipedia_search": [
                    0.3,
                    0.2,
                    0.5
                ],
                "answer_relation_to_question": [
                    0.28,
                    0.0,
                    1.72
                ],
                "question_related_to_answer": [
                    0.3333333333333333,
                    0.0,
                    0.6666666666666666
                ],
                "result_count_noun_chunks": [
                    550000.0,
                    174000.0,
                    15000000.0
                ],
                "word_count_noun_chunks": [
                    1.0,
                    0.0,
                    2.0
                ],
                "word_count_raw": [
                    1.0,
                    0.0,
                    5.0
                ],
                "result_count": [
                    1420000.0,
                    170000.0,
                    2140000.0
                ],
                "word_count_appended": [
                    362.0,
                    223.0,
                    497.0
                ]
            },
            "negative_question": true
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "What tech mogul became a billionaire the youngest?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "mark zuckerberg"
            ],
            "lines": [
                [
                    0.7403149266609146,
                    0.0,
                    0.008022922636103151,
                    0.07599782863346762,
                    0.8279370952821462,
                    0.4163832199546485,
                    0.3881278538812785,
                    0.1111111111111111,
                    0.30434782608695654,
                    1.0
                ],
                [
                    0.1555004314063848,
                    1.0,
                    0.8510028653295129,
                    0.8999742864489586,
                    0.0818686401480111,
                    0.34268707482993194,
                    0.3881278538812785,
                    0.8888888888888888,
                    0.6086956521739131,
                    1.0
                ],
                [
                    0.1041846419327006,
                    0.0,
                    0.14097421203438396,
                    0.024027884917573784,
                    0.09019426456984274,
                    0.24092970521541948,
                    0.2237442922374429,
                    0.0,
                    0.08695652173913043,
                    1.0
                ]
            ],
            "fraction_answers": {
                "mark zuckerberg": 0.5796384103452089,
                "evan spiegel": 0.319138087138514,
                "larry page": 0.10122350251627711
            },
            "question": "what tech mogul became a billionaire the youngest?",
            "rate_limited": false,
            "answers": [
                "evan spiegel",
                "mark zuckerberg",
                "larry page"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "mark zuckerberg": 0.7564748205637808,
                "evan spiegel": 0.3930163204942245,
                "larry page": 0.02450169742898447
            },
            "integer_answers": {
                "mark zuckerberg": 5,
                "evan spiegel": 4,
                "larry page": 0
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    26600.0,
                    315000.0,
                    8410.0
                ],
                "wikipedia_search": [
                    1.2491496598639455,
                    1.0280612244897958,
                    0.7227891156462585
                ],
                "answer_relation_to_question": [
                    2.9612597066436583,
                    0.6220017256255392,
                    0.4167385677308024
                ],
                "question_related_to_answer": [
                    0.0,
                    2.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    1790000.0,
                    177000.0,
                    195000.0
                ],
                "word_count_noun_chunks": [
                    1.0,
                    8.0,
                    0.0
                ],
                "word_count_raw": [
                    7.0,
                    14.0,
                    2.0
                ],
                "result_count": [
                    2800.0,
                    297000.0,
                    49200.0
                ],
                "word_count_appended": [
                    85.0,
                    85.0,
                    49.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Which actor currently stars in a show that is both one word long and pluralized?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "paul giamatti"
            ],
            "lines": [
                [
                    0.5253250773993808,
                    0,
                    0.10182767624020887,
                    0.3261802575107296,
                    0.5572052401746724,
                    0.30431887366818877,
                    0.3620689655172414,
                    0,
                    0,
                    -1.0
                ],
                [
                    0.2620433436532507,
                    0,
                    0.09530026109660575,
                    0.2875536480686695,
                    0.35458515283842795,
                    0.33656773211567736,
                    0.3448275862068966,
                    0,
                    0,
                    -1.0
                ],
                [
                    0.21263157894736837,
                    0,
                    0.8028720626631853,
                    0.38626609442060084,
                    0.08820960698689956,
                    0.359113394216134,
                    0.29310344827586204,
                    0,
                    0,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "william h. macy": 0.3628210150850703,
                "taraji p. henson": 0.28014628732992136,
                "paul giamatti": 0.3570326975850084
            },
            "question": "which actor currently stars in a show that is both one word long and pluralized?",
            "rate_limited": false,
            "answers": [
                "william h. macy",
                "taraji p. henson",
                "paul giamatti"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "william h. macy": 0.2959887982908165,
                "taraji p. henson": 0.1539700517977633,
                "paul giamatti": 0.3158853597986339
            },
            "integer_answers": {
                "william h. macy": 3,
                "taraji p. henson": 0,
                "paul giamatti": 3
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    76.0,
                    67.0,
                    90.0
                ],
                "wikipedia_search": [
                    1.217275494672755,
                    1.3462709284627095,
                    1.436453576864536
                ],
                "answer_relation_to_question": [
                    2.6266253869969045,
                    1.3102167182662539,
                    1.063157894736842
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    638000.0,
                    406000.0,
                    101000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_appended": [
                    21.0,
                    20.0,
                    17.0
                ],
                "result_count": [
                    78.0,
                    73.0,
                    615.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which animal is specifically mentioned in the Judeo-Christian Ten Commandments?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "ox"
            ],
            "question": "which animal is specifically mentioned in the judeo-christian ten commandments?",
            "answers": [
                "pig",
                "ox",
                "goat"
            ],
            "integer_answers": {
                "ox": 4,
                "goat": 5,
                "pig": 0
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    65900.0,
                    45800.0,
                    74200.0
                ],
                "wikipedia_search": [
                    0.2967032967032967,
                    0.16483516483516483,
                    2.5384615384615383
                ],
                "answer_relation_to_question": [
                    0.4083333333333333,
                    0.11666666666666667,
                    1.475
                ],
                "question_related_to_answer": [
                    0.16666666666666666,
                    1.6666666666666665,
                    0.16666666666666666
                ],
                "result_count_noun_chunks": [
                    94600.0,
                    60500.0,
                    97500.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    20.0,
                    0.0
                ],
                "word_count_raw": [
                    1.0,
                    18.0,
                    0.0
                ],
                "word_count_appended": [
                    208.0,
                    210.0,
                    169.0
                ],
                "result_count": [
                    9460.0,
                    23200.0,
                    48000.0
                ]
            },
            "negative_question": false,
            "fraction_answers": {
                "ox": 0.4472485130966672,
                "goat": 0.3705674836587357,
                "pig": 0.1821840032445972
            },
            "lines": [
                [
                    0.20416666666666666,
                    0.08333333333333333,
                    0.11728242003471362,
                    0.3544916621839699,
                    0.3745051464766429,
                    0.0989010989010989,
                    0.3543441226575809,
                    0.0,
                    0.05263157894736842,
                    -1.0
                ],
                [
                    0.058333333333333334,
                    0.8333333333333333,
                    0.2876270766179023,
                    0.24636901559978483,
                    0.23950910530482977,
                    0.054945054945054944,
                    0.3577512776831346,
                    1.0,
                    0.9473684210526315,
                    -1.0
                ],
                [
                    0.7375,
                    0.08333333333333333,
                    0.5950905033473841,
                    0.3991393222162453,
                    0.3859857482185273,
                    0.8461538461538461,
                    0.2879045996592845,
                    0.0,
                    0.0,
                    -1.0
                ]
            ],
            "rate_limited": false,
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "ox": 0.761417935723833,
                "goat": 0.37414476001192254,
                "pig": 0.14732220289077885
            }
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Which human sense is most closely associated with the bony labyrinth?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "hearing"
            ],
            "lines": [
                [
                    0.31363636363636366,
                    0.36250000000000004,
                    0.3393552957846263,
                    0.3467048710601719,
                    0.3541666666666667,
                    0.3904761904761905,
                    0.30272596843615496,
                    0.3625,
                    0.044444444444444446,
                    -1.0
                ],
                [
                    0.434469696969697,
                    0.28750000000000003,
                    0.34041799504073683,
                    0.32521489971346706,
                    0.34558823529411764,
                    0.5,
                    0.4103299856527977,
                    0.2875,
                    0.9111111111111111,
                    -1.0
                ],
                [
                    0.2518939393939394,
                    0.35000000000000003,
                    0.3202267091746369,
                    0.32808022922636104,
                    0.3002450980392157,
                    0.10952380952380951,
                    0.28694404591104733,
                    0.35,
                    0.044444444444444446,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "touch": 0.31294553338940206,
                "sight": 0.2601509195237172,
                "hearing": 0.4269035470868808
            },
            "question": "which human sense is most closely associated with the bony labyrinth?",
            "rate_limited": false,
            "answers": [
                "touch",
                "hearing",
                "sight"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "touch": 0.16548397242585064,
                "sight": 0.23761720759765378,
                "hearing": 0.54953496210252
            },
            "integer_answers": {
                "touch": 4,
                "sight": 0,
                "hearing": 5
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    242000.0,
                    227000.0,
                    229000.0
                ],
                "wikipedia_search": [
                    1.9523809523809523,
                    2.5,
                    0.5476190476190476
                ],
                "answer_relation_to_question": [
                    0.9409090909090909,
                    1.303409090909091,
                    0.7556818181818181
                ],
                "question_related_to_answer": [
                    0.3625,
                    0.2875,
                    0.35
                ],
                "result_count_noun_chunks": [
                    289000000.0,
                    282000000.0,
                    245000000.0
                ],
                "word_count_noun_chunks": [
                    29.0,
                    23.0,
                    28.0
                ],
                "word_count_raw": [
                    2.0,
                    41.0,
                    2.0
                ],
                "result_count": [
                    95800.0,
                    96100.0,
                    90400.0
                ],
                "word_count_appended": [
                    211.0,
                    286.0,
                    200.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Which of these utensils is tined?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "spoon"
            ],
            "lines": [
                [
                    0.0,
                    0.32894736842105265,
                    0.05735140771637122,
                    0.4,
                    0.32504215851602025,
                    0.8333333333333334,
                    0.4056603773584906,
                    0.32894736842105265,
                    0.1,
                    -1.0
                ],
                [
                    1.0,
                    0.09210526315789473,
                    0.47758081334723673,
                    0.29028571428571426,
                    0.3330522765598651,
                    0.16666666666666669,
                    0.264937106918239,
                    0.09210526315789473,
                    0.0,
                    -1.0
                ],
                [
                    0.0,
                    0.5789473684210527,
                    0.46506777893639206,
                    0.3097142857142857,
                    0.34190556492411467,
                    0.0,
                    0.32940251572327045,
                    0.5789473684210527,
                    0.9,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "fork": 0.3088091126407023,
                "spoon": 0.38933165357112975,
                "knife": 0.3018592337881679
            },
            "question": "which of these utensils is tined?",
            "rate_limited": false,
            "answers": [
                "fork",
                "knife",
                "spoon"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "fork": 0.33451501716403953,
                "spoon": 0.570955297592969,
                "knife": 0.3625832284368784
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    350000.0,
                    254000.0,
                    271000.0
                ],
                "wikipedia_search": [
                    1.6666666666666665,
                    0.3333333333333333,
                    0.0
                ],
                "answer_relation_to_question": [
                    0.0,
                    1.0,
                    0.0
                ],
                "question_related_to_answer": [
                    0.32894736842105265,
                    0.09210526315789473,
                    0.5789473684210527
                ],
                "result_count_noun_chunks": [
                    7710000.0,
                    7900000.0,
                    8110000.0
                ],
                "word_count_noun_chunks": [
                    25.0,
                    7.0,
                    44.0
                ],
                "word_count_raw": [
                    1.0,
                    0.0,
                    9.0
                ],
                "result_count": [
                    275000.0,
                    2290000.0,
                    2230000.0
                ],
                "word_count_appended": [
                    516.0,
                    337.0,
                    419.0
                ]
            },
            "integer_answers": {
                "fork": 3,
                "spoon": 4,
                "knife": 2
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which TV comedy centers on a vice president?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "veep"
            ],
            "lines": [
                [
                    0.12736008736008736,
                    0.0,
                    0.04942381562099872,
                    0.06030150753768844,
                    0.06204485872414797,
                    0.312767094017094,
                    0.07708779443254818,
                    0.0,
                    0.0,
                    -1.0
                ],
                [
                    0.176015561015561,
                    0.0,
                    0.3001280409731114,
                    0.2964824120603015,
                    0.8447422079813575,
                    0.027136752136752137,
                    0.28051391862955033,
                    0.0,
                    0.0,
                    -1.0
                ],
                [
                    0.6966243516243517,
                    1.0,
                    0.6504481434058899,
                    0.6432160804020101,
                    0.09321293329449461,
                    0.6600961538461538,
                    0.6423982869379015,
                    1.0,
                    1.0,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "young sheldon": 0.07655390641028498,
                "veep": 0.7095551055012002,
                "superstore": 0.21389098808851487
            },
            "question": "which tv comedy centers on a vice president?",
            "rate_limited": false,
            "answers": [
                "young sheldon",
                "superstore",
                "veep"
            ],
            "ml_answers": {
                "young sheldon": 0.05869533217740398,
                "veep": 0.8705377241780575,
                "superstore": 0.20028959128047302
            },
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "integer_answers": {
                "young sheldon": 0,
                "veep": 8,
                "superstore": 1
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    12000.0,
                    59000.0,
                    128000.0
                ],
                "wikipedia_search": [
                    1.251068376068376,
                    0.10854700854700855,
                    2.6403846153846153
                ],
                "answer_relation_to_question": [
                    0.6368004368004367,
                    0.8800778050778051,
                    3.4831217581217584
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    1.0
                ],
                "result_count_noun_chunks": [
                    85200.0,
                    1160000.0,
                    128000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    28.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    31.0
                ],
                "result_count": [
                    9650.0,
                    58600.0,
                    127000.0
                ],
                "word_count_appended": [
                    72.0,
                    262.0,
                    600.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which organization began as the North West Police Agency?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "pinkerton"
            ],
            "question": "which organization began as the north west police agency?",
            "answers": [
                "fbi",
                "nra",
                "pinkerton"
            ],
            "integer_answers": {
                "pinkerton": 2,
                "fbi": 6,
                "nra": 0
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    739000.0,
                    455000.0,
                    109000.0
                ],
                "wikipedia_search": [
                    5.0,
                    0.0,
                    0.0
                ],
                "answer_relation_to_question": [
                    2.742317331791016,
                    0.7307692307692307,
                    2.5269134374397533
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    8930000.0,
                    419000.0,
                    160000.0
                ],
                "word_count_noun_chunks": [
                    1.0,
                    0.0,
                    1.0
                ],
                "word_count_raw": [
                    7.0,
                    0.0,
                    18.0
                ],
                "word_count_appended": [
                    481.0,
                    428.0,
                    510.0
                ],
                "result_count": [
                    688000.0,
                    455000.0,
                    109000.0
                ]
            },
            "negative_question": false,
            "fraction_answers": {
                "pinkerton": 0.27351253114665447,
                "fbi": 0.5789759753552692,
                "nra": 0.14751149349807632
            },
            "lines": [
                [
                    0.45705288863183596,
                    0,
                    0.549520766773163,
                    0.5671527244819647,
                    0.9391103165422232,
                    1.0,
                    0.3389711064129669,
                    0.5,
                    0.28,
                    -1.0
                ],
                [
                    0.12179487179487179,
                    0,
                    0.3634185303514377,
                    0.34919416730621644,
                    0.04406351877168998,
                    0.0,
                    0.30162085976039466,
                    0.0,
                    0.0,
                    -1.0
                ],
                [
                    0.42115223957329223,
                    0,
                    0.08706070287539937,
                    0.08365310821181889,
                    0.016826164686086865,
                    0.0,
                    0.3594080338266385,
                    0.5,
                    0.72,
                    -1.0
                ]
            ],
            "rate_limited": false,
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "pinkerton": 0.733840982747197,
                "fbi": 0.36787148372018696,
                "nra": 0.443213532146012
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Mount Rushmore was named after a person with what profession?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "architect"
            ],
            "lines": [
                [
                    0.27398989898989895,
                    0.0,
                    0.18068763716166789,
                    0.02295684113865932,
                    0.12578899909828675,
                    0.265625,
                    0.2886866059817945,
                    0.0,
                    0.16666666666666666,
                    1.0
                ],
                [
                    0.18686868686868685,
                    0.9,
                    0.37673738112655447,
                    0.5509641873278237,
                    0.5184851217312895,
                    0.6437190594059405,
                    0.32769830949284784,
                    0.4,
                    0.8333333333333334,
                    1.0
                ],
                [
                    0.5391414141414141,
                    0.1,
                    0.4425749817117776,
                    0.426078971533517,
                    0.3557258791704238,
                    0.0906559405940594,
                    0.3836150845253576,
                    0.6,
                    0.0,
                    1.0
                ]
            ],
            "fraction_answers": {
                "architect": 0.3264213635196166,
                "prospector": 0.14715573878188604,
                "lawyer": 0.5264228976984974
            },
            "question": "mount rushmore was named after a person with what profession?",
            "rate_limited": false,
            "answers": [
                "prospector",
                "lawyer",
                "architect"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "architect": 0.7118864529333779,
                "prospector": 0.21204707222979924,
                "lawyer": 0.04564040691853912
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    625.0,
                    15000.0,
                    11600.0
                ],
                "wikipedia_search": [
                    1.0625,
                    2.574876237623762,
                    0.3626237623762376
                ],
                "answer_relation_to_question": [
                    1.0959595959595958,
                    0.7474747474747474,
                    2.1565656565656566
                ],
                "question_related_to_answer": [
                    0.0,
                    1.8,
                    0.2
                ],
                "result_count_noun_chunks": [
                    2790000.0,
                    11500000.0,
                    7890000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    2.0,
                    3.0
                ],
                "word_count_raw": [
                    1.0,
                    5.0,
                    0.0
                ],
                "word_count_appended": [
                    222.0,
                    252.0,
                    295.0
                ],
                "result_count": [
                    49400.0,
                    103000.0,
                    121000.0
                ]
            },
            "integer_answers": {
                "architect": 4,
                "prospector": 0,
                "lawyer": 5
            }
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "What is the total cost of all the vowels on \u201cWheel of Fortune\u201d?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "$1,250"
            ],
            "lines": [
                [
                    0.06869369369369369,
                    0,
                    0.31125827814569534,
                    0.09563294637921503,
                    0.2608695652173913,
                    0.0,
                    0.38461538461538464,
                    0,
                    0,
                    1.0
                ],
                [
                    0.4622747747747748,
                    0,
                    0.423841059602649,
                    0.865118850193477,
                    0.6326836581709145,
                    1.0,
                    0.358974358974359,
                    0,
                    0,
                    1.0
                ],
                [
                    0.46903153153153154,
                    0,
                    0.26490066225165565,
                    0.03924820342730791,
                    0.10644677661169415,
                    0.0,
                    0.2564102564102564,
                    0,
                    0,
                    1.0
                ]
            ],
            "fraction_answers": {
                "$2,500": 0.623815450286029,
                "$1,250": 0.18684497800856334,
                "$2,900": 0.1893395717054076
            },
            "question": "what is the total cost of all the vowels on \u201cwheel of fortune\u201d?",
            "rate_limited": false,
            "answers": [
                "$1,250",
                "$2,500",
                "$2,900"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "$2,500": 0.33265973196216064,
                "$1,250": 0.4287489198620564,
                "$2,900": 0.28579815204583603
            },
            "integer_answers": {
                "$2,500": 4,
                "$1,250": 1,
                "$2,900": 1
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    3460.0,
                    31300.0,
                    1420.0
                ],
                "wikipedia_search": [
                    0.0,
                    1.0,
                    0.0
                ],
                "answer_relation_to_question": [
                    0.27477477477477474,
                    1.8490990990990992,
                    1.8761261261261262
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    3480.0,
                    8440.0,
                    1420.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_appended": [
                    15.0,
                    14.0,
                    10.0
                ],
                "result_count": [
                    47.0,
                    64.0,
                    40.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which brand mascot was NOT a real person?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "sara lee"
            ],
            "lines": [
                [
                    0.3896358543417367,
                    0.5,
                    0.49670612454966545,
                    0.41346153846153844,
                    0.47337057123372195,
                    0.3032407407407408,
                    0.3054662379421222,
                    0.5,
                    0.5,
                    -1.0
                ],
                [
                    0.31097917427840704,
                    0.5,
                    0.4836507119574541,
                    0.4337606837606838,
                    0.4845257038937421,
                    0.4207175925925926,
                    0.3440514469453376,
                    0.5,
                    0.5,
                    -1.0
                ],
                [
                    0.2993849713798563,
                    0.0,
                    0.019643163492880422,
                    0.1527777777777778,
                    0.04210372487253594,
                    0.2760416666666667,
                    0.3504823151125402,
                    0.0,
                    0.0,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "betty crocker": 0.7465703068217207,
                "sara lee": 0.11606993034928507,
                "little debbie": 0.13735976282899431
            },
            "question": "which brand mascot was not a real person?",
            "rate_limited": false,
            "answers": [
                "little debbie",
                "sara lee",
                "betty crocker"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "betty crocker": 0.12747452556313071,
                "sara lee": 0.2225826042464715,
                "little debbie": 0.1535587651222483
            },
            "negative_question": true,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    162000.0,
                    124000.0,
                    650000.0
                ],
                "wikipedia_search": [
                    1.574074074074074,
                    0.6342592592592593,
                    1.7916666666666667
                ],
                "answer_relation_to_question": [
                    0.6621848739495798,
                    1.134124954329558,
                    1.2036901717208623
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    1.0
                ],
                "result_count_noun_chunks": [
                    164000.0,
                    95300.0,
                    2820000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    2.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    2.0
                ],
                "result_count": [
                    19200.0,
                    95300.0,
                    2800000.0
                ],
                "word_count_appended": [
                    121.0,
                    97.0,
                    93.0
                ]
            },
            "integer_answers": {
                "betty crocker": 8,
                "sara lee": 0,
                "little debbie": 1
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "What iconic painting once hung in Napoleon's bedroom?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "mona lisa"
            ],
            "lines": [
                [
                    0.3756701030927835,
                    0.0625,
                    0.17136563876651983,
                    0.0005184283182426485,
                    0.13940465664603596,
                    0.7300724637681159,
                    0.13312693498452013,
                    0.0,
                    0.0,
                    1.0
                ],
                [
                    0.09360824742268041,
                    0.9375,
                    0.6387665198237885,
                    0.7896989498812438,
                    0.671971706454465,
                    0.20591787439613526,
                    0.6687306501547987,
                    0.9629629629629629,
                    0.9824561403508771,
                    1.0
                ],
                [
                    0.530721649484536,
                    0.0,
                    0.18986784140969162,
                    0.2097826218005136,
                    0.18862363689949896,
                    0.06400966183574879,
                    0.19814241486068113,
                    0.037037037037037035,
                    0.017543859649122806,
                    1.0
                ]
            ],
            "fraction_answers": {
                "the birth of venus": 0.15952541366409223,
                "mona lisa": 0.6612903390496613,
                "the starry night": 0.17918424728624646
            },
            "question": "what iconic painting once hung in napoleon's bedroom?",
            "rate_limited": false,
            "answers": [
                "the starry night",
                "mona lisa",
                "the birth of venus"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "the birth of venus": 0.19299306425178933,
                "mona lisa": 0.6938884422038486,
                "the starry night": 0.15919695791032806
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    86.0,
                    131000.0,
                    34800.0
                ],
                "wikipedia_search": [
                    2.1902173913043477,
                    0.6177536231884058,
                    0.19202898550724637
                ],
                "answer_relation_to_question": [
                    1.8783505154639175,
                    0.46804123711340206,
                    2.6536082474226803
                ],
                "question_related_to_answer": [
                    0.125,
                    1.875,
                    0.0
                ],
                "result_count_noun_chunks": [
                    47300.0,
                    228000.0,
                    64000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    26.0,
                    1.0
                ],
                "word_count_raw": [
                    0.0,
                    56.0,
                    1.0
                ],
                "word_count_appended": [
                    43.0,
                    216.0,
                    64.0
                ],
                "result_count": [
                    38900.0,
                    145000.0,
                    43100.0
                ]
            },
            "integer_answers": {
                "the birth of venus": 1,
                "mona lisa": 7,
                "the starry night": 1
            }
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Which of these is NOT among the four \u201cC\u2019s\u201d of diamond buying?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "core"
            ],
            "lines": [
                [
                    0.33579130367963367,
                    0.09837455293879477,
                    0.21957375210319685,
                    0.24599465954606142,
                    0.21610169491525422,
                    0.15657439199123635,
                    0.27210884353741494,
                    0.21544715447154472,
                    0.19402985074626866,
                    -1.0
                ],
                [
                    0.2675370303139898,
                    0.4266575942296301,
                    0.32192933258553,
                    0.3931909212283044,
                    0.34227871939736343,
                    0.45210846887589246,
                    0.3180272108843537,
                    0.2845528455284553,
                    0.30597014925373134,
                    -1.0
                ],
                [
                    0.39667166600637654,
                    0.47496785283157505,
                    0.4584969153112731,
                    0.3608144192256342,
                    0.4416195856873823,
                    0.39131713913287125,
                    0.4098639455782313,
                    0.5,
                    0.5,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "color": 0.565778621349021,
                "core": 0.1258329947170347,
                "cut": 0.3083883839339443
            },
            "question": "which of these is not among the four \u201cc\u2019s\u201d of diamond buying?",
            "rate_limited": false,
            "answers": [
                "color",
                "cut",
                "core"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "color": 0.25419002466975366,
                "core": 0.28913190499361713,
                "cut": 0.1813273255142162
            },
            "negative_question": true,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    7610000.0,
                    3200000.0,
                    4170000.0
                ],
                "wikipedia_search": [
                    1.3737024320350546,
                    0.19156612449643015,
                    0.4347314434685151
                ],
                "answer_relation_to_question": [
                    0.985252177922198,
                    1.394777818116061,
                    0.6199700039617408
                ],
                "question_related_to_answer": [
                    2.4097526823672313,
                    0.44005443462221916,
                    0.1501928830105495
                ],
                "result_count_noun_chunks": [
                    603000.0,
                    335000.0,
                    124000.0
                ],
                "word_count_noun_chunks": [
                    140.0,
                    106.0,
                    0.0
                ],
                "word_count_raw": [
                    164.0,
                    104.0,
                    0.0
                ],
                "result_count": [
                    2000000.0,
                    1270000.0,
                    296000.0
                ],
                "word_count_appended": [
                    402.0,
                    321.0,
                    159.0
                ]
            },
            "integer_answers": {
                "color": 8,
                "core": 0,
                "cut": 1
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Rejected in the late 1700s, what was the name of the proposed 14th U.S. colony?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "vandalia"
            ],
            "lines": [
                [
                    0.2780969030969031,
                    0.02702702702702703,
                    0.7123444428550995,
                    0.640461215932914,
                    0.8832147341984093,
                    0.008620689655172414,
                    0.5847750865051903,
                    0.0,
                    0.0,
                    1.0
                ],
                [
                    0.6375187312687313,
                    0.972972972972973,
                    0.27463882134172507,
                    0.23060796645702306,
                    0.08183340309753034,
                    0.24233716475095785,
                    0.3737024221453287,
                    0.9333333333333333,
                    1.0,
                    1.0
                ],
                [
                    0.08438436563436563,
                    0.0,
                    0.013016735803175512,
                    0.1289308176100629,
                    0.034951862704060276,
                    0.7490421455938697,
                    0.04152249134948097,
                    0.06666666666666667,
                    0.0,
                    1.0
                ]
            ],
            "fraction_answers": {
                "roanoke": 0.3482822332523018,
                "new albion": 0.12427945392907574,
                "vandalia": 0.5274383128186225
            },
            "question": "rejected in the late 1700s, what was the name of the proposed 14th u.s. colony?",
            "rate_limited": false,
            "answers": [
                "roanoke",
                "vandalia",
                "new albion"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "roanoke": 0.30297181973569653,
                "new albion": 0.11380595576033048,
                "vandalia": 0.821196948265014
            },
            "integer_answers": {
                "roanoke": 4,
                "new albion": 1,
                "vandalia": 4
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    6110.0,
                    2200.0,
                    1230.0
                ],
                "wikipedia_search": [
                    0.017241379310344827,
                    0.4846743295019157,
                    1.4980842911877394
                ],
                "answer_relation_to_question": [
                    1.1123876123876124,
                    2.550074925074925,
                    0.33753746253746253
                ],
                "question_related_to_answer": [
                    0.02702702702702703,
                    0.972972972972973,
                    0.0
                ],
                "result_count_noun_chunks": [
                    42200.0,
                    3910.0,
                    1670.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    14.0,
                    1.0
                ],
                "word_count_raw": [
                    0.0,
                    7.0,
                    0.0
                ],
                "word_count_appended": [
                    169.0,
                    108.0,
                    12.0
                ],
                "result_count": [
                    4980.0,
                    1920.0,
                    91.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "In which version of \u201cDragnet\u201d is the line \u201cJust the facts, ma\u2019am\u201d first said?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "'80s movie"
            ],
            "lines": [
                [
                    0.4061372549019608,
                    0,
                    0.2608695652173913,
                    0.2037037037037037,
                    0.3983849259757739,
                    0.012077294685990338,
                    0.3333333333333333,
                    0,
                    0,
                    -1.0
                ],
                [
                    0.23075816993464052,
                    0,
                    0.21739130434782608,
                    0.2037037037037037,
                    0.41184387617765816,
                    0.8140096618357487,
                    0.3333333333333333,
                    0,
                    0,
                    -1.0
                ],
                [
                    0.36310457516339867,
                    0,
                    0.5217391304347826,
                    0.5925925925925926,
                    0.18977119784656796,
                    0.17391304347826086,
                    0.3333333333333333,
                    0,
                    0,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "'80s movie": 0.362408978808156,
                "'50s movie": 0.36850667488881844,
                "'50s tv show": 0.2690843463030256
            },
            "question": "in which version of \u201cdragnet\u201d is the line \u201cjust the facts, ma\u2019am\u201d first said?",
            "rate_limited": false,
            "answers": [
                "'50s tv show",
                "'50s movie",
                "'80s movie"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "'80s movie": 0.5013703482515799,
                "'50s movie": 0.16736678956384726,
                "'50s tv show": 0.26837615087040356
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    11.0,
                    11.0,
                    32.0
                ],
                "wikipedia_search": [
                    0.036231884057971016,
                    2.442028985507246,
                    0.5217391304347826
                ],
                "answer_relation_to_question": [
                    2.030686274509804,
                    1.1537908496732026,
                    1.8155228758169935
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    148000.0,
                    153000.0,
                    70500.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count": [
                    12.0,
                    10.0,
                    24.0
                ],
                "word_count_appended": [
                    3.0,
                    3.0,
                    3.0
                ]
            },
            "integer_answers": {
                "'80s movie": 2,
                "'50s movie": 2,
                "'50s tv show": 2
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which of these companies went public first?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "facebook"
            ],
            "lines": [
                [
                    0.5711538461538461,
                    1.0,
                    0.9722264288094012,
                    0.987455865889715,
                    0.9893902594912438,
                    0.5554804804804805,
                    0.29873695771554093,
                    1.0,
                    1.0,
                    -1.0
                ],
                [
                    0.1653846153846154,
                    0.0,
                    0.014568252718296634,
                    0.006028073599908143,
                    0.005189824875367506,
                    0.12832475332475332,
                    0.3552992861065349,
                    0.0,
                    0.0,
                    -1.0
                ],
                [
                    0.26346153846153847,
                    0.0,
                    0.013205318472302148,
                    0.0065160605103768985,
                    0.005419915633388725,
                    0.31619476619476616,
                    0.34596375617792424,
                    0.0,
                    0.0,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "facebook": 0.819382648726692,
                "ferrari": 0.07497720066771955,
                "alibaba": 0.10564015060558853
            },
            "question": "which of these companies went public first?",
            "rate_limited": false,
            "answers": [
                "facebook",
                "ferrari",
                "alibaba"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "facebook": 0.7104230161084534,
                "ferrari": 0.4089234388602467,
                "alibaba": 0.4714726137222247
            },
            "integer_answers": {
                "facebook": 8,
                "ferrari": 1,
                "alibaba": 0
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    344000000.0,
                    2100000.0,
                    2270000.0
                ],
                "wikipedia_search": [
                    1.6664414414414415,
                    0.38497425997425994,
                    0.9485842985842985
                ],
                "answer_relation_to_question": [
                    1.1423076923076922,
                    0.3307692307692308,
                    0.5269230769230769
                ],
                "question_related_to_answer": [
                    1.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    387000000.0,
                    2030000.0,
                    2120000.0
                ],
                "word_count_noun_chunks": [
                    1.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    7.0,
                    0.0,
                    0.0
                ],
                "word_count_appended": [
                    544.0,
                    647.0,
                    630.0
                ],
                "result_count": [
                    321000000.0,
                    4810000.0,
                    4360000.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "What topic would a herpetologist study?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "venereal disease"
            ],
            "lines": [
                [
                    0.3916256157635468,
                    0,
                    0.9644789461303223,
                    0.9454145357484871,
                    0.4861788617886179,
                    0.7333333333333334,
                    0.4146341463414634,
                    0,
                    0,
                    1.0
                ],
                [
                    0.10344827586206896,
                    0,
                    0.025052928722653495,
                    0.0438069235314493,
                    0.3853658536585366,
                    0.0,
                    0.2804878048780488,
                    0,
                    0,
                    1.0
                ],
                [
                    0.5049261083743842,
                    0,
                    0.01046812514702423,
                    0.010778540720063571,
                    0.12845528455284552,
                    0.26666666666666666,
                    0.3048780487804878,
                    0,
                    0,
                    1.0
                ]
            ],
            "fraction_answers": {
                "venereal disease": 0.6559442398509617,
                "mushroom farming": 0.13969363110879288,
                "crocodile teeth": 0.2043621290402453
            },
            "question": "what topic would a herpetologist study?",
            "rate_limited": false,
            "answers": [
                "venereal disease",
                "mushroom farming",
                "crocodile teeth"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "venereal disease": 0.3523794237977019,
                "mushroom farming": 0.1870894792286009,
                "crocodile teeth": 0.19789760380930052
            },
            "integer_answers": {
                "venereal disease": 5,
                "mushroom farming": 0,
                "crocodile teeth": 1
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    46400.0,
                    2150.0,
                    529.0
                ],
                "wikipedia_search": [
                    1.4666666666666668,
                    0.0,
                    0.5333333333333333
                ],
                "answer_relation_to_question": [
                    0.7832512315270936,
                    0.20689655172413793,
                    1.0098522167487685
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    299000.0,
                    237000.0,
                    79000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_appended": [
                    34.0,
                    23.0,
                    25.0
                ],
                "result_count": [
                    8200.0,
                    213.0,
                    89.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "In the U.K., who appoints the Prime Minister?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "the queen"
            ],
            "lines": [
                [
                    0.07142857142857142,
                    0.5,
                    0.4506206152185645,
                    0.34498308906426156,
                    0.9184091840918409,
                    0.0,
                    0.23728813559322035,
                    0.4,
                    0.07142857142857142,
                    0.0
                ],
                [
                    0.8571428571428572,
                    0.3333333333333333,
                    0.3264975715056665,
                    0.37579857196542654,
                    0.05576055760557606,
                    0.393939393939394,
                    0.2288135593220339,
                    0.0,
                    0.07142857142857142,
                    0.0
                ],
                [
                    0.07142857142857142,
                    0.16666666666666666,
                    0.22288181327576903,
                    0.2792183389703119,
                    0.025830258302583026,
                    0.6060606060606061,
                    0.5338983050847458,
                    0.6,
                    0.8571428571428571,
                    0.0
                ]
            ],
            "fraction_answers": {
                "the people": 0.3326842407583367,
                "the parliament": 0.2936349351380954,
                "the queen": 0.3736808241035679
            },
            "question": "in the u.k., who appoints the prime minister?",
            "rate_limited": false,
            "answers": [
                "the people",
                "the parliament",
                "the queen"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "the people": 0.20621570718740584,
                "the parliament": 0.3845200088601342,
                "the queen": 0.6535812952551161
            },
            "integer_answers": {
                "the people": 3,
                "the parliament": 2,
                "the queen": 4
            },
            "categorical_data": {
                "question_type": 0
            },
            "data": {
                "result_count_important_words": [
                    918000.0,
                    1000000.0,
                    743000.0
                ],
                "wikipedia_search": [
                    0.0,
                    0.7878787878787878,
                    1.212121212121212
                ],
                "answer_relation_to_question": [
                    0.14285714285714285,
                    1.7142857142857144,
                    0.14285714285714285
                ],
                "question_related_to_answer": [
                    1.5,
                    1.0,
                    0.5
                ],
                "result_count_noun_chunks": [
                    44800000.0,
                    2720000.0,
                    1260000.0
                ],
                "word_count_noun_chunks": [
                    2.0,
                    0.0,
                    3.0
                ],
                "word_count_raw": [
                    1.0,
                    1.0,
                    12.0
                ],
                "word_count_appended": [
                    56.0,
                    54.0,
                    126.0
                ],
                "result_count": [
                    1670000.0,
                    1210000.0,
                    826000.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which writer has stated that his/her trademark series of books would never be adapted for film?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "sue grafton"
            ],
            "lines": [
                [
                    0.38170178237429864,
                    0.0,
                    0.05338621110433189,
                    0.31302006852667646,
                    0.10091743119266056,
                    0.19386621622785488,
                    0.291044776119403,
                    0.25,
                    0,
                    -1.0
                ],
                [
                    0.2943177141273742,
                    0.5,
                    0.47333740085417936,
                    0.3411649534997553,
                    0.459480122324159,
                    0.3061337837721452,
                    0.34701492537313433,
                    0.5,
                    0,
                    -1.0
                ],
                [
                    0.3239805034983273,
                    0.5,
                    0.4732763880414887,
                    0.3458149779735683,
                    0.4396024464831804,
                    0.5,
                    0.3619402985074627,
                    0.25,
                    0,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "jeff kinney": 0.20134634637399318,
                "james patterson": 0.6040158786136937,
                "sue grafton": 0.1946377750123132
            },
            "question": "which writer has stated that his/her trademark series of books would never be adapted for film?",
            "rate_limited": false,
            "answers": [
                "james patterson",
                "sue grafton",
                "jeff kinney"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "jeff kinney": 0.15526662357313428,
                "james patterson": 0.1984435786574521,
                "sue grafton": 0.24448788663100535
            },
            "integer_answers": {
                "jeff kinney": 0,
                "james patterson": 7,
                "sue grafton": 1
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    76400.0,
                    64900.0,
                    63000.0
                ],
                "wikipedia_search": [
                    3.6736054052657416,
                    2.3263945947342584,
                    0.0
                ],
                "answer_relation_to_question": [
                    1.4195786115084166,
                    2.4681874304715103,
                    2.112233958020073
                ],
                "question_related_to_answer": [
                    2.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    26100.0,
                    2650.0,
                    3950.0
                ],
                "word_count_noun_chunks": [
                    1.0,
                    0.0,
                    1.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_appended": [
                    56.0,
                    41.0,
                    37.0
                ],
                "result_count": [
                    7320.0,
                    437.0,
                    438.0
                ]
            },
            "negative_question": true
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "In Harry Potter's Quidditch, what ALWAYS happens when one team catches the snitch?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "the game ends"
            ],
            "lines": [
                [
                    0.17114914425427874,
                    0,
                    0.2033898305084746,
                    0.024416135881104035,
                    0.011343012704174229,
                    0.0625,
                    0.125,
                    0.0,
                    0.0,
                    1.0
                ],
                [
                    0.823960880195599,
                    0,
                    0.0423728813559322,
                    0.006369426751592357,
                    0.004083484573502722,
                    0.9375,
                    0.09375,
                    0.0,
                    0.0,
                    1.0
                ],
                [
                    0.004889975550122249,
                    0,
                    0.7542372881355932,
                    0.9692144373673036,
                    0.984573502722323,
                    0.0,
                    0.78125,
                    1.0,
                    1.0,
                    1.0
                ]
            ],
            "fraction_answers": {
                "the game ends": 0.6867706504719178,
                "that team loses": 0.23850458410957828,
                "that team wins": 0.07472476541850395
            },
            "question": "in harry potter's quidditch, what always happens when one team catches the snitch?",
            "rate_limited": false,
            "answers": [
                "that team wins",
                "that team loses",
                "the game ends"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "the game ends": 0.7237559788487874,
                "that team loses": 0.345860217442856,
                "that team wins": 0.16169264526347432
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    23.0,
                    6.0,
                    913.0
                ],
                "wikipedia_search": [
                    0.0625,
                    0.9375,
                    0.0
                ],
                "answer_relation_to_question": [
                    0.5134474327628362,
                    2.471882640586797,
                    0.014669926650366748
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    25.0,
                    9.0,
                    2170.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    4.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    8.0
                ],
                "result_count": [
                    24.0,
                    5.0,
                    89.0
                ],
                "word_count_appended": [
                    8.0,
                    6.0,
                    50.0
                ]
            },
            "integer_answers": {
                "the game ends": 6,
                "that team loses": 2,
                "that team wins": 0
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Laurie Metcalf, Amy Morton and Tracy Letts are members of a theatre company from what city?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "chicago"
            ],
            "lines": [
                [
                    0.446609395923398,
                    0.29539314536282396,
                    0.3888731195004258,
                    0.39101254741756636,
                    0.3858447488584475,
                    0.2384799271652288,
                    0.1346704871060172,
                    0.07086614173228346,
                    0.061946902654867256,
                    1.0
                ],
                [
                    0.317615792546463,
                    0.16358543417366947,
                    0.2563156400794777,
                    0.26466297052815874,
                    0.2625570776255708,
                    0.2840352524392133,
                    0.0659025787965616,
                    0.0,
                    0.0,
                    1.0
                ],
                [
                    0.23577481153013896,
                    0.5410214204635067,
                    0.3548112404200965,
                    0.34432448205427485,
                    0.3515981735159817,
                    0.47748482039555795,
                    0.7994269340974212,
                    0.9291338582677166,
                    0.9380530973451328,
                    1.0
                ]
            ],
            "fraction_answers": {
                "new york": 0.2681884906356731,
                "los angeles": 0.17940830513212383,
                "chicago": 0.552403204232203
            },
            "question": "laurie metcalf, amy morton and tracy letts are members of a theatre company from what city?",
            "rate_limited": false,
            "answers": [
                "new york",
                "los angeles",
                "chicago"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "new york": 0.22215203608222375,
                "los angeles": 0.12397158568350967,
                "chicago": 0.7804599792446593
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    1340.0,
                    907.0,
                    1180.0
                ],
                "wikipedia_search": [
                    0.9539197086609152,
                    1.1361410097568532,
                    1.9099392815822318
                ],
                "answer_relation_to_question": [
                    2.23304697961699,
                    1.5880789627323149,
                    1.1788740576506949
                ],
                "question_related_to_answer": [
                    1.4769657268141199,
                    0.8179271708683473,
                    2.705107102317533
                ],
                "result_count_noun_chunks": [
                    1690.0,
                    1150.0,
                    1540.0
                ],
                "word_count_noun_chunks": [
                    9.0,
                    0.0,
                    118.0
                ],
                "word_count_raw": [
                    7.0,
                    0.0,
                    106.0
                ],
                "result_count": [
                    1370.0,
                    903.0,
                    1250.0
                ],
                "word_count_appended": [
                    47.0,
                    23.0,
                    279.0
                ]
            },
            "integer_answers": {
                "new york": 4,
                "los angeles": 0,
                "chicago": 5
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which artist painted the ceiling of one of France's most iconic opera houses?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "marc chagall"
            ],
            "question": "which artist painted the ceiling of one of france's most iconic opera houses?",
            "answers": [
                "marc chagall",
                "edgar degas",
                "auguste renoir"
            ],
            "integer_answers": {
                "marc chagall": 7,
                "edgar degas": 1,
                "auguste renoir": 1
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    88300.0,
                    85400.0,
                    3230000.0
                ],
                "wikipedia_search": [
                    5.058841158841159,
                    0.4237762237762238,
                    0.5173826173826174
                ],
                "answer_relation_to_question": [
                    4.373546285239604,
                    0.9416545523769966,
                    1.6847991623834
                ],
                "question_related_to_answer": [
                    1.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    49300.0,
                    146000.0,
                    102000.0
                ],
                "word_count_noun_chunks": [
                    23.0,
                    1.0,
                    0.0
                ],
                "word_count_raw": [
                    29.0,
                    0.0,
                    0.0
                ],
                "result_count": [
                    45300.0,
                    69.0,
                    70.0
                ],
                "word_count_appended": [
                    132.0,
                    46.0,
                    14.0
                ]
            },
            "negative_question": false,
            "fraction_answers": {
                "marc chagall": 0.7002749920899783,
                "edgar degas": 0.11156630626720518,
                "auguste renoir": 0.18815870164281645
            },
            "lines": [
                [
                    0.6247923264628005,
                    1.0,
                    0.9969409538062017,
                    0.02594235684696066,
                    0.16582576522031617,
                    0.8431401931401932,
                    0.6875,
                    0.9583333333333334,
                    1.0,
                    -1.0
                ],
                [
                    0.13452207891099952,
                    0.0,
                    0.0015185193336120953,
                    0.025090342862179392,
                    0.49108644466868484,
                    0.07062937062937064,
                    0.23958333333333334,
                    0.041666666666666664,
                    0.0,
                    -1.0
                ],
                [
                    0.2406855946262,
                    0.0,
                    0.0015405268601861837,
                    0.94896730029086,
                    0.343087790110999,
                    0.08623043623043623,
                    0.07291666666666667,
                    0.0,
                    0.0,
                    -1.0
                ]
            ],
            "rate_limited": false,
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "marc chagall": 0.8877784901599672,
                "edgar degas": 0.036872876009686355,
                "auguste renoir": 0.1616734825266822
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which of these two U.S. cities are in the same time zone?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "pensacola / sioux falls"
            ],
            "lines": [
                [
                    0.26159298622169913,
                    0,
                    0.5938483402700233,
                    0.0002782190101226428,
                    0.4942418714971134,
                    0.014492753623188406,
                    0.4117647058823529,
                    0,
                    0,
                    -1.0
                ],
                [
                    0.56740722149138,
                    0,
                    0.00010151253679829459,
                    7.440740968396261e-05,
                    7.82599796524053e-05,
                    0.7671497584541062,
                    0.23529411764705882,
                    0,
                    0,
                    -1.0
                ],
                [
                    0.17099979228692103,
                    0,
                    0.40605014719317833,
                    0.9996473735801934,
                    0.5056798685232342,
                    0.2183574879227053,
                    0.35294117647058826,
                    0,
                    0,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "el paso / pierre": 0.2960364794174166,
                "pensacola / sioux falls": 0.4422793076628034,
                "bismarck / cheyenne": 0.26168421291977995
            },
            "question": "which of these two u.s. cities are in the same time zone?",
            "rate_limited": false,
            "answers": [
                "el paso / pierre",
                "bismarck / cheyenne",
                "pensacola / sioux falls"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "el paso / pierre": 0.1451005388960218,
                "pensacola / sioux falls": 0.4659728009452708,
                "bismarck / cheyenne": 0.2557961481846344
            },
            "integer_answers": {
                "el paso / pierre": 2,
                "pensacola / sioux falls": 2,
                "bismarck / cheyenne": 2
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    86.0,
                    23.0,
                    309000.0
                ],
                "wikipedia_search": [
                    0.043478260869565216,
                    2.3014492753623186,
                    0.6550724637681159
                ],
                "answer_relation_to_question": [
                    1.0463719448867963,
                    2.2696288859655196,
                    0.683999169147684
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    82100.0,
                    13.0,
                    84000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count": [
                    81900.0,
                    14.0,
                    56000.0
                ],
                "word_count_appended": [
                    7.0,
                    4.0,
                    6.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Until it was banned, lithium was a key ingredient in which of these brands?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "7up"
            ],
            "lines": [
                [
                    0.0661764705882353,
                    0,
                    0.15164661802405838,
                    0.1521865889212828,
                    0.5933333333333334,
                    0.13513513513513514,
                    0.05421686746987952,
                    0.0,
                    0.0,
                    -1.0
                ],
                [
                    0.8002321981424149,
                    0,
                    0.8479589824492211,
                    0.847424684159378,
                    0.4033333333333333,
                    0.8648648648648649,
                    0.9216867469879518,
                    1.0,
                    1.0,
                    -1.0
                ],
                [
                    0.13359133126934986,
                    0,
                    0.00039439952672056796,
                    0.00038872691933916425,
                    0.0033333333333333335,
                    0.0,
                    0.024096385542168676,
                    0.0,
                    0.0,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "cracker jack": 0.14408687668399056,
                "7up": 0.8356876012421455,
                "good and plenty": 0.02022552207386395
            },
            "question": "until it was banned, lithium was a key ingredient in which of these brands?",
            "rate_limited": false,
            "answers": [
                "cracker jack",
                "7up",
                "good and plenty"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "cracker jack": 0.17968482661247104,
                "7up": 0.7703436663068937,
                "good and plenty": 0.02955315113544481
            },
            "integer_answers": {
                "cracker jack": 1,
                "7up": 7,
                "good and plenty": 0
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    783.0,
                    4360.0,
                    2.0
                ],
                "wikipedia_search": [
                    0.40540540540540543,
                    2.5945945945945947,
                    0.0
                ],
                "answer_relation_to_question": [
                    0.2647058823529412,
                    3.2009287925696595,
                    0.5343653250773994
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    1780.0,
                    1210.0,
                    10.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    11.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    9.0,
                    0.0
                ],
                "word_count_appended": [
                    9.0,
                    153.0,
                    4.0
                ],
                "result_count": [
                    769.0,
                    4300.0,
                    2.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Aside from blood cells, what would you also find inside your blood vessels?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "plasma"
            ],
            "lines": [
                [
                    0.3849128903274943,
                    0.7692307692307692,
                    0.0002981514609421586,
                    0.5537400145243282,
                    0.5283775166256719,
                    0.08711650922177237,
                    0.3708513708513709,
                    0.6,
                    0.7333333333333333,
                    1.0
                ],
                [
                    0.42139899086062454,
                    0.23076923076923078,
                    0.9332140727489565,
                    0.43391430646332607,
                    0.4691627949348638,
                    0.8813045434098065,
                    0.44733044733044736,
                    0.4,
                    0.26666666666666666,
                    1.0
                ],
                [
                    0.1936881188118812,
                    0.0,
                    0.06648777579010137,
                    0.012345679012345678,
                    0.0024596884394643345,
                    0.031578947368421054,
                    0.18181818181818182,
                    0.0,
                    0.0,
                    1.0
                ]
            ],
            "fraction_answers": {
                "marrow": 0.4981956725759914,
                "plasma": 0.44754006173063143,
                "plastids": 0.05426426569337727
            },
            "question": "aside from blood cells, what would you also find inside your blood vessels?",
            "rate_limited": false,
            "answers": [
                "plasma",
                "marrow",
                "plastids"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "marrow": 0.17178393724074767,
                "plasma": 0.5362794402188403,
                "plastids": 0.20309116013316703
            },
            "integer_answers": {
                "marrow": 4,
                "plasma": 5,
                "plastids": 0
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    122000.0,
                    95600.0,
                    2720.0
                ],
                "wikipedia_search": [
                    0.4355825461088619,
                    4.406522717049032,
                    0.15789473684210525
                ],
                "answer_relation_to_question": [
                    1.5396515613099773,
                    1.6855959634424982,
                    0.7747524752475248
                ],
                "question_related_to_answer": [
                    1.5384615384615383,
                    0.46153846153846156,
                    0.0
                ],
                "result_count_noun_chunks": [
                    5800000.0,
                    5150000.0,
                    27000.0
                ],
                "word_count_noun_chunks": [
                    15.0,
                    10.0,
                    0.0
                ],
                "word_count_raw": [
                    11.0,
                    4.0,
                    0.0
                ],
                "result_count": [
                    100.0,
                    313000.0,
                    22300.0
                ],
                "word_count_appended": [
                    257.0,
                    310.0,
                    126.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which of these Kentucky Derby winners was named for its trainer?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "clyde van dusen"
            ],
            "lines": [
                [
                    0.8532552397497145,
                    0,
                    0.008535784635587657,
                    0.3664705275110973,
                    0.010295542635658914,
                    0.7333333333333334,
                    0.5321100917431193,
                    0,
                    0,
                    -1.0
                ],
                [
                    0.025416204217536074,
                    0,
                    0.8338804990151018,
                    0.6322906988747806,
                    0.9823158914728682,
                    0.0,
                    0.3669724770642202,
                    0,
                    0,
                    -1.0
                ],
                [
                    0.12132855603274946,
                    0,
                    0.15758371634931057,
                    0.0012387736141220192,
                    0.007388565891472868,
                    0.26666666666666666,
                    0.10091743119266056,
                    0,
                    0,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "lieut. gibson": 0.10918728495783035,
                "paul jones": 0.4734792951074178,
                "clyde van dusen": 0.41733341993475187
            },
            "question": "which of these kentucky derby winners was named for its trainer?",
            "rate_limited": false,
            "answers": [
                "clyde van dusen",
                "paul jones",
                "lieut. gibson"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "lieut. gibson": 0.01445216805373401,
                "paul jones": 0.24722269754121534,
                "clyde van dusen": 0.42650972356908745
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    28400.0,
                    49000.0,
                    96.0
                ],
                "wikipedia_search": [
                    2.2,
                    0.0,
                    0.8
                ],
                "answer_relation_to_question": [
                    4.266276198748572,
                    0.12708102108768035,
                    0.6066427801637472
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    85.0,
                    8110.0,
                    61.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_appended": [
                    58.0,
                    40.0,
                    11.0
                ],
                "result_count": [
                    78.0,
                    7620.0,
                    1440.0
                ]
            },
            "integer_answers": {
                "lieut. gibson": 0,
                "paul jones": 3,
                "clyde van dusen": 3
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which of these Hebrew texts does NOT form a significant part of the Christian Old Testament?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "talmud"
            ],
            "lines": [
                [
                    0.37256685006937784,
                    0.02542372881355931,
                    0.16205533596837945,
                    0.10913510747185262,
                    0.3622174381054898,
                    0.3473424212550529,
                    0.289838337182448,
                    0.033333333333333326,
                    0.019230769230769218,
                    -1.0
                ],
                [
                    0.36800968663961586,
                    0.4872881355932203,
                    0.4762845849802372,
                    0.4740276356192426,
                    0.48905633297452455,
                    0.4468275234427879,
                    0.3741339491916859,
                    0.5,
                    0.4807692307692308,
                    -1.0
                ],
                [
                    0.25942346329100624,
                    0.4872881355932203,
                    0.3616600790513834,
                    0.41683725690890483,
                    0.14872622891998566,
                    0.2058300553021592,
                    0.33602771362586603,
                    0.4666666666666667,
                    0.5,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "talmud": 0.2927867556979573,
                "ketuvim": 0.08968953795321219,
                "torah": 0.6175237063488306
            },
            "question": "which of these hebrew texts does not form a significant part of the christian old testament?",
            "rate_limited": false,
            "answers": [
                "torah",
                "ketuvim",
                "talmud"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "talmud": 0.44878427422131595,
                "ketuvim": 0.23587463818014778,
                "torah": 0.09666823934821256
            },
            "negative_question": true,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    611000.0,
                    40600.0,
                    130000.0
                ],
                "wikipedia_search": [
                    2.1372061024292597,
                    0.7444146718009689,
                    4.118379225769771
                ],
                "answer_relation_to_question": [
                    1.7840640990287098,
                    1.847864387045378,
                    3.3680715139259125
                ],
                "question_related_to_answer": [
                    1.8983050847457628,
                    0.05084745762711865,
                    0.05084745762711865
                ],
                "result_count_noun_chunks": [
                    384000.0,
                    30500.0,
                    979000.0
                ],
                "word_count_noun_chunks": [
                    14.0,
                    0.0,
                    1.0
                ],
                "word_count_raw": [
                    25.0,
                    1.0,
                    0.0
                ],
                "word_count_appended": [
                    364.0,
                    218.0,
                    284.0
                ],
                "result_count": [
                    342000.0,
                    24000.0,
                    140000.0
                ]
            },
            "integer_answers": {
                "talmud": 3,
                "ketuvim": 0,
                "torah": 6
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "How many of the three Baltic countries border Russia?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "three"
            ],
            "lines": [
                [
                    0.30537974683544306,
                    0.3544857768052516,
                    0.405446293494705,
                    0.04897119341563786,
                    0.41223272003978123,
                    0.02857142857142857,
                    0.4861111111111111,
                    0.6844783715012722,
                    0.6712328767123288,
                    5.0
                ],
                [
                    0.5332278481012659,
                    0.041240732878278195,
                    0.4341906202723147,
                    0.07037037037037037,
                    0.4485330681253108,
                    0.2357142857142857,
                    0.22008547008547008,
                    0.01272264631043257,
                    0.0136986301369863,
                    5.0
                ],
                [
                    0.16139240506329117,
                    0.6042734903164702,
                    0.16036308623298035,
                    0.8806584362139918,
                    0.139234211834908,
                    0.7357142857142858,
                    0.2938034188034188,
                    0.30279898218829515,
                    0.3150684931506849,
                    5.0
                ]
            ],
            "fraction_answers": {
                "none": 0.3992563121687029,
                "three": 0.37743439094299547,
                "two": 0.22330929688830162
            },
            "question": "how many of the three baltic countries border russia?",
            "rate_limited": false,
            "answers": [
                "three",
                "two",
                "none"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "none": 0.31296165669266407,
                "three": 0.5049897025693251,
                "two": 0.11967254079215477
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 5
            },
            "data": {
                "result_count_important_words": [
                    1190000.0,
                    1710000.0,
                    21400000.0
                ],
                "wikipedia_search": [
                    0.05714285714285714,
                    0.4714285714285714,
                    1.4714285714285715
                ],
                "answer_relation_to_question": [
                    0.610759493670886,
                    1.0664556962025316,
                    0.3227848101265823
                ],
                "question_related_to_answer": [
                    0.7089715536105032,
                    0.08248146575655639,
                    1.2085469806329403
                ],
                "result_count_noun_chunks": [
                    8290000.0,
                    9020000.0,
                    2800000.0
                ],
                "word_count_noun_chunks": [
                    269.0,
                    5.0,
                    119.0
                ],
                "word_count_raw": [
                    245.0,
                    5.0,
                    115.0
                ],
                "result_count": [
                    5360000.0,
                    5740000.0,
                    2120000.0
                ],
                "word_count_appended": [
                    455.0,
                    206.0,
                    275.0
                ]
            },
            "integer_answers": {
                "none": 3,
                "three": 3,
                "two": 3
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which NBA franchise has NOT retired any jersey numbers?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "dallas mavericks"
            ],
            "lines": [
                [
                    0.40376379509141824,
                    0.25,
                    0.00027355056406430656,
                    0.34426606684438654,
                    0.25941885637347567,
                    0.36394707455711417,
                    0.2924107142857143,
                    0.5,
                    0.25,
                    -1.0
                ],
                [
                    0.2752875693186186,
                    0.5,
                    0.4998731581183389,
                    0.4999693464882703,
                    0.24059076687226938,
                    0.3047349146498657,
                    0.3526785714285714,
                    0.33333333333333337,
                    0.5,
                    -1.0
                ],
                [
                    0.3209486355899632,
                    0.25,
                    0.4998532913175968,
                    0.15576458666734316,
                    0.49999037675425495,
                    0.33131801079302015,
                    0.3549107142857143,
                    0.16666666666666669,
                    0.25,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "dallas mavericks": 0.22078496439794051,
                "brooklyn nets": 0.40798220939640595,
                "los angeles clippers": 0.37123282620565357
            },
            "question": "which nba franchise has not retired any jersey numbers?",
            "rate_limited": false,
            "answers": [
                "brooklyn nets",
                "dallas mavericks",
                "los angeles clippers"
            ],
            "ml_answers": {
                "dallas mavericks": 0.34570450978684714,
                "brooklyn nets": 0.3265319299169249,
                "los angeles clippers": 0.03693481809088563
            },
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "integer_answers": {
                "dallas mavericks": 3,
                "brooklyn nets": 4,
                "los angeles clippers": 2
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    442000.0,
                    87.0,
                    977000.0
                ],
                "wikipedia_search": [
                    1.360529254428858,
                    1.9526508535013432,
                    1.6868198920697985
                ],
                "answer_relation_to_question": [
                    0.7698896392686543,
                    1.7976994454510513,
                    1.4324109152802944
                ],
                "question_related_to_answer": [
                    0.5,
                    0.0,
                    0.5
                ],
                "result_count_noun_chunks": [
                    2300000.0,
                    2480000.0,
                    92.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    2.0,
                    4.0
                ],
                "word_count_raw": [
                    1.0,
                    0.0,
                    1.0
                ],
                "result_count": [
                    327000.0,
                    83.0,
                    96.0
                ],
                "word_count_appended": [
                    93.0,
                    66.0,
                    65.0
                ]
            },
            "negative_question": true
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Tom from MySpace shares his name with a key character in what film franchise?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "harry potter"
            ],
            "lines": [
                [
                    0.35878473042109404,
                    0.9583333333333334,
                    0.6078098471986417,
                    0.22584238373712057,
                    0.19824561403508772,
                    0.23463153875525009,
                    0.2777777777777778,
                    1.0,
                    0.16666666666666666,
                    1.0
                ],
                [
                    0.3175956972320609,
                    0.04166666666666667,
                    0.17826825127334464,
                    0.34530771372876634,
                    0.37719298245614036,
                    0.2946366297569047,
                    0.16666666666666666,
                    0.0,
                    0.0,
                    1.0
                ],
                [
                    0.3236195723468451,
                    0.0,
                    0.21392190152801357,
                    0.42884990253411304,
                    0.4245614035087719,
                    0.4707318314878452,
                    0.5555555555555556,
                    0.0,
                    0.8333333333333334,
                    1.0
                ]
            ],
            "fraction_answers": {
                "the godfather": 0.19125940086450557,
                "the matrix": 0.3611748333660531,
                "harry potter": 0.44756576576944135
            },
            "question": "tom from myspace shares his name with a key character in what film franchise?",
            "rate_limited": false,
            "answers": [
                "harry potter",
                "the godfather",
                "the matrix"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "the godfather": -0.006733706031096052,
                "the matrix": 0.2714393989431872,
                "harry potter": 0.6655556698334149
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    811000.0,
                    1240000.0,
                    1540000.0
                ],
                "wikipedia_search": [
                    1.1731576937762505,
                    1.4731831487845235,
                    2.353659157439226
                ],
                "answer_relation_to_question": [
                    1.7939236521054702,
                    1.5879784861603043,
                    1.6180978617342254
                ],
                "question_related_to_answer": [
                    1.9166666666666665,
                    0.08333333333333333,
                    0.0
                ],
                "result_count_noun_chunks": [
                    1130000.0,
                    2150000.0,
                    2420000.0
                ],
                "word_count_noun_chunks": [
                    2.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    1.0,
                    0.0,
                    5.0
                ],
                "word_count_appended": [
                    55.0,
                    33.0,
                    110.0
                ],
                "result_count": [
                    3580000.0,
                    1050000.0,
                    1260000.0
                ]
            },
            "integer_answers": {
                "the godfather": 0,
                "the matrix": 5,
                "harry potter": 4
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "The \u201cCC:\u201d feature in email stands for what?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "carbon copy"
            ],
            "lines": [
                [
                    0.15411054994388326,
                    0.0,
                    0.004093125114060015,
                    0.006282257876176464,
                    0.15548172757475084,
                    0.1873479318734793,
                    0.0992063492063492,
                    0.0,
                    0.0,
                    1.0
                ],
                [
                    0.36401047512158624,
                    0.0,
                    0.2780891797238227,
                    0.04320511922277494,
                    0.7308970099667774,
                    0.25669099756691,
                    0.21031746031746032,
                    0.0,
                    0.0,
                    1.0
                ],
                [
                    0.48187897493453047,
                    1.0,
                    0.7178176951621174,
                    0.9505126229010487,
                    0.11362126245847176,
                    0.5559610705596106,
                    0.6904761904761905,
                    1.0,
                    1.0,
                    1.0
                ]
            ],
            "fraction_answers": {
                "carbon copy": 0.72336309072133,
                "copy chain": 0.06739132684318878,
                "copy contacts": 0.2092455824354813
            },
            "question": "the \u201ccc:\u201d feature in email stands for what?",
            "rate_limited": false,
            "answers": [
                "copy chain",
                "copy contacts",
                "carbon copy"
            ],
            "ml_answers": {
                "carbon copy": 0.8928980541233057,
                "copy chain": 0.04772280041566025,
                "copy contacts": 0.011943486423493174
            },
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "integer_answers": {
                "carbon copy": 8,
                "copy chain": 0,
                "copy contacts": 1
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    269.0,
                    1850.0,
                    40700.0
                ],
                "wikipedia_search": [
                    0.5620437956204379,
                    0.7700729927007299,
                    1.667883211678832
                ],
                "answer_relation_to_question": [
                    0.46233164983164976,
                    1.0920314253647587,
                    1.4456369248035914
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    1.0
                ],
                "result_count_noun_chunks": [
                    2340000.0,
                    11000000.0,
                    1710000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    38.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    36.0
                ],
                "result_count": [
                    471.0,
                    32000.0,
                    82600.0
                ],
                "word_count_appended": [
                    25.0,
                    53.0,
                    174.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which of these foods is cultivated in a paddy?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "rice"
            ],
            "lines": [
                [
                    0.625,
                    0.6,
                    0.4395798533261612,
                    0.8978651934635414,
                    0.3350691902986003,
                    1.0,
                    0.6094049904030711,
                    0.9205298013245033,
                    1.0,
                    -1.0
                ],
                [
                    0.05,
                    0.4,
                    0.5604122300698453,
                    0.10211015925663804,
                    0.6649261931925556,
                    0.0,
                    0.34452975047984646,
                    0.07947019867549669,
                    0.0,
                    -1.0
                ],
                [
                    0.325,
                    0.0,
                    7.916603993551718e-06,
                    2.4647279820567802e-05,
                    4.616508844114048e-06,
                    0.0,
                    0.046065259117082535,
                    0.0,
                    0.0,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "cake": 0.24460539240826465,
                "rice": 0.7141610032017641,
                "dunkaroos": 0.041233604389971194
            },
            "question": "which of these foods is cultivated in a paddy?",
            "rate_limited": false,
            "answers": [
                "rice",
                "cake",
                "dunkaroos"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "integer_answers": {
                "cake": 2,
                "rice": 7,
                "dunkaroos": 0
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    1530000.0,
                    174000.0,
                    42.0
                ],
                "wikipedia_search": [
                    3.0,
                    0.0,
                    0.0
                ],
                "answer_relation_to_question": [
                    1.25,
                    0.1,
                    0.65
                ],
                "question_related_to_answer": [
                    1.2,
                    0.8,
                    0.0
                ],
                "result_count_noun_chunks": [
                    4500000.0,
                    8930000.0,
                    62.0
                ],
                "word_count_noun_chunks": [
                    139.0,
                    12.0,
                    0.0
                ],
                "word_count_raw": [
                    293.0,
                    0.0,
                    0.0
                ],
                "result_count": [
                    2110000.0,
                    2690000.0,
                    38.0
                ],
                "word_count_appended": [
                    635.0,
                    359.0,
                    48.0
                ]
            },
            "ml_answers": {
                "cake": 0.215726767571972,
                "rice": 0.7901798780894566,
                "dunkaroos": 0.002178964057465912
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which of these phrases appears in a Shakespeare play?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "in such a pickle"
            ],
            "lines": [
                [
                    0.8298286604361371,
                    0,
                    4.0592331217581825e-05,
                    0.00011375917183322905,
                    7.24716787101142e-05,
                    0.813953488372093,
                    0.31313131313131315,
                    0,
                    0,
                    -1.0
                ],
                [
                    0.08800623052959501,
                    0,
                    0.9999574275550644,
                    0.99988324716575,
                    0.9999256935952466,
                    0.13953488372093023,
                    0.6464646464646465,
                    0,
                    0,
                    -1.0
                ],
                [
                    0.08216510903426791,
                    0,
                    1.9801137179308206e-06,
                    2.9936624166639225e-06,
                    1.8347260432940305e-06,
                    0.046511627906976744,
                    0.04040404040404041,
                    0,
                    0,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "at a loss": 0.645628688171872,
                "in such a pickle": 0.3261900475202173,
                "up a dark creek": 0.028181264307910486
            },
            "question": "which of these phrases appears in a shakespeare play?",
            "rate_limited": false,
            "answers": [
                "in such a pickle",
                "at a loss",
                "up a dark creek"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "at a loss": 0.3253362619924653,
                "in such a pickle": 0.3974106134474868,
                "up a dark creek": 0.06506951462881502
            },
            "integer_answers": {
                "at a loss": 4,
                "in such a pickle": 2,
                "up a dark creek": 0
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    76.0,
                    668000.0,
                    2.0
                ],
                "wikipedia_search": [
                    0.813953488372093,
                    0.13953488372093023,
                    0.046511627906976744
                ],
                "answer_relation_to_question": [
                    3.3193146417445485,
                    0.35202492211838005,
                    0.32866043613707163
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    79.0,
                    1090000.0,
                    2.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_appended": [
                    31.0,
                    64.0,
                    4.0
                ],
                "result_count": [
                    41.0,
                    1010000.0,
                    2.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "J.K. Rowling\u2019s first book published in England was titled \u201cHarry Potter and the\u201d what?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "philosopher's stone"
            ],
            "lines": [
                [
                    0.2005245701874359,
                    0,
                    0.5827324494281584,
                    0.6318594062317274,
                    0.5087630041578218,
                    0.0700354609929078,
                    0.508130081300813,
                    0.6470588235294118,
                    0.6455696202531646,
                    1.0
                ],
                [
                    0.7109504171708926,
                    0,
                    0.4172477489837542,
                    0.36811702530018936,
                    0.4912194522903107,
                    0.874113475177305,
                    0.4715447154471545,
                    0.35294117647058826,
                    0.35443037974683544,
                    1.0
                ],
                [
                    0.08852501264167141,
                    0,
                    1.9801588087364605e-05,
                    2.356846808324383e-05,
                    1.7543551867511095e-05,
                    0.05585106382978724,
                    0.02032520325203252,
                    0.0,
                    0.0,
                    1.0
                ]
            ],
            "fraction_answers": {
                "magician's stone": 0.02059527416644116,
                "philosopher's stone": 0.4743341770101801,
                "sorcerer's stone": 0.5050705488233788
            },
            "question": "j.k. rowling\u2019s first book published in england was titled \u201charry potter and the\u201d what?",
            "rate_limited": false,
            "answers": [
                "philosopher's stone",
                "sorcerer's stone",
                "magician's stone"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "magician's stone": 0.04402923741740191,
                "philosopher's stone": 0.7013678310004541,
                "sorcerer's stone": 0.2900916728899772
            },
            "integer_answers": {
                "magician's stone": 0,
                "philosopher's stone": 6,
                "sorcerer's stone": 2
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    563000.0,
                    328000.0,
                    21.0
                ],
                "wikipedia_search": [
                    0.42021276595744683,
                    5.24468085106383,
                    0.3351063829787234
                ],
                "answer_relation_to_question": [
                    1.6041965614994873,
                    5.687603337367141,
                    0.7082001011333713
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    1160000.0,
                    1120000.0,
                    40.0
                ],
                "word_count_noun_chunks": [
                    22.0,
                    12.0,
                    0.0
                ],
                "word_count_raw": [
                    51.0,
                    28.0,
                    0.0
                ],
                "result_count": [
                    412000.0,
                    295000.0,
                    14.0
                ],
                "word_count_appended": [
                    125.0,
                    116.0,
                    5.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which former NFL star does NOT have a football video game named after him?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "kurt warner"
            ],
            "lines": [
                [
                    0.3771119563933276,
                    0,
                    0.4022529069767442,
                    0.39582156973461324,
                    0.43918413173652693,
                    0.414966373785995,
                    0.34478371501272265,
                    0,
                    0.0,
                    -1.0
                ],
                [
                    0.2813209381869136,
                    0,
                    0.20675872093023256,
                    0.21202710333145114,
                    0.31904940119760483,
                    0.2899205822012069,
                    0.3307888040712468,
                    0,
                    0.5,
                    -1.0
                ],
                [
                    0.3415671054197588,
                    0,
                    0.3909883720930233,
                    0.3921513269339356,
                    0.24176646706586824,
                    0.2951130440127982,
                    0.3244274809160306,
                    0,
                    0.5,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "kurt warner": 0.28971034387388156,
                "brett favre": 0.388609842880384,
                "emmitt smith": 0.3216798132457344
            },
            "question": "which former nfl star does not have a football video game named after him?",
            "rate_limited": false,
            "answers": [
                "emmitt smith",
                "brett favre",
                "kurt warner"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "kurt warner": 0.5171054825881436,
                "brett favre": 0.42120409031278944,
                "emmitt smith": 0.32685277976174515
            },
            "integer_answers": {
                "kurt warner": 2,
                "brett favre": 4,
                "emmitt smith": 1
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    36900.0,
                    102000.0,
                    38200.0
                ],
                "wikipedia_search": [
                    1.020403514568061,
                    2.5209530135855176,
                    2.458643471846422
                ],
                "answer_relation_to_question": [
                    1.4746565232800686,
                    2.624148741757037,
                    1.9011947349628942
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    32500.0,
                    96700.0,
                    138000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    2.0,
                    0.0,
                    0.0
                ],
                "result_count": [
                    26900.0,
                    80700.0,
                    30000.0
                ],
                "word_count_appended": [
                    122.0,
                    133.0,
                    138.0
                ]
            },
            "negative_question": true
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "How do you spell the last name of Duke University\u2019s men's basketball coach?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "krzyzewski"
            ],
            "lines": [
                [
                    0.34444444444444444,
                    0.0,
                    0.0,
                    0.0,
                    0.0,
                    0.0,
                    0.050156739811912224,
                    0.0,
                    0.0,
                    5.0
                ],
                [
                    0.3111111111111111,
                    1.0,
                    1.0,
                    1.0,
                    1.0,
                    1.0,
                    0.8996865203761756,
                    1.0,
                    1.0,
                    5.0
                ],
                [
                    0.34444444444444444,
                    0.0,
                    0.0,
                    0.0,
                    0.0,
                    0.0,
                    0.050156739811912224,
                    0.0,
                    0.0,
                    5.0
                ]
            ],
            "fraction_answers": {
                "khzyrweski": 0.043844576028484065,
                "crzyzewski": 0.043844576028484065,
                "krzyzewski": 0.9123108479430316
            },
            "question": "how do you spell the last name of duke university\u2019s men's basketball coach?",
            "rate_limited": false,
            "answers": [
                "crzyzewski",
                "krzyzewski",
                "khzyrweski"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "khzyrweski": 0.05913656897019091,
                "crzyzewski": 0.05913656897019091,
                "krzyzewski": 0.8451955810971544
            },
            "integer_answers": {
                "khzyrweski": 0,
                "crzyzewski": 1,
                "krzyzewski": 8
            },
            "categorical_data": {
                "question_type": 5
            },
            "data": {
                "result_count_important_words": [
                    0,
                    50200.0,
                    0
                ],
                "wikipedia_search": [
                    0.0,
                    5.0,
                    0.0
                ],
                "answer_relation_to_question": [
                    2.0666666666666664,
                    1.8666666666666665,
                    2.0666666666666664
                ],
                "question_related_to_answer": [
                    0.0,
                    1.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    0,
                    16200.0,
                    0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    136.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    64.0,
                    0.0
                ],
                "word_count_appended": [
                    16.0,
                    287.0,
                    16.0
                ],
                "result_count": [
                    0,
                    53400.0,
                    0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Which of these consists of frozen water?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "drake"
            ],
            "lines": [
                [
                    0.625,
                    0,
                    0.35553158101216165,
                    0.4918918918918919,
                    0.46404165310771234,
                    0.6818181818181819,
                    0.48337028824833705,
                    0,
                    0,
                    -1.0
                ],
                [
                    0.125,
                    0,
                    0.024127108670066694,
                    0.015444015444015444,
                    0.013342011064106736,
                    0.0,
                    0.045454545454545456,
                    0,
                    0,
                    -1.0
                ],
                [
                    0.25,
                    0,
                    0.6203413103177716,
                    0.49266409266409267,
                    0.5226163358281809,
                    0.3181818181818182,
                    0.47117516629711753,
                    0,
                    0,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "garden rake": 0.03722794677212239,
                "snowflake": 0.5169422660130474,
                "drake": 0.4458297872148302
            },
            "question": "which of these consists of frozen water?",
            "rate_limited": false,
            "answers": [
                "snowflake",
                "garden rake",
                "drake"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "garden rake": 0.029959740354836496,
                "snowflake": 0.33540551323401724,
                "drake": 0.33625502450610145
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    637000.0,
                    20000.0,
                    638000.0
                ],
                "wikipedia_search": [
                    1.3636363636363638,
                    0.0,
                    0.6363636363636364
                ],
                "answer_relation_to_question": [
                    1.25,
                    0.25,
                    0.5
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    713000.0,
                    20500.0,
                    803000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_appended": [
                    436.0,
                    41.0,
                    425.0
                ],
                "result_count": [
                    1450000.0,
                    98400.0,
                    2530000.0
                ]
            },
            "integer_answers": {
                "garden rake": 0,
                "snowflake": 3,
                "drake": 3
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which country did NOT have a native player selected in the first round of the 2016 NBA draft?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "bahamas"
            ],
            "lines": [
                [
                    0.37623116644353094,
                    0.5,
                    0.49014860577725833,
                    0.4948142202319343,
                    0.37847222222222227,
                    0.3753654432396138,
                    0.34051724137931033,
                    0.0,
                    0.0,
                    -1.0
                ],
                [
                    0.24245375032677557,
                    0.25,
                    0.05585239605944231,
                    0.298272110855284,
                    0.33767361111111116,
                    0.2638855120163557,
                    0.33448275862068966,
                    0.5,
                    0.5,
                    -1.0
                ],
                [
                    0.38131508322969343,
                    0.25,
                    0.45399899816329936,
                    0.20691366891278173,
                    0.2838541666666667,
                    0.36074904474403063,
                    0.325,
                    0.5,
                    0.5,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "bahamas": 0.38163996911340925,
                "brazil": 0.27514867517411734,
                "haiti": 0.34321135571247335
            },
            "question": "which country did not have a native player selected in the first round of the 2016 nba draft?",
            "rate_limited": false,
            "answers": [
                "haiti",
                "bahamas",
                "brazil"
            ],
            "ml_answers": {
                "bahamas": 0.6487492016027828,
                "brazil": 0.6211097495216681,
                "haiti": 0.24878587232203367
            },
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "integer_answers": {
                "bahamas": 4,
                "brazil": 3,
                "haiti": 2
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    98200.0,
                    3820000.0,
                    5550000.0
                ],
                "wikipedia_search": [
                    1.9941529081661797,
                    3.77783180773831,
                    2.2280152840955103
                ],
                "answer_relation_to_question": [
                    1.2376883355646906,
                    2.575462496732244,
                    1.1868491677030655
                ],
                "question_related_to_answer": [
                    0.0,
                    0.5,
                    0.5
                ],
                "result_count_noun_chunks": [
                    140000.0,
                    187000.0,
                    249000.0
                ],
                "word_count_noun_chunks": [
                    1.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    1.0,
                    0.0,
                    0.0
                ],
                "result_count": [
                    118000.0,
                    5320000.0,
                    551000.0
                ],
                "word_count_appended": [
                    185.0,
                    192.0,
                    203.0
                ]
            },
            "negative_question": true
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "What word describes joining a cause just to feel good about it?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "slacktivism"
            ],
            "lines": [
                [
                    0.2381670838813696,
                    0,
                    0.0004324947740214806,
                    0.0004668366430854311,
                    0.0013780431786862655,
                    0.08739837398373984,
                    0.0918580375782881,
                    0,
                    0,
                    1.0
                ],
                [
                    0.062419279562136706,
                    0,
                    2.402748744563781e-05,
                    2.394034067104775e-05,
                    3.994328054163088e-05,
                    0.2516759378120097,
                    0.04384133611691023,
                    0,
                    0,
                    1.0
                ],
                [
                    0.6994136365564938,
                    0,
                    0.9995434777385329,
                    0.9995092230162436,
                    0.9985820135407721,
                    0.6609256882042505,
                    0.8643006263048016,
                    0,
                    0,
                    1.0
                ]
            ],
            "fraction_answers": {
                "slacktivism": 0.8703791108935158,
                "gung-faux": 0.05967074409995249,
                "joinerism": 0.0699501450065318
            },
            "question": "what word describes joining a cause just to feel good about it?",
            "rate_limited": false,
            "answers": [
                "joinerism",
                "gung-faux",
                "slacktivism"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "slacktivism": 0.43124896356718595,
                "gung-faux": 0.022869663103948105,
                "joinerism": 0.07489381071580559
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    39.0,
                    2.0,
                    83500.0
                ],
                "wikipedia_search": [
                    0.524390243902439,
                    1.5100556268720582,
                    3.9655541292255028
                ],
                "answer_relation_to_question": [
                    1.190835419406848,
                    0.31209639781068355,
                    3.497068182782469
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    69.0,
                    2.0,
                    50000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count": [
                    36.0,
                    2.0,
                    83200.0
                ],
                "word_count_appended": [
                    44.0,
                    21.0,
                    414.0
                ]
            },
            "integer_answers": {
                "slacktivism": 6,
                "gung-faux": 0,
                "joinerism": 0
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "One of Apple\u2019s biggest flops was a product named after a man who did what?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "invented the transistor"
            ],
            "lines": [
                [
                    0.328962703962704,
                    0,
                    0.5214285714285715,
                    0.5661764705882353,
                    0.5510204081632653,
                    0.3467086834733893,
                    0.35,
                    0,
                    0,
                    1.0
                ],
                [
                    0.5188908313908315,
                    0,
                    0.15,
                    0.11764705882352941,
                    0.1564625850340136,
                    0.2574229691876751,
                    0.35,
                    0,
                    0,
                    1.0
                ],
                [
                    0.15214646464646467,
                    0,
                    0.32857142857142857,
                    0.3161764705882353,
                    0.2925170068027211,
                    0.39586834733893556,
                    0.3,
                    0,
                    0,
                    1.0
                ]
            ],
            "fraction_answers": {
                "invented the transistor": 0.25840390740600827,
                "developed calculus": 0.2975466196579642,
                "discovered saturn": 0.4440494729360276
            },
            "question": "one of apple\u2019s biggest flops was a product named after a man who did what?",
            "rate_limited": false,
            "answers": [
                "discovered saturn",
                "invented the transistor",
                "developed calculus"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "invented the transistor": 0.5311487924271747,
                "developed calculus": 0.2703112385335609,
                "discovered saturn": 0.10566372604436748
            },
            "integer_answers": {
                "invented the transistor": 1,
                "developed calculus": 1,
                "discovered saturn": 4
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    77.0,
                    16.0,
                    43.0
                ],
                "wikipedia_search": [
                    1.040126050420168,
                    0.7722689075630252,
                    1.1876050420168067
                ],
                "answer_relation_to_question": [
                    1.3158508158508158,
                    2.0755633255633255,
                    0.6085858585858586
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    81.0,
                    23.0,
                    43.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_appended": [
                    7.0,
                    7.0,
                    6.0
                ],
                "result_count": [
                    73.0,
                    21.0,
                    46.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "What dish is made with ham, poached eggs and Hollandaise sauce?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "eggs benedict"
            ],
            "lines": [
                [
                    0.05021367521367521,
                    0.0,
                    0.0013064782326352616,
                    0.0055762081784386614,
                    0.0021822807119638863,
                    0.0,
                    0.16725978647686832,
                    0.0,
                    0.0,
                    1.0
                ],
                [
                    0.8956252600915522,
                    1.0,
                    0.9984676473381469,
                    0.9538250831539816,
                    0.9976140397549195,
                    0.8927489177489177,
                    0.7295373665480427,
                    1.0,
                    1.0,
                    1.0
                ],
                [
                    0.05416106469477256,
                    0.0,
                    0.00022587442921788412,
                    0.04059870866757973,
                    0.0002036795331166294,
                    0.10725108225108224,
                    0.10320284697508897,
                    0.0,
                    0.0,
                    1.0
                ]
            ],
            "fraction_answers": {
                "eggs benedict": 0.9408687016261733,
                "benedict cumberbatch": 0.033960361838984224,
                "pope benedict": 0.02517093653484237
            },
            "question": "what dish is made with ham, poached eggs and hollandaise sauce?",
            "rate_limited": false,
            "answers": [
                "pope benedict",
                "eggs benedict",
                "benedict cumberbatch"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "eggs benedict": 0.8619448566740576,
                "benedict cumberbatch": 0.18226547826425724,
                "pope benedict": 0.15081013989614972
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    2280.0,
                    390000.0,
                    16600.0
                ],
                "wikipedia_search": [
                    0.0,
                    5.356493506493507,
                    0.6435064935064935
                ],
                "answer_relation_to_question": [
                    0.30128205128205127,
                    5.373751560549313,
                    0.3249663881686354
                ],
                "question_related_to_answer": [
                    0.0,
                    1.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    1050.0,
                    480000.0,
                    98.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    84.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    144.0,
                    0.0
                ],
                "word_count_appended": [
                    47.0,
                    205.0,
                    29.0
                ],
                "result_count": [
                    509.0,
                    389000.0,
                    88.0
                ]
            },
            "integer_answers": {
                "eggs benedict": 9,
                "benedict cumberbatch": 0,
                "pope benedict": 0
            }
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Though perhaps more famous as butter, which of these is a location in Florida?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "kerrygold"
            ],
            "lines": [
                [
                    0.20158033973823447,
                    0.5,
                    0.9504878930249367,
                    0.5285834321571806,
                    0.0878972278566599,
                    0.19230769230769232,
                    0.6330275229357798,
                    0.0,
                    0,
                    -1.0
                ],
                [
                    0.32917536897800054,
                    0.5,
                    0.024575352367184677,
                    0.4713748532540359,
                    0.6896551724137931,
                    0.5,
                    0.3669724770642202,
                    1.0,
                    0,
                    -1.0
                ],
                [
                    0.469244291283765,
                    0.0,
                    0.02493675460787857,
                    4.1714588783543e-05,
                    0.222447599729547,
                    0.3076923076923077,
                    0.0,
                    0.0,
                    0,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "tillamook": 0.38673551350256047,
                "kerrygold": 0.4852191530096543,
                "land o\u2019 lakes": 0.12804533348778524
            },
            "question": "though perhaps more famous as butter, which of these is a location in florida?",
            "rate_limited": false,
            "answers": [
                "tillamook",
                "kerrygold",
                "land o\u2019 lakes"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "tillamook": 0.43820244849894757,
                "kerrygold": 0.5987024526131917,
                "land o\u2019 lakes": 0.25365743138611696
            },
            "integer_answers": {
                "tillamook": 4,
                "kerrygold": 3,
                "land o\u2019 lakes": 1
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    887000.0,
                    791000.0,
                    70.0
                ],
                "wikipedia_search": [
                    0.38461538461538464,
                    1.0,
                    0.6153846153846154
                ],
                "answer_relation_to_question": [
                    0.8063213589529379,
                    1.3167014759120022,
                    1.87697716513506
                ],
                "question_related_to_answer": [
                    0.5,
                    0.5,
                    0.0
                ],
                "result_count_noun_chunks": [
                    130000.0,
                    1020000.0,
                    329000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    8.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_appended": [
                    207.0,
                    120.0,
                    0.0
                ],
                "result_count": [
                    2630.0,
                    68.0,
                    69.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which Oscar-winning actress has NOT won the award for playing a real person?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "susan sarandon"
            ],
            "lines": [
                [
                    0.3732775160687573,
                    0.33333333333333337,
                    0.37089201877934275,
                    0.3516949152542373,
                    0.35205992509363293,
                    0.15571548907652633,
                    0.34728033472803344,
                    0.5,
                    0,
                    -1.0
                ],
                [
                    0.35031416798932574,
                    0.5,
                    0.32863849765258213,
                    0.3326271186440678,
                    0.32209737827715357,
                    0.3973421303873431,
                    0.34100418410041844,
                    0.5,
                    0,
                    -1.0
                ],
                [
                    0.276408315941917,
                    0.16666666666666669,
                    0.3004694835680751,
                    0.3156779661016949,
                    0.3258426966292135,
                    0.44694238053613056,
                    0.3117154811715481,
                    0.0,
                    0,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "hilary swank": 0.4640692523461885,
                "emma thompson": 0.3039366169165342,
                "susan sarandon": 0.23199413073727732
            },
            "question": "which oscar-winning actress has not won the award for playing a real person?",
            "rate_limited": false,
            "answers": [
                "emma thompson",
                "susan sarandon",
                "hilary swank"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "hilary swank": 0.22643394420364163,
                "emma thompson": 0.30500660428308035,
                "susan sarandon": 0.3072272005890843
            },
            "negative_question": true,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    70.0,
                    79.0,
                    87.0
                ],
                "wikipedia_search": [
                    5.508552174775579,
                    1.6425259138025097,
                    0.8489219114219113
                ],
                "answer_relation_to_question": [
                    2.0275597428998835,
                    2.3949733121707886,
                    3.5774669449293284
                ],
                "question_related_to_answer": [
                    0.3333333333333333,
                    0.0,
                    0.6666666666666666
                ],
                "result_count_noun_chunks": [
                    79.0,
                    95.0,
                    93.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    1.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count": [
                    55.0,
                    73.0,
                    85.0
                ],
                "word_count_appended": [
                    73.0,
                    76.0,
                    90.0
                ]
            },
            "integer_answers": {
                "hilary swank": 6,
                "emma thompson": 1,
                "susan sarandon": 1
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "According to Alexa, which of these is NOT one the top five most popular sports sites?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "sports illustrated"
            ],
            "lines": [
                [
                    0.2585967617579029,
                    0.375,
                    0.375,
                    0.4878369612224304,
                    0.4762798848416573,
                    0.29144171779141104,
                    0.42950391644908614,
                    0.375,
                    0,
                    -1.0
                ],
                [
                    0.3625417630429196,
                    0.125,
                    0.21400000000000002,
                    0.029695833933977234,
                    0.12260608336462636,
                    0.37903374233128834,
                    0.3981723237597911,
                    0.125,
                    0,
                    -1.0
                ],
                [
                    0.37886147519917757,
                    0.5,
                    0.41100000000000003,
                    0.48246720484359235,
                    0.40111403179371635,
                    0.3295245398773006,
                    0.1723237597911227,
                    0.5,
                    0,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "deadspin": 0.20617724712377258,
                "sports illustrated": 0.5609875633918493,
                "yahoo sports": 0.23283518948437804
            },
            "question": "according to alexa, which of these is not one the top five most popular sports sites?",
            "rate_limited": false,
            "answers": [
                "yahoo sports",
                "sports illustrated",
                "deadspin"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "deadspin": 0.397635285316155,
                "sports illustrated": 0.5414113537103427,
                "yahoo sports": 0.18916848096589828
            },
            "integer_answers": {
                "deadspin": 1,
                "sports illustrated": 5,
                "yahoo sports": 2
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    67500.0,
                    2610000.0,
                    97300.0
                ],
                "wikipedia_search": [
                    2.0855828220858896,
                    1.2096625766871165,
                    1.7047546012269938
                ],
                "answer_relation_to_question": [
                    2.414032382420971,
                    1.3745823695708044,
                    1.2113852480082241
                ],
                "question_related_to_answer": [
                    0.25,
                    0.75,
                    0.0
                ],
                "result_count_noun_chunks": [
                    37900.0,
                    603000.0,
                    158000.0
                ],
                "word_count_noun_chunks": [
                    1.0,
                    3.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count": [
                    250000.0,
                    572000.0,
                    178000.0
                ],
                "word_count_appended": [
                    54.0,
                    78.0,
                    251.0
                ]
            },
            "negative_question": true
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "The best-selling book \u201cThe Chocolate War\u201d is about what?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "high school conformity"
            ],
            "lines": [
                [
                    0.21923076923076926,
                    0,
                    0.09090909090909091,
                    1.1596309281299405e-05,
                    8.057952796512518e-06,
                    0.061224489795918366,
                    0.38461538461538464,
                    0,
                    0,
                    1.0
                ],
                [
                    0.1262724837351703,
                    0,
                    0.9090909090909091,
                    0.14572695330166252,
                    0.12570406362559527,
                    0.2571428571428571,
                    0.38461538461538464,
                    0,
                    0,
                    1.0
                ],
                [
                    0.6544967470340604,
                    0,
                    0.0,
                    0.8542614503890562,
                    0.8742878784216082,
                    0.6816326530612244,
                    0.23076923076923078,
                    0,
                    0,
                    1.0
                ]
            ],
            "fraction_answers": {
                "high school conformity": 0.12599989813554016,
                "the rise of hershey's": 0.5492413266125299,
                "sugar addiction": 0.3247587752519298
            },
            "question": "the best-selling book \u201cthe chocolate war\u201d is about what?",
            "rate_limited": false,
            "answers": [
                "high school conformity",
                "sugar addiction",
                "the rise of hershey's"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "high school conformity": 0.3676571981176803,
                "the rise of hershey's": 0.28220064890596847,
                "sugar addiction": 0.20811894012113358
            },
            "integer_answers": {
                "high school conformity": 1,
                "the rise of hershey's": 4,
                "sugar addiction": 1
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    3.0,
                    37700.0,
                    221000.0
                ],
                "wikipedia_search": [
                    0.30612244897959184,
                    1.2857142857142856,
                    3.4081632653061225
                ],
                "answer_relation_to_question": [
                    1.0961538461538463,
                    0.6313624186758515,
                    3.2724837351703018
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    2.0,
                    31200.0,
                    217000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_appended": [
                    5.0,
                    5.0,
                    3.0
                ],
                "result_count": [
                    2.0,
                    20.0,
                    0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which of these celebrities has NOT been a ProActiv spokesperson?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "katy perry"
            ],
            "lines": [
                [
                    0.36363636363636365,
                    0.0,
                    0.21850576235262947,
                    0.21746575342465752,
                    0.09423587409935535,
                    0.4431818181818182,
                    0.26991150442477874,
                    0.05769230769230771,
                    0.05882352941176472,
                    -1.0
                ],
                [
                    0.4318181818181818,
                    0.5,
                    0.345674923830971,
                    0.2970890410958904,
                    0.4207432688661358,
                    0.23958333333333331,
                    0.32079646017699115,
                    0.46153846153846156,
                    0.47058823529411764,
                    -1.0
                ],
                [
                    0.20454545454545453,
                    0.5,
                    0.4358193138163995,
                    0.4854452054794521,
                    0.4850208570345089,
                    0.3172348484848485,
                    0.4092920353982301,
                    0.4807692307692308,
                    0.47058823529411764,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "selena gomez": 0.15806329315061285,
                "katy perry": 0.6170104637280721,
                "lindsay lohan": 0.22492624312131498
            },
            "question": "which of these celebrities has not been a proactiv spokesperson?",
            "rate_limited": false,
            "answers": [
                "katy perry",
                "lindsay lohan",
                "selena gomez"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "integer_answers": {
                "selena gomez": 1,
                "katy perry": 7,
                "lindsay lohan": 1
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    330000.0,
                    237000.0,
                    17000.0
                ],
                "wikipedia_search": [
                    0.34090909090909094,
                    1.5625,
                    1.0965909090909092
                ],
                "answer_relation_to_question": [
                    0.2727272727272727,
                    0.13636363636363635,
                    0.5909090909090909
                ],
                "question_related_to_answer": [
                    2.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    428000.0,
                    83600.0,
                    15800.0
                ],
                "word_count_noun_chunks": [
                    23.0,
                    2.0,
                    1.0
                ],
                "word_count_raw": [
                    15.0,
                    1.0,
                    1.0
                ],
                "word_count_appended": [
                    104.0,
                    81.0,
                    41.0
                ],
                "result_count": [
                    425000.0,
                    233000.0,
                    96900.0
                ]
            },
            "ml_answers": {
                "selena gomez": 0.26896831878421873,
                "katy perry": 0.3509003270451261,
                "lindsay lohan": 0.24411216492898005
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "One symptom of argyria is turning roughly the same skin color as which cartoon character?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "garfield"
            ],
            "lines": [
                [
                    0.4559998268805105,
                    0.5,
                    0.0171990171990172,
                    0.029550033579583614,
                    0.028548770816812053,
                    0.0347008547008547,
                    0.09375,
                    0,
                    0,
                    -1.0
                ],
                [
                    0.13204998206976715,
                    0.0,
                    0.00819000819000819,
                    0.0167897918065816,
                    0.011895321173671689,
                    0.06256410256410257,
                    0.09375,
                    0,
                    0,
                    -1.0
                ],
                [
                    0.41195019104972236,
                    0.5,
                    0.9746109746109746,
                    0.9536601746138348,
                    0.9595559080095163,
                    0.9027350427350427,
                    0.8125,
                    0,
                    0,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "garfield": 0.787858898717013,
                "the grinch": 0.04646274368630445,
                "papa smurf": 0.16567835759668256
            },
            "question": "one symptom of argyria is turning roughly the same skin color as which cartoon character?",
            "rate_limited": false,
            "answers": [
                "papa smurf",
                "the grinch",
                "garfield"
            ],
            "ml_answers": {
                "garfield": 0.4384324764482004,
                "the grinch": 0.0065399522386105635,
                "papa smurf": 0.16152902472249187
            },
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "integer_answers": {
                "garfield": 5,
                "the grinch": 0,
                "papa smurf": 2
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    44.0,
                    25.0,
                    1420.0
                ],
                "wikipedia_search": [
                    0.1735042735042735,
                    0.3128205128205128,
                    4.513675213675214
                ],
                "answer_relation_to_question": [
                    2.735998961283063,
                    0.7922998924186029,
                    2.4717011462983343
                ],
                "question_related_to_answer": [
                    1.0,
                    0.0,
                    1.0
                ],
                "result_count_noun_chunks": [
                    36.0,
                    15.0,
                    1210.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count": [
                    21.0,
                    10.0,
                    1190.0
                ],
                "word_count_appended": [
                    6.0,
                    6.0,
                    52.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which three-letter-titled movie grossed the most worldwide?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "saw"
            ],
            "lines": [
                [
                    0.9396825396825398,
                    0.2222222222222222,
                    0.27599051811716896,
                    0.30245144858325373,
                    0.2955367913148372,
                    0.0,
                    0.33879093198992444,
                    0.2222222222222222,
                    0.16666666666666666,
                    -1.0
                ],
                [
                    0.05079365079365081,
                    0.4444444444444444,
                    0.06705045716220792,
                    0.29003502069404646,
                    0.1278648974668275,
                    0.0,
                    0.3866498740554156,
                    0.4444444444444444,
                    0.8333333333333334,
                    -1.0
                ],
                [
                    0.009523809523809525,
                    0.3333333333333333,
                    0.6569590247206231,
                    0.4075135307226998,
                    0.5765983112183354,
                    1.0,
                    0.27455919395465994,
                    0.3333333333333333,
                    0.0,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "big": 0.3990911707563105,
                "saw": 0.3070625934220928,
                "ray": 0.2938462358215967
            },
            "question": "which three-letter-titled movie grossed the most worldwide?",
            "rate_limited": false,
            "answers": [
                "saw",
                "ray",
                "big"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "big": 0.1856614853847551,
                "saw": 0.505161047652944,
                "ray": 0.3906911810372505
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    950000.0,
                    911000.0,
                    1280000.0
                ],
                "wikipedia_search": [
                    0.0,
                    0.0,
                    1.0
                ],
                "answer_relation_to_question": [
                    2.819047619047619,
                    0.1523809523809524,
                    0.02857142857142857
                ],
                "question_related_to_answer": [
                    0.2222222222222222,
                    0.4444444444444444,
                    0.3333333333333333
                ],
                "result_count_noun_chunks": [
                    2450000.0,
                    1060000.0,
                    4780000.0
                ],
                "word_count_noun_chunks": [
                    2.0,
                    4.0,
                    3.0
                ],
                "word_count_raw": [
                    1.0,
                    5.0,
                    0.0
                ],
                "result_count": [
                    8150000.0,
                    1980000.0,
                    19400000.0
                ],
                "word_count_appended": [
                    269.0,
                    307.0,
                    218.0
                ]
            },
            "integer_answers": {
                "big": 4,
                "saw": 1,
                "ray": 4
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Talking is discouraged on what Amtrak car?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "quiet car"
            ],
            "lines": [
                [
                    0.1390402075226978,
                    0,
                    0.9885793074741799,
                    0.9907489575862195,
                    0.9076665406018694,
                    0.20454545454545456,
                    0.08870967741935484,
                    0,
                    0.0,
                    1.0
                ],
                [
                    0.025853869433635972,
                    0,
                    0.011037896778941032,
                    0.008934975261667132,
                    0.058890269598573665,
                    0.20454545454545456,
                    0.0,
                    0,
                    0.0,
                    1.0
                ],
                [
                    0.8351059230436663,
                    0,
                    0.0003827957468790997,
                    0.0003160671521133952,
                    0.033443189799556974,
                    0.5909090909090909,
                    0.9112903225806451,
                    0,
                    1.0,
                    1.0
                ]
            ],
            "fraction_answers": {
                "sports argument car": 0.47418430644996795,
                "quiet car": 0.4816353413188503,
                "meet & greet car": 0.04418035223118177
            },
            "question": "talking is discouraged on what amtrak car?",
            "rate_limited": false,
            "answers": [
                "sports argument car",
                "meet & greet car",
                "quiet car"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "sports argument car": 0.09468923866623011,
                "quiet car": 0.5995768710699738,
                "meet & greet car": 0.02112279365866881
            },
            "integer_answers": {
                "sports argument car": 3,
                "quiet car": 4,
                "meet & greet car": 0
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    3260000.0,
                    29400.0,
                    1040.0
                ],
                "wikipedia_search": [
                    0.4090909090909091,
                    0.4090909090909091,
                    1.1818181818181819
                ],
                "answer_relation_to_question": [
                    0.4171206225680934,
                    0.07756160830090791,
                    2.5053177691309987
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    1680000.0,
                    109000.0,
                    61900.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    5.0
                ],
                "result_count": [
                    2660000.0,
                    29700.0,
                    1030.0
                ],
                "word_count_appended": [
                    11.0,
                    0.0,
                    113.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "The creator of Wonder Woman also created an early version of what device?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "lie detector"
            ],
            "lines": [
                [
                    0.22999999999999998,
                    0,
                    0.21936099189318073,
                    0.31227217496962334,
                    0.14842767295597484,
                    0.03469387755102041,
                    0.15300546448087432,
                    0.0,
                    0.0,
                    1.0
                ],
                [
                    0.5055555555555555,
                    0,
                    0.5007153075822603,
                    0.23572296476306198,
                    0.10943396226415095,
                    0.3508967223252938,
                    0.3879781420765027,
                    0.0,
                    0.0,
                    1.0
                ],
                [
                    0.2644444444444445,
                    0,
                    0.2799237005245589,
                    0.4520048602673147,
                    0.7421383647798742,
                    0.6144094001236857,
                    0.45901639344262296,
                    1.0,
                    1.0,
                    1.0
                ]
            ],
            "fraction_answers": {
                "lie detector": 0.6014921454478126,
                "hearing aid": 0.2612878318208532,
                "magic marker": 0.13722002273133418
            },
            "question": "the creator of wonder woman also created an early version of what device?",
            "rate_limited": false,
            "answers": [
                "magic marker",
                "hearing aid",
                "lie detector"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "lie detector": 0.8011367709037928,
                "hearing aid": 0.4840525301902888,
                "magic marker": 0.10844944022410384
            },
            "integer_answers": {
                "lie detector": 6,
                "hearing aid": 2,
                "magic marker": 0
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    25700.0,
                    19400.0,
                    37200.0
                ],
                "wikipedia_search": [
                    0.24285714285714285,
                    2.4562770562770564,
                    4.3008658008658
                ],
                "answer_relation_to_question": [
                    1.15,
                    2.5277777777777777,
                    1.3222222222222224
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    23600.0,
                    17400.0,
                    118000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    12.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    27.0
                ],
                "result_count": [
                    46000.0,
                    105000.0,
                    58700.0
                ],
                "word_count_appended": [
                    28.0,
                    71.0,
                    84.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which of these verbs has two meanings that are opposites of each other?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "cleave"
            ],
            "lines": [
                [
                    0.0,
                    0.0,
                    0.1365149833518313,
                    0.3148148148148148,
                    0.8883770667105372,
                    0,
                    0.33423180592991913,
                    0.0,
                    0,
                    -1.0
                ],
                [
                    0.25,
                    0.0,
                    0.42896781354051056,
                    0.20959595959595959,
                    0.0051821995558114665,
                    0,
                    0.261455525606469,
                    0.0,
                    0,
                    -1.0
                ],
                [
                    0.75,
                    1.0,
                    0.4345172031076582,
                    0.47558922558922556,
                    0.1064407337336514,
                    0,
                    0.40431266846361186,
                    1.0,
                    0,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "cleave": 0.5958371186991639,
                "jut": 0.16502878547125008,
                "branch": 0.23913409582958606
            },
            "question": "which of these verbs has two meanings that are opposites of each other?",
            "rate_limited": false,
            "answers": [
                "branch",
                "jut",
                "cleave"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "cleave": 0.6117455284224178,
                "jut": 0.2177658429768738,
                "branch": 0.2606717235961164
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    374000.0,
                    249000.0,
                    565000.0
                ],
                "wikipedia_search": [
                    0.0,
                    0.0,
                    0.0
                ],
                "answer_relation_to_question": [
                    0.0,
                    0.5,
                    1.5
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    1.0
                ],
                "result_count_noun_chunks": [
                    54000000.0,
                    315000.0,
                    6470000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    7.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_appended": [
                    248.0,
                    194.0,
                    300.0
                ],
                "result_count": [
                    2460000.0,
                    7730000.0,
                    7830000.0
                ]
            },
            "integer_answers": {
                "cleave": 6,
                "jut": 0,
                "branch": 1
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which of these is NOT a real animal?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "liger"
            ],
            "lines": [
                [
                    0.3981028151774786,
                    0.5,
                    0.2735699152542373,
                    0.3363892806770099,
                    0.3377622377622378,
                    0.16379310344827586,
                    0.32041522491349483,
                    0.5,
                    0.5,
                    -1.0
                ],
                [
                    0.24984700122399023,
                    0.0,
                    0.2523834745762712,
                    0.2447108603667137,
                    0.24545454545454548,
                    0.39655172413793105,
                    0.28269896193771626,
                    0.0,
                    0.0,
                    -1.0
                ],
                [
                    0.35205018359853124,
                    0.5,
                    0.4740466101694915,
                    0.41889985895627646,
                    0.4167832167832168,
                    0.4396551724137931,
                    0.3968858131487889,
                    0.5,
                    0.5,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "liger": 0.6285229849561849,
                "wholphin": 0.1114842544288671,
                "jackalope": 0.25999276061494797
            },
            "question": "which of these is not a real animal?",
            "rate_limited": false,
            "answers": [
                "jackalope",
                "liger",
                "wholphin"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "liger": 0.3908188380752038,
                "wholphin": 0.2709999234592075,
                "jackalope": 0.2779000671766876
            },
            "negative_question": true,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    2320000.0,
                    3620000.0,
                    1150000.0
                ],
                "wikipedia_search": [
                    1.3448275862068966,
                    0.41379310344827586,
                    0.2413793103448276
                ],
                "answer_relation_to_question": [
                    0.40758873929008566,
                    1.000611995104039,
                    0.5917992656058751
                ],
                "question_related_to_answer": [
                    0.0,
                    1.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    2320000.0,
                    3640000.0,
                    1190000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    6.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    7.0,
                    0.0
                ],
                "result_count": [
                    1710000.0,
                    1870000.0,
                    196000.0
                ],
                "word_count_appended": [
                    519.0,
                    628.0,
                    298.0
                ]
            },
            "integer_answers": {
                "liger": 8,
                "wholphin": 0,
                "jackalope": 1
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which Hawaiian island has active volcanoes?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "big island"
            ],
            "lines": [
                [
                    0.6767201064574292,
                    0.4083333333333333,
                    0.3717948717948718,
                    0.37797619047619047,
                    0.3717948717948718,
                    0.0,
                    0.17560975609756097,
                    0.0,
                    0.05714285714285714,
                    -1.0
                ],
                [
                    0.15834815556968984,
                    0.41041666666666665,
                    0.3401206636500754,
                    0.33630952380952384,
                    0.3401206636500754,
                    0.3795045045045045,
                    0.45365853658536587,
                    0.5853658536585366,
                    0.6571428571428571,
                    -1.0
                ],
                [
                    0.16493173797288094,
                    0.18125,
                    0.28808446455505277,
                    0.2857142857142857,
                    0.28808446455505277,
                    0.6204954954954954,
                    0.37073170731707317,
                    0.4146341463414634,
                    0.2857142857142857,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "maui": 0.4067763805819218,
                "oahu": 0.3221822875183989,
                "big island": 0.27104133189967944
            },
            "question": "which hawaiian island has active volcanoes?",
            "rate_limited": false,
            "answers": [
                "big island",
                "maui",
                "oahu"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "maui": 0.34224756863120587,
                "oahu": 0.30318215930877723,
                "big island": 0.3660360199722858
            },
            "integer_answers": {
                "maui": 4,
                "oahu": 1,
                "big island": 4
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    508000.0,
                    452000.0,
                    384000.0
                ],
                "wikipedia_search": [
                    0.0,
                    1.1385135135135136,
                    1.8614864864864864
                ],
                "answer_relation_to_question": [
                    2.7068804258297168,
                    0.6333926222787594,
                    0.6597269518915237
                ],
                "question_related_to_answer": [
                    0.8166666666666667,
                    0.8208333333333333,
                    0.3625
                ],
                "result_count_noun_chunks": [
                    493000.0,
                    451000.0,
                    382000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    24.0,
                    17.0
                ],
                "word_count_raw": [
                    2.0,
                    23.0,
                    10.0
                ],
                "result_count": [
                    493000.0,
                    451000.0,
                    382000.0
                ],
                "word_count_appended": [
                    144.0,
                    372.0,
                    304.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Pixies, Bon Iver, Iron & Wine and Bauhaus were all once signed to which record label?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "4ad"
            ],
            "lines": [
                [
                    0.31900439919557566,
                    0.0,
                    0.3333333333333333,
                    0.017190278601066984,
                    0.1896551724137931,
                    0.3812222222222222,
                    0.02564102564102564,
                    0.0,
                    0.0,
                    -1.0
                ],
                [
                    0.5021383861236802,
                    1.0,
                    0.3333333333333333,
                    0.31890930646117366,
                    0.257736516357206,
                    0.6154444444444445,
                    0.9487179487179487,
                    1.0,
                    1.0,
                    -1.0
                ],
                [
                    0.1788572146807441,
                    0.0,
                    0.3333333333333333,
                    0.6639004149377593,
                    0.5526083112290009,
                    0.0033333333333333335,
                    0.02564102564102564,
                    0.0,
                    0.0,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "4ad": 0.6640311039375317,
                "geffen": 0.19529707035057742,
                "subpop": 0.14067182571189077
            },
            "question": "pixies, bon iver, iron & wine and bauhaus were all once signed to which record label?",
            "rate_limited": false,
            "answers": [
                "subpop",
                "4ad",
                "geffen"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "4ad": 0.8555938027464317,
                "geffen": 0.31760110560997185,
                "subpop": 0.05561560262082811
            },
            "integer_answers": {
                "4ad": 6,
                "geffen": 2,
                "subpop": 1
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    29.0,
                    538.0,
                    1120.0
                ],
                "wikipedia_search": [
                    2.287333333333333,
                    3.6926666666666668,
                    0.02
                ],
                "answer_relation_to_question": [
                    2.5520351935646053,
                    4.017107088989442,
                    1.4308577174459527
                ],
                "question_related_to_answer": [
                    0.0,
                    1.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    42900.0,
                    58300.0,
                    125000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    79.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    36.0,
                    0.0
                ],
                "word_count_appended": [
                    1.0,
                    37.0,
                    1.0
                ],
                "result_count": [
                    222000.0,
                    222000.0,
                    222000.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Which of these would an oologist study?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "ostrich egg"
            ],
            "lines": [
                [
                    0.0,
                    0,
                    0.0583989501312336,
                    0.4995766299745978,
                    0.05857230018303844,
                    0.0,
                    0.13861386138613863,
                    0,
                    0,
                    -1.0
                ],
                [
                    1.0,
                    0,
                    0.04921259842519685,
                    0.017781541066892465,
                    0.05064063453325198,
                    0.08333333333333333,
                    0.22772277227722773,
                    0,
                    0,
                    -1.0
                ],
                [
                    0.0,
                    0,
                    0.8923884514435696,
                    0.4826418289585097,
                    0.8907870652837095,
                    0.9166666666666666,
                    0.6336633663366337,
                    0,
                    0,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "ice cave": 0.1258602902791681,
                "human liver": 0.23811514660598368,
                "ostrich egg": 0.6360245631148482
            },
            "question": "which of these would an oologist study?",
            "rate_limited": false,
            "answers": [
                "ice cave",
                "human liver",
                "ostrich egg"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "ice cave": 0.03772834502052751,
                "human liver": 0.2120761645974999,
                "ostrich egg": 0.42492789709638873
            },
            "integer_answers": {
                "ice cave": 1,
                "human liver": 1,
                "ostrich egg": 4
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    2360.0,
                    84.0,
                    2280.0
                ],
                "wikipedia_search": [
                    0.0,
                    0.08333333333333333,
                    0.9166666666666666
                ],
                "answer_relation_to_question": [
                    0.0,
                    1.0,
                    0.0
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    96.0,
                    83.0,
                    1460.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_appended": [
                    14.0,
                    23.0,
                    64.0
                ],
                "result_count": [
                    89.0,
                    75.0,
                    1360.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which of these best-selling authors uses his/her given last name?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "r.l. stine"
            ],
            "lines": [
                [
                    0.43046783625730994,
                    0,
                    0.33373349339735897,
                    0.08914450035945364,
                    0.19852760736196318,
                    0.265625,
                    0.226890756302521,
                    0.0,
                    0,
                    -1.0
                ],
                [
                    0.23450292397660819,
                    0,
                    0.23529411764705882,
                    0.098490294751977,
                    0.1928834355828221,
                    0.5587121212121212,
                    0.4369747899159664,
                    1.0,
                    0,
                    -1.0
                ],
                [
                    0.33502923976608184,
                    0,
                    0.4309723889555822,
                    0.8123652048885693,
                    0.6085889570552148,
                    0.17566287878787878,
                    0.33613445378151263,
                    0.0,
                    0,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "r.l. stine": 0.39383681186950764,
                "e.l. james": 0.38553616046211997,
                "j.d. robb": 0.2206270276683724
            },
            "question": "which of these best-selling authors uses his/her given last name?",
            "rate_limited": false,
            "answers": [
                "j.d. robb",
                "r.l. stine",
                "e.l. james"
            ],
            "ml_answers": {
                "r.l. stine": 0.5616289856041582,
                "e.l. james": 0.10074496648410726,
                "j.d. robb": 0.18708025358634117
            },
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "integer_answers": {
                "r.l. stine": 3,
                "e.l. james": 3,
                "j.d. robb": 1
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    124000.0,
                    137000.0,
                    1130000.0
                ],
                "wikipedia_search": [
                    1.0625,
                    2.234848484848485,
                    0.7026515151515151
                ],
                "answer_relation_to_question": [
                    2.1523391812865498,
                    1.172514619883041,
                    1.6751461988304093
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    80900.0,
                    78600.0,
                    248000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    3.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_appended": [
                    27.0,
                    52.0,
                    40.0
                ],
                "result_count": [
                    27800.0,
                    19600.0,
                    35900.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Who holds the record as the youngest solo artist with a Billboard #1 hit?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "justin bieber"
            ],
            "lines": [
                [
                    0.3624281514193441,
                    0.35714285714285715,
                    0.3390158853157691,
                    0.42439862542955326,
                    0.3333333333333333,
                    0.33041159359030725,
                    0.38461538461538464,
                    0.45454545454545453,
                    0.36,
                    0.0
                ],
                [
                    0.3103936195281164,
                    0.07142857142857142,
                    0.33281673769856646,
                    0.16895761741122567,
                    0.3333333333333333,
                    0.5173005833887676,
                    0.15384615384615385,
                    0.22727272727272727,
                    0.16,
                    0.0
                ],
                [
                    0.32717822905253946,
                    0.5714285714285714,
                    0.32816737698566445,
                    0.4066437571592211,
                    0.3333333333333333,
                    0.15228782302092517,
                    0.46153846153846156,
                    0.3181818181818182,
                    0.48,
                    0.0
                ]
            ],
            "fraction_answers": {
                "justin bieber": 0.3717656983768893,
                "stevie wonder": 0.3754177078556149,
                "michael jackson": 0.25281659376749577
            },
            "question": "who holds the record as the youngest solo artist with a billboard #1 hit?",
            "rate_limited": false,
            "answers": [
                "justin bieber",
                "michael jackson",
                "stevie wonder"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "justin bieber": 0.29887457683736907,
                "stevie wonder": 0.2815039490605053,
                "michael jackson": 0.181766881836912
            },
            "integer_answers": {
                "justin bieber": 5,
                "stevie wonder": 3,
                "michael jackson": 1
            },
            "categorical_data": {
                "question_type": 0
            },
            "data": {
                "result_count_important_words": [
                    74100.0,
                    29500.0,
                    71000.0
                ],
                "wikipedia_search": [
                    2.643292748722458,
                    4.138404667110141,
                    1.2183025841674013
                ],
                "answer_relation_to_question": [
                    2.5369970599354086,
                    2.172755336696815,
                    2.290247603367776
                ],
                "question_related_to_answer": [
                    0.35714285714285715,
                    0.07142857142857142,
                    0.5714285714285714
                ],
                "result_count_noun_chunks": [
                    761000.0,
                    761000.0,
                    761000.0
                ],
                "word_count_noun_chunks": [
                    10.0,
                    5.0,
                    7.0
                ],
                "word_count_raw": [
                    9.0,
                    4.0,
                    12.0
                ],
                "result_count": [
                    875000.0,
                    859000.0,
                    847000.0
                ],
                "word_count_appended": [
                    10.0,
                    4.0,
                    12.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which of these states does NOT touch the Mason-Dixon Line?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "tennessee"
            ],
            "lines": [
                [
                    0.33605365707434054,
                    0.44375000000000003,
                    0.12868117797695264,
                    0.1691988950276243,
                    0.351931330472103,
                    0.3343458009483992,
                    0.44240400667779634,
                    0.3833333333333333,
                    0.3666666666666667,
                    -1.0
                ],
                [
                    0.23294814148681053,
                    0.17500000000000002,
                    0.41421254801536495,
                    0.42058011049723754,
                    0.37553648068669526,
                    0.3213965038300738,
                    0.2404006677796327,
                    0.15000000000000002,
                    0.2,
                    -1.0
                ],
                [
                    0.4309982014388489,
                    0.38125000000000003,
                    0.4571062740076825,
                    0.4102209944751381,
                    0.27253218884120173,
                    0.344257695221527,
                    0.31719532554257096,
                    0.4666666666666667,
                    0.43333333333333335,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "tennessee": 0.2192087378828957,
                "delaware": 0.43776123282315227,
                "west virginia": 0.34303002929395193
            },
            "question": "which of these states does not touch the mason-dixon line?",
            "rate_limited": false,
            "answers": [
                "west virginia",
                "delaware",
                "tennessee"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "tennessee": 0.44561479954880884,
                "delaware": 0.27137939861524063,
                "west virginia": 0.31258348553681076
            },
            "negative_question": true,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    4790000.0,
                    1150000.0,
                    1300000.0
                ],
                "wikipedia_search": [
                    0.6626167962064031,
                    0.7144139846797048,
                    0.622969219113892
                ],
                "answer_relation_to_question": [
                    1.6394634292565948,
                    2.6705185851318944,
                    0.6900179856115107
                ],
                "question_related_to_answer": [
                    0.225,
                    1.3,
                    0.475
                ],
                "result_count_noun_chunks": [
                    138000.0,
                    116000.0,
                    212000.0
                ],
                "word_count_noun_chunks": [
                    7.0,
                    21.0,
                    2.0
                ],
                "word_count_raw": [
                    4.0,
                    9.0,
                    2.0
                ],
                "result_count": [
                    1160000.0,
                    268000.0,
                    134000.0
                ],
                "word_count_appended": [
                    69.0,
                    311.0,
                    219.0
                ]
            },
            "integer_answers": {
                "tennessee": 1,
                "delaware": 6,
                "west virginia": 2
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "One of Tupac Shakur\u2019s biggest posthumous hits samples what singer?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "bruce hornsby"
            ],
            "lines": [
                [
                    0.5810570381998954,
                    0,
                    0.030485643388869197,
                    0.029621698786581014,
                    0.09465505062396987,
                    0.36768018018018017,
                    0.175,
                    0,
                    0.0,
                    1.0
                ],
                [
                    0.1130821559392988,
                    0,
                    0.7656859269762496,
                    0.7673090649536045,
                    0.4497292206263245,
                    0.4671546546546546,
                    0.1625,
                    0,
                    0.0,
                    1.0
                ],
                [
                    0.30586080586080583,
                    0,
                    0.20382842963488124,
                    0.2030692362598144,
                    0.4556157287497057,
                    0.16516516516516516,
                    0.6625,
                    0,
                    1.0,
                    1.0
                ]
            ],
            "fraction_answers": {
                "john mellencamp": 0.3893515747357332,
                "bruce hornsby": 0.428005623667196,
                "christopher cross": 0.18264280159707078
            },
            "question": "one of tupac shakur\u2019s biggest posthumous hits samples what singer?",
            "rate_limited": false,
            "answers": [
                "christopher cross",
                "john mellencamp",
                "bruce hornsby"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "john mellencamp": 0.27063768753841355,
                "bruce hornsby": 0.5015735741531359,
                "christopher cross": 0.1794375959025348
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    83.0,
                    2150.0,
                    569.0
                ],
                "wikipedia_search": [
                    1.1030405405405406,
                    1.4014639639639639,
                    0.4954954954954955
                ],
                "answer_relation_to_question": [
                    2.905285190999477,
                    0.565410779696494,
                    1.5293040293040292
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    80400.0,
                    382000.0,
                    387000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    10.0
                ],
                "result_count": [
                    86.0,
                    2160.0,
                    575.0
                ],
                "word_count_appended": [
                    14.0,
                    13.0,
                    53.0
                ]
            },
            "integer_answers": {
                "john mellencamp": 3,
                "bruce hornsby": 3,
                "christopher cross": 1
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "To help first create Maps, Google acquired what company?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "waze"
            ],
            "lines": [
                [
                    0.28276672878388154,
                    0.0,
                    0.05365070707161028,
                    0.36034988811717183,
                    0.49947794677879054,
                    0.10114341399718757,
                    0.3419182948490231,
                    0.0,
                    0.16129032258064516,
                    1.0
                ],
                [
                    0.48725422839734195,
                    0.0,
                    0.0029910269192422734,
                    0.020661997617041062,
                    0.01233174365775884,
                    0.7860637062877629,
                    0.05772646536412078,
                    0.0,
                    0.08064516129032258,
                    1.0
                ],
                [
                    0.2299790428187766,
                    1.0,
                    0.9433582660091474,
                    0.6189881142657871,
                    0.4881903095634506,
                    0.11279287971504952,
                    0.6003552397868561,
                    1.0,
                    0.7580645161290323,
                    1.0
                ]
            ],
            "fraction_answers": {
                "mapquest": 0.20006636690870114,
                "waze": 0.6390809298097887,
                "where 2 technologies": 0.16085270328151002
            },
            "question": "to help first create maps, google acquired what company?",
            "rate_limited": false,
            "answers": [
                "mapquest",
                "where 2 technologies",
                "waze"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "integer_answers": {
                "mapquest": 1,
                "waze": 6,
                "where 2 technologies": 2
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    124000.0,
                    7110.0,
                    213000.0
                ],
                "wikipedia_search": [
                    0.6068604839831254,
                    4.716382237726577,
                    0.6767572782902971
                ],
                "answer_relation_to_question": [
                    1.6966003727032892,
                    2.9235253703840516,
                    1.3798742569126596
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    1.0
                ],
                "result_count_noun_chunks": [
                    1770000.0,
                    43700.0,
                    1730000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    12.0
                ],
                "word_count_raw": [
                    10.0,
                    5.0,
                    47.0
                ],
                "word_count_appended": [
                    385.0,
                    65.0,
                    676.0
                ],
                "result_count": [
                    120000.0,
                    6690.0,
                    2110000.0
                ]
            },
            "ml_answers": {
                "mapquest": 0.23345401140998456,
                "waze": 0.5738656745607617,
                "where 2 technologies": 0.34280060827538933
            }
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "The lyrics to \u201cThe Star-Spangled Banner\u201d were written during what conflict?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "the war of 1812"
            ],
            "lines": [
                [
                    0.17251685802806632,
                    0.0,
                    0.5408198415432312,
                    0.4623217922606925,
                    0.5488308115543329,
                    0.19660919540229885,
                    0.3089887640449438,
                    0.10526315789473684,
                    0.038461538461538464,
                    1.0
                ],
                [
                    0.0951776927282668,
                    0.0,
                    0.3995866345160179,
                    0.32382892057026474,
                    0.3170563961485557,
                    0.0932758620689655,
                    0.21910112359550563,
                    0.0,
                    0.07692307692307693,
                    1.0
                ],
                [
                    0.7323054492436668,
                    1.0,
                    0.059593523940750945,
                    0.21384928716904278,
                    0.13411279229711143,
                    0.7101149425287357,
                    0.47191011235955055,
                    0.8947368421052632,
                    0.8846153846153846,
                    1.0
                ]
            ],
            "fraction_answers": {
                "american revolution": 0.1694388562834059,
                "the war of 1812": 0.5668042593621673,
                "the civil war": 0.26375688435442673
            },
            "question": "the lyrics to \u201cthe star-spangled banner\u201d were written during what conflict?",
            "rate_limited": false,
            "answers": [
                "the civil war",
                "american revolution",
                "the war of 1812"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "american revolution": 0.326641540684977,
                "the war of 1812": 0.8581115236314334,
                "the civil war": 0.2403994579091386
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    227000.0,
                    159000.0,
                    105000.0
                ],
                "wikipedia_search": [
                    1.1796551724137931,
                    0.559655172413793,
                    4.260689655172414
                ],
                "answer_relation_to_question": [
                    0.8625842901403316,
                    0.475888463641334,
                    3.661527246218334
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    1.0
                ],
                "result_count_noun_chunks": [
                    798000.0,
                    461000.0,
                    195000.0
                ],
                "word_count_noun_chunks": [
                    2.0,
                    0.0,
                    17.0
                ],
                "word_count_raw": [
                    1.0,
                    2.0,
                    23.0
                ],
                "word_count_appended": [
                    55.0,
                    39.0,
                    84.0
                ],
                "result_count": [
                    157000.0,
                    116000.0,
                    17300.0
                ]
            },
            "integer_answers": {
                "american revolution": 0,
                "the war of 1812": 6,
                "the civil war": 3
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Where do marsupials keep their undeveloped young?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "underwater"
            ],
            "lines": [
                [
                    1.0,
                    0,
                    0.0002479087695727972,
                    0.0003993433021253938,
                    0.20274557751536068,
                    0,
                    0.07216494845360824,
                    0,
                    0.0,
                    3.0
                ],
                [
                    0.0,
                    0,
                    0.00011995585624490187,
                    0.00013311443404179793,
                    0.00020119790135112128,
                    0,
                    0.03608247422680412,
                    0,
                    0.0,
                    3.0
                ],
                [
                    0.0,
                    0,
                    0.9996321353741823,
                    0.9994675422638328,
                    0.7970532245832882,
                    0,
                    0.8917525773195877,
                    0,
                    1.0,
                    3.0
                ]
            ],
            "fraction_answers": {
                "in their pouches": 0.21259296300677785,
                "underwater": 0.7813175799234818,
                "in a paper bag": 0.006089457069740324
            },
            "question": "where do marsupials keep their undeveloped young?",
            "rate_limited": false,
            "answers": [
                "in their pouches",
                "in a paper bag",
                "underwater"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "in their pouches": 0.2873924497316899,
                "underwater": 0.3043780525627146,
                "in a paper bag": 0.06872492676521963
            },
            "integer_answers": {
                "in their pouches": 1,
                "underwater": 5,
                "in a paper bag": 0
            },
            "categorical_data": {
                "question_type": 3
            },
            "data": {
                "result_count_important_words": [
                    36.0,
                    12.0,
                    90100.0
                ],
                "wikipedia_search": [
                    0.0,
                    0.0,
                    0.0
                ],
                "answer_relation_to_question": [
                    2.0,
                    0.0,
                    0.0
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    52400.0,
                    52.0,
                    206000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    1.0
                ],
                "result_count": [
                    31.0,
                    15.0,
                    125000.0
                ],
                "word_count_appended": [
                    14.0,
                    7.0,
                    173.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Catching a catfish with your bare hands is called what?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "noodling"
            ],
            "lines": [
                [
                    0.030405405405405407,
                    0.0,
                    0.02635870994896617,
                    0.019430828366893537,
                    0.018905273459220214,
                    0.06666666666666667,
                    0.200652528548124,
                    0.0,
                    0.0,
                    1.0
                ],
                [
                    0.12105263157894737,
                    0.0,
                    0.000315673173041511,
                    0.00021158796769757027,
                    0.0002446564800604969,
                    0.06666666666666667,
                    0.037520391517128875,
                    0.0,
                    0.0,
                    1.0
                ],
                [
                    0.8485419630156473,
                    1.0,
                    0.9733256168779924,
                    0.9803575836654089,
                    0.9808500700607193,
                    0.8666666666666666,
                    0.7618270799347472,
                    1.0,
                    1.0,
                    1.0
                ]
            ],
            "fraction_answers": {
                "noodling": 0.9346187755801313,
                "whiskering": 0.025112400820393607,
                "strumming": 0.04026882359947511
            },
            "question": "catching a catfish with your bare hands is called what?",
            "rate_limited": false,
            "answers": [
                "strumming",
                "whiskering",
                "noodling"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "noodling": 0.8619448566740576,
                "whiskering": 0.1335098556894184,
                "strumming": 0.21910104729702942
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    551.0,
                    6.0,
                    27800.0
                ],
                "wikipedia_search": [
                    0.3333333333333333,
                    0.3333333333333333,
                    4.333333333333333
                ],
                "answer_relation_to_question": [
                    0.15202702702702703,
                    0.6052631578947368,
                    4.2427098150782365
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    1.0
                ],
                "result_count_noun_chunks": [
                    850.0,
                    11.0,
                    44100.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    134.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    206.0
                ],
                "word_count_appended": [
                    123.0,
                    23.0,
                    467.0
                ],
                "result_count": [
                    501.0,
                    6.0,
                    18500.0
                ]
            },
            "integer_answers": {
                "noodling": 9,
                "whiskering": 0,
                "strumming": 0
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which verb describes the sound minerals make when they are heated?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "decrepitate"
            ],
            "lines": [
                [
                    0.8777777777777778,
                    0,
                    1.0,
                    1.0,
                    1.0,
                    1.0,
                    0.7333333333333333,
                    1.0,
                    1.0,
                    2.0
                ],
                [
                    0.005555555555555556,
                    0,
                    0.0,
                    0.0,
                    0.0,
                    0.0,
                    0.13333333333333333,
                    0.0,
                    0.0,
                    2.0
                ],
                [
                    0.11666666666666665,
                    0,
                    0.0,
                    0.0,
                    0.0,
                    0.0,
                    0.13333333333333333,
                    0.0,
                    0.0,
                    2.0
                ]
            ],
            "fraction_answers": {
                "frangelle": 0.017361111111111112,
                "decrepitate": 0.9513888888888888,
                "recleft": 0.03125
            },
            "question": "which verb describes the sound minerals make when they are heated?",
            "rate_limited": false,
            "answers": [
                "decrepitate",
                "frangelle",
                "recleft"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "frangelle": 0.03161545542734504,
                "decrepitate": 0.8453017164499212,
                "recleft": 0.01853092797577398
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 2
            },
            "data": {
                "result_count_important_words": [
                    4440.0,
                    0,
                    0
                ],
                "wikipedia_search": [
                    2.0,
                    0.0,
                    0.0
                ],
                "answer_relation_to_question": [
                    3.511111111111111,
                    0.022222222222222223,
                    0.4666666666666666
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    4640.0,
                    0,
                    0
                ],
                "word_count_noun_chunks": [
                    10.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    6.0,
                    0.0,
                    0.0
                ],
                "result_count": [
                    4420.0,
                    0,
                    0
                ],
                "word_count_appended": [
                    88.0,
                    16.0,
                    16.0
                ]
            },
            "integer_answers": {
                "frangelle": 0,
                "decrepitate": 8,
                "recleft": 0
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Before a performance, an orchestra usually tunes to what instrument?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "oboe"
            ],
            "lines": [
                [
                    0.366044616044616,
                    0.95,
                    0.09508460918614021,
                    0.40237099023709905,
                    0.4073587385019711,
                    0.23219795418965544,
                    0.4839476813317479,
                    1.0,
                    0.94,
                    1.0
                ],
                [
                    0.2958092020592021,
                    0.05,
                    0.821917808219178,
                    0.19595536959553697,
                    0.26872536136662284,
                    0.41594850516012344,
                    0.11652794292508918,
                    0.0,
                    0.02,
                    1.0
                ],
                [
                    0.3381461818961819,
                    0.0,
                    0.08299758259468171,
                    0.401673640167364,
                    0.32391590013140603,
                    0.3518535406502211,
                    0.3995243757431629,
                    0.0,
                    0.04,
                    1.0
                ]
            ],
            "fraction_answers": {
                "french horn": 0.24276490992508362,
                "bassoon": 0.2153456912425575,
                "oboe": 0.5418893988323589
            },
            "question": "before a performance, an orchestra usually tunes to what instrument?",
            "rate_limited": false,
            "answers": [
                "oboe",
                "french horn",
                "bassoon"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "french horn": 0.10844907835606492,
                "bassoon": 0.3525774416387707,
                "oboe": 0.7317453664723605
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    577000.0,
                    281000.0,
                    576000.0
                ],
                "wikipedia_search": [
                    0.9287918167586218,
                    1.6637940206404938,
                    1.4074141626008845
                ],
                "answer_relation_to_question": [
                    1.464178464178464,
                    1.1832368082368083,
                    1.3525847275847276
                ],
                "question_related_to_answer": [
                    1.9,
                    0.1,
                    0.0
                ],
                "result_count_noun_chunks": [
                    1240000.0,
                    818000.0,
                    986000.0
                ],
                "word_count_noun_chunks": [
                    14.0,
                    0.0,
                    0.0
                ],
                "word_count_raw": [
                    47.0,
                    1.0,
                    2.0
                ],
                "word_count_appended": [
                    407.0,
                    98.0,
                    336.0
                ],
                "result_count": [
                    1180000.0,
                    10200000.0,
                    1030000.0
                ]
            },
            "integer_answers": {
                "french horn": 2,
                "bassoon": 0,
                "oboe": 7
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "The \u201cAmerican Craftsman\u201d style of house was an architectural reaction to what?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "industrial revolution"
            ],
            "lines": [
                [
                    0.1576193810887236,
                    0.6,
                    0.0008980825936625305,
                    0.27876106194690264,
                    0.017225180081428124,
                    0.4568860134502426,
                    0.23893805309734514,
                    0.0,
                    0.0,
                    1.0
                ],
                [
                    0.31320061873398874,
                    0.4,
                    0.9983684832881797,
                    0.4336283185840708,
                    0.967741935483871,
                    0.36962458500042567,
                    0.6017699115044248,
                    1.0,
                    1.0,
                    1.0
                ],
                [
                    0.5291800001772877,
                    0.0,
                    0.0007334341181577332,
                    0.28761061946902655,
                    0.015032884434700909,
                    0.17348940154933173,
                    0.1592920353982301,
                    0.0,
                    0.0,
                    1.0
                ]
            ],
            "fraction_answers": {
                "world war i": 0.1944808635842561,
                "industrial revolution": 0.6760370947327734,
                "the great depression": 0.12948204168297053
            },
            "question": "the \u201camerican craftsman\u201d style of house was an architectural reaction to what?",
            "rate_limited": false,
            "answers": [
                "world war i",
                "industrial revolution",
                "the great depression"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "world war i": 0.04230420661170556,
                "industrial revolution": 0.8695485802579912,
                "the great depression": 0.1440639611695696
            },
            "integer_answers": {
                "world war i": 2,
                "industrial revolution": 6,
                "the great depression": 1
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    6300000.0,
                    9800000.0,
                    6500000.0
                ],
                "wikipedia_search": [
                    2.284430067251213,
                    1.8481229250021283,
                    0.8674470077466587
                ],
                "answer_relation_to_question": [
                    0.788096905443618,
                    1.5660030936699436,
                    2.6459000008864386
                ],
                "question_related_to_answer": [
                    1.2,
                    0.8,
                    0.0
                ],
                "result_count_noun_chunks": [
                    55.0,
                    3090.0,
                    48.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    12.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    11.0,
                    0.0
                ],
                "word_count_appended": [
                    27.0,
                    68.0,
                    18.0
                ],
                "result_count": [
                    60.0,
                    66700.0,
                    49.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "In the original NES \u201cMike Tyson\u2019s Punch-Out!!\u201d, who does Little Mac face right before the final opponent?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "mr. dream"
            ],
            "lines": [
                [
                    0.34204483954213644,
                    1.0,
                    0.32443125618199803,
                    0.5138510119133056,
                    0.25895663104965433,
                    0.0104775828460039,
                    0.39316239316239315,
                    0.5483870967741935,
                    0.4375,
                    0.0
                ],
                [
                    0.5273578219433609,
                    0.0,
                    0.380811078140455,
                    0.012487440792306587,
                    0.2853551225644249,
                    0.91973858256753,
                    0.3076923076923077,
                    0.25806451612903225,
                    0.375,
                    0.0
                ],
                [
                    0.13059733851450278,
                    0.0,
                    0.29475766567754697,
                    0.4736615472943878,
                    0.4556882463859208,
                    0.06978383458646617,
                    0.29914529914529914,
                    0.1935483870967742,
                    0.1875,
                    0.0
                ]
            ],
            "fraction_answers": {
                "super macho man": 0.34072298553660196,
                "mr. dream": 0.42542342349663165,
                "mr. sandman": 0.23385359096676644
            },
            "question": "in the original nes \u201cmike tyson\u2019s punch-out!!\u201d, who does little mac face right before the final opponent?",
            "rate_limited": false,
            "answers": [
                "mr. dream",
                "super macho man",
                "mr. sandman"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "super macho man": 0.2853939485450921,
                "mr. dream": 0.4295525773236582,
                "mr. sandman": 0.12048661046151658
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 0
            },
            "data": {
                "result_count_important_words": [
                    3580.0,
                    87.0,
                    3300.0
                ],
                "wikipedia_search": [
                    0.09429824561403508,
                    8.277647243107769,
                    0.6280545112781954
                ],
                "answer_relation_to_question": [
                    3.7624932349635007,
                    5.8009360413769695,
                    1.4365707236595306
                ],
                "question_related_to_answer": [
                    1.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    8240.0,
                    9080.0,
                    14500.0
                ],
                "word_count_noun_chunks": [
                    17.0,
                    8.0,
                    6.0
                ],
                "word_count_raw": [
                    7.0,
                    6.0,
                    3.0
                ],
                "word_count_appended": [
                    46.0,
                    36.0,
                    35.0
                ],
                "result_count": [
                    3280.0,
                    3850.0,
                    2980.0
                ]
            },
            "integer_answers": {
                "super macho man": 3,
                "mr. dream": 5,
                "mr. sandman": 1
            }
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Which of these do NOT have flippers?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "new yorkers"
            ],
            "lines": [
                [
                    0.5,
                    0.5,
                    0.20697204445941392,
                    0.28176527643064986,
                    0.28176527643064986,
                    0.5,
                    0.4428754813863928,
                    0.5,
                    0.5,
                    -1.0
                ],
                [
                    0.5,
                    0.5,
                    0.29903446727293137,
                    0.3195926285160039,
                    0.3195926285160039,
                    0.4,
                    0.11681643132220798,
                    0.5,
                    0.0,
                    -1.0
                ],
                [
                    0.0,
                    0.0,
                    0.49399348826765466,
                    0.39864209505334625,
                    0.39864209505334625,
                    0.09999999999999998,
                    0.44030808729139925,
                    0.0,
                    0.5,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "new yorkers": 0.1748048713984208,
                "pinball machines": 0.48186982985205634,
                "dolphins": 0.3433252987495229
            },
            "question": "which of these do not have flippers?",
            "rate_limited": false,
            "answers": [
                "new yorkers",
                "dolphins",
                "pinball machines"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "new yorkers": 0.6533498851475958,
                "pinball machines": 0.2848915232207105,
                "dolphins": 0.49974354694952916
            },
            "negative_question": true,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    450000.0,
                    372000.0,
                    209000.0
                ],
                "wikipedia_search": [
                    0.0,
                    0.2,
                    0.8
                ],
                "answer_relation_to_question": [
                    0.0,
                    0.0,
                    1.0
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    1.0
                ],
                "result_count_noun_chunks": [
                    450000.0,
                    372000.0,
                    209000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    4.0
                ],
                "word_count_raw": [
                    0.0,
                    17.0,
                    0.0
                ],
                "result_count": [
                    5220000.0,
                    3580000.0,
                    107000.0
                ],
                "word_count_appended": [
                    89.0,
                    597.0,
                    93.0
                ]
            },
            "integer_answers": {
                "new yorkers": 3,
                "pinball machines": 4,
                "dolphins": 2
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "In \u201cPeanuts,\u201d what breed of dog is Snoopy?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "beagle"
            ],
            "lines": [
                [
                    0.3050439538611492,
                    0.0,
                    0.11173385374796062,
                    0.15699658703071673,
                    2.7422717361705004e-05,
                    0.5347605109704354,
                    0.08881199538638986,
                    0.0,
                    0.0,
                    1.0
                ],
                [
                    0.09275196287211422,
                    0.0,
                    7.669866231851534e-05,
                    0.2912400455062571,
                    0.7078887504998268,
                    0.007907335556916934,
                    0.19492502883506344,
                    0.0,
                    0.0,
                    1.0
                ],
                [
                    0.6022040832667366,
                    1.0,
                    0.8881894475897208,
                    0.5517633674630261,
                    0.2920838267828114,
                    0.45733215347264766,
                    0.7162629757785467,
                    1.0,
                    1.0,
                    1.0
                ]
            ],
            "fraction_answers": {
                "beagle": 0.7230928727059431,
                "border collie": 0.13304159152377928,
                "pitbull": 0.14386553577027747
            },
            "question": "in \u201cpeanuts,\u201d what breed of dog is snoopy?",
            "rate_limited": false,
            "answers": [
                "border collie",
                "pitbull",
                "beagle"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "beagle": 0.8567984544501706,
                "border collie": 0.12925871235938477,
                "pitbull": 0.08896451419206808
            },
            "integer_answers": {
                "beagle": 7,
                "border collie": 1,
                "pitbull": 1
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    138000.0,
                    256000.0,
                    485000.0
                ],
                "wikipedia_search": [
                    1.0695210219408708,
                    0.01581467111383387,
                    0.9146643069452953
                ],
                "answer_relation_to_question": [
                    0.9151318615834476,
                    0.27825588861634265,
                    1.8066122498002097
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    2.0
                ],
                "result_count_noun_chunks": [
                    43.0,
                    1110000.0,
                    458000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    2.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    116.0
                ],
                "result_count": [
                    118000.0,
                    81.0,
                    938000.0
                ],
                "word_count_appended": [
                    77.0,
                    169.0,
                    621.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which of the following is a dice-based game?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "farkle"
            ],
            "lines": [
                [
                    0.41354861225914297,
                    0.0,
                    0.05499016505601642,
                    0.006601353140436255,
                    0.059520503563824864,
                    0.0,
                    0.16898954703832753,
                    0.0,
                    0.0,
                    -1.0
                ],
                [
                    0.013941698352344739,
                    0.0,
                    0.603780039339776,
                    0.6327438072368361,
                    0.5711376469499213,
                    0.0,
                    0.27264808362369336,
                    0.0,
                    0.0,
                    -1.0
                ],
                [
                    0.5725096893885123,
                    1.0,
                    0.34122979560420763,
                    0.36065483962272765,
                    0.3693418494862538,
                    1.0,
                    0.5583623693379791,
                    1.0,
                    1.0,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "sparkle": 0.2326945861669524,
                "quirkle": 0.0781833534508609,
                "farkle": 0.6891220603821868
            },
            "question": "which of the following is a dice-based game?",
            "rate_limited": false,
            "answers": [
                "quirkle",
                "sparkle",
                "farkle"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "sparkle": 0.22124162286194937,
                "quirkle": 0.1877328256285103,
                "farkle": 0.8458093115450728
            },
            "integer_answers": {
                "sparkle": 3,
                "quirkle": 0,
                "farkle": 6
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    7230.0,
                    693000.0,
                    395000.0
                ],
                "wikipedia_search": [
                    0.0,
                    0.0,
                    4.0
                ],
                "answer_relation_to_question": [
                    1.240645836777429,
                    0.04182509505703422,
                    1.717529068165537
                ],
                "question_related_to_answer": [
                    0.0,
                    0.0,
                    1.0
                ],
                "result_count_noun_chunks": [
                    64300.0,
                    617000.0,
                    399000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    0.0,
                    7.0
                ],
                "word_count_raw": [
                    0.0,
                    0.0,
                    5.0
                ],
                "word_count_appended": [
                    194.0,
                    313.0,
                    641.0
                ],
                "result_count": [
                    64300.0,
                    706000.0,
                    399000.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "What was the first popular home video game?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "pong"
            ],
            "lines": [
                [
                    0.3693027521819075,
                    0.0,
                    0.02130492676431425,
                    0.012828298163048429,
                    0.02470687674736135,
                    0.09539914521327161,
                    0.16208393632416787,
                    0.0,
                    0.0,
                    1.0
                ],
                [
                    0.40573655245943097,
                    1.0,
                    0.9454061251664447,
                    0.9716107484439047,
                    0.9557660215426627,
                    0.7075650244795225,
                    0.7004341534008683,
                    1.0,
                    1.0,
                    1.0
                ],
                [
                    0.22496069535866153,
                    0.0,
                    0.033288948069241014,
                    0.01556095339304691,
                    0.019527101709975944,
                    0.19703583030720578,
                    0.13748191027496381,
                    0.0,
                    0.0,
                    1.0
                ]
            ],
            "fraction_answers": {
                "tekken 2": 0.0761806594882301,
                "pong": 0.8540576250547594,
                "half-life 3": 0.06976171545701056
            },
            "question": "what was the first popular home video game?",
            "rate_limited": false,
            "answers": [
                "tekken 2",
                "pong",
                "half-life 3"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "tekken 2": 0.0892106141568407,
                "pong": 0.8619448566740576,
                "half-life 3": 0.15485414438730802
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    169000.0,
                    12800000.0,
                    205000.0
                ],
                "wikipedia_search": [
                    0.38159658085308645,
                    2.83026009791809,
                    0.7881433212288231
                ],
                "answer_relation_to_question": [
                    1.47721100872763,
                    1.6229462098377239,
                    0.8998427814346461
                ],
                "question_related_to_answer": [
                    0.0,
                    1.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    114000.0,
                    4410000.0,
                    90100.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    24.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    25.0,
                    0.0
                ],
                "word_count_appended": [
                    112.0,
                    484.0,
                    95.0
                ],
                "result_count": [
                    96000.0,
                    4260000.0,
                    150000.0
                ]
            },
            "integer_answers": {
                "tekken 2": 0,
                "pong": 9,
                "half-life 3": 0
            }
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Featuring 20 scoops of ice cream, the Vermonster is found on what chain's menu?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "ben & jerry's"
            ],
            "lines": [
                [
                    0.6502833438173448,
                    0.25,
                    0.020579588408231837,
                    0.04535398230088496,
                    0.04403409090909091,
                    0.15921843066037847,
                    0.7244897959183674,
                    0.021739130434782608,
                    0.046511627906976744,
                    1.0
                ],
                [
                    0.22171059586568076,
                    0.03571428571428571,
                    0.01763964720705586,
                    0.04314159292035398,
                    0.03977272727272727,
                    0.36529698691253404,
                    0.2755102040816326,
                    0.021739130434782608,
                    0.023255813953488372,
                    1.0
                ],
                [
                    0.12800606031697453,
                    0.7142857142857143,
                    0.9617807643847123,
                    0.911504424778761,
                    0.9161931818181818,
                    0.47548458242708747,
                    0.0,
                    0.9565217391304348,
                    0.9302325581395349,
                    1.0
                ]
            ],
            "fraction_answers": {
                "ben & jerry's": 0.6660010028090446,
                "dairy queen": 0.11597566492917125,
                "baskin-robbins": 0.21802333226178422
            },
            "question": "featuring 20 scoops of ice cream, the vermonster is found on what chain's menu?",
            "rate_limited": false,
            "answers": [
                "baskin-robbins",
                "dairy queen",
                "ben & jerry's"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "ben & jerry's": 0.6840696234786783,
                "dairy queen": 0.1265395468004419,
                "baskin-robbins": 0.4884161721822697
            },
            "integer_answers": {
                "ben & jerry's": 7,
                "dairy queen": 0,
                "baskin-robbins": 2
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    41.0,
                    39.0,
                    824.0
                ],
                "wikipedia_search": [
                    1.2737474452830277,
                    2.9223758953002723,
                    3.8038766594166997
                ],
                "answer_relation_to_question": [
                    5.202266750538758,
                    1.773684766925446,
                    1.0240484825357963
                ],
                "question_related_to_answer": [
                    1.0,
                    0.14285714285714285,
                    2.857142857142857
                ],
                "result_count_noun_chunks": [
                    62.0,
                    56.0,
                    1290.0
                ],
                "word_count_noun_chunks": [
                    1.0,
                    1.0,
                    44.0
                ],
                "word_count_raw": [
                    2.0,
                    1.0,
                    40.0
                ],
                "word_count_appended": [
                    71.0,
                    27.0,
                    0.0
                ],
                "result_count": [
                    49.0,
                    42.0,
                    2290.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Who is NOT considered an official member of the Eagles?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "j.d. souther"
            ],
            "lines": [
                [
                    0.3611861976192289,
                    0.5,
                    0.4996834100329645,
                    0.38741721854304634,
                    0.38706140350877194,
                    0.33333333333333337,
                    0.4329608938547486,
                    0.5,
                    0.5,
                    0.0
                ],
                [
                    0.32073942232036345,
                    0.25,
                    0.49968014621887136,
                    0.2814569536423841,
                    0.2817982456140351,
                    0.2691658223573117,
                    0.26256983240223464,
                    0.25,
                    0.25,
                    0.0
                ],
                [
                    0.3180743800604076,
                    0.25,
                    0.0006364437481641283,
                    0.33112582781456956,
                    0.33114035087719296,
                    0.39750084430935495,
                    0.3044692737430168,
                    0.25,
                    0.25,
                    0.0
                ]
            ],
            "fraction_answers": {
                "j.d. souther": 0.13296834291286808,
                "randy meisner": 0.40768657276551107,
                "bernie leadon": 0.45934508432162097
            },
            "question": "who is not considered an official member of the eagles?",
            "rate_limited": false,
            "answers": [
                "j.d. souther",
                "randy meisner",
                "bernie leadon"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "j.d. souther": 0.5192436466317687,
                "randy meisner": 0.16698220725353222,
                "bernie leadon": 0.11031531982375467
            },
            "integer_answers": {
                "j.d. souther": 0,
                "randy meisner": 7,
                "bernie leadon": 2
            },
            "categorical_data": {
                "question_type": 0
            },
            "data": {
                "result_count_important_words": [
                    102000.0,
                    198000.0,
                    153000.0
                ],
                "wikipedia_search": [
                    1.0,
                    1.3850050658561297,
                    0.6149949341438703
                ],
                "answer_relation_to_question": [
                    1.1105104190461688,
                    1.4340846214370924,
                    1.455404959516739
                ],
                "question_related_to_answer": [
                    0.0,
                    0.5,
                    0.5
                ],
                "result_count_noun_chunks": [
                    103000.0,
                    199000.0,
                    154000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    1.0,
                    1.0
                ],
                "word_count_raw": [
                    0.0,
                    1.0,
                    1.0
                ],
                "word_count_appended": [
                    48.0,
                    170.0,
                    140.0
                ],
                "result_count": [
                    97.0,
                    98.0,
                    153000.0
                ]
            },
            "negative_question": true
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "The U.S. has never had a Miss America from what state?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "new mexico"
            ],
            "lines": [
                [
                    0.34002488942044606,
                    0.25,
                    0.28268710550045084,
                    0.2517973296816159,
                    0.3597285067873303,
                    0.318804923840329,
                    0.43803418803418803,
                    0.5,
                    0.5,
                    1.0
                ],
                [
                    0.33166248605894877,
                    0.4166666666666667,
                    0.36834986474301173,
                    0.3005819924683327,
                    0.3156108597285068,
                    0.2949478392633389,
                    0.3696581196581197,
                    0.0,
                    0.0,
                    1.0
                ],
                [
                    0.32831262452060517,
                    0.33333333333333337,
                    0.3489630297565374,
                    0.44762067785005133,
                    0.3246606334841629,
                    0.3862472368963321,
                    0.1923076923076923,
                    0.5,
                    0.5,
                    1.0
                ]
            ],
            "fraction_answers": {
                "nebraska": 0.2530121715225079,
                "new mexico": 0.2797606792745866,
                "north dakota": 0.46722714920290553
            },
            "question": "the u.s. has never had a miss america from what state?",
            "rate_limited": false,
            "answers": [
                "new mexico",
                "north dakota",
                "nebraska"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "nebraska": 0.32741304810447325,
                "new mexico": 0.4970644724751062,
                "north dakota": 0.328920025822875
            },
            "negative_question": true,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "result_count_important_words": [
                    2900000.0,
                    2330000.0,
                    612000.0
                ],
                "wikipedia_search": [
                    1.0871704569580258,
                    1.2303129644199668,
                    0.6825165786220073
                ],
                "answer_relation_to_question": [
                    1.2798008846364315,
                    1.3467001115284096,
                    1.3734990038351587
                ],
                "question_related_to_answer": [
                    0.5,
                    0.16666666666666666,
                    0.3333333333333333
                ],
                "result_count_noun_chunks": [
                    1240000.0,
                    1630000.0,
                    1550000.0
                ],
                "word_count_noun_chunks": [
                    0.0,
                    37.0,
                    0.0
                ],
                "word_count_raw": [
                    0.0,
                    21.0,
                    0.0
                ],
                "word_count_appended": [
                    87.0,
                    183.0,
                    432.0
                ],
                "result_count": [
                    4820000.0,
                    2920000.0,
                    3350000.0
                ]
            },
            "integer_answers": {
                "nebraska": 2,
                "new mexico": 3,
                "north dakota": 4
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which of these do adverbs NOT typically modify?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "pronoun"
            ],
            "lines": [
                [
                    0.4968553459119497,
                    0.4985687022900763,
                    0.31931193986701356,
                    0.3651685393258427,
                    0.3116703539823009,
                    0.5,
                    0.4203675344563553,
                    0.4985687022900763,
                    0.4958791208791209,
                    -1.0
                ],
                [
                    0.15904335868460234,
                    0.041030534351145065,
                    0.32220294882914136,
                    0.37991573033707865,
                    0.3708517699115044,
                    0.1739750445632799,
                    0.21311893823379274,
                    0.041030534351145065,
                    0.10256410256410259,
                    -1.0
                ],
                [
                    0.3441012954034479,
                    0.4604007633587786,
                    0.3584851113038451,
                    0.25491573033707865,
                    0.3174778761061947,
                    0.32602495543672017,
                    0.366513527309852,
                    0.4604007633587786,
                    0.4015567765567766,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "adjective": 0.26891626685078396,
                "adverb": 0.5991704529276017,
                "pronoun": 0.13191328022161428
            },
            "question": "which of these do adverbs not typically modify?",
            "rate_limited": false,
            "answers": [
                "pronoun",
                "adverb",
                "adjective"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "question_related_to_answer",
                "result_count",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_noun_chunks",
                "word_count_raw",
                "question_type"
            ],
            "ml_answers": {
                "adjective": 0.43117409569123727,
                "adverb": 0.08347318077536826,
                "pronoun": 0.7224792891827513
            },
            "negative_question": true,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "result_count_important_words": [
                    192000.0,
                    171000.0,
                    349000.0
                ],
                "wikipedia_search": [
                    0.0,
                    1.9561497326203208,
                    1.0438502673796792
                ],
                "answer_relation_to_question": [
                    0.018867924528301886,
                    2.045739847892386,
                    0.9353922275793123
                ],
                "question_related_to_answer": [
                    0.0028625954198473282,
                    0.9179389312977099,
                    0.07919847328244274
                ],
                "result_count_noun_chunks": [
                    681000.0,
                    467000.0,
                    660000.0
                ],
                "word_count_noun_chunks": [
                    3.0,
                    962.0,
                    83.0
                ],
                "word_count_raw": [
                    9.0,
                    868.0,
                    215.0
                ],
                "word_count_appended": [
                    312.0,
                    1124.0,
                    523.0
                ],
                "result_count": [
                    1250000.0,
                    1230000.0,
                    979000.0
                ]
            },
            "integer_answers": {
                "adjective": 1,
                "adverb": 6,
                "pronoun": 2
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    }
}