{
    "Which of these versions of the Old Testament typically contains the most books?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "protestant"
            ],
            "lines": [
                [
                    0.18005880780539962,
                    0.1931478715459298,
                    0.2728832663744709,
                    0.08667260314633422,
                    0.33550065019505854,
                    0.47988668555240793,
                    0.21949128322377823,
                    0.28238038277511956,
                    0.5529411764705883,
                    0.3341588362189339,
                    -1.0
                ],
                [
                    0.3904570970328789,
                    0.4334391336818521,
                    0.14621734367712147,
                    0.09409320273078065,
                    0.33550065019505854,
                    0.44645892351274785,
                    0.5887396398971134,
                    0.2269554568238779,
                    0.39294117647058824,
                    0.3415662419947296,
                    -1.0
                ],
                [
                    0.4294840951617215,
                    0.3734129947722181,
                    0.5808993899484076,
                    0.8192341941228851,
                    0.328998699609883,
                    0.07365439093484419,
                    0.19176907687910832,
                    0.4906641604010026,
                    0.05411764705882353,
                    0.3242749217863365,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "catholic": 0.29371215633080205,
                "protestant": 0.3396368866016749,
                "eastern orthodox": 0.36665095706752304
            },
            "question": "which of these versions of the old testament typically contains the most books?",
            "rate_limited": false,
            "answers": [
                "catholic",
                "protestant",
                "eastern orthodox"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "catholic": 0.36915778311386327,
                "protestant": 0.6440242520249059,
                "eastern orthodox": 0.2897039310347773
            },
            "integer_answers": {
                "catholic": 3,
                "protestant": 3,
                "eastern orthodox": 4
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    2.0049530173136034,
                    2.0493974519683777,
                    1.9456495307180188
                ],
                "result_count_important_words": [
                    847000.0,
                    788000.0,
                    130000.0
                ],
                "wikipedia_search": [
                    1.411901913875598,
                    1.1347772841193895,
                    2.453320802005013
                ],
                "answer_relation_to_question": [
                    0.9002940390269981,
                    1.9522854851643945,
                    2.1474204758086075
                ],
                "answer_relation_to_question_bing": [
                    0.7725914861837192,
                    1.7337565347274084,
                    1.4936519790888725
                ],
                "result_count_noun_chunks": [
                    768000.0,
                    2060000.0,
                    671000.0
                ],
                "question_answer_similarity": [
                    2.474046828225255,
                    1.3256531269289553,
                    5.266619358211756
                ],
                "result_count_bing": [
                    258000.0,
                    258000.0,
                    253000.0
                ],
                "word_count_appended": [
                    470.0,
                    334.0,
                    46.0
                ],
                "result_count": [
                    584000.0,
                    634000.0,
                    5520000.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "The material that forms images in an Etch A Sketch is also the main component in which item?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "soda cans"
            ],
            "lines": [
                [
                    0.3421740615706133,
                    0.3008960573476702,
                    0.4638491537378296,
                    0.0,
                    0.07147235503248743,
                    0.0,
                    0.0,
                    0.6167328042328043,
                    0.17391304347826086,
                    0.2315544849295401,
                    -1.0
                ],
                [
                    0.49062273932963585,
                    0.257078853046595,
                    0.28927240464062043,
                    0.3,
                    0.04462424911119284,
                    0.4270833333333333,
                    0.4782608695652174,
                    0.024305555555555552,
                    0.13043478260869565,
                    0.29227983288204884,
                    -1.0
                ],
                [
                    0.16720319909975082,
                    0.4420250896057347,
                    0.24687844162154998,
                    0.7,
                    0.8839033958563197,
                    0.5729166666666666,
                    0.5217391304347826,
                    0.3589616402116402,
                    0.6956521739130435,
                    0.47616568218841104,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "zinc supplement tablets": 0.22005919603292057,
                "soda cans": 0.5065445419597899,
                "u.s. nickels": 0.27339626200728945
            },
            "question": "the material that forms images in an etch a sketch is also the main component in which item?",
            "rate_limited": false,
            "answers": [
                "zinc supplement tablets",
                "u.s. nickels",
                "soda cans"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "zinc supplement tablets": 0.15486741064430554,
                "soda cans": 0.4423943016404533,
                "u.s. nickels": 0.18137095957725358
            },
            "integer_answers": {
                "zinc supplement tablets": 2,
                "soda cans": 7,
                "u.s. nickels": 1
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.8524358794363207,
                    2.3382386630563907,
                    3.8093254575072883
                ],
                "result_count_important_words": [
                    0,
                    41.0,
                    55.0
                ],
                "wikipedia_search": [
                    3.7003968253968256,
                    0.14583333333333331,
                    2.153769841269841
                ],
                "answer_relation_to_question": [
                    2.05304436942368,
                    2.943736435977815,
                    1.003219194598505
                ],
                "answer_relation_to_question_bing": [
                    1.8053763440860213,
                    1.54247311827957,
                    2.6521505376344083
                ],
                "result_count_noun_chunks": [
                    0,
                    22.0,
                    24.0
                ],
                "question_answer_similarity": [
                    10.300920786336064,
                    6.42401112918742,
                    5.4825480449944735
                ],
                "result_count_bing": [
                    5830.0,
                    3640.0,
                    72100.0
                ],
                "result_count": [
                    0,
                    15.0,
                    35.0
                ],
                "word_count_appended": [
                    4.0,
                    3.0,
                    16.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Who was NOT a wife of Henry VIII?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "catherine of york"
            ],
            "lines": [
                [
                    0.2989270139200797,
                    0.27205743879472694,
                    0.45652423034116846,
                    0.25352167605260284,
                    0.4913396960056557,
                    0.2323067509687946,
                    0.23706645844454893,
                    0.4230769230769231,
                    0.2660891089108911,
                    0.2775714820737455,
                    0.0
                ],
                [
                    0.36806436559405264,
                    0.43735875706214694,
                    0.18501086754974566,
                    0.49997660015911893,
                    0.016908212560386493,
                    0.49997733813764816,
                    0.49997211310922895,
                    0.3205128205128205,
                    0.46905940594059403,
                    0.44900878291244395,
                    0.0
                ],
                [
                    0.33300862048586766,
                    0.2905838041431262,
                    0.3584649021090859,
                    0.24650172378827823,
                    0.4917520914339578,
                    0.26771591089355723,
                    0.2629614284462221,
                    0.2564102564102564,
                    0.26485148514851486,
                    0.27341973501381056,
                    0.0
                ]
            ],
            "fraction_answers": {
                "catherine of york": 0.25083014729236275,
                "catherine parr": 0.3583038442821726,
                "catherine howard": 0.39086600842546465
            },
            "question": "who was not a wife of henry viii?",
            "rate_limited": false,
            "answers": [
                "catherine parr",
                "catherine of york",
                "catherine howard"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "catherine of york": 0.4021363405713253,
                "catherine parr": 0.3146435910416931,
                "catherine howard": 0.17771695961739858
            },
            "negative_question": true,
            "categorical_data": {
                "question_type": 0
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.334571107557527,
                    0.3059473025253362,
                    1.359481589917137
                ],
                "result_count_important_words": [
                    378000.0,
                    32.0,
                    328000.0
                ],
                "wikipedia_search": [
                    0.46153846153846156,
                    1.0769230769230769,
                    1.4615384615384617
                ],
                "answer_relation_to_question": [
                    1.2064379164795218,
                    0.7916138064356839,
                    1.0019482770847943
                ],
                "answer_relation_to_question_bing": [
                    1.3676553672316385,
                    0.3758474576271187,
                    1.256497175141243
                ],
                "result_count_noun_chunks": [
                    396000.0,
                    42.0,
                    357000.0
                ],
                "question_answer_similarity": [
                    0.8619754314422607,
                    6.24515438079834,
                    2.8061556592583656
                ],
                "result_count_bing": [
                    1470000.0,
                    82000000.0,
                    1400000.0
                ],
                "result_count": [
                    316000.0,
                    30.0,
                    325000.0
                ],
                "word_count_appended": [
                    189.0,
                    25.0,
                    190.0
                ]
            },
            "integer_answers": {
                "catherine of york": 2,
                "catherine parr": 4,
                "catherine howard": 4
            }
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "How many U.S. state names are only four letters long?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "50 states"
            ],
            "lines": [
                [
                    0.5304367841943793,
                    0.14833333333333334,
                    0.3242400805892452,
                    0.00034273687462588583,
                    0.23882088433674745,
                    0.25660377358490566,
                    0.10737597911227154,
                    0.3599468488990129,
                    0.1968503937007874,
                    0.28619896203263484,
                    5.0
                ],
                [
                    0.32484177159584904,
                    0.4605555555555556,
                    0.3526356132102328,
                    0.0004103187935662013,
                    0.24906320259805145,
                    0.37358490566037733,
                    0.8191906005221932,
                    0.5162743609212858,
                    0.5748031496062992,
                    0.3684507207255595,
                    5.0
                ],
                [
                    0.14472144420977168,
                    0.39111111111111113,
                    0.323124306200522,
                    0.9992469443318079,
                    0.5121159130652011,
                    0.36981132075471695,
                    0.07343342036553525,
                    0.12377879017970134,
                    0.2283464566929134,
                    0.3453503172418057,
                    5.0
                ]
            ],
            "fraction_answers": {
                "12 states": 0.24491497766579431,
                "50 states": 0.403981019918897,
                "3 states": 0.35110400241530865
            },
            "question": "how many u.s. state names are only four letters long?",
            "rate_limited": false,
            "answers": [
                "12 states",
                "50 states",
                "3 states"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "12 states": 0.549456060231098,
                "50 states": 0.7068710851565735,
                "3 states": 0.2087733938601499
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 5
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.4309948101631742,
                    1.8422536036277974,
                    1.7267515862090286
                ],
                "result_count_important_words": [
                    68.0,
                    99.0,
                    98.0
                ],
                "wikipedia_search": [
                    1.0798405466970387,
                    1.5488230827638572,
                    0.371336370539104
                ],
                "answer_relation_to_question": [
                    2.1217471367775174,
                    1.2993670863833962,
                    0.5788857768390867
                ],
                "answer_relation_to_question_bing": [
                    0.5933333333333333,
                    1.8422222222222222,
                    1.5644444444444443
                ],
                "result_count_noun_chunks": [
                    329000.0,
                    2510000.0,
                    225000.0
                ],
                "question_answer_similarity": [
                    6.924035631120205,
                    7.53041248396039,
                    6.900208652019501
                ],
                "result_count_bing": [
                    95600000.0,
                    99700000.0,
                    205000000.0
                ],
                "result_count": [
                    71.0,
                    85.0,
                    207000.0
                ],
                "word_count_appended": [
                    25.0,
                    73.0,
                    29.0
                ]
            },
            "integer_answers": {
                "12 states": 1,
                "50 states": 7,
                "3 states": 2
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "What play has the stage direction, \u201cEnter a Messenger, with two heads and a hand\u201d?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "titus andronicus"
            ],
            "lines": [
                [
                    0.2829295460874408,
                    0.3716644672440926,
                    0.11433539847364375,
                    0.03125,
                    0.09382831167317443,
                    0.008324449384172206,
                    0.17553746608223753,
                    0.22264552781439853,
                    0.038461538461538464,
                    0.12131473609376689,
                    1.0
                ],
                [
                    0.5482768110002469,
                    0.2587504491778497,
                    0.5014528563136913,
                    0.796875,
                    0.05530625327816306,
                    0.06283031279061856,
                    0.40701314965560426,
                    0.7545288609212119,
                    0.5769230769230769,
                    0.6624209721505862,
                    1.0
                ],
                [
                    0.16879364291231222,
                    0.36958508357805786,
                    0.38421174521266493,
                    0.171875,
                    0.8508654350486625,
                    0.9288452378252092,
                    0.4174493842621582,
                    0.022825611264389683,
                    0.38461538461538464,
                    0.21626429175564701,
                    1.0
                ]
            ],
            "fraction_answers": {
                "oedipus rex": 0.1460291441314465,
                "agamemnon": 0.3915330816474486,
                "titus andronicus": 0.4624377742211049
            },
            "question": "what play has the stage direction, \u201center a messenger, with two heads and a hand\u201d?",
            "rate_limited": false,
            "answers": [
                "oedipus rex",
                "titus andronicus",
                "agamemnon"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "oedipus rex": 0.1688642384833969,
                "agamemnon": 0.317921621101151,
                "titus andronicus": 0.4089370733011643
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    0.8492031526563681,
                    4.6369468050541025,
                    1.513850042289529
                ],
                "result_count_important_words": [
                    7340.0,
                    55400.0,
                    819000.0
                ],
                "wikipedia_search": [
                    1.5585186947007896,
                    5.281702026448483,
                    0.1597792788507278
                ],
                "answer_relation_to_question": [
                    1.9805068226120857,
                    3.8379376770017286,
                    1.1815555003861855
                ],
                "answer_relation_to_question_bing": [
                    2.2299868034645556,
                    1.552502695067098,
                    2.217510501468347
                ],
                "result_count_noun_chunks": [
                    841.0,
                    1950.0,
                    2000.0
                ],
                "question_answer_similarity": [
                    -1.0870871188817546,
                    -4.767753015272319,
                    -3.6530387327075005
                ],
                "result_count_bing": [
                    161000.0,
                    94900.0,
                    1460000.0
                ],
                "result_count": [
                    2.0,
                    51.0,
                    11.0
                ],
                "word_count_appended": [
                    3.0,
                    45.0,
                    30.0
                ]
            },
            "integer_answers": {
                "oedipus rex": 2,
                "agamemnon": 3,
                "titus andronicus": 5
            }
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Wrestling legend Ric Flair entered the ring to the same music used in what classic film?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "star wars: episode iv"
            ],
            "lines": [
                [
                    0.1550579906005203,
                    0.23829878674130053,
                    0.2685614919917738,
                    0.6380312179560215,
                    0.0407386255473063,
                    0.6355615373112008,
                    0.33886489940553416,
                    0.732760827637417,
                    0.19298245614035087,
                    0.28318497630118045,
                    1.0
                ],
                [
                    0.47417638714938104,
                    0.322701954460143,
                    0.2846153253030925,
                    0.3596521210740192,
                    0.01503902531886541,
                    0.36189621653955434,
                    0.6603024611273551,
                    0.0445646010268299,
                    0.543859649122807,
                    0.42640342850771945,
                    1.0
                ],
                [
                    0.3707656222500987,
                    0.4389992587985565,
                    0.44682318270513366,
                    0.0023166609699593636,
                    0.9442223491338283,
                    0.0025422461492448033,
                    0.0008326394671107411,
                    0.22267457133575316,
                    0.2631578947368421,
                    0.2904115951911002,
                    1.0
                ]
            ],
            "fraction_answers": {
                "star wars: episode iv": 0.35240428096326065,
                "back to the future": 0.2982746020737627,
                "2001: a space odyssey": 0.3493211169629767
            },
            "question": "wrestling legend ric flair entered the ring to the same music used in what classic film?",
            "rate_limited": false,
            "answers": [
                "star wars: episode iv",
                "2001: a space odyssey",
                "back to the future"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "star wars: episode iv": 0.48180671300584743,
                "back to the future": 0.32471375454250334,
                "2001: a space odyssey": 0.2715643879364109
            },
            "integer_answers": {
                "star wars: episode iv": 3,
                "back to the future": 3,
                "2001: a space odyssey": 4
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    2.548664786710624,
                    3.8376308565694752,
                    2.613704356719902
                ],
                "result_count_important_words": [
                    17000.0,
                    9680.0,
                    68.0
                ],
                "wikipedia_search": [
                    5.129325793461918,
                    0.31195220718780925,
                    1.5587219993502717
                ],
                "answer_relation_to_question": [
                    1.0854059342036422,
                    3.3192347100456674,
                    2.595359355750691
                ],
                "answer_relation_to_question_bing": [
                    0.9531951469652021,
                    1.290807817840572,
                    1.755997035194226
                ],
                "result_count_noun_chunks": [
                    17500.0,
                    34100.0,
                    43.0
                ],
                "question_answer_similarity": [
                    15.269633424468338,
                    16.18240817822516,
                    25.405080061405897
                ],
                "result_count_bing": [
                    1070.0,
                    395.0,
                    24800.0
                ],
                "result_count": [
                    16800.0,
                    9470.0,
                    61.0
                ],
                "word_count_appended": [
                    11.0,
                    31.0,
                    15.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "The man famously known as the Science Guy holds a patent for which of these items?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "mechanical pencil"
            ],
            "lines": [
                [
                    0.3605907980907981,
                    0.1915954415954416,
                    0.42282793452805056,
                    0.0059381285317498325,
                    0.3389261744966443,
                    0.01233026377399719,
                    0.002073570273296562,
                    0.23888888888888887,
                    0.2,
                    0.21629646129654392,
                    -1.0
                ],
                [
                    0.2635836385836386,
                    0.5249287749287749,
                    0.2974400935604148,
                    0.9864955464036012,
                    0.32046979865771813,
                    0.9739347588574996,
                    0.9953137311823498,
                    0.711111111111111,
                    0.5714285714285714,
                    0.4688304004447194,
                    -1.0
                ],
                [
                    0.3758255633255633,
                    0.2834757834757835,
                    0.27973197191153465,
                    0.00756632506464898,
                    0.34060402684563756,
                    0.013734977368503199,
                    0.002612698544353668,
                    0.05,
                    0.22857142857142856,
                    0.3148731382587367,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "pulse rate monitor": 0.1989467661475411,
                "mechanical pencil": 0.6113536425158399,
                "ballet shoe": 0.189699591336619
            },
            "question": "the man famously known as the science guy holds a patent for which of these items?",
            "rate_limited": false,
            "answers": [
                "pulse rate monitor",
                "mechanical pencil",
                "ballet shoe"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "pulse rate monitor": 0.17340191756159953,
                "mechanical pencil": 0.6978368670522547,
                "ballet shoe": 0.2416961322931678
            },
            "integer_answers": {
                "pulse rate monitor": 1,
                "mechanical pencil": 7,
                "ballet shoe": 2
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.7303716903723514,
                    3.7506432035577553,
                    2.5189851060698936
                ],
                "result_count_important_words": [
                    79.0,
                    6240.0,
                    88.0
                ],
                "wikipedia_search": [
                    1.1944444444444444,
                    3.5555555555555554,
                    0.25
                ],
                "answer_relation_to_question": [
                    2.1635447885447885,
                    1.5815018315018317,
                    2.25495337995338
                ],
                "answer_relation_to_question_bing": [
                    0.5747863247863247,
                    1.5747863247863247,
                    0.8504273504273505
                ],
                "result_count_noun_chunks": [
                    50.0,
                    24000.0,
                    63.0
                ],
                "question_answer_similarity": [
                    9.788729492109269,
                    6.885923039168119,
                    6.475969016551971
                ],
                "result_count_bing": [
                    202000.0,
                    191000.0,
                    203000.0
                ],
                "result_count": [
                    62.0,
                    10300.0,
                    79.0
                ],
                "word_count_appended": [
                    14.0,
                    40.0,
                    16.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "What advertising mascot wears epaulettes?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "cap'n crunch"
            ],
            "lines": [
                [
                    0.19892473118279572,
                    0.21428571428571427,
                    0.5168333507362561,
                    0.08823529411764706,
                    0.042958129418162044,
                    0.08490566037735849,
                    0.08256880733944955,
                    0.08333333333333333,
                    0.1411764705882353,
                    0.18144443708499428,
                    1.0
                ],
                [
                    0.4129032258064516,
                    0.7142857142857143,
                    0.3766530791713206,
                    0.5686274509803921,
                    0.7069059271343121,
                    0.5660377358490566,
                    0.6238532110091743,
                    0.21794871794871795,
                    0.3411764705882353,
                    0.4263865616000807,
                    1.0
                ],
                [
                    0.3881720430107527,
                    0.07142857142857142,
                    0.10651357009242324,
                    0.3431372549019608,
                    0.2501359434475258,
                    0.3490566037735849,
                    0.29357798165137616,
                    0.6987179487179488,
                    0.5176470588235295,
                    0.39216900131492505,
                    1.0
                ]
            ],
            "fraction_answers": {
                "sun-maid raisin girl": 0.1634665928463946,
                "mr. peanut": 0.4954778094373456,
                "cap'n crunch": 0.3410555977162598
            },
            "question": "what advertising mascot wears epaulettes?",
            "rate_limited": false,
            "answers": [
                "sun-maid raisin girl",
                "mr. peanut",
                "cap'n crunch"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "sun-maid raisin girl": 0.17492663854886034,
                "mr. peanut": 0.2998502181204233,
                "cap'n crunch": 0.5119758329504096
            },
            "integer_answers": {
                "sun-maid raisin girl": 1,
                "mr. peanut": 7,
                "cap'n crunch": 2
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    0.7257777483399771,
                    1.7055462464003228,
                    1.5686760052597002
                ],
                "result_count_important_words": [
                    9.0,
                    60.0,
                    37.0
                ],
                "wikipedia_search": [
                    0.25,
                    0.6538461538461539,
                    2.0961538461538463
                ],
                "answer_relation_to_question": [
                    0.5967741935483871,
                    1.238709677419355,
                    1.164516129032258
                ],
                "answer_relation_to_question_bing": [
                    0.42857142857142855,
                    1.4285714285714286,
                    0.14285714285714285
                ],
                "result_count_noun_chunks": [
                    9.0,
                    68.0,
                    32.0
                ],
                "question_answer_similarity": [
                    3.976561378221959,
                    2.898002006812021,
                    0.8195248013362288
                ],
                "result_count_bing": [
                    31600.0,
                    520000.0,
                    184000.0
                ],
                "result_count": [
                    9.0,
                    58.0,
                    35.0
                ],
                "word_count_appended": [
                    12.0,
                    29.0,
                    44.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which alum from \u201cThe Hills\u201d founded a wildly popular millennial skincare line?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "lauren conrad"
            ],
            "lines": [
                [
                    0.4062462613879946,
                    0.5664217071791973,
                    -0.04123031383057541,
                    0.1791044776119403,
                    0.8923742563547864,
                    0.17692307692307693,
                    0.2748091603053435,
                    0.3956185567010309,
                    0.2857142857142857,
                    0.31369365159294055,
                    -1.0
                ],
                [
                    0.3426343434661755,
                    0.20824921263021884,
                    0.2483397479870632,
                    0.582089552238806,
                    0.09889515568260836,
                    0.5076923076923077,
                    0.35877862595419846,
                    0.514555517998986,
                    0.4857142857142857,
                    0.40778043527616503,
                    -1.0
                ],
                [
                    0.2511193951458299,
                    0.22532908019058387,
                    0.7928905658435123,
                    0.23880597014925373,
                    0.00873058796260527,
                    0.3153846153846154,
                    0.366412213740458,
                    0.0898259252999831,
                    0.22857142857142856,
                    0.2785259131308944,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "emily weiss": 0.34496751199400205,
                "whitney port": 0.2795595695419165,
                "lauren conrad": 0.3754729184640815
            },
            "question": "which alum from \u201cthe hills\u201d founded a wildly popular millennial skincare line?",
            "rate_limited": false,
            "answers": [
                "emily weiss",
                "lauren conrad",
                "whitney port"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "emily weiss": 0.4353139591099019,
                "whitney port": 0.24519118843286147,
                "lauren conrad": 0.6156274730888655
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    2.5095492127435244,
                    3.2622434822093203,
                    2.2282073050471554
                ],
                "result_count_important_words": [
                    23.0,
                    66.0,
                    41.0
                ],
                "wikipedia_search": [
                    1.5824742268041236,
                    2.058222071995944,
                    0.3593037011999324
                ],
                "answer_relation_to_question": [
                    2.843723829715962,
                    2.3984404042632286,
                    1.7578357660208095
                ],
                "answer_relation_to_question_bing": [
                    2.265686828716789,
                    0.8329968505208754,
                    0.9013163207623355
                ],
                "result_count_noun_chunks": [
                    36.0,
                    47.0,
                    48.0
                ],
                "question_answer_similarity": [
                    -0.11563500203192234,
                    0.6964964511571452,
                    2.2237498014001176
                ],
                "result_count_bing": [
                    23100.0,
                    2560.0,
                    226.0
                ],
                "result_count": [
                    12.0,
                    39.0,
                    16.0
                ],
                "word_count_appended": [
                    10.0,
                    17.0,
                    8.0
                ]
            },
            "integer_answers": {
                "emily weiss": 3,
                "whitney port": 2,
                "lauren conrad": 5
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which color is NOT represented in the original electronic Simon game?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "orange"
            ],
            "lines": [
                [
                    0.3049659863945578,
                    0.15383104125736735,
                    0.32260869715949814,
                    0.020214229925242688,
                    0.29365079365079366,
                    0.4042553191489362,
                    0.23394973354752163,
                    0.3572197484054904,
                    0.3221003134796238,
                    0.3218661418780134,
                    -1.0
                ],
                [
                    0.37642857142857145,
                    0.42639980353634577,
                    0.3519548682225229,
                    0.49559266560047605,
                    0.40620490620490624,
                    0.3058510638297872,
                    0.4999973800875287,
                    0.4315209564118391,
                    0.33620689655172414,
                    0.350275147933944,
                    -1.0
                ],
                [
                    0.31860544217687076,
                    0.4197691552062868,
                    0.32543643461797894,
                    0.48419310447428127,
                    0.30014430014430016,
                    0.2898936170212766,
                    0.26605288636494967,
                    0.21125929518267056,
                    0.34169278996865204,
                    0.32785871018804275,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "blue": 0.45306759903059096,
                "orange": 0.20391354803847092,
                "green": 0.3430188529309381
            },
            "question": "which color is not represented in the original electronic simon game?",
            "rate_limited": false,
            "answers": [
                "blue",
                "orange",
                "green"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "blue": 0.5055764265678385,
                "orange": 0.646356950527933,
                "green": 0.2124088185142459
            },
            "negative_question": true,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    2.13760629746384,
                    1.7966982247926728,
                    2.0656954777434873
                ],
                "result_count_important_words": [
                    1080000.0,
                    2190000.0,
                    2370000.0
                ],
                "wikipedia_search": [
                    1.1422420127560768,
                    0.5478323487052876,
                    2.3099256385386355
                ],
                "answer_relation_to_question": [
                    1.950340136054422,
                    1.2357142857142855,
                    1.8139455782312925
                ],
                "answer_relation_to_question_bing": [
                    2.769351669941061,
                    0.5888015717092339,
                    0.6418467583497053
                ],
                "result_count_noun_chunks": [
                    7210000.0,
                    71.0,
                    6340000.0
                ],
                "question_answer_similarity": [
                    3.33958138525486,
                    2.787108264863491,
                    3.286346197128296
                ],
                "result_count_bing": [
                    2860000.0,
                    1300000.0,
                    2770000.0
                ],
                "result_count": [
                    51600000.0,
                    474000.0,
                    1700000.0
                ],
                "word_count_appended": [
                    227.0,
                    209.0,
                    202.0
                ]
            },
            "integer_answers": {
                "blue": 8,
                "orange": 0,
                "green": 2
            }
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "What car brand is sung about by Will Smith, Charli XCX and Janis Joplin?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "porsche"
            ],
            "lines": [
                [
                    0.6594363929146537,
                    0.4681776556776557,
                    0.3745326544279725,
                    0.3966083150984683,
                    0.3333333333333333,
                    0.12055600106923282,
                    0.39922373163293595,
                    0.00904977375565611,
                    0.2956521739130435,
                    0.2905104560366788,
                    1.0
                ],
                [
                    0.1552012882447665,
                    0.2657967032967033,
                    0.46095148978453654,
                    0.35557986870897157,
                    0.3333333333333333,
                    0.1376637262763967,
                    0.3410036041031328,
                    0.23546170604994132,
                    0.30869565217391304,
                    0.38363360678842634,
                    1.0
                ],
                [
                    0.18536231884057972,
                    0.266025641025641,
                    0.16451585578749095,
                    0.24781181619256018,
                    0.3333333333333333,
                    0.7417802726543705,
                    0.25977266426393125,
                    0.7554885201944025,
                    0.39565217391304347,
                    0.3258559371748948,
                    1.0
                ]
            ],
            "fraction_answers": {
                "porsche": 0.3785573398825561,
                "rolls-royce": 0.3148023403272845,
                "mercedes-benz": 0.3066403197901594
            },
            "question": "what car brand is sung about by will smith, charli xcx and janis joplin?",
            "rate_limited": false,
            "answers": [
                "rolls-royce",
                "mercedes-benz",
                "porsche"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "porsche": 0.4785353019798712,
                "rolls-royce": 0.3870509407029392,
                "mercedes-benz": 0.3346150681066401
            },
            "integer_answers": {
                "porsche": 3,
                "rolls-royce": 5,
                "mercedes-benz": 2
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    2.3240836482934304,
                    3.0690688543074107,
                    2.6068474973991584
                ],
                "result_count_important_words": [
                    9020.0,
                    10300.0,
                    55500.0
                ],
                "wikipedia_search": [
                    0.027149321266968326,
                    0.706385118149824,
                    2.2664655605832076
                ],
                "answer_relation_to_question": [
                    1.9783091787439613,
                    0.4656038647342995,
                    0.5560869565217391
                ],
                "answer_relation_to_question_bing": [
                    1.8727106227106227,
                    1.0631868131868132,
                    1.064102564102564
                ],
                "result_count_noun_chunks": [
                    14400.0,
                    12300.0,
                    9370.0
                ],
                "question_answer_similarity": [
                    4.242357361596078,
                    5.221229505375959,
                    1.8634825125336647
                ],
                "result_count_bing": [
                    160000.0,
                    160000.0,
                    160000.0
                ],
                "word_count_appended": [
                    68.0,
                    71.0,
                    91.0
                ],
                "result_count": [
                    14500.0,
                    13000.0,
                    9060.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which person is most likely to use a Reuleaux triangle at work?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "banksy"
            ],
            "lines": [
                [
                    0.5350907020557184,
                    0.3390772128060264,
                    0.46353960348186013,
                    0.11827956989247312,
                    0.35561497326203206,
                    0.1111111111111111,
                    0.005712245626561942,
                    0.02611754966887417,
                    0.14285714285714285,
                    0.31208016621060103,
                    -1.0
                ],
                [
                    0.18941374705490907,
                    0.3631703922050274,
                    -0.09629011091222073,
                    0.3118279569892473,
                    0.3449197860962567,
                    0.2727272727272727,
                    0.012495537308104248,
                    0.15378565970453387,
                    0.11428571428571428,
                    0.3353562942693378,
                    -1.0
                ],
                [
                    0.2754955508893725,
                    0.2977523949889462,
                    0.6327505074303607,
                    0.5698924731182796,
                    0.2994652406417112,
                    0.6161616161616161,
                    0.9817922170653338,
                    0.820096790626592,
                    0.7428571428571429,
                    0.35256353952006125,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "banksy": 0.5588827473299417,
                "adam levine": 0.20016922497281825,
                "greta gerwig": 0.24094802769724014
            },
            "question": "which person is most likely to use a reuleaux triangle at work?",
            "rate_limited": false,
            "answers": [
                "greta gerwig",
                "adam levine",
                "banksy"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "banksy": 0.6686223491779206,
                "adam levine": 0.18525936689242672,
                "greta gerwig": 0.32471375454250334
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.872480997263606,
                    2.0121377656160266,
                    2.1153812371203675
                ],
                "result_count_important_words": [
                    11.0,
                    27.0,
                    61.0
                ],
                "wikipedia_search": [
                    0.07835264900662252,
                    0.46135697911360163,
                    2.460290371879776
                ],
                "answer_relation_to_question": [
                    2.1403628082228736,
                    0.7576549882196363,
                    1.10198220355749
                ],
                "answer_relation_to_question_bing": [
                    1.017231638418079,
                    1.0895111766150822,
                    0.8932571849668386
                ],
                "result_count_noun_chunks": [
                    16.0,
                    35.0,
                    2750.0
                ],
                "question_answer_similarity": [
                    -0.7148150510620326,
                    0.1484870333224535,
                    -0.9757517650723457
                ],
                "result_count_bing": [
                    133000.0,
                    129000.0,
                    112000.0
                ],
                "result_count": [
                    11.0,
                    29.0,
                    53.0
                ],
                "word_count_appended": [
                    5.0,
                    4.0,
                    26.0
                ]
            },
            "integer_answers": {
                "banksy": 6,
                "adam levine": 2,
                "greta gerwig": 2
            }
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Which of these songs was written by the man nicknamed \u201cSlowhand\u201d?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "lay down sally"
            ],
            "lines": [
                [
                    0.4869865246685503,
                    0.5319672131147541,
                    0.2857582590948446,
                    0.9922671593786354,
                    0.24367088607594936,
                    0.4444647049438151,
                    0.17428449380606578,
                    0.2256383712905452,
                    0.6470588235294118,
                    0.5767041099162373,
                    -1.0
                ],
                [
                    0.31857657755560387,
                    0.36475409836065575,
                    0.35340078968954997,
                    0.005748306302607267,
                    0.22943037974683544,
                    0.5538714015453696,
                    0.3814609141392567,
                    0.6922015182884748,
                    0.27058823529411763,
                    0.2926341743289448,
                    -1.0
                ],
                [
                    0.19443689777584583,
                    0.10327868852459016,
                    0.36084095121560544,
                    0.001984534318757271,
                    0.5268987341772152,
                    0.0016638935108153079,
                    0.4442545920546775,
                    0.08216011042097998,
                    0.08235294117647059,
                    0.1306617157548178,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "lay down sally": 0.4608800545818809,
                "lover lay down": 0.19285330589297747,
                "lay lady lay": 0.3462666395251416
            },
            "question": "which of these songs was written by the man nicknamed \u201cslowhand\u201d?",
            "rate_limited": false,
            "answers": [
                "lay down sally",
                "lay lady lay",
                "lover lay down"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "lay down sally": 0.6759866614328084,
                "lover lay down": 0.19178495078073882,
                "lay lady lay": 0.12212254939649132
            },
            "integer_answers": {
                "lay down sally": 5,
                "lover lay down": 3,
                "lay lady lay": 2
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    2.8835205495811866,
                    1.463170871644724,
                    0.653308578774089
                ],
                "result_count_important_words": [
                    19500.0,
                    24300.0,
                    73.0
                ],
                "wikipedia_search": [
                    0.6769151138716356,
                    2.0766045548654244,
                    0.24648033126293994
                ],
                "answer_relation_to_question": [
                    1.9479460986742012,
                    1.2743063102224155,
                    0.7777475911033833
                ],
                "answer_relation_to_question_bing": [
                    2.1278688524590166,
                    1.459016393442623,
                    0.4131147540983606
                ],
                "result_count_noun_chunks": [
                    40800.0,
                    89300.0,
                    104000.0
                ],
                "question_answer_similarity": [
                    8.875952580478042,
                    10.97700084373355,
                    11.208100099116564
                ],
                "result_count_bing": [
                    15400.0,
                    14500.0,
                    33300.0
                ],
                "result_count": [
                    14500.0,
                    84.0,
                    29.0
                ],
                "word_count_appended": [
                    55.0,
                    23.0,
                    7.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which of these quantities is the largest?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "dozen"
            ],
            "lines": [
                [
                    1.0,
                    0.0,
                    0.13127215168613302,
                    0.9620372192141702,
                    0.8548058264351158,
                    0.9691702755379283,
                    0.9775629746068242,
                    0,
                    0.7530120481927711,
                    0.5419176706827309,
                    -1.0
                ],
                [
                    0.0,
                    0.0,
                    0.5353932794064021,
                    1.7886482163344466e-05,
                    0.14197637002284394,
                    1.4581298027150377e-05,
                    6.3985940156083035e-06,
                    0,
                    0.010040160642570281,
                    0.08740238732708613,
                    -1.0
                ],
                [
                    0.0,
                    1.0,
                    0.3333345689074648,
                    0.037944894303666474,
                    0.0032178035420402347,
                    0.030815143164044462,
                    0.02243062679916022,
                    0,
                    0.23694779116465864,
                    0.37067994199018295,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "two half-dozens": 0.08609456264145651,
                "baker's dozen": 0.22615230776346865,
                "dozen": 0.6877531295950747
            },
            "question": "which of these quantities is the largest?",
            "rate_limited": false,
            "answers": [
                "dozen",
                "two half-dozens",
                "baker's dozen"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "two half-dozens": 0.18236501519393916,
                "baker's dozen": 0.18728337059543107,
                "dozen": 0.25489723292888966
            },
            "integer_answers": {
                "two half-dozens": 1,
                "baker's dozen": 1,
                "dozen": 7
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.0838353413654618,
                    0.17480477465417227,
                    0.7413598839803659
                ],
                "result_count_important_words": [
                    997000.0,
                    15.0,
                    31700.0
                ],
                "wikipedia_search": [
                    0.0,
                    0.0,
                    0.0
                ],
                "answer_relation_to_question": [
                    2.0,
                    0.0,
                    0.0
                ],
                "answer_relation_to_question_bing": [
                    0.0,
                    0.0,
                    1.0
                ],
                "result_count_noun_chunks": [
                    2750000.0,
                    18.0,
                    63100.0
                ],
                "question_answer_similarity": [
                    2.4537939727306366,
                    10.007795142941177,
                    6.230829201638699
                ],
                "result_count_bing": [
                    17400000.0,
                    2890000.0,
                    65500.0
                ],
                "result_count": [
                    753000.0,
                    14.0,
                    29700.0
                ],
                "word_count_appended": [
                    375.0,
                    5.0,
                    118.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "The actor who played Don Draper provides the voice for what car company\u2019s ads?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "bmw"
            ],
            "lines": [
                [
                    0.2974269548917436,
                    0.2613960113960114,
                    0.5822662502763025,
                    0.2542139662882697,
                    0.40899795501022496,
                    0.2736212056434374,
                    0.02950885939500101,
                    0.39248912330889796,
                    0.32321428571428573,
                    0.3443109882290854,
                    1.0
                ],
                [
                    0.2790801217561781,
                    0.4652615902615903,
                    0.24786561416360686,
                    0.45751633986928103,
                    0.3593339176161262,
                    0.4318084651560496,
                    0.04075995418715893,
                    0.5416774936925124,
                    0.3125,
                    0.3181269110054121,
                    1.0
                ],
                [
                    0.4234929233520783,
                    0.2733423983423984,
                    0.16986813556009067,
                    0.28826969384244927,
                    0.23166812737364884,
                    0.294570329200513,
                    0.92973118641784,
                    0.06583338299858951,
                    0.36428571428571427,
                    0.3375621007655025,
                    1.0
                ]
            ],
            "fraction_answers": {
                "jaguar": 0.33786239921388245,
                "bmw": 0.3453930407707915,
                "mercedes-benz": 0.3167445600153259
            },
            "question": "the actor who played don draper provides the voice for what car company\u2019s ads?",
            "rate_limited": false,
            "answers": [
                "mercedes-benz",
                "bmw",
                "jaguar"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "jaguar": 0.27546792013348903,
                "bmw": 0.49543571864651936,
                "mercedes-benz": 0.3921966780179034
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    2.754487905832683,
                    2.545015288043297,
                    2.70049680612402
                ],
                "result_count_important_words": [
                    64000.0,
                    101000.0,
                    68900.0
                ],
                "wikipedia_search": [
                    1.96244561654449,
                    2.708387468462562,
                    0.32916691499294753
                ],
                "answer_relation_to_question": [
                    1.7845617293504616,
                    1.6744807305370686,
                    2.5409575401124695
                ],
                "answer_relation_to_question_bing": [
                    1.0455840455840455,
                    1.8610463610463612,
                    1.0933695933695935
                ],
                "result_count_noun_chunks": [
                    87600.0,
                    121000.0,
                    2760000.0
                ],
                "question_answer_similarity": [
                    3.793542579282075,
                    1.6148776626214385,
                    1.106713646557182
                ],
                "result_count_bing": [
                    140000.0,
                    123000.0,
                    79300.0
                ],
                "word_count_appended": [
                    181.0,
                    175.0,
                    204.0
                ],
                "result_count": [
                    73900.0,
                    133000.0,
                    83800.0
                ]
            },
            "integer_answers": {
                "jaguar": 3,
                "bmw": 4,
                "mercedes-benz": 3
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which of these substances expands when it freezes?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "carbon dioxide"
            ],
            "lines": [
                [
                    0.3333333333333333,
                    0,
                    0.36134323360892967,
                    0.22385624634810786,
                    0.17589285714285716,
                    0.43481370235285705,
                    0.41676104190260477,
                    0.0,
                    0.2813688212927757,
                    0.32752083089138373,
                    2.0
                ],
                [
                    0.0,
                    0,
                    0.4964247601308732,
                    0.7740114280510848,
                    0.6991071428571428,
                    0.5606808267181578,
                    0.5383163457908645,
                    1.0,
                    0.376425855513308,
                    0.3613951055425296,
                    2.0
                ],
                [
                    0.6666666666666666,
                    0,
                    0.1422320062601971,
                    0.0021323256008074,
                    0.125,
                    0.004505470928985196,
                    0.04492261230653077,
                    0.0,
                    0.34220532319391633,
                    0.31108406356608653,
                    2.0
                ]
            ],
            "fraction_answers": {
                "sodium chloride": 0.28387667409698325,
                "carbon dioxide": 0.5340401627337735,
                "dihydrogen monoxide": 0.18208316316924333
            },
            "question": "which of these substances expands when it freezes?",
            "rate_limited": false,
            "answers": [
                "sodium chloride",
                "carbon dioxide",
                "dihydrogen monoxide"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "sodium chloride": 0.24725035670390455,
                "carbon dioxide": 0.5674933126622883,
                "dihydrogen monoxide": 0.2416961322931678
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 2
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    0.9825624926741514,
                    1.084185316627589,
                    0.9332521906982597
                ],
                "result_count_important_words": [
                    304000.0,
                    392000.0,
                    3150.0
                ],
                "wikipedia_search": [
                    0.0,
                    1.0,
                    0.0
                ],
                "answer_relation_to_question": [
                    0.3333333333333333,
                    0.0,
                    0.6666666666666666
                ],
                "answer_relation_to_question_bing": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    5520000.0,
                    7130000.0,
                    595000.0
                ],
                "question_answer_similarity": [
                    2.973916858434677,
                    4.085661016404629,
                    1.170593834016472
                ],
                "result_count_bing": [
                    1970000.0,
                    7830000.0,
                    1400000.0
                ],
                "word_count_appended": [
                    74.0,
                    99.0,
                    90.0
                ],
                "result_count": [
                    295000.0,
                    1020000.0,
                    2810.0
                ]
            },
            "integer_answers": {
                "sodium chloride": 0,
                "carbon dioxide": 8,
                "dihydrogen monoxide": 1
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which U.S. president's wife was NOT born in North America?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "rutherford b. hayes"
            ],
            "lines": [
                [
                    0.2896683828392672,
                    0.2822160797160797,
                    0.278352176574437,
                    0.1698362387744321,
                    0.4030271934325295,
                    0.1755345599204376,
                    0.17664092664092662,
                    0.34878386668759187,
                    0.31546134663341646,
                    0.3314246095602935,
                    -1.0
                ],
                [
                    0.33684821982701496,
                    0.39496382746382747,
                    0.37061459986955764,
                    0.42776016904384573,
                    0.14340687532067725,
                    0.42516161113873696,
                    0.42265926640926643,
                    0.39652199759360457,
                    0.3728179551122195,
                    0.33790987460877747,
                    -1.0
                ],
                [
                    0.3734833973337178,
                    0.32282009282009283,
                    0.35103322355600536,
                    0.4024035921817221,
                    0.45356593124679323,
                    0.39930382894082544,
                    0.40069980694980695,
                    0.25469413571880367,
                    0.3117206982543641,
                    0.33066551583092907,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "martin van buren": 0.2799219554333878,
                "john quincy adams": 0.44581092384411763,
                "rutherford b. hayes": 0.27426712072249443
            },
            "question": "which u.s. president's wife was not born in north america?",
            "rate_limited": false,
            "answers": [
                "john quincy adams",
                "rutherford b. hayes",
                "martin van buren"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "martin van buren": 0.26805047286206546,
                "john quincy adams": 0.3931173256449866,
                "rutherford b. hayes": 0.6540546729759611
            },
            "integer_answers": {
                "martin van buren": 3,
                "john quincy adams": 6,
                "rutherford b. hayes": 1
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    2.022904685276478,
                    1.9450815046946703,
                    2.0320138100288516
                ],
                "result_count_important_words": [
                    261000.0,
                    60200.0,
                    81000.0
                ],
                "wikipedia_search": [
                    1.5121613331240817,
                    1.034780024063955,
                    2.4530586428119636
                ],
                "answer_relation_to_question": [
                    2.5239794059287934,
                    1.957821362075821,
                    1.5181992319953856
                ],
                "answer_relation_to_question_bing": [
                    2.177839202839203,
                    1.0503617253617255,
                    1.7717990717990717
                ],
                "result_count_noun_chunks": [
                    268000.0,
                    64100.0,
                    82300.0
                ],
                "question_answer_similarity": [
                    5.790412285365164,
                    3.380113546270877,
                    3.8916648902813904
                ],
                "result_count_bing": [
                    3780000.0,
                    13900000.0,
                    1810000.0
                ],
                "word_count_appended": [
                    148.0,
                    102.0,
                    151.0
                ],
                "result_count": [
                    250000.0,
                    54700.0,
                    73900.0
                ]
            },
            "negative_question": true
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Who was the president of the Screen Actors Guild before its merger with AFTRA?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "ken howard"
            ],
            "lines": [
                [
                    0.4372606711904001,
                    0.23293233082706766,
                    -0.17112530697925354,
                    0.002650957290132548,
                    0.08618444418136617,
                    0.21095890410958903,
                    0.15358744394618834,
                    0.3790243902439025,
                    0.22077922077922077,
                    0.17839911666066546,
                    0.0
                ],
                [
                    0.055027393738731445,
                    0.3190476190476191,
                    0.29934179764972413,
                    0.9916543937162494,
                    0.037764886942109624,
                    0.2106544901065449,
                    0.7286995515695067,
                    0.10941734417344173,
                    0.2987012987012987,
                    0.47537317753946645,
                    0.0
                ],
                [
                    0.5077119350708684,
                    0.4480200501253133,
                    0.8717835093295294,
                    0.0056946489936180655,
                    0.8760506688765242,
                    0.578386605783866,
                    0.11771300448430494,
                    0.5115582655826558,
                    0.4805194805194805,
                    0.3462277057998681,
                    0.0
                ]
            ],
            "fraction_answers": {
                "gabrielle carteris": 0.1730652172249279,
                "ken howard": 0.4743665874566029,
                "melissa gilbert": 0.3525681953184692
            },
            "question": "who was the president of the screen actors guild before its merger with aftra?",
            "rate_limited": false,
            "answers": [
                "gabrielle carteris",
                "melissa gilbert",
                "ken howard"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "gabrielle carteris": 0.1440270869367544,
                "ken howard": 0.6377804057614753,
                "melissa gilbert": 0.28692547272019814
            },
            "integer_answers": {
                "gabrielle carteris": 0,
                "ken howard": 7,
                "melissa gilbert": 3
            },
            "categorical_data": {
                "question_type": 0
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.0703946999639928,
                    2.8522390652367986,
                    2.0773662347992086
                ],
                "result_count_important_words": [
                    6930.0,
                    6920.0,
                    19000.0
                ],
                "wikipedia_search": [
                    2.274146341463415,
                    0.6565040650406504,
                    3.069349593495935
                ],
                "answer_relation_to_question": [
                    2.6235640271424003,
                    0.33016436243238867,
                    3.0462716104252108
                ],
                "answer_relation_to_question_bing": [
                    1.1646616541353383,
                    1.5952380952380953,
                    2.2401002506265666
                ],
                "result_count_noun_chunks": [
                    13700.0,
                    65000.0,
                    10500.0
                ],
                "question_answer_similarity": [
                    -0.4703610949218273,
                    0.8227814937708899,
                    2.3962151082232594
                ],
                "result_count_bing": [
                    72800.0,
                    31900.0,
                    740000.0
                ],
                "word_count_appended": [
                    51.0,
                    69.0,
                    111.0
                ],
                "result_count": [
                    27.0,
                    10100.0,
                    58.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Jean Valjean, the protagonist of \u201cLes Mis\u00e9rables,\u201d is identified by what prisoner number?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "24601"
            ],
            "lines": [
                [
                    0.007246376811594203,
                    0.03809523809523809,
                    0.4163131932104924,
                    0.47752808988764045,
                    0.34356846473029046,
                    0.5641025641025641,
                    0.08731563421828908,
                    0.07152317880794704,
                    0.26104417670682734,
                    0.31371904291092384,
                    1.0
                ],
                [
                    0.8871635610766045,
                    0.8952380952380953,
                    0.0845695215090429,
                    0.2303370786516854,
                    0.5593360995850623,
                    0.36538461538461536,
                    0.9085545722713865,
                    0.8211920529801325,
                    0.5301204819277109,
                    0.46301387514578934,
                    1.0
                ],
                [
                    0.10559006211180123,
                    0.06666666666666667,
                    0.4991172852804647,
                    0.29213483146067415,
                    0.0970954356846473,
                    0.07051282051282051,
                    0.004129793510324484,
                    0.10728476821192054,
                    0.20883534136546184,
                    0.22326708194328684,
                    1.0
                ]
            ],
            "fraction_answers": {
                "y2k": 0.2580455959481808,
                "24601": 0.5744909953770125,
                "867-5309": 0.16746340867480683
            },
            "question": "jean valjean, the protagonist of \u201cles mis\u00e9rables,\u201d is identified by what prisoner number?",
            "rate_limited": false,
            "answers": [
                "y2k",
                "24601",
                "867-5309"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "y2k": 0.17759367929346728,
                "24601": 0.6456282311587889,
                "867-5309": 0.16591114716690172
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.882314257465543,
                    2.778083250874736,
                    1.3396024916597211
                ],
                "result_count_important_words": [
                    88.0,
                    57.0,
                    11.0
                ],
                "wikipedia_search": [
                    0.3576158940397351,
                    4.105960264900662,
                    0.5364238410596026
                ],
                "answer_relation_to_question": [
                    0.043478260869565216,
                    5.3229813664596275,
                    0.6335403726708074
                ],
                "answer_relation_to_question_bing": [
                    0.19047619047619047,
                    4.476190476190476,
                    0.3333333333333333
                ],
                "result_count_noun_chunks": [
                    592.0,
                    6160.0,
                    28.0
                ],
                "question_answer_similarity": [
                    -1.5125535689294338,
                    -0.3072588946670294,
                    -1.8133982863801066
                ],
                "result_count_bing": [
                    20700.0,
                    33700.0,
                    5850.0
                ],
                "result_count": [
                    85.0,
                    41.0,
                    52.0
                ],
                "word_count_appended": [
                    65.0,
                    132.0,
                    52.0
                ]
            },
            "integer_answers": {
                "y2k": 2,
                "24601": 8,
                "867-5309": 0
            }
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "What is the grammatically correct way to announce people have arrived?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "they're here"
            ],
            "lines": [
                [
                    0.4844093406593407,
                    0.3,
                    0.4380747507787122,
                    0.7009203388797465,
                    0.6738373932299905,
                    0.7379553466509988,
                    0.35580870133375,
                    0.0,
                    0.5945945945945946,
                    0.36097046290981694,
                    1.0
                ],
                [
                    0.08846153846153845,
                    0.3,
                    0.2967852168339446,
                    0.24684585847504115,
                    0.16925023726668775,
                    0.2209165687426557,
                    0.6434384898370809,
                    0.5,
                    0.1891891891891892,
                    0.3673176479316341,
                    1.0
                ],
                [
                    0.4271291208791209,
                    0.4,
                    0.2651400323873432,
                    0.05223380264521241,
                    0.15691236950332174,
                    0.041128084606345476,
                    0.0007528088291692116,
                    0.5,
                    0.21621621621621623,
                    0.27171188915854905,
                    1.0
                ]
            ],
            "fraction_answers": {
                "their here": 0.23312243242252784,
                "there here": 0.30222047467377716,
                "they're here": 0.4646570929036951
            },
            "question": "what is the grammatically correct way to announce people have arrived?",
            "rate_limited": false,
            "answers": [
                "they're here",
                "there here",
                "their here"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "their here": 0.15269028718379205,
                "there here": 0.3072184762297369,
                "they're here": 0.5301148541425811
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    2.1658227774589016,
                    2.2039058875898045,
                    1.6302713349512943
                ],
                "result_count_important_words": [
                    157000.0,
                    47000.0,
                    8750.0
                ],
                "wikipedia_search": [
                    0.0,
                    2.0,
                    2.0
                ],
                "answer_relation_to_question": [
                    2.4220467032967035,
                    0.4423076923076923,
                    2.1356456043956045
                ],
                "answer_relation_to_question_bing": [
                    1.2,
                    1.2,
                    1.6
                ],
                "result_count_noun_chunks": [
                    5010000.0,
                    9060000.0,
                    10600.0
                ],
                "question_answer_similarity": [
                    17.52471286058426,
                    11.872575849294662,
                    10.60664401948452
                ],
                "result_count_bing": [
                    426000.0,
                    107000.0,
                    99200.0
                ],
                "result_count": [
                    115000.0,
                    40500.0,
                    8570.0
                ],
                "word_count_appended": [
                    22.0,
                    7.0,
                    8.0
                ]
            },
            "integer_answers": {
                "their here": 1,
                "there here": 3,
                "they're here": 6
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which of these is NOT a Slavic language?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "hungarian"
            ],
            "lines": [
                [
                    0.31366279069767444,
                    0.3147233201581028,
                    0.3406021580808316,
                    0.42354533152909335,
                    0.32630522088353414,
                    0.45973509933774837,
                    0.3435486839683416,
                    0.1857976653696498,
                    0.33399999999999996,
                    0.329195485034278,
                    -1.0
                ],
                [
                    0.27063953488372094,
                    0.3211462450592885,
                    0.3457162185637367,
                    0.18200270635994586,
                    0.3785140562248996,
                    0.14503311258278145,
                    0.24047487575924903,
                    0.43093385214007784,
                    0.3312,
                    0.3248772740732515,
                    -1.0
                ],
                [
                    0.4156976744186046,
                    0.36413043478260865,
                    0.3136816233554317,
                    0.3944519621109608,
                    0.29518072289156627,
                    0.3952317880794702,
                    0.4159764402724093,
                    0.38326848249027234,
                    0.3348,
                    0.34592724089247046,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "bulgarian": 0.3257768489881492,
                "hungarian": 0.26833072614124115,
                "serbian": 0.4058924248706098
            },
            "question": "which of these is not a slavic language?",
            "rate_limited": false,
            "answers": [
                "bulgarian",
                "serbian",
                "hungarian"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "bulgarian": 0.21449014091858146,
                "hungarian": 0.6913883145531048,
                "serbian": 0.3931173256449866
            },
            "negative_question": true,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    0.6832180598628881,
                    0.700490903706994,
                    0.6162910364301182
                ],
                "result_count_important_words": [
                    304000.0,
                    2680000.0,
                    791000.0
                ],
                "wikipedia_search": [
                    1.2568093385214008,
                    0.27626459143968873,
                    0.4669260700389105
                ],
                "answer_relation_to_question": [
                    0.7453488372093022,
                    0.9174418604651162,
                    0.3372093023255814
                ],
                "answer_relation_to_question_bing": [
                    0.7411067193675889,
                    0.7154150197628458,
                    0.5434782608695652
                ],
                "result_count_noun_chunks": [
                    1700000.0,
                    2820000.0,
                    913000.0
                ],
                "question_answer_similarity": [
                    0.840626840479672,
                    0.81365648470819,
                    0.9825994279235601
                ],
                "result_count_bing": [
                    17300000.0,
                    12100000.0,
                    20400000.0
                ],
                "word_count_appended": [
                    415.0,
                    422.0,
                    413.0
                ],
                "result_count": [
                    1130000.0,
                    4700000.0,
                    1560000.0
                ]
            },
            "integer_answers": {
                "bulgarian": 2,
                "hungarian": 2,
                "serbian": 6
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Basketball is NOT a major theme of which of these 90s movies?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "eddie"
            ],
            "lines": [
                [
                    0.11323195945044684,
                    0.2928743961352657,
                    0.1692651722464626,
                    0.49752675460428075,
                    0.46433686622744197,
                    0.4999673248803559,
                    0.49895933311046164,
                    0.28125,
                    0.39413265306122447,
                    0.3319342640937799,
                    -1.0
                ],
                [
                    0.39918300653594774,
                    0.27355072463768115,
                    0.34904573858107607,
                    0.49504832420773187,
                    0.37653967344600403,
                    0.4901594697815934,
                    0.49818826904204727,
                    0.28125,
                    0.4285714285714286,
                    0.35630795792886893,
                    -1.0
                ],
                [
                    0.4875850340136054,
                    0.4335748792270532,
                    0.48168908917246134,
                    0.007424921187987377,
                    0.159123460326554,
                    0.009873205338050695,
                    0.002852397847491084,
                    0.4375,
                    0.17729591836734693,
                    0.31175777797735116,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "white men can't jump": 0.29130425523805603,
                "point break": 0.21043108145352418,
                "eddie": 0.49826466330841973
            },
            "question": "basketball is not a major theme of which of these 90s movies?",
            "rate_limited": false,
            "answers": [
                "white men can't jump",
                "point break",
                "eddie"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "white men can't jump": 0.2326690336830119,
                "point break": 0.27249385535515275,
                "eddie": 0.4727941863905904
            },
            "integer_answers": {
                "white men can't jump": 3,
                "point break": 1,
                "eddie": 6
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.680657359062201,
                    1.4369204207113104,
                    1.8824222202264884
                ],
                "result_count_important_words": [
                    86.0,
                    25900.0,
                    1290000.0
                ],
                "wikipedia_search": [
                    1.75,
                    1.75,
                    0.5
                ],
                "answer_relation_to_question": [
                    3.8676804054955314,
                    1.0081699346405228,
                    0.12414965986394558
                ],
                "answer_relation_to_question_bing": [
                    1.6570048309178742,
                    1.8115942028985508,
                    0.5314009661835748
                ],
                "result_count_noun_chunks": [
                    9650.0,
                    16800.0,
                    4610000.0
                ],
                "question_answer_similarity": [
                    20.746155932545662,
                    9.468977510929108,
                    1.148596940562129
                ],
                "result_count_bing": [
                    249000.0,
                    862000.0,
                    2380000.0
                ],
                "result_count": [
                    9540.0,
                    19100.0,
                    1900000.0
                ],
                "word_count_appended": [
                    83.0,
                    56.0,
                    253.0
                ]
            },
            "negative_question": true
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "What generation of the iPod was the first to offer video?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "u2 special edition"
            ],
            "lines": [
                [
                    0.23160860060004185,
                    0.20035541439806412,
                    0.36328898009034727,
                    0.49023715746249896,
                    0.48591261739485503,
                    0.00025043826696719256,
                    0.00022371537233180846,
                    0.5,
                    0.24157303370786518,
                    0.33469293326932464,
                    1.0
                ],
                [
                    0.5126171593366979,
                    0.4592429984698053,
                    0.3134969339667955,
                    0.0714824436436772,
                    0.030216414863209473,
                    0.1182068620085149,
                    0.12420060326007298,
                    0.5,
                    0.5280898876404494,
                    0.3097787975554804,
                    1.0
                ],
                [
                    0.2557742400632602,
                    0.34040158713213053,
                    0.3232140859428573,
                    0.43828039889382386,
                    0.4838709677419355,
                    0.8815426997245179,
                    0.8755756813675952,
                    0.0,
                    0.2303370786516854,
                    0.3555282691751949,
                    1.0
                ]
            ],
            "fraction_answers": {
                "third generation": 0.2848142890562296,
                "u2 special edition": 0.2967332100744703,
                "fifth generation": 0.4184525008693001
            },
            "question": "what generation of the ipod was the first to offer video?",
            "rate_limited": false,
            "answers": [
                "third generation",
                "u2 special edition",
                "fifth generation"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "third generation": 0.3716387121526565,
                "u2 special edition": 0.4727941863905904,
                "fifth generation": 0.3128410728270124
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.3387717330772986,
                    1.2391151902219215,
                    1.4221130767007797
                ],
                "result_count_important_words": [
                    75.0,
                    35400.0,
                    264000.0
                ],
                "wikipedia_search": [
                    1.5,
                    1.5,
                    0.0
                ],
                "answer_relation_to_question": [
                    0.9264344024001674,
                    2.0504686373467917,
                    1.0230969602530409
                ],
                "answer_relation_to_question_bing": [
                    0.8014216575922565,
                    1.8369719938792213,
                    1.3616063485285221
                ],
                "result_count_noun_chunks": [
                    58.0,
                    32200.0,
                    227000.0
                ],
                "question_answer_similarity": [
                    8.978684231638908,
                    7.748074210714549,
                    7.988233543932438
                ],
                "result_count_bing": [
                    23800000.0,
                    1480000.0,
                    23700000.0
                ],
                "result_count": [
                    58500.0,
                    8530.0,
                    52300.0
                ],
                "word_count_appended": [
                    43.0,
                    94.0,
                    41.0
                ]
            },
            "integer_answers": {
                "third generation": 4,
                "u2 special edition": 3,
                "fifth generation": 3
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which of these actresses is NOT mentioned in Madonna\u2019s song \u201cVogue\u201d?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "jean harlow"
            ],
            "lines": [
                [
                    0.37896825396825395,
                    0.5,
                    3.5234309945219278,
                    0.25135135135135134,
                    0.2949236298292902,
                    0.3279894087860691,
                    0.2857142857142857,
                    0.5000000000000001,
                    0.28735632183908044,
                    0.2566969471722043,
                    -1.0
                ],
                [
                    0.29166666666666663,
                    0.25,
                    1.9884020602008625,
                    0.37027027027027026,
                    0.27313566936208444,
                    0.4996037958292263,
                    0.39761904761904765,
                    0.14871794871794872,
                    0.3735632183908046,
                    0.39274327579690926,
                    -1.0
                ],
                [
                    0.3293650793650794,
                    0.25,
                    -4.51183305472279,
                    0.3783783783783784,
                    0.43194070080862534,
                    0.1724067953847046,
                    0.31666666666666665,
                    0.3512820512820513,
                    0.3390804597701149,
                    0.35055977703088637,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "jean harlow": -0.32128623863649264,
                "audrey hepburn": 0.0028556094292358945,
                "rita hayworth": 1.3184306292072567
            },
            "question": "which of these actresses is not mentioned in madonna\u2019s song \u201cvogue\u201d?",
            "rate_limited": false,
            "answers": [
                "jean harlow",
                "audrey hepburn",
                "rita hayworth"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "jean harlow": 0.45068890405177003,
                "audrey hepburn": 0.22915511860866647,
                "rita hayworth": 0.3889320307775609
            },
            "integer_answers": {
                "jean harlow": 5,
                "audrey hepburn": 4,
                "rita hayworth": 1
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    2.4330305282779565,
                    1.0725672420309074,
                    1.4944022296911357
                ],
                "result_count_important_words": [
                    17800.0,
                    41.0,
                    33900.0
                ],
                "wikipedia_search": [
                    0.0,
                    2.1076923076923078,
                    0.8923076923076922
                ],
                "answer_relation_to_question": [
                    0.7261904761904763,
                    1.25,
                    1.0238095238095237
                ],
                "answer_relation_to_question_bing": [
                    0.0,
                    1.0,
                    1.0
                ],
                "result_count_noun_chunks": [
                    90.0,
                    43.0,
                    77.0
                ],
                "question_answer_similarity": [
                    0.8370858241105452,
                    0.41208820953033864,
                    -1.3876071292907
                ],
                "result_count_bing": [
                    91300.0,
                    101000.0,
                    30300.0
                ],
                "result_count": [
                    92.0,
                    48.0,
                    45.0
                ],
                "word_count_appended": [
                    37.0,
                    22.0,
                    28.0
                ]
            },
            "negative_question": true
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Which of these is NOT a step in the famous Korean 10-step skin care regime?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "cleansing"
            ],
            "lines": [
                [
                    0.32859638420585624,
                    0.4284900284900285,
                    0.15906619240928,
                    0.21761621363879335,
                    0.136579886348619,
                    0.16449923236701885,
                    0.20792530175358687,
                    0.4184626436781609,
                    0.29116117850953205,
                    0.29438065182263284,
                    -1.0
                ],
                [
                    0.18830412599822532,
                    0.14330484330484328,
                    0.2844611204772735,
                    0.28288740513347616,
                    0.49061715342936435,
                    0.3424094644631085,
                    0.30072876337964016,
                    0.3315373563218391,
                    0.33535528596187175,
                    0.29749409626972767,
                    -1.0
                ],
                [
                    0.4830994897959184,
                    0.42820512820512824,
                    0.5564726871134464,
                    0.4994963812277305,
                    0.37280296022201664,
                    0.49309130316987265,
                    0.49134593486677297,
                    0.25,
                    0.3734835355285962,
                    0.4081252519076395,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "moisturizing": 0.40058007705212595,
                "spelunking": 0.1287754655925757,
                "cleansing": 0.47064445735529825
            },
            "question": "which of these is not a step in the famous korean 10-step skin care regime?",
            "rate_limited": false,
            "answers": [
                "cleansing",
                "moisturizing",
                "spelunking"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "moisturizing": 0.17103731983876694,
                "spelunking": 0.2998502181204233,
                "cleansing": 0.3889320307775609
            },
            "integer_answers": {
                "moisturizing": 2,
                "spelunking": 1,
                "cleansing": 7
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    2.8786708744831397,
                    2.8350826522238126,
                    1.2862464732930474
                ],
                "result_count_important_words": [
                    743000.0,
                    349000.0,
                    15300.0
                ],
                "wikipedia_search": [
                    0.6522988505747127,
                    1.3477011494252873,
                    2.0
                ],
                "answer_relation_to_question": [
                    1.3712289263531499,
                    2.493566992014197,
                    0.13520408163265307
                ],
                "answer_relation_to_question_bing": [
                    0.715099715099715,
                    3.566951566951567,
                    0.717948717948718
                ],
                "result_count_noun_chunks": [
                    513000.0,
                    350000.0,
                    15200.0
                ],
                "question_answer_similarity": [
                    3.367438416928053,
                    2.1288997661322355,
                    -0.5577865610830486
                ],
                "result_count_bing": [
                    2200000.0,
                    56800.0,
                    770000.0
                ],
                "result_count": [
                    411000.0,
                    316000.0,
                    733.0
                ],
                "word_count_appended": [
                    241.0,
                    190.0,
                    146.0
                ]
            },
            "negative_question": true
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Napa cabbage is named after what?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "city in california"
            ],
            "question": "napa cabbage is named after what?",
            "answers": [
                "city in california",
                "scientist edward napa",
                "japanese for \u201cvegetable\u201d"
            ],
            "integer_answers": {
                "city in california": 6,
                "scientist edward napa": 1,
                "japanese for \u201cvegetable\u201d": 3
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.045697012802276,
                    0.3067211948790896,
                    0.6475817923186344
                ],
                "result_count_important_words": [
                    47.0,
                    0,
                    15.0
                ],
                "wikipedia_search": [
                    0.0,
                    0.0,
                    1.0
                ],
                "answer_relation_to_question": [
                    0.6,
                    0.6666666666666667,
                    0.7333333333333333
                ],
                "answer_relation_to_question_bing": [
                    0.0,
                    1.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    22.0,
                    0,
                    16.0
                ],
                "question_answer_similarity": [
                    5.399515964090824,
                    3.6875174193410203,
                    8.128326654434204
                ],
                "result_count_bing": [
                    1030000.0,
                    538000.0,
                    384000.0
                ],
                "result_count": [
                    42.0,
                    0,
                    13.0
                ],
                "word_count_appended": [
                    23.0,
                    4.0,
                    0.0
                ]
            },
            "negative_question": false,
            "fraction_answers": {
                "city in california": 0.461665779441914,
                "scientist edward napa": 0.21246560952613697,
                "japanese for \u201cvegetable\u201d": 0.3258686110319489
            },
            "lines": [
                [
                    0.3,
                    0.0,
                    0.31364525355347306,
                    0.7636363636363637,
                    0.5276639344262295,
                    0.7580645161290323,
                    0.5789473684210527,
                    0.0,
                    0.8518518518518519,
                    0.522848506401138,
                    1.0
                ],
                [
                    0.33333333333333337,
                    1.0,
                    0.21419926224198277,
                    0.0,
                    0.27561475409836067,
                    0.0,
                    0.0,
                    0.0,
                    0.14814814814814814,
                    0.1533605974395448,
                    1.0
                ],
                [
                    0.36666666666666664,
                    0.0,
                    0.4721554842045442,
                    0.23636363636363636,
                    0.19672131147540983,
                    0.24193548387096775,
                    0.42105263157894735,
                    1.0,
                    0.0,
                    0.3237908961593172,
                    1.0
                ]
            ],
            "rate_limited": false,
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "city in california": 0.5027409292761662,
                "scientist edward napa": 0.0926273498473653,
                "japanese for \u201cvegetable\u201d": 0.20968777779154218
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Lonnie Lynn's only Academy Award win was in what category?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "best original song"
            ],
            "lines": [
                [
                    0.33930236472766223,
                    0.2860586501951415,
                    0.31892247574764543,
                    0.40575916230366493,
                    0.12222222222222222,
                    0.17785778577857786,
                    0.4295774647887324,
                    0.3192177423386492,
                    0.25949367088607594,
                    0.32331914547270973,
                    1.0
                ],
                [
                    0.3239075668367389,
                    0.3449161498076076,
                    0.2546514258871344,
                    0.324934554973822,
                    0.23450292397660819,
                    0.13987398739873988,
                    0.34330985915492956,
                    0.26135276137150854,
                    0.17721518987341772,
                    0.33050810500091904,
                    1.0
                ],
                [
                    0.3367900684355989,
                    0.3690251999972509,
                    0.4264260983652201,
                    0.2693062827225131,
                    0.6432748538011696,
                    0.6822682268226823,
                    0.22711267605633803,
                    0.4194294962898423,
                    0.5632911392405063,
                    0.34617274952637117,
                    1.0
                ]
            ],
            "fraction_answers": {
                "best adapted screenplay": 0.29817306844610814,
                "best original song": 0.4283096791257493,
                "best cinematography": 0.27351725242814257
            },
            "question": "lonnie lynn's only academy award win was in what category?",
            "rate_limited": false,
            "answers": [
                "best adapted screenplay",
                "best cinematography",
                "best original song"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "best adapted screenplay": 0.11994121262686765,
                "best original song": 0.5360866619015449,
                "best cinematography": 0.2587360348178726
            },
            "integer_answers": {
                "best adapted screenplay": 3,
                "best original song": 7,
                "best cinematography": 0
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.9399148728362583,
                    1.9830486300055143,
                    2.077036497158227
                ],
                "result_count_important_words": [
                    9880.0,
                    7770.0,
                    37900.0
                ],
                "wikipedia_search": [
                    1.2768709693545968,
                    1.0454110454860341,
                    1.677717985159369
                ],
                "answer_relation_to_question": [
                    1.357209458910649,
                    1.2956302673469555,
                    1.3471602737423956
                ],
                "answer_relation_to_question_bing": [
                    1.144234600780566,
                    1.3796645992304304,
                    1.4761007999890037
                ],
                "result_count_noun_chunks": [
                    12200.0,
                    9750.0,
                    6450.0
                ],
                "question_answer_similarity": [
                    6.861212283256464,
                    5.478502219542861,
                    9.174016278237104
                ],
                "result_count_bing": [
                    20900.0,
                    40100.0,
                    110000.0
                ],
                "result_count": [
                    12400.0,
                    9930.0,
                    8230.0
                ],
                "word_count_appended": [
                    41.0,
                    28.0,
                    89.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which of these products was featured on \u201cShark Tank\u201d?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "scrub daddy"
            ],
            "lines": [
                [
                    0.006666666666666667,
                    0.10416666666666666,
                    0.3683393131998138,
                    0.006250887910214519,
                    0.6044905008635578,
                    4.021853481760894e-05,
                    0.7976011994002998,
                    0.03125,
                    0.11191335740072202,
                    0.2559674329145904,
                    -1.0
                ],
                [
                    0.7619047619047619,
                    0.75,
                    0.2753979538597314,
                    0.7955675522091206,
                    0.20552677029360966,
                    0.020955973404964662,
                    0.10314842578710645,
                    0.84375,
                    0.6462093862815884,
                    0.5049720132623191,
                    -1.0
                ],
                [
                    0.23142857142857143,
                    0.14583333333333331,
                    0.35626273294045474,
                    0.19818155988066485,
                    0.18998272884283246,
                    0.9790038080602177,
                    0.0992503748125937,
                    0.125,
                    0.24187725631768953,
                    0.23906055382309058,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "scrub daddy": 0.49074328370032017,
                "sticky buddy": 0.28058809194394485,
                "instant pot": 0.22866862435573493
            },
            "question": "which of these products was featured on \u201cshark tank\u201d?",
            "rate_limited": false,
            "answers": [
                "instant pot",
                "scrub daddy",
                "sticky buddy"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "scrub daddy": 0.4318157351400259,
                "sticky buddy": 0.14429542047080754,
                "instant pot": 0.3784734714488044
            },
            "integer_answers": {
                "scrub daddy": 6,
                "sticky buddy": 1,
                "instant pot": 3
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.0238697316583616,
                    2.0198880530492764,
                    0.9562422152923623
                ],
                "result_count_important_words": [
                    76.0,
                    39600.0,
                    1850000.0
                ],
                "wikipedia_search": [
                    0.125,
                    3.375,
                    0.5
                ],
                "answer_relation_to_question": [
                    0.02666666666666667,
                    3.0476190476190474,
                    0.9257142857142857
                ],
                "answer_relation_to_question_bing": [
                    0.41666666666666663,
                    3.0,
                    0.5833333333333333
                ],
                "result_count_noun_chunks": [
                    266000.0,
                    34400.0,
                    33100.0
                ],
                "question_answer_similarity": [
                    4.791550762951374,
                    3.5825208676978946,
                    4.634452279889956
                ],
                "result_count_bing": [
                    3500000.0,
                    1190000.0,
                    1100000.0
                ],
                "word_count_appended": [
                    31.0,
                    179.0,
                    67.0
                ],
                "result_count": [
                    88.0,
                    11200.0,
                    2790.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "What are the first words spoken by God in the King James Bible?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "let there be light"
            ],
            "lines": [
                [
                    0.27824749289555883,
                    0.7289562289562289,
                    0.3809094603511877,
                    0.9997652066560127,
                    0.4981432360742706,
                    0.9997252663390214,
                    0.016222543589290542,
                    0.5000000000000001,
                    0.8738738738738738,
                    0.7403375779711734,
                    1.0
                ],
                [
                    0.2592621949787454,
                    0.23400673400673402,
                    0.27323773210923086,
                    6.0591830706425004e-05,
                    0.0779840848806366,
                    9.157788699288744e-05,
                    7.166585521373331e-07,
                    0.33333333333333337,
                    0.04504504504504504,
                    0.09507900359568966,
                    1.0
                ],
                [
                    0.4624903121256958,
                    0.037037037037037035,
                    0.3458528075395815,
                    0.0001742015132809719,
                    0.42387267904509285,
                    0.0001831557739857749,
                    0.9837767397521573,
                    0.16666666666666669,
                    0.08108108108108109,
                    0.16458341843313698,
                    1.0
                ]
            ],
            "fraction_answers": {
                "hello, my children": 0.13181010143256663,
                "let there be light": 0.6016180886706618,
                "this is my gift": 0.26657180989677154
            },
            "question": "what are the first words spoken by god in the king james bible?",
            "rate_limited": false,
            "answers": [
                "let there be light",
                "hello, my children",
                "this is my gift"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "hello, my children": 0.18656392672845115,
                "let there be light": 0.4581020770693755,
                "this is my gift": 0.38026526514226805
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    4.44202546782704,
                    0.570474021574138,
                    0.9875005105988219
                ],
                "result_count_important_words": [
                    131000.0,
                    12.0,
                    24.0
                ],
                "wikipedia_search": [
                    1.0,
                    0.6666666666666666,
                    0.3333333333333333
                ],
                "answer_relation_to_question": [
                    1.669484957373353,
                    1.5555731698724724,
                    2.774941872754175
                ],
                "answer_relation_to_question_bing": [
                    2.186868686868687,
                    0.7020202020202021,
                    0.1111111111111111
                ],
                "result_count_noun_chunks": [
                    498000.0,
                    22.0,
                    30200000.0
                ],
                "question_answer_similarity": [
                    21.874170124530792,
                    15.690995521843433,
                    19.861000940203667
                ],
                "result_count_bing": [
                    939000.0,
                    147000.0,
                    799000.0
                ],
                "result_count": [
                    132000.0,
                    8.0,
                    23.0
                ],
                "word_count_appended": [
                    97.0,
                    5.0,
                    9.0
                ]
            },
            "integer_answers": {
                "hello, my children": 0,
                "let there be light": 8,
                "this is my gift": 2
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which of these grape varieties is typically white?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "riesling"
            ],
            "lines": [
                [
                    0.6372834351714997,
                    0.6797385620915033,
                    0.2126182900314809,
                    0.23489278752436646,
                    0.5245628642797668,
                    0.14643019554342884,
                    0.2794923565041823,
                    0.646306572358468,
                    0.3447905477980666,
                    0.3582853246407317,
                    -1.0
                ],
                [
                    0.3193218238428289,
                    0.26143790849673204,
                    0.41102817302529326,
                    0.14717348927875243,
                    0.021053883668371597,
                    0.098681218735789,
                    0.4441880588404961,
                    0.3536934276415321,
                    0.35660580021482274,
                    0.32792594519814894,
                    -1.0
                ],
                [
                    0.04339474098567155,
                    0.05882352941176472,
                    0.3763535369432258,
                    0.6179337231968811,
                    0.45438325205186153,
                    0.7548885857207822,
                    0.2763195846553216,
                    0.0,
                    0.29860365198711064,
                    0.31378873016111947,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "riesling": 0.40644009359434946,
                "concord": 0.3194489335113738,
                "merlot": 0.27411097289427666
            },
            "question": "which of these grape varieties is typically white?",
            "rate_limited": false,
            "answers": [
                "riesling",
                "merlot",
                "concord"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "riesling": 0.4727941863905904,
                "concord": 0.17759367929346728,
                "merlot": 0.33396156266774674
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.4331412985629266,
                    1.3117037807925955,
                    1.2551549206444776
                ],
                "result_count_important_words": [
                    322000.0,
                    217000.0,
                    1660000.0
                ],
                "wikipedia_search": [
                    2.585226289433872,
                    1.4147737105661284,
                    0.0
                ],
                "answer_relation_to_question": [
                    1.9118503055144989,
                    0.9579654715284868,
                    0.13018422295701465
                ],
                "answer_relation_to_question_bing": [
                    2.0392156862745097,
                    0.7843137254901961,
                    0.17647058823529413
                ],
                "result_count_noun_chunks": [
                    969000.0,
                    1540000.0,
                    958000.0
                ],
                "question_answer_similarity": [
                    0.5918847410939634,
                    1.1442162559833378,
                    1.047689339146018
                ],
                "result_count_bing": [
                    4410000.0,
                    177000.0,
                    3820000.0
                ],
                "result_count": [
                    241000.0,
                    151000.0,
                    634000.0
                ],
                "word_count_appended": [
                    321.0,
                    332.0,
                    278.0
                ]
            },
            "integer_answers": {
                "riesling": 5,
                "concord": 2,
                "merlot": 3
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "The inventor of the Erector Set made another toy that contained what?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "uranium ore"
            ],
            "lines": [
                [
                    0.3686886708296164,
                    0.1819620253164557,
                    0.23705153961247064,
                    0.6164383561643836,
                    0.1588785046728972,
                    0.3258426966292135,
                    0.37168141592920356,
                    0.2516666666666667,
                    0.6086956521739131,
                    0.5599776598464411,
                    1.0
                ],
                [
                    0.21366636931311328,
                    0.634493670886076,
                    0.44099157939983646,
                    0.2191780821917808,
                    0.37595581988105353,
                    0.550561797752809,
                    0.504424778761062,
                    0.12666666666666668,
                    0.2391304347826087,
                    0.274141148172875,
                    1.0
                ],
                [
                    0.4176449598572703,
                    0.18354430379746836,
                    0.3219568809876929,
                    0.1643835616438356,
                    0.46516567544604925,
                    0.12359550561797752,
                    0.12389380530973451,
                    0.6216666666666667,
                    0.15217391304347827,
                    0.16588119198068382,
                    1.0
                ]
            ],
            "fraction_answers": {
                "asbestos powder": 0.2739906464350857,
                "uranium ore": 0.3680883187841261,
                "live ants": 0.3579210347807882
            },
            "question": "the inventor of the erector set made another toy that contained what?",
            "rate_limited": false,
            "answers": [
                "uranium ore",
                "live ants",
                "asbestos powder"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "asbestos powder": 0.17727771920882973,
                "uranium ore": 0.49880159536846214,
                "live ants": 0.18102957556684324
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    2.799888299232206,
                    1.3707057408643752,
                    0.8294059599034193
                ],
                "result_count_important_words": [
                    29.0,
                    49.0,
                    11.0
                ],
                "wikipedia_search": [
                    0.5033333333333334,
                    0.25333333333333335,
                    1.2433333333333334
                ],
                "answer_relation_to_question": [
                    1.4747546833184657,
                    0.8546654772524531,
                    1.6705798394290812
                ],
                "answer_relation_to_question_bing": [
                    0.3639240506329114,
                    1.268987341772152,
                    0.3670886075949367
                ],
                "result_count_noun_chunks": [
                    42.0,
                    57.0,
                    14.0
                ],
                "question_answer_similarity": [
                    2.8342179199680686,
                    5.272550597786903,
                    3.8493568236008286
                ],
                "result_count_bing": [
                    7480.0,
                    17700.0,
                    21900.0
                ],
                "word_count_appended": [
                    28.0,
                    11.0,
                    7.0
                ],
                "result_count": [
                    45.0,
                    16.0,
                    12.0
                ]
            },
            "integer_answers": {
                "asbestos powder": 3,
                "uranium ore": 3,
                "live ants": 4
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which of these outfits can be defined as a \u201cCanadian tuxedo\u201d?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "jean jacket / jeans"
            ],
            "lines": [
                [
                    0.3333333333333333,
                    0.3333333333333333,
                    0.2512944300771902,
                    0.0,
                    0.32437619961612285,
                    0.6301369863013698,
                    8.787127096293851e-05,
                    0.0,
                    0.3333333333333333,
                    0.2738444471835326,
                    -1.0
                ],
                [
                    0.4615384615384615,
                    0.3333333333333333,
                    0.46840606948299485,
                    0.0,
                    0.35572616762635956,
                    0.0410958904109589,
                    7.955912370968757e-05,
                    0.1111111111111111,
                    0.3333333333333333,
                    0.30807500308147423,
                    -1.0
                ],
                [
                    0.20512820512820515,
                    0.3333333333333333,
                    0.28029950043981494,
                    1.0,
                    0.3198976327575176,
                    0.3287671232876712,
                    0.9998325696053274,
                    0.8888888888888888,
                    0.3333333333333333,
                    0.41808054973499326,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "wool sweater / slacks": 0.24797399344491788,
                "cotton t-shirt / shorts": 0.24126989290417367,
                "jean jacket / jeans": 0.5107561136509086
            },
            "question": "which of these outfits can be defined as a \u201ccanadian tuxedo\u201d?",
            "rate_limited": false,
            "answers": [
                "wool sweater / slacks",
                "cotton t-shirt / shorts",
                "jean jacket / jeans"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "wool sweater / slacks": 0.18925749138396367,
                "cotton t-shirt / shorts": 0.32471375454250334,
                "jean jacket / jeans": 0.6978368670522547
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.0953777887341303,
                    1.2323000123258967,
                    1.6723221989399728
                ],
                "result_count_important_words": [
                    46.0,
                    3.0,
                    24.0
                ],
                "wikipedia_search": [
                    0.0,
                    0.3333333333333333,
                    2.6666666666666665
                ],
                "answer_relation_to_question": [
                    1.0,
                    1.3846153846153846,
                    0.6153846153846154
                ],
                "answer_relation_to_question_bing": [
                    0.3333333333333333,
                    0.3333333333333333,
                    0.3333333333333333
                ],
                "result_count_noun_chunks": [
                    74.0,
                    67.0,
                    842000.0
                ],
                "question_answer_similarity": [
                    8.091569856274873,
                    15.082468923646957,
                    9.025520334020257
                ],
                "result_count_bing": [
                    50700.0,
                    55600.0,
                    50000.0
                ],
                "result_count": [
                    0,
                    0,
                    11.0
                ],
                "word_count_appended": [
                    3.0,
                    3.0,
                    3.0
                ]
            },
            "integer_answers": {
                "wool sweater / slacks": 3,
                "cotton t-shirt / shorts": 3,
                "jean jacket / jeans": 4
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which of these creatures is most likely to bark?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "dog"
            ],
            "lines": [
                [
                    0.0,
                    0.0,
                    0.07340714686114677,
                    2.529118913334877e-05,
                    0.18562644119907765,
                    2.7973975869767452e-05,
                    0.4029680365296804,
                    0.038461538461538464,
                    0.21137440758293838,
                    0.28684490921944206,
                    -1.0
                ],
                [
                    0.6666666666666666,
                    0.0,
                    0.5597380241609013,
                    0.08838019938906493,
                    0.10338201383551114,
                    5.1186423931914916e-05,
                    0.16552511415525115,
                    0.2692307692307692,
                    0.15450236966824646,
                    0.30178998099769144,
                    -1.0
                ],
                [
                    0.3333333333333333,
                    1.0,
                    0.36685482897795185,
                    0.9115945094218018,
                    0.7109915449654112,
                    0.9999208396001983,
                    0.4315068493150685,
                    0.6923076923076923,
                    0.6341232227488152,
                    0.4113651097828665,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "blue whale": 0.23092663245280337,
                "mime": 0.1198735745018827,
                "dog": 0.6491997930453139
            },
            "question": "which of these creatures is most likely to bark?",
            "rate_limited": false,
            "answers": [
                "mime",
                "blue whale",
                "dog"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "blue whale": 0.22363237741484862,
                "mime": 0.17962674237195894,
                "dog": 0.44721741089142497
            },
            "integer_answers": {
                "blue whale": 2,
                "mime": 0,
                "dog": 8
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    0.8605347276583262,
                    0.9053699429930744,
                    1.2340953293485994
                ],
                "result_count_important_words": [
                    47.0,
                    86.0,
                    1680000.0
                ],
                "wikipedia_search": [
                    0.07692307692307693,
                    0.5384615384615384,
                    1.3846153846153846
                ],
                "answer_relation_to_question": [
                    0.0,
                    1.3333333333333333,
                    0.6666666666666666
                ],
                "answer_relation_to_question_bing": [
                    0.0,
                    0.0,
                    1.0
                ],
                "result_count_noun_chunks": [
                    3530000.0,
                    1450000.0,
                    3780000.0
                ],
                "question_answer_similarity": [
                    0.6018534117611125,
                    4.58920219540596,
                    3.0077838450670242
                ],
                "result_count_bing": [
                    4830000.0,
                    2690000.0,
                    18500000.0
                ],
                "result_count": [
                    91.0,
                    318000.0,
                    3280000.0
                ],
                "word_count_appended": [
                    223.0,
                    163.0,
                    669.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which of these phrases, written backwards, is a hip hop group?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "blues rhythm"
            ],
            "lines": [
                [
                    0.5451457194899818,
                    0.5128205128205128,
                    0.3006900407745902,
                    0.0007348851990148566,
                    0.11234148955170566,
                    0.0006232835355758556,
                    0.0010318431598397044,
                    0.45426458424560895,
                    0.3055555555555556,
                    0.21146721071950195,
                    -1.0
                ],
                [
                    0.25984517304189436,
                    0.22435897435897434,
                    0.30967054954573076,
                    0.0002184793834909033,
                    0.35006251116270765,
                    0.00017529849438070939,
                    0.0007198905766323518,
                    0.0,
                    0.2777777777777778,
                    0.14867319539089327,
                    -1.0
                ],
                [
                    0.19500910746812386,
                    0.26282051282051283,
                    0.389639409679679,
                    0.9990466354174943,
                    0.5375959992855867,
                    0.9992014179700435,
                    0.9982482662635279,
                    0.545735415754391,
                    0.4166666666666667,
                    0.6398595938896047,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "beat chefs": 0.15715018497324823,
                "drummers ear": 0.24446751250518872,
                "blues rhythm": 0.598382302521563
            },
            "question": "which of these phrases, written backwards, is a hip hop group?",
            "rate_limited": false,
            "answers": [
                "drummers ear",
                "beat chefs",
                "blues rhythm"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "beat chefs": 0.1939278289317177,
                "drummers ear": 0.17582467931916962,
                "blues rhythm": 0.40258391884874273
            },
            "integer_answers": {
                "beat chefs": 0,
                "drummers ear": 2,
                "blues rhythm": 8
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.2688032643170117,
                    0.8920391723453597,
                    3.8391575633376283
                ],
                "result_count_important_words": [
                    32.0,
                    9.0,
                    51300.0
                ],
                "wikipedia_search": [
                    1.8170583369824358,
                    0.0,
                    2.182941663017564
                ],
                "answer_relation_to_question": [
                    2.725728597449909,
                    1.2992258652094717,
                    0.9750455373406193
                ],
                "answer_relation_to_question_bing": [
                    2.051282051282051,
                    0.8974358974358974,
                    1.0512820512820513
                ],
                "result_count_noun_chunks": [
                    43.0,
                    30.0,
                    41600.0
                ],
                "question_answer_similarity": [
                    4.85761278308928,
                    5.0026918621733785,
                    6.2945795357227325
                ],
                "result_count_bing": [
                    62900.0,
                    196000.0,
                    301000.0
                ],
                "word_count_appended": [
                    11.0,
                    10.0,
                    15.0
                ],
                "result_count": [
                    37.0,
                    11.0,
                    50300.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which of these is a French territory?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "french guiana"
            ],
            "lines": [
                [
                    0.6582594235033259,
                    0.7190594059405941,
                    0.22107387686146088,
                    0.9956904374909594,
                    0.10704960835509138,
                    0.9998604257746405,
                    0.9997514934411422,
                    0.48484848484848486,
                    0.5769230769230769,
                    0.5168333747147638,
                    -1.0
                ],
                [
                    0.1917960088691796,
                    0.18193069306930695,
                    0.3876407651729475,
                    0.004298978398090888,
                    0.44386422976501305,
                    0.00013366417225296637,
                    0.0002472270504388074,
                    0.18181818181818182,
                    0.35,
                    0.31181055581172634,
                    -1.0
                ],
                [
                    0.14994456762749447,
                    0.09900990099009903,
                    0.3912853579655916,
                    1.0584110949707049e-05,
                    0.4490861618798956,
                    5.910053106479199e-06,
                    1.2795084189376875e-06,
                    0.3333333333333333,
                    0.07307692307692308,
                    0.17135606947350995,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "french guiana": 0.6279349607853539,
                "french stewart": 0.20535403041271377,
                "french cyprus": 0.16671100880193218
            },
            "question": "which of these is a french territory?",
            "rate_limited": false,
            "answers": [
                "french guiana",
                "french stewart",
                "french cyprus"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "french guiana": 0.6800759067258717,
                "french stewart": 0.18591099076218698,
                "french cyprus": 0.1898758105780399
            },
            "integer_answers": {
                "french guiana": 8,
                "french stewart": 0,
                "french cyprus": 2
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.0336667494295275,
                    0.6236211116234527,
                    0.3427121389470199
                ],
                "result_count_important_words": [
                    76300000.0,
                    10200.0,
                    451.0
                ],
                "wikipedia_search": [
                    0.9696969696969697,
                    0.36363636363636365,
                    0.6666666666666666
                ],
                "answer_relation_to_question": [
                    1.3165188470066518,
                    0.3835920177383592,
                    0.29988913525498895
                ],
                "answer_relation_to_question_bing": [
                    1.438118811881188,
                    0.36386138613861385,
                    0.19801980198019803
                ],
                "result_count_noun_chunks": [
                    46100000.0,
                    11400.0,
                    59.0
                ],
                "question_answer_similarity": [
                    1.5891291573643684,
                    2.786449721083045,
                    2.8126478805206716
                ],
                "result_count_bing": [
                    4100000.0,
                    17000000.0,
                    17200000.0
                ],
                "word_count_appended": [
                    150.0,
                    91.0,
                    19.0
                ],
                "result_count": [
                    7620000.0,
                    32900.0,
                    81.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "What makeup item often contains dried cochineal bugs as an ingredient?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "lipstick"
            ],
            "lines": [
                [
                    0.33221112344308795,
                    0.35580349420515484,
                    0.3281592940631894,
                    0.12008599508599509,
                    0.45268924302788843,
                    0.8399718837863168,
                    0.11779201577131591,
                    0.1989795918367347,
                    0.2585227272727273,
                    0.3401234613928182,
                    1.0
                ],
                [
                    0.3977309162658774,
                    0.22941532606815432,
                    0.2816521449245784,
                    0.7278869778869779,
                    0.1150398406374502,
                    0.082825679475164,
                    0.7195662888122227,
                    0.07312925170068027,
                    0.21164772727272727,
                    0.2891590610500279,
                    1.0
                ],
                [
                    0.2700579602910347,
                    0.4147811797266909,
                    0.39018856101223226,
                    0.15202702702702703,
                    0.43227091633466136,
                    0.07720243673851922,
                    0.1626416954164613,
                    0.7278911564625851,
                    0.5298295454545454,
                    0.3707174775571539,
                    1.0
                ]
            ],
            "fraction_answers": {
                "mascara": 0.3344338829885229,
                "eyeliner": 0.31280532140938605,
                "lipstick": 0.3527607956020911
            },
            "question": "what makeup item often contains dried cochineal bugs as an ingredient?",
            "rate_limited": false,
            "answers": [
                "mascara",
                "eyeliner",
                "lipstick"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "mascara": 0.4340784494595492,
                "eyeliner": 0.1696670315089333,
                "lipstick": 0.4410718499804481
            },
            "integer_answers": {
                "mascara": 2,
                "eyeliner": 3,
                "lipstick": 5
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    2.380864229749727,
                    2.0241134273501955,
                    2.5950223429000774
                ],
                "result_count_important_words": [
                    71700.0,
                    7070.0,
                    6590.0
                ],
                "wikipedia_search": [
                    1.3928571428571428,
                    0.5119047619047619,
                    5.095238095238096
                ],
                "answer_relation_to_question": [
                    1.6610556172154398,
                    1.9886545813293872,
                    1.3502898014551734
                ],
                "answer_relation_to_question_bing": [
                    1.4232139768206191,
                    0.9176613042726172,
                    1.6591247189067633
                ],
                "result_count_noun_chunks": [
                    9560.0,
                    58400.0,
                    13200.0
                ],
                "question_answer_similarity": [
                    2.2088891826570034,
                    1.8958426211029291,
                    2.6264174357056618
                ],
                "result_count_bing": [
                    90900.0,
                    23100.0,
                    86800.0
                ],
                "result_count": [
                    7820.0,
                    47400.0,
                    9900.0
                ],
                "word_count_appended": [
                    182.0,
                    149.0,
                    373.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "What term describes a person from the state between New York and Rhode Island?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "hoosier"
            ],
            "lines": [
                [
                    0.2500587037284285,
                    0.35757241040746196,
                    0.8662525025803617,
                    0.5968815981809322,
                    0.3385416666666667,
                    0.6471021186419746,
                    0.0010175793353119598,
                    0.2922962962962963,
                    0.27232142857142855,
                    0.2956149880995719,
                    1.0
                ],
                [
                    0.4508321306486444,
                    0.27706952626411385,
                    -0.0,
                    0.02793568296248173,
                    0.3385416666666667,
                    0.004648267890397696,
                    0.0009719187241120641,
                    0.0654074074074074,
                    0.30357142857142855,
                    0.3220905595082995,
                    1.0
                ],
                [
                    0.29910916562292705,
                    0.36535806332842413,
                    0.13374749741963826,
                    0.375182718856586,
                    0.3229166666666667,
                    0.3482496134676276,
                    0.998010501940576,
                    0.6422962962962963,
                    0.42410714285714285,
                    0.3822944523921286,
                    1.0
                ]
            ],
            "fraction_answers": {
                "hoosier": 0.42912721188480135,
                "nutmegger": 0.1791068588643552,
                "cheesehead": 0.3917659292508434
            },
            "question": "what term describes a person from the state between new york and rhode island?",
            "rate_limited": false,
            "answers": [
                "cheesehead",
                "nutmegger",
                "hoosier"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "hoosier": 0.7182946967646568,
                "nutmegger": 0.25034516619724345,
                "cheesehead": 0.18582391854454794
            },
            "integer_answers": {
                "hoosier": 5,
                "nutmegger": 1,
                "cheesehead": 3
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    2.364919904796575,
                    2.576724476066396,
                    3.058355619137029
                ],
                "result_count_important_words": [
                    131000.0,
                    941.0,
                    70500.0
                ],
                "wikipedia_search": [
                    1.4614814814814814,
                    0.327037037037037,
                    3.2114814814814814
                ],
                "answer_relation_to_question": [
                    1.500352222370571,
                    2.704992783891867,
                    1.7946549937375627
                ],
                "answer_relation_to_question_bing": [
                    1.4302896416298478,
                    1.1082781050564554,
                    1.4614322533136965
                ],
                "result_count_noun_chunks": [
                    15600.0,
                    14900.0,
                    15300000.0
                ],
                "question_answer_similarity": [
                    -1.2163297208026052,
                    0.0,
                    -0.1877986565232277
                ],
                "result_count_bing": [
                    32500000.0,
                    32500000.0,
                    31000000.0
                ],
                "result_count": [
                    73500.0,
                    3440.0,
                    46200.0
                ],
                "word_count_appended": [
                    122.0,
                    136.0,
                    190.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Where in the home does the Maillard reaction typically occur?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "kitchen"
            ],
            "lines": [
                [
                    0.6674107142857143,
                    0.3829787234042553,
                    0.36107745697333116,
                    0.6703865762113123,
                    0.41836734693877553,
                    0.7821698906644239,
                    0.7828511910761684,
                    0.7032784793978824,
                    0.5694444444444444,
                    0.514133118372379,
                    3.0
                ],
                [
                    0.16294642857142858,
                    0.3191489361702128,
                    0.29718541806908144,
                    0.32756613544217417,
                    0.22157434402332363,
                    0.216148023549201,
                    0.21615204560472176,
                    0.12590891695369308,
                    0.2400793650793651,
                    0.26575561424849686,
                    3.0
                ],
                [
                    0.16964285714285715,
                    0.2978723404255319,
                    0.34173712495758735,
                    0.002047288346513588,
                    0.36005830903790087,
                    0.001682085786375105,
                    0.0009967633191098567,
                    0.17081260364842454,
                    0.19047619047619047,
                    0.22011126737912426,
                    3.0
                ]
            ],
            "fraction_answers": {
                "bathroom": 0.17554368305196152,
                "bedroom": 0.23924652277116984,
                "kitchen": 0.5852097941768686
            },
            "question": "where in the home does the maillard reaction typically occur?",
            "rate_limited": false,
            "answers": [
                "kitchen",
                "bedroom",
                "bathroom"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "bathroom": 0.14397009605180525,
                "bedroom": 0.11089226797187203,
                "kitchen": 0.6024336648864341
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 3
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    2.5706655918618946,
                    1.3287780712424844,
                    1.1005563368956213
                ],
                "result_count_important_words": [
                    27900.0,
                    7710.0,
                    60.0
                ],
                "wikipedia_search": [
                    2.109835438193647,
                    0.3777267508610792,
                    0.5124378109452736
                ],
                "answer_relation_to_question": [
                    1.3348214285714286,
                    0.32589285714285715,
                    0.3392857142857143
                ],
                "answer_relation_to_question_bing": [
                    0.3829787234042553,
                    0.3191489361702128,
                    0.2978723404255319
                ],
                "result_count_noun_chunks": [
                    69900.0,
                    19300.0,
                    89.0
                ],
                "question_answer_similarity": [
                    2.3942533154040575,
                    1.9705942831933498,
                    2.266010321676731
                ],
                "result_count_bing": [
                    287000.0,
                    152000.0,
                    247000.0
                ],
                "result_count": [
                    16700.0,
                    8160.0,
                    51.0
                ],
                "word_count_appended": [
                    287.0,
                    121.0,
                    96.0
                ]
            },
            "integer_answers": {
                "bathroom": 0,
                "bedroom": 0,
                "kitchen": 10
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Who is the director of \u201cTyler Perry\u2019s Madea\u2019s Family Reunion\u201d?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "tyler perry"
            ],
            "lines": [
                [
                    0.8884426037211485,
                    0.8166666666666667,
                    0.4348694138685192,
                    0.564625850340136,
                    0.5378442854044676,
                    0.4644149577804584,
                    0.5684931506849316,
                    0.6392543859649122,
                    0.8290909090909091,
                    0.715941102674356,
                    0.0
                ],
                [
                    0.08716312056737589,
                    0.10925925925925925,
                    0.3171647754190037,
                    0.2585034013605442,
                    0.21492084146605941,
                    0.49155609167671893,
                    0.2602739726027397,
                    0.15021929824561403,
                    0.08727272727272728,
                    0.1398267942388697,
                    0.0
                ],
                [
                    0.024394275711475646,
                    0.07407407407407407,
                    0.24796581071247714,
                    0.17687074829931973,
                    0.247234873129473,
                    0.04402895054282268,
                    0.17123287671232876,
                    0.21052631578947367,
                    0.08363636363636363,
                    0.1442321030867744,
                    0.0
                ]
            ],
            "fraction_answers": {
                "george lucas": 0.2116160282108912,
                "abraham lincoln": 0.14241963916945827,
                "tyler perry": 0.6459643326196505
            },
            "question": "who is the director of \u201ctyler perry\u2019s madea\u2019s family reunion\u201d?",
            "rate_limited": false,
            "answers": [
                "tyler perry",
                "george lucas",
                "abraham lincoln"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "george lucas": 0.15329545742094602,
                "abraham lincoln": 0.14830662400076883,
                "tyler perry": 0.62859599020155
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 0
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    4.2956466160461355,
                    0.8389607654332182,
                    0.8653926185206463
                ],
                "result_count_important_words": [
                    154000.0,
                    163000.0,
                    14600.0
                ],
                "wikipedia_search": [
                    3.8355263157894735,
                    0.9013157894736842,
                    1.263157894736842
                ],
                "answer_relation_to_question": [
                    5.330655622326891,
                    0.5229787234042553,
                    0.14636565426885387
                ],
                "answer_relation_to_question_bing": [
                    4.083333333333333,
                    0.5462962962962963,
                    0.37037037037037035
                ],
                "result_count_noun_chunks": [
                    83.0,
                    38.0,
                    25.0
                ],
                "question_answer_similarity": [
                    5.762457792647183,
                    4.202752765268087,
                    3.2857967764139175
                ],
                "result_count_bing": [
                    248000.0,
                    99100.0,
                    114000.0
                ],
                "result_count": [
                    83.0,
                    38.0,
                    26.0
                ],
                "word_count_appended": [
                    228.0,
                    24.0,
                    23.0
                ]
            },
            "integer_answers": {
                "george lucas": 1,
                "abraham lincoln": 0,
                "tyler perry": 9
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "The first person to lead an expedition to the South Pole came from what country?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "canada"
            ],
            "lines": [
                [
                    0.15250206782464845,
                    0.15733333333333333,
                    0.24177599908722341,
                    0.3707865168539326,
                    0.06917363045496751,
                    0.34600760456273766,
                    0.4575642491416125,
                    0.3841568718276065,
                    0.34069400630914826,
                    0.3742919380587955,
                    1.0
                ],
                [
                    0.44948008980267046,
                    0.30133333333333334,
                    0.12069222672759346,
                    0.26591760299625467,
                    0.15088207985143917,
                    0.2737642585551331,
                    2.5150882568711152e-05,
                    0.3842689900612428,
                    0.27602523659305994,
                    0.2686605451924486,
                    1.0
                ],
                [
                    0.3980178423726811,
                    0.5413333333333333,
                    0.6375317741851831,
                    0.36329588014981273,
                    0.7799442896935933,
                    0.38022813688212925,
                    0.5424105999758188,
                    0.23157413811115066,
                    0.3832807570977918,
                    0.3570475167487559,
                    1.0
                ]
            ],
            "fraction_answers": {
                "canada": 0.461466426855025,
                "iceland": 0.2491049513995744,
                "norway": 0.28942862174540057
            },
            "question": "the first person to lead an expedition to the south pole came from what country?",
            "rate_limited": false,
            "answers": [
                "norway",
                "iceland",
                "canada"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "canada": 0.6265079187220989,
                "iceland": 0.15305284074121187,
                "norway": 0.3520255306072356
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    2.6200435664115687,
                    1.88062381634714,
                    2.4993326172412913
                ],
                "result_count_important_words": [
                    91.0,
                    72.0,
                    100.0
                ],
                "wikipedia_search": [
                    2.6890981027932455,
                    2.6898829304286997,
                    1.6210189667780546
                ],
                "answer_relation_to_question": [
                    1.0675144747725391,
                    3.146360628618693,
                    2.7861248966087677
                ],
                "answer_relation_to_question_bing": [
                    0.7866666666666666,
                    1.5066666666666666,
                    2.7066666666666666
                ],
                "result_count_noun_chunks": [
                    1510000.0,
                    83.0,
                    1790000.0
                ],
                "question_answer_similarity": [
                    1.361483957618475,
                    0.6796395470155403,
                    3.590055614709854
                ],
                "result_count_bing": [
                    149000.0,
                    325000.0,
                    1680000.0
                ],
                "word_count_appended": [
                    216.0,
                    175.0,
                    243.0
                ],
                "result_count": [
                    99.0,
                    71.0,
                    97.0
                ]
            },
            "integer_answers": {
                "canada": 6,
                "iceland": 2,
                "norway": 2
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which of these modes of transportation has only one wheel?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "bus"
            ],
            "lines": [
                [
                    0.09090909090909091,
                    0.0,
                    0.6515017310824474,
                    0.30623818525519847,
                    0.13217837664420917,
                    0.022014886256421007,
                    0.30700179533213645,
                    0.09574468085106383,
                    0.10963455149501661,
                    0.2683094481097097,
                    -1.0
                ],
                [
                    0.4846394984326019,
                    0.5,
                    0.33917109880097696,
                    0.4612476370510397,
                    0.6993904395251844,
                    0.9686549952825244,
                    0.473967684021544,
                    0.5425531914893617,
                    0.39867109634551495,
                    0.3761548768184437,
                    -1.0
                ],
                [
                    0.4244514106583072,
                    0.5,
                    0.009327170116575717,
                    0.23251417769376181,
                    0.16843118383060635,
                    0.009330118461054618,
                    0.21903052064631956,
                    0.3617021276595745,
                    0.49169435215946844,
                    0.3555356750718466,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "unicycle": 0.27720167362975145,
                "bus": 0.5244450517767192,
                "monster truck": 0.19835327459352933
            },
            "question": "which of these modes of transportation has only one wheel?",
            "rate_limited": false,
            "answers": [
                "monster truck",
                "bus",
                "unicycle"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "unicycle": 0.4353139591099019,
                "bus": 0.6069509685565283,
                "monster truck": 0.2026779059169742
            },
            "integer_answers": {
                "unicycle": 1,
                "bus": 8,
                "monster truck": 1
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    0.8049283443291291,
                    1.128464630455331,
                    1.0666070252155397
                ],
                "result_count_important_words": [
                    1050000.0,
                    46200000.0,
                    445000.0
                ],
                "wikipedia_search": [
                    0.19148936170212766,
                    1.0851063829787233,
                    0.723404255319149
                ],
                "answer_relation_to_question": [
                    0.18181818181818182,
                    0.9692789968652038,
                    0.8489028213166144
                ],
                "answer_relation_to_question_bing": [
                    0.0,
                    1.0,
                    1.0
                ],
                "result_count_noun_chunks": [
                    1710000.0,
                    2640000.0,
                    1220000.0
                ],
                "question_answer_similarity": [
                    5.47492903470993,
                    2.8502421528100967,
                    0.07838136423379183
                ],
                "result_count_bing": [
                    412000.0,
                    2180000.0,
                    525000.0
                ],
                "result_count": [
                    1620000.0,
                    2440000.0,
                    1230000.0
                ],
                "word_count_appended": [
                    99.0,
                    360.0,
                    444.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Who defeated Napoleon at the Battle of Waterloo?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "the duke of wellington"
            ],
            "lines": [
                [
                    0.0,
                    0.0,
                    0.05217046836658575,
                    0.15239154616240266,
                    0.3326551373346897,
                    0.07036797934151065,
                    0.0003233277685765,
                    0.0375,
                    0.14345991561181434,
                    0.1548963689008156,
                    0.0
                ],
                [
                    0.9691506410256411,
                    1.0,
                    0.7759516233692595,
                    0.7230255839822024,
                    0.3336724313326551,
                    0.8392511297611362,
                    0.9105965727256531,
                    0.9625,
                    0.4177215189873418,
                    0.5430219935438354,
                    0.0
                ],
                [
                    0.030849358974358976,
                    0.0,
                    0.17187790826415475,
                    0.12458286985539488,
                    0.3336724313326551,
                    0.09038089089735313,
                    0.08908009950577041,
                    0.0,
                    0.4388185654008439,
                    0.302081637555349,
                    0.0
                ]
            ],
            "fraction_answers": {
                "jack skellington": 0.09437647434863952,
                "beef wellington": 0.158134376178588,
                "the duke of wellington": 0.7474891494727726
            },
            "question": "who defeated napoleon at the battle of waterloo?",
            "rate_limited": false,
            "answers": [
                "jack skellington",
                "the duke of wellington",
                "beef wellington"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "jack skellington": 0.18248396633023328,
                "beef wellington": 0.22637827720841625,
                "the duke of wellington": 0.687718449821491
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 0
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    0.6195854756032624,
                    2.1720879741753416,
                    1.208326550221396
                ],
                "result_count_important_words": [
                    10900.0,
                    130000.0,
                    14000.0
                ],
                "wikipedia_search": [
                    0.15,
                    3.85,
                    0.0
                ],
                "answer_relation_to_question": [
                    0.0,
                    3.8766025641025643,
                    0.1233974358974359
                ],
                "answer_relation_to_question_bing": [
                    0.0,
                    4.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    98.0,
                    276000.0,
                    27000.0
                ],
                "question_answer_similarity": [
                    0.6204546950757504,
                    9.228263478260487,
                    2.0441153491847217
                ],
                "result_count_bing": [
                    327000.0,
                    328000.0,
                    328000.0
                ],
                "word_count_appended": [
                    34.0,
                    99.0,
                    104.0
                ],
                "result_count": [
                    13700.0,
                    65000.0,
                    11200.0
                ]
            },
            "integer_answers": {
                "jack skellington": 0,
                "beef wellington": 1,
                "the duke of wellington": 9
            }
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Made famous in a documentary, where is the \u201cGrey Gardens\u201d home located?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "cape cod, ma"
            ],
            "lines": [
                [
                    0.30178950561116163,
                    0.4477124183006536,
                    0.3674592436367138,
                    0.25203252032520324,
                    0.0743142144638404,
                    0.2469879518072289,
                    0.8037941646465067,
                    0.3482142857142857,
                    0.18181818181818182,
                    0.198085938749492,
                    3.0
                ],
                [
                    0.46663633606308763,
                    0.22875816993464052,
                    0.39010097015012135,
                    0.5121951219512195,
                    0.07448046550290939,
                    0.40963855421686746,
                    0.19598487201739526,
                    0.38125,
                    0.5909090909090909,
                    0.6251737028347236,
                    3.0
                ],
                [
                    0.23157415832575068,
                    0.3235294117647059,
                    0.24243978621316487,
                    0.23577235772357724,
                    0.8512053200332502,
                    0.3433734939759036,
                    0.00022096333609804367,
                    0.27053571428571427,
                    0.22727272727272727,
                    0.17674035841578437,
                    3.0
                ]
            ],
            "fraction_answers": {
                "east hampton, ny": 0.3875127283580056,
                "savannah, ga": 0.2902664291346676,
                "cape cod, ma": 0.3222208425073268
            },
            "question": "made famous in a documentary, where is the \u201cgrey gardens\u201d home located?",
            "rate_limited": false,
            "answers": [
                "cape cod, ma",
                "east hampton, ny",
                "savannah, ga"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "east hampton, ny": 0.473571595033892,
                "savannah, ga": 0.1882088422080287,
                "cape cod, ma": 0.6856366170222606
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 3
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.1885156324969521,
                    3.7510422170083415,
                    1.0604421504947061
                ],
                "result_count_important_words": [
                    41.0,
                    68.0,
                    57.0
                ],
                "wikipedia_search": [
                    1.3928571428571428,
                    1.525,
                    1.082142857142857
                ],
                "answer_relation_to_question": [
                    0.905368516833485,
                    1.399909008189263,
                    0.694722474977252
                ],
                "answer_relation_to_question_bing": [
                    1.7908496732026145,
                    0.9150326797385621,
                    1.2941176470588236
                ],
                "result_count_noun_chunks": [
                    251000.0,
                    61200.0,
                    69.0
                ],
                "question_answer_similarity": [
                    10.66745613887906,
                    11.324752502143383,
                    7.038102403283119
                ],
                "result_count_bing": [
                    447000.0,
                    448000.0,
                    5120000.0
                ],
                "result_count": [
                    31.0,
                    63.0,
                    29.0
                ],
                "word_count_appended": [
                    4.0,
                    13.0,
                    5.0
                ]
            },
            "integer_answers": {
                "east hampton, ny": 7,
                "savannah, ga": 1,
                "cape cod, ma": 2
            }
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Which of these is NOT a machine used for printing?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "hydraulophone"
            ],
            "lines": [
                [
                    0.49796747967479676,
                    0.5,
                    0.5,
                    0.40298507462686567,
                    0.33691363437088995,
                    0.38567293777134587,
                    0.3627450980392157,
                    0.5,
                    0.33999999999999997,
                    0.40864072088247233,
                    -1.0
                ],
                [
                    0.35904707884288145,
                    0.2693452380952381,
                    0.5,
                    0.32918739635157546,
                    0.3261727312582201,
                    0.19247467438494936,
                    0.21345811051693403,
                    0.30978260869565216,
                    0.2683333333333333,
                    0.27952334690163194,
                    -1.0
                ],
                [
                    0.14298544148232184,
                    0.23065476190476192,
                    0.0,
                    0.2678275290215589,
                    0.33691363437088995,
                    0.42185238784370477,
                    0.4237967914438503,
                    0.19021739130434784,
                    0.39166666666666666,
                    0.31183593221589584,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "spirit duplicator": 0.45644989274920045,
                "hydraulophone": 0.15301501092688277,
                "hectograph": 0.39053509632391686
            },
            "question": "which of these is not a machine used for printing?",
            "rate_limited": false,
            "answers": [
                "hydraulophone",
                "hectograph",
                "spirit duplicator"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "spirit duplicator": 0.22965373427764146,
                "hydraulophone": 0.701337037036607,
                "hectograph": 0.1709426959438961
            },
            "integer_answers": {
                "spirit duplicator": 5,
                "hydraulophone": 0,
                "hectograph": 5
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    0.3654371164701108,
                    0.8819066123934725,
                    0.7526562711364168
                ],
                "result_count_important_words": [
                    15800.0,
                    42500.0,
                    10800.0
                ],
                "wikipedia_search": [
                    0.0,
                    0.7608695652173914,
                    1.2391304347826086
                ],
                "answer_relation_to_question": [
                    0.008130081300813009,
                    0.5638116846284742,
                    1.4280582340707126
                ],
                "answer_relation_to_question_bing": [
                    0.0,
                    0.9226190476190477,
                    1.0773809523809523
                ],
                "result_count_noun_chunks": [
                    30800.0,
                    64300.0,
                    17100.0
                ],
                "question_answer_similarity": [
                    0.0,
                    0.0,
                    3.38682275544852
                ],
                "result_count_bing": [
                    74400000.0,
                    79300000.0,
                    74400000.0
                ],
                "result_count": [
                    11700.0,
                    20600.0,
                    28000.0
                ],
                "word_count_appended": [
                    192.0,
                    278.0,
                    130.0
                ]
            },
            "negative_question": true
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Dominique Ansel is credited with creating what food craze?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "cronut"
            ],
            "lines": [
                [
                    0.3063459801264679,
                    0.33333333333333337,
                    0.47362092526786315,
                    0.16477272727272727,
                    0.20420624151967434,
                    0.0005279691666006705,
                    0.06606942889137737,
                    0.0,
                    0.047058823529411764,
                    0.1672646026036548,
                    1.0
                ],
                [
                    0.18320643523895555,
                    0.1619047619047619,
                    0.5263790747321369,
                    0.5340909090909091,
                    0.3378561736770692,
                    0.001610305958132045,
                    0.03807390817469205,
                    0.24393939393939396,
                    0.16470588235294117,
                    0.4455919468366816,
                    1.0
                ],
                [
                    0.5104475846345765,
                    0.5047619047619047,
                    0.0,
                    0.30113636363636365,
                    0.45793758480325647,
                    0.9978617248752673,
                    0.8958566629339306,
                    0.7560606060606061,
                    0.788235294117647,
                    0.38714345055966365,
                    1.0
                ]
            ],
            "fraction_answers": {
                "ramen burger": 0.2637358791905674,
                "cronut": 0.5599441176383216,
                "rainbow bagel": 0.17632000317111107
            },
            "question": "dominique ansel is credited with creating what food craze?",
            "rate_limited": false,
            "answers": [
                "rainbow bagel",
                "ramen burger",
                "cronut"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "ramen burger": 0.2119432357178932,
                "cronut": 0.6313603980252503,
                "rainbow bagel": 0.18001489362249232
            },
            "integer_answers": {
                "ramen burger": 3,
                "cronut": 7,
                "rainbow bagel": 0
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.0035876156219288,
                    2.6735516810200894,
                    2.322860703357982
                ],
                "result_count_important_words": [
                    20.0,
                    61.0,
                    37800.0
                ],
                "wikipedia_search": [
                    0.0,
                    0.9757575757575758,
                    3.0242424242424244
                ],
                "answer_relation_to_question": [
                    1.8380758807588076,
                    1.0992386114337334,
                    3.0626855078074593
                ],
                "answer_relation_to_question_bing": [
                    1.6666666666666667,
                    0.8095238095238095,
                    2.5238095238095237
                ],
                "result_count_noun_chunks": [
                    17700.0,
                    10200.0,
                    240000.0
                ],
                "question_answer_similarity": [
                    2.7380473613739014,
                    3.043047212995589,
                    0.0
                ],
                "result_count_bing": [
                    6020.0,
                    9960.0,
                    13500.0
                ],
                "word_count_appended": [
                    20.0,
                    70.0,
                    335.0
                ],
                "result_count": [
                    29.0,
                    94.0,
                    53.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which person is most famous for being a children\u2019s book writer?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "dr. seuss"
            ],
            "lines": [
                [
                    0.20620553599277006,
                    0.2096732026143791,
                    0.21003198744933138,
                    0.276981852913085,
                    0.35098814229249015,
                    0.44856808883693744,
                    0.23728813559322035,
                    0.43396549975696663,
                    0.24479166666666666,
                    0.30032336980330687,
                    -1.0
                ],
                [
                    0.6885678938870428,
                    0.5384313725490196,
                    0.444350695785928,
                    0.6813116841770137,
                    0.33992094861660077,
                    0.429573348918761,
                    0.6571056062581486,
                    0.3450155786116677,
                    0.4036458333333333,
                    0.38929678917617544,
                    -1.0
                ],
                [
                    0.10522657012018714,
                    0.2518954248366013,
                    0.3456173167647406,
                    0.04170646290990131,
                    0.3090909090909091,
                    0.12185856224430158,
                    0.10560625814863103,
                    0.2210189216313656,
                    0.3515625,
                    0.3103798410205177,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "tiger woods": 0.21639627667671552,
                "paris hilton": 0.29188174819191537,
                "dr. seuss": 0.49172197513136917
            },
            "question": "which person is most famous for being a children\u2019s book writer?",
            "rate_limited": false,
            "answers": [
                "paris hilton",
                "dr. seuss",
                "tiger woods"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "tiger woods": 0.17649852132536462,
                "paris hilton": 0.5055764265678385,
                "dr. seuss": 0.6776973064760211
            },
            "integer_answers": {
                "tiger woods": 0,
                "paris hilton": 3,
                "dr. seuss": 7
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.5016168490165342,
                    1.9464839458808771,
                    1.5518992051025884
                ],
                "result_count_important_words": [
                    3070000.0,
                    2940000.0,
                    834000.0
                ],
                "wikipedia_search": [
                    2.169827498784833,
                    1.7250778930583386,
                    1.105094608156828
                ],
                "answer_relation_to_question": [
                    1.0310276799638503,
                    3.442839469435214,
                    0.5261328506009357
                ],
                "answer_relation_to_question_bing": [
                    1.0483660130718955,
                    2.6921568627450982,
                    1.2594771241830065
                ],
                "result_count_noun_chunks": [
                    910000.0,
                    2520000.0,
                    405000.0
                ],
                "question_answer_similarity": [
                    2.633950650691986,
                    5.572474071756005,
                    4.334287207573652
                ],
                "result_count_bing": [
                    44400000.0,
                    43000000.0,
                    39100000.0
                ],
                "result_count": [
                    1740000.0,
                    4280000.0,
                    262000.0
                ],
                "word_count_appended": [
                    94.0,
                    155.0,
                    135.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "How does the second verse of \u201cThe Star-Spangled Banner\u201d begin?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "where the foe"
            ],
            "lines": [
                [
                    0.31621323529411766,
                    0.22568005764727075,
                    0.22182574101272395,
                    0.0004115486893757123,
                    0.2130841121495327,
                    0.00900098030478567,
                    0.006735769378424598,
                    0.5833333333333334,
                    0.10465116279069768,
                    0.1035011516005932,
                    5.0
                ],
                [
                    0.29029411764705887,
                    0.5454347565003302,
                    0.38012396174727164,
                    0.8230973787514246,
                    0.5719626168224299,
                    0.7869173870421531,
                    0.5228073849160646,
                    0.06250000000000001,
                    0.47674418604651164,
                    0.4461345014910456,
                    5.0
                ],
                [
                    0.39349264705882353,
                    0.22888518585239895,
                    0.3980502972400044,
                    0.17649107255919969,
                    0.21495327102803738,
                    0.20408163265306123,
                    0.4704568457055108,
                    0.3541666666666667,
                    0.4186046511627907,
                    0.4503643469083612,
                    5.0
                ]
            ],
            "fraction_answers": {
                "on the shore": 0.490601629096429,
                "travels far": 0.1784437092200855,
                "where the foe": 0.3309546616834854
            },
            "question": "how does the second verse of \u201cthe star-spangled banner\u201d begin?",
            "rate_limited": false,
            "answers": [
                "travels far",
                "on the shore",
                "where the foe"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "on the shore": 0.3128410728270124,
                "travels far": 0.3889320307775609,
                "where the foe": 0.47931646876622047
            },
            "integer_answers": {
                "on the shore": 6,
                "travels far": 1,
                "where the foe": 3
            },
            "categorical_data": {
                "question_type": 5
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    0.6210069096035592,
                    2.6768070089462737,
                    2.7021860814501673
                ],
                "result_count_important_words": [
                    1010.0,
                    88300.0,
                    22900.0
                ],
                "wikipedia_search": [
                    2.333333333333333,
                    0.25,
                    1.4166666666666665
                ],
                "answer_relation_to_question": [
                    1.5810661764705882,
                    1.4514705882352943,
                    1.9674632352941177
                ],
                "answer_relation_to_question_bing": [
                    0.6770401729418123,
                    1.6363042695009908,
                    0.6866555575571969
                ],
                "result_count_noun_chunks": [
                    965.0,
                    74900.0,
                    67400.0
                ],
                "question_answer_similarity": [
                    7.946084663271904,
                    13.616531466512242,
                    14.258675966411829
                ],
                "result_count_bing": [
                    114000.0,
                    306000.0,
                    115000.0
                ],
                "result_count": [
                    52.0,
                    104000.0,
                    22300.0
                ],
                "word_count_appended": [
                    9.0,
                    41.0,
                    36.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Which of these substances is both artificially made and found in nature?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "latex"
            ],
            "lines": [
                [
                    0.42857142857142855,
                    0.16666666666666666,
                    0.08729518727437834,
                    0.2799043062200957,
                    0.3245192307692308,
                    0.04970445996775927,
                    0.43478260869565216,
                    0.2833333333333333,
                    0.3040473840078973,
                    0.3220176453849576,
                    -1.0
                ],
                [
                    0.3333333333333333,
                    0.08333333333333333,
                    0.43601795054528153,
                    0.35406698564593303,
                    0.33774038461538464,
                    0.9027404621171413,
                    0.2596944770857814,
                    0.09999999999999999,
                    0.3099703849950642,
                    0.3421219445730691,
                    -1.0
                ],
                [
                    0.23809523809523808,
                    0.75,
                    0.4766868621803401,
                    0.3660287081339713,
                    0.33774038461538464,
                    0.04755507791509941,
                    0.30552291421856637,
                    0.6166666666666667,
                    0.3859822309970385,
                    0.3358604100419733,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "latex": 0.3860138492864279,
                "teflon": 0.26808422508914,
                "nylon": 0.3459019256244322
            },
            "question": "which of these substances is both artificially made and found in nature?",
            "rate_limited": false,
            "answers": [
                "teflon",
                "nylon",
                "latex"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "latex": 0.39209654186505877,
                "teflon": 0.3415581052153964,
                "nylon": 0.16959880372520833
            },
            "integer_answers": {
                "latex": 5,
                "teflon": 2,
                "nylon": 3
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.2880705815398303,
                    1.3684877782922764,
                    1.3434416401678932
                ],
                "result_count_important_words": [
                    1850000.0,
                    33600000.0,
                    1770000.0
                ],
                "wikipedia_search": [
                    0.85,
                    0.3,
                    1.85
                ],
                "answer_relation_to_question": [
                    0.42857142857142855,
                    0.3333333333333333,
                    0.23809523809523808
                ],
                "answer_relation_to_question_bing": [
                    0.3333333333333333,
                    0.16666666666666666,
                    1.5
                ],
                "result_count_noun_chunks": [
                    3700000.0,
                    2210000.0,
                    2600000.0
                ],
                "question_answer_similarity": [
                    0.3373199393681716,
                    1.684829980134964,
                    1.8419799357652664
                ],
                "result_count_bing": [
                    2700000.0,
                    2810000.0,
                    2810000.0
                ],
                "result_count": [
                    2340000.0,
                    2960000.0,
                    3060000.0
                ],
                "word_count_appended": [
                    308.0,
                    314.0,
                    391.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Every U.S. state that starts with which of these letters has a Democratic governor?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "v"
            ],
            "lines": [
                [
                    0.06060606060606061,
                    0.24985994397759104,
                    0.29650389086959006,
                    0.09939205429096565,
                    0.3351583887368009,
                    0.11399636458062841,
                    0.12286758732737611,
                    0.10294117647058823,
                    0.22748046587055876,
                    0.33059418137206853,
                    -1.0
                ],
                [
                    0.5515151515151515,
                    0.28879551820728294,
                    0.48435498304797675,
                    0.4594938498515481,
                    0.33476730543605787,
                    0.7400675149311867,
                    0.6803411860276198,
                    0.7205882352941176,
                    0.4503169688928203,
                    0.31451728267336665,
                    -1.0
                ],
                [
                    0.3878787878787879,
                    0.461344537815126,
                    0.2191411260824332,
                    0.44111409585748623,
                    0.3300743058271412,
                    0.14593612048818488,
                    0.19679122664500406,
                    0.17647058823529413,
                    0.32220256523662094,
                    0.3548885359545649,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "c": 0.5024757995877129,
                "w": 0.19394001141022282,
                "v": 0.30358418900206435
            },
            "question": "every u.s. state that starts with which of these letters has a democratic governor?",
            "rate_limited": false,
            "answers": [
                "w",
                "c",
                "v"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "c": 0.26135364127844146,
                "w": 0.3713789965773139,
                "v": 0.6058723177510446
            },
            "integer_answers": {
                "c": 7,
                "w": 1,
                "v": 2
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.9835650882324112,
                    1.8871036960402,
                    2.1293312157273894
                ],
                "result_count_important_words": [
                    439000.0,
                    2850000.0,
                    562000.0
                ],
                "wikipedia_search": [
                    0.20588235294117646,
                    1.4411764705882353,
                    0.35294117647058826
                ],
                "answer_relation_to_question": [
                    0.18181818181818182,
                    1.6545454545454545,
                    1.1636363636363636
                ],
                "answer_relation_to_question_bing": [
                    0.7495798319327731,
                    0.8663865546218488,
                    1.3840336134453781
                ],
                "result_count_noun_chunks": [
                    605000.0,
                    3350000.0,
                    969000.0
                ],
                "question_answer_similarity": [
                    1.6639529606327415,
                    2.718156263232231,
                    1.2298001367598772
                ],
                "result_count_bing": [
                    8570000.0,
                    8560000.0,
                    8440000.0
                ],
                "word_count_appended": [
                    3086.0,
                    6109.0,
                    4371.0
                ],
                "result_count": [
                    703000.0,
                    3250000.0,
                    3120000.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "What does a rattlesnake typically do when it feels threatened?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "rattles its tail"
            ],
            "lines": [
                [
                    0.5851851851851851,
                    1.0,
                    0.25338692452378664,
                    1.1570114064795945e-05,
                    0.33236363636363636,
                    0.00010308215647871353,
                    0.0026145056647622735,
                    0.7222222222222222,
                    0.7096774193548387,
                    0.22551915995757207,
                    1.0
                ],
                [
                    0.27037037037037037,
                    0.0,
                    0.3386160289864902,
                    0.9999884298859352,
                    0.3338181818181818,
                    0.9998969178435213,
                    0.9973854943352377,
                    0.0,
                    0.1935483870967742,
                    0.6983455707184495,
                    1.0
                ],
                [
                    0.14444444444444446,
                    0.0,
                    0.40799704648972324,
                    0.0,
                    0.3338181818181818,
                    0.0,
                    0.0,
                    0.27777777777777773,
                    0.0967741935483871,
                    0.07613526932397846,
                    1.0
                ]
            ],
            "fraction_answers": {
                "sends an angry email": 0.13369469134024928,
                "rattles its tail": 0.38310837055425473,
                "eats its feelings": 0.483196938105496
            },
            "question": "what does a rattlesnake typically do when it feels threatened?",
            "rate_limited": false,
            "answers": [
                "rattles its tail",
                "eats its feelings",
                "sends an angry email"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "sends an angry email": 0.17649852132536462,
                "rattles its tail": 0.4727941863905904,
                "eats its feelings": 0.250265656109275
            },
            "integer_answers": {
                "sends an angry email": 1,
                "rattles its tail": 4,
                "eats its feelings": 5
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    0.9020766398302883,
                    2.793382282873798,
                    0.30454107729591384
                ],
                "result_count_important_words": [
                    30.0,
                    291000.0,
                    0
                ],
                "wikipedia_search": [
                    2.166666666666667,
                    0.0,
                    0.8333333333333334
                ],
                "answer_relation_to_question": [
                    1.7555555555555555,
                    0.8111111111111111,
                    0.43333333333333335
                ],
                "answer_relation_to_question_bing": [
                    2.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    1080.0,
                    412000.0,
                    0
                ],
                "question_answer_similarity": [
                    8.451388319954276,
                    11.294093243777752,
                    13.608206026256084
                ],
                "result_count_bing": [
                    457000.0,
                    459000.0,
                    459000.0
                ],
                "result_count": [
                    28.0,
                    2420000.0,
                    0
                ],
                "word_count_appended": [
                    22.0,
                    6.0,
                    3.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Which of these was a name the ancient Greeks gave the planet Venus?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "antimony"
            ],
            "lines": [
                [
                    0.16666666666666666,
                    0.0,
                    2.7138827596323836,
                    0.006559256193084124,
                    0.3333333333333333,
                    0.01793103448275862,
                    0.0061136538268800325,
                    0.14285714285714288,
                    0.14423076923076922,
                    0.2087339394719338,
                    -1.0
                ],
                [
                    0.16666666666666666,
                    0.0,
                    -1.7518389244612156,
                    0.5911821520303976,
                    0.3333333333333333,
                    0.6151724137931035,
                    0.6748404770654461,
                    0.634920634920635,
                    0.592948717948718,
                    0.43859282176138403,
                    -1.0
                ],
                [
                    0.6666666666666666,
                    1.0,
                    0.037956164828831886,
                    0.4022585917765183,
                    0.3333333333333333,
                    0.36689655172413793,
                    0.3190458691076738,
                    0.22222222222222224,
                    0.26282051282051283,
                    0.35267323876668216,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "antimony": 0.3963873151246579,
                "flourine": 0.3740308555694952,
                "phosphorus": 0.22958182930584684
            },
            "question": "which of these was a name the ancient greeks gave the planet venus?",
            "rate_limited": false,
            "answers": [
                "flourine",
                "phosphorus",
                "antimony"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "antimony": 0.659310368654777,
                "flourine": 0.16531039642028056,
                "phosphorus": 0.3064264677175037
            },
            "integer_answers": {
                "antimony": 2,
                "flourine": 1,
                "phosphorus": 7
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.043669697359669,
                    2.1929641088069203,
                    1.7633661938334109
                ],
                "result_count_important_words": [
                    1950.0,
                    66900.0,
                    39900.0
                ],
                "wikipedia_search": [
                    0.42857142857142855,
                    1.9047619047619047,
                    0.6666666666666666
                ],
                "answer_relation_to_question": [
                    0.5,
                    0.5,
                    2.0
                ],
                "answer_relation_to_question_bing": [
                    0.0,
                    0.0,
                    1.0
                ],
                "result_count_noun_chunks": [
                    732.0,
                    80800.0,
                    38200.0
                ],
                "question_answer_similarity": [
                    -1.692743442952633,
                    1.0926831094548106,
                    -0.023674585390836
                ],
                "result_count_bing": [
                    217000.0,
                    217000.0,
                    217000.0
                ],
                "result_count": [
                    618.0,
                    55700.0,
                    37900.0
                ],
                "word_count_appended": [
                    90.0,
                    370.0,
                    164.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Which of these film composers most recently won an Oscar?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "ennio morricone"
            ],
            "lines": [
                [
                    0.2650228430279581,
                    0.4252873563218391,
                    1.1155468231376293,
                    0.3149171270718232,
                    0.008565059251437288,
                    0.39603960396039606,
                    0.30881017257039056,
                    0.633674007152268,
                    0.3709090909090909,
                    0.3295234202908013,
                    -1.0
                ],
                [
                    0.2871781756180733,
                    0.5402298850574713,
                    0.07337292286749557,
                    0.3425414364640884,
                    0.44878563885955647,
                    0.3217821782178218,
                    0.48440811383590676,
                    0.23200451722190857,
                    0.31636363636363635,
                    0.34687015986500785,
                    -1.0
                ],
                [
                    0.44779898135396856,
                    0.034482758620689655,
                    -0.18891974600512493,
                    0.3425414364640884,
                    0.5426493018890062,
                    0.28217821782178215,
                    0.2067817135937027,
                    0.13432147562582347,
                    0.31272727272727274,
                    0.3236064198441908,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "ennio morricone": 0.4168295503693634,
                "danny elfman": 0.24381678319353997,
                "hans zimmer": 0.33935366643709663
            },
            "question": "which of these film composers most recently won an oscar?",
            "rate_limited": false,
            "answers": [
                "ennio morricone",
                "hans zimmer",
                "danny elfman"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "ennio morricone": 0.4253818863279722,
                "danny elfman": 0.23745047209429754,
                "hans zimmer": 0.2686608587011491
            },
            "integer_answers": {
                "ennio morricone": 3,
                "danny elfman": 3,
                "hans zimmer": 4
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.6476171014540064,
                    1.7343507993250393,
                    1.618032099220954
                ],
                "result_count_important_words": [
                    80.0,
                    65.0,
                    57.0
                ],
                "wikipedia_search": [
                    3.16837003576134,
                    1.1600225861095428,
                    0.6716073781291173
                ],
                "answer_relation_to_question": [
                    1.3251142151397906,
                    1.4358908780903665,
                    2.2389949067698427
                ],
                "answer_relation_to_question_bing": [
                    1.2758620689655173,
                    1.6206896551724137,
                    0.10344827586206896
                ],
                "result_count_noun_chunks": [
                    102000.0,
                    160000.0,
                    68300.0
                ],
                "question_answer_similarity": [
                    -1.6189286317676306,
                    -0.10648188239429146,
                    0.27416830882430077
                ],
                "result_count_bing": [
                    29200.0,
                    1530000.0,
                    1850000.0
                ],
                "result_count": [
                    57.0,
                    62.0,
                    62.0
                ],
                "word_count_appended": [
                    102.0,
                    87.0,
                    86.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which of these figure skating jumps was invented the most recently?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "salchow"
            ],
            "lines": [
                [
                    0.06930064923442407,
                    0.036062378167641324,
                    0.9895528445480137,
                    0.17275747508305647,
                    0.30489335006273527,
                    0.40643863179074446,
                    0.3304470754550274,
                    0.013447286636385369,
                    0.31586021505376344,
                    0.3237099780741647,
                    -1.0
                ],
                [
                    0.8177914639504044,
                    0.8557504873294347,
                    0.8631500662168717,
                    0.4318936877076412,
                    0.3989962358845671,
                    0.28772635814889336,
                    0.10584908994522,
                    0.9759144154912742,
                    0.31048387096774194,
                    0.3544031725707689,
                    -1.0
                ],
                [
                    0.11290788681517158,
                    0.10818713450292398,
                    -0.8527029107648855,
                    0.3953488372093023,
                    0.2961104140526976,
                    0.3058350100603622,
                    0.5637038345997526,
                    0.010638297872340425,
                    0.3736559139784946,
                    0.3218868493550664,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "salchow": 0.5401958848212817,
                "lutz": 0.2962469884105956,
                "axel": 0.16355712676812262
            },
            "question": "which of these figure skating jumps was invented the most recently?",
            "rate_limited": false,
            "answers": [
                "lutz",
                "salchow",
                "axel"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "salchow": 0.5666428659357521,
                "lutz": 0.17337281852561925,
                "axel": 0.25323972088761126
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.6185498903708235,
                    1.7720158628538445,
                    1.609434246775332
                ],
                "result_count_important_words": [
                    101000.0,
                    71500.0,
                    76000.0
                ],
                "wikipedia_search": [
                    0.053789146545541476,
                    3.903657661965097,
                    0.0425531914893617
                ],
                "answer_relation_to_question": [
                    0.34650324617212036,
                    4.088957319752022,
                    0.5645394340758579
                ],
                "answer_relation_to_question_bing": [
                    0.10818713450292397,
                    2.5672514619883042,
                    0.32456140350877194
                ],
                "result_count_noun_chunks": [
                    187000.0,
                    59900.0,
                    319000.0
                ],
                "question_answer_similarity": [
                    -0.4557744115591049,
                    -0.3975550327450037,
                    0.3927432168275118
                ],
                "result_count_bing": [
                    24300.0,
                    31800.0,
                    23600.0
                ],
                "result_count": [
                    104000.0,
                    260000.0,
                    238000.0
                ],
                "word_count_appended": [
                    235.0,
                    231.0,
                    278.0
                ]
            },
            "integer_answers": {
                "salchow": 6,
                "lutz": 1,
                "axel": 3
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Romaine, Iceberg and Butterhead are all varieties of what?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "lettuce"
            ],
            "lines": [
                [
                    1.0,
                    1.0,
                    0.33551107167246474,
                    0.99198598435077,
                    0.7185496351978775,
                    0.9981263242684785,
                    0.9981791094189704,
                    0.9895833333333334,
                    0.979933110367893,
                    0.6691471396903442,
                    1.0
                ],
                [
                    0.0,
                    0.0,
                    0.251214040558982,
                    0.007836452525539496,
                    0.14083572849878398,
                    0.0015759889330554924,
                    0.0015063731170336038,
                    0.0,
                    0.006688963210702341,
                    0.25085397320586267,
                    1.0
                ],
                [
                    0.0,
                    0.0,
                    0.41327488776855326,
                    0.00017756312369047198,
                    0.14061463630333848,
                    0.00029768679846603745,
                    0.00031451746399602714,
                    0.010416666666666666,
                    0.013377926421404682,
                    0.07999888710379313,
                    1.0
                ]
            ],
            "fraction_answers": {
                "lettuce": 0.8681015708300132,
                "race cars": 0.06584727716499086,
                "disney dwarfs": 0.06605115200499596
            },
            "question": "romaine, iceberg and butterhead are all varieties of what?",
            "rate_limited": false,
            "answers": [
                "lettuce",
                "disney dwarfs",
                "race cars"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "lettuce": 0.61925554794234,
                "race cars": 0.18236501519393916,
                "disney dwarfs": 0.17211758533290114
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    2.676588558761377,
                    1.0034158928234507,
                    0.3199955484151725
                ],
                "result_count_important_words": [
                    57000.0,
                    90.0,
                    17.0
                ],
                "wikipedia_search": [
                    3.9583333333333335,
                    0.0,
                    0.041666666666666664
                ],
                "answer_relation_to_question": [
                    4.0,
                    0.0,
                    0.0
                ],
                "answer_relation_to_question_bing": [
                    4.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    60300.0,
                    91.0,
                    19.0
                ],
                "question_answer_similarity": [
                    3.1902155205607414,
                    2.3886750657111406,
                    3.9296347349882126
                ],
                "result_count_bing": [
                    325000.0,
                    63700.0,
                    63600.0
                ],
                "result_count": [
                    83800.0,
                    662.0,
                    15.0
                ],
                "word_count_appended": [
                    879.0,
                    6.0,
                    12.0
                ]
            },
            "integer_answers": {
                "lettuce": 9,
                "race cars": 1,
                "disney dwarfs": 0
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Rejected in the late 1700s, what was the name of the proposed 14th U.S. colony?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "vandalia"
            ],
            "lines": [
                [
                    0.2940803382663848,
                    0.24780701754385964,
                    -0.07189610347694714,
                    0.6998028724303014,
                    0.2857142857142857,
                    0.6321243523316062,
                    0.6412698412698413,
                    0.008620689655172414,
                    0.5729166666666666,
                    0.42776881645431414,
                    1.0
                ],
                [
                    0.6373150105708245,
                    0.6896929824561404,
                    -1.2384314651496962,
                    0.2872430301323571,
                    0.3915966386554622,
                    0.24145077720207253,
                    0.2526984126984127,
                    0.24233716475095785,
                    0.3784722222222222,
                    0.3030356674622775,
                    1.0
                ],
                [
                    0.0686046511627907,
                    0.0625,
                    2.310327568626643,
                    0.012954097437341595,
                    0.3226890756302521,
                    0.12642487046632125,
                    0.10603174603174603,
                    0.7490421455938697,
                    0.04861111111111111,
                    0.26919551608340836,
                    1.0
                ]
            ],
            "fraction_answers": {
                "roanoke": 0.37382087768554856,
                "new albion": 0.40763807821434844,
                "vandalia": 0.21854104410010308
            },
            "question": "rejected in the late 1700s, what was the name of the proposed 14th u.s. colony?",
            "rate_limited": false,
            "answers": [
                "roanoke",
                "vandalia",
                "new albion"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "roanoke": 0.2326690336830119,
                "new albion": 0.3146435910416931,
                "vandalia": 0.3411771737078913
            },
            "integer_answers": {
                "roanoke": 5,
                "new albion": 2,
                "vandalia": 3
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    2.566612898725885,
                    1.818214004773665,
                    1.61517309650045
                ],
                "result_count_important_words": [
                    6100.0,
                    2330.0,
                    1220.0
                ],
                "wikipedia_search": [
                    0.017241379310344827,
                    0.4846743295019157,
                    1.4980842911877394
                ],
                "answer_relation_to_question": [
                    1.1763213530655392,
                    2.549260042283298,
                    0.2744186046511628
                ],
                "answer_relation_to_question_bing": [
                    0.9912280701754386,
                    2.7587719298245617,
                    0.25
                ],
                "result_count_noun_chunks": [
                    10100.0,
                    3980.0,
                    1670.0
                ],
                "question_answer_similarity": [
                    -0.12943960819393396,
                    -2.229635207913816,
                    4.159445099532604
                ],
                "result_count_bing": [
                    51000.0,
                    69900.0,
                    57600.0
                ],
                "word_count_appended": [
                    165.0,
                    109.0,
                    14.0
                ],
                "result_count": [
                    4970.0,
                    2040.0,
                    92.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Which of these are you most likely to find in a toolbox?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "mc hammer"
            ],
            "lines": [
                [
                    0.4239766081871345,
                    0.2777777777777778,
                    0.3402481905319875,
                    0.9462412587412588,
                    0.4785463704236754,
                    0.7376509330406147,
                    0.9721443260422509,
                    0.05555555555555555,
                    0.7961630695443646,
                    0.45665024491906486,
                    -1.0
                ],
                [
                    0.12280701754385964,
                    0.3055555555555556,
                    0.42028756764684777,
                    0.02972027972027972,
                    0.4758478006656472,
                    0.11306256860592755,
                    0.01607777154608338,
                    0.8888888888888888,
                    0.12709832134292565,
                    0.2899598060280606,
                    -1.0
                ],
                [
                    0.45321637426900585,
                    0.41666666666666663,
                    0.23946424182116474,
                    0.02403846153846154,
                    0.04560582891067734,
                    0.14928649835345773,
                    0.011777902411665733,
                    0.05555555555555555,
                    0.07673860911270983,
                    0.2533899490528746,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "mc hammer": 0.27893055775440756,
                "hammer": 0.5484954334763684,
                "hammerhead shark": 0.17257400876922396
            },
            "question": "which of these are you most likely to find in a toolbox?",
            "rate_limited": false,
            "answers": [
                "hammer",
                "mc hammer",
                "hammerhead shark"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "mc hammer": 0.3146435910416931,
                "hammer": 0.27249385535515275,
                "hammerhead shark": 0.31446632468146535
            },
            "integer_answers": {
                "mc hammer": 2,
                "hammer": 6,
                "hammerhead shark": 2
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.3699507347571944,
                    0.8698794180841817,
                    0.7601698471586237
                ],
                "result_count_important_words": [
                    672000.0,
                    103000.0,
                    136000.0
                ],
                "wikipedia_search": [
                    0.1111111111111111,
                    1.7777777777777777,
                    0.1111111111111111
                ],
                "answer_relation_to_question": [
                    1.2719298245614035,
                    0.3684210526315789,
                    1.3596491228070176
                ],
                "answer_relation_to_question_bing": [
                    0.5555555555555556,
                    0.6111111111111112,
                    0.8333333333333333
                ],
                "result_count_noun_chunks": [
                    10400000.0,
                    172000.0,
                    126000.0
                ],
                "question_answer_similarity": [
                    2.6737168580293655,
                    3.3026772400480695,
                    1.8817427926696837
                ],
                "result_count_bing": [
                    53200000.0,
                    52900000.0,
                    5070000.0
                ],
                "word_count_appended": [
                    332.0,
                    53.0,
                    32.0
                ],
                "result_count": [
                    4330000.0,
                    136000.0,
                    110000.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which of these is usually found on the ocean floor?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "sea cucumber"
            ],
            "lines": [
                [
                    0.04960317460317461,
                    0.05555555555555555,
                    0.37064613271934366,
                    0.7526588491955277,
                    0.41805513480763407,
                    0.778840523130978,
                    0.7039586919104991,
                    0.28108974358974365,
                    0.35511363636363635,
                    0.3064133513011424,
                    -1.0
                ],
                [
                    0.053571428571428575,
                    0.3055555555555556,
                    0.2753523892912719,
                    0.07035724025088629,
                    0.34837927900636173,
                    0.06792894788210033,
                    0.060240963855421686,
                    0.03541666666666667,
                    0.13636363636363635,
                    0.2822155821161109,
                    -1.0
                ],
                [
                    0.8968253968253969,
                    0.6388888888888888,
                    0.3540014779893844,
                    0.17698391055358603,
                    0.23356558618600423,
                    0.15323052898692172,
                    0.23580034423407917,
                    0.6834935897435898,
                    0.5085227272727273,
                    0.4113710665827467,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "sweet potato": 0.4071934793177235,
                "cherry tomato": 0.16353816895594403,
                "sea cucumber": 0.4292683517263325
            },
            "question": "which of these is usually found on the ocean floor?",
            "rate_limited": false,
            "answers": [
                "sweet potato",
                "cherry tomato",
                "sea cucumber"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "sweet potato": 0.250265656109275,
                "cherry tomato": 0.18389380015222964,
                "sea cucumber": 0.4727941863905904
            },
            "integer_answers": {
                "sweet potato": 5,
                "cherry tomato": 0,
                "sea cucumber": 5
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.2256534052045696,
                    1.1288623284644437,
                    1.6454842663309868
                ],
                "result_count_important_words": [
                    399000.0,
                    34800.0,
                    78500.0
                ],
                "wikipedia_search": [
                    1.1243589743589744,
                    0.14166666666666666,
                    2.7339743589743586
                ],
                "answer_relation_to_question": [
                    0.1984126984126984,
                    0.21428571428571427,
                    3.587301587301587
                ],
                "answer_relation_to_question_bing": [
                    0.2222222222222222,
                    1.2222222222222223,
                    2.5555555555555554
                ],
                "result_count_noun_chunks": [
                    409000.0,
                    35000.0,
                    137000.0
                ],
                "question_answer_similarity": [
                    5.230855330824852,
                    3.8859936371445656,
                    4.995952621102333
                ],
                "result_count_bing": [
                    1380000.0,
                    1150000.0,
                    771000.0
                ],
                "result_count": [
                    276000.0,
                    25800.0,
                    64900.0
                ],
                "word_count_appended": [
                    125.0,
                    48.0,
                    179.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "The '90s band The Lightning Seeds took their name from which song?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "purple rain"
            ],
            "lines": [
                [
                    0.12479930425474982,
                    0.4285714285714286,
                    0.0985450346115554,
                    0.20567092651757188,
                    0.19498069498069498,
                    0.15940224159402241,
                    0.18700240696167375,
                    0.241156116068292,
                    0.37681159420289856,
                    0.3631236136170717,
                    -1.0
                ],
                [
                    0.2561546695210062,
                    0.4444444444444445,
                    0.3294429145588686,
                    0.625,
                    0.4266409266409266,
                    0.6760362924746487,
                    0.6517311608961304,
                    0.4220824843673154,
                    0.3333333333333333,
                    0.3476388700819512,
                    -1.0
                ],
                [
                    0.6190460262242441,
                    0.126984126984127,
                    0.5720120508295761,
                    0.16932907348242812,
                    0.3783783783783784,
                    0.16456146593132895,
                    0.16126643214219588,
                    0.33676139956439266,
                    0.2898550724637681,
                    0.28923751630097705,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "when doves cry": 0.31074315423014165,
                "raspberry beret": 0.2380063361379959,
                "purple rain": 0.45125050963186253
            },
            "question": "the '90s band the lightning seeds took their name from which song?",
            "rate_limited": false,
            "answers": [
                "raspberry beret",
                "purple rain",
                "when doves cry"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "when doves cry": 0.3802200657383125,
                "raspberry beret": 0.17653686325184953,
                "purple rain": 0.6354254300557068
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    2.17874168170243,
                    2.085833220491707,
                    1.7354250978058623
                ],
                "result_count_important_words": [
                    8960.0,
                    38000.0,
                    9250.0
                ],
                "wikipedia_search": [
                    0.964624464273168,
                    1.6883299374692615,
                    1.3470455982575706
                ],
                "answer_relation_to_question": [
                    0.4991972170189992,
                    1.0246186780840245,
                    2.476184104896976
                ],
                "answer_relation_to_question_bing": [
                    1.2857142857142856,
                    1.3333333333333333,
                    0.38095238095238093
                ],
                "result_count_noun_chunks": [
                    10100.0,
                    35200.0,
                    8710.0
                ],
                "question_answer_similarity": [
                    2.0106428859289736,
                    6.721719212830067,
                    11.670927563216537
                ],
                "result_count_bing": [
                    101000.0,
                    221000.0,
                    196000.0
                ],
                "word_count_appended": [
                    26.0,
                    23.0,
                    20.0
                ],
                "result_count": [
                    10300.0,
                    31300.0,
                    8480.0
                ]
            },
            "integer_answers": {
                "when doves cry": 2,
                "raspberry beret": 2,
                "purple rain": 6
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which Las Vegas hotel features a replica of the Rialto Bridge?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "caesars palace"
            ],
            "lines": [
                [
                    0.21446682693551827,
                    0.282306819651666,
                    0.10272598544463916,
                    0.3306641544983514,
                    0.460552663195835,
                    0.8107064727834256,
                    0.23373983739837398,
                    0.1981892595339231,
                    0.49404761904761907,
                    0.3106245220545881,
                    -1.0
                ],
                [
                    0.4152347357846544,
                    0.32135465060395374,
                    0.5243955590488556,
                    0.6123410268487989,
                    0.1461754104925911,
                    0.047741603397246174,
                    0.23170731707317074,
                    0.0324301175737756,
                    0.4107142857142857,
                    0.3546533444748174,
                    -1.0
                ],
                [
                    0.3702984372798273,
                    0.3963385297443802,
                    0.37287845550650517,
                    0.05699481865284974,
                    0.39327192631157387,
                    0.14155192381932827,
                    0.5345528455284553,
                    0.7693806228923012,
                    0.09523809523809523,
                    0.3347221334705946,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "caesars palace": 0.3465227788443911,
                "luxor": 0.34380241605439393,
                "the venetian": 0.309674805101215
            },
            "question": "which las vegas hotel features a replica of the rialto bridge?",
            "rate_limited": false,
            "answers": [
                "luxor",
                "the venetian",
                "caesars palace"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "caesars palace": 0.4769909867028702,
                "luxor": 0.201153201189611,
                "the venetian": 0.3236230054024135
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    2.1743716543821168,
                    2.4825734113237217,
                    2.343054934294162
                ],
                "result_count_important_words": [
                    126000.0,
                    7420.0,
                    22000.0
                ],
                "wikipedia_search": [
                    1.1891355572035387,
                    0.19458070544265357,
                    4.6162837373538075
                ],
                "answer_relation_to_question": [
                    1.0723341346775914,
                    2.076173678923272,
                    1.8514921863991365
                ],
                "answer_relation_to_question_bing": [
                    0.846920458954998,
                    0.9640639518118612,
                    1.1890155892331407
                ],
                "result_count_noun_chunks": [
                    11500.0,
                    11400.0,
                    26300.0
                ],
                "question_answer_similarity": [
                    1.2180064041167498,
                    6.217678481712937,
                    4.421163202263415
                ],
                "result_count_bing": [
                    115000.0,
                    36500.0,
                    98200.0
                ],
                "result_count": [
                    70200.0,
                    130000.0,
                    12100.0
                ],
                "word_count_appended": [
                    166.0,
                    138.0,
                    32.0
                ]
            },
            "integer_answers": {
                "caesars palace": 3,
                "luxor": 3,
                "the venetian": 4
            }
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "What TV series derived from a nearly 20-year-old Michael Crichton screenplay?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "er"
            ],
            "lines": [
                [
                    0.2666556591889201,
                    0.31911143241066414,
                    0.7845441344844274,
                    0.06854130052724078,
                    0.2,
                    0.07673869822924989,
                    0.0636604774535809,
                    0.022727272727272728,
                    0.016318537859007835,
                    0.3259522909620539,
                    1.0
                ],
                [
                    0.20353927101144045,
                    0.13604203283431968,
                    -0.0476483362648449,
                    0.15817223198594024,
                    0.4,
                    0.012802170237276799,
                    0.15826702033598586,
                    0.30612627286125815,
                    0.07441253263707572,
                    0.2538172576096846,
                    1.0
                ],
                [
                    0.5298050697996395,
                    0.5448465347550162,
                    0.2631042017804175,
                    0.773286467486819,
                    0.4,
                    0.9104591315334734,
                    0.7780725022104332,
                    0.6711464544114691,
                    0.9092689295039165,
                    0.4202304514282615,
                    1.0
                ]
            ],
            "fraction_answers": {
                "numb3rs": 0.16555304532481369,
                "the expanse": 0.21442498038424182,
                "er": 0.6200219742909445
            },
            "question": "what tv series derived from a nearly 20-year-old michael crichton screenplay?",
            "rate_limited": false,
            "answers": [
                "the expanse",
                "numb3rs",
                "er"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "numb3rs": 0.16768221684966514,
                "the expanse": 0.1864687616495298,
                "er": 0.6176644697293239
            },
            "integer_answers": {
                "numb3rs": 1,
                "the expanse": 1,
                "er": 8
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    2.9335706186584853,
                    2.2843553184871612,
                    3.7820740628543534
                ],
                "result_count_important_words": [
                    4130.0,
                    689.0,
                    49000.0
                ],
                "wikipedia_search": [
                    0.09090909090909091,
                    1.2245050914450326,
                    2.6845858176458766
                ],
                "answer_relation_to_question": [
                    1.3332782959446006,
                    1.0176963550572022,
                    2.6490253489981974
                ],
                "answer_relation_to_question_bing": [
                    1.9146685944639847,
                    0.816252197005918,
                    3.2690792085300973
                ],
                "result_count_noun_chunks": [
                    14400.0,
                    35800.0,
                    176000.0
                ],
                "question_answer_similarity": [
                    5.145800360478461,
                    -0.3125239424407482,
                    1.72569220373407
                ],
                "result_count_bing": [
                    10300.0,
                    20600.0,
                    20600.0
                ],
                "result_count": [
                    15600.0,
                    36000.0,
                    176000.0
                ],
                "word_count_appended": [
                    25.0,
                    114.0,
                    1393.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which of these video games was NOT produced by FromSoftware?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "beyond: two souls"
            ],
            "lines": [
                [
                    0.3049055879023128,
                    0.3230113636363636,
                    0.39252312988145766,
                    0.14190476190476192,
                    0.13980712252367394,
                    0.08710168202180713,
                    0.13173652694610777,
                    0.3576882323610072,
                    0.2262180974477958,
                    0.32072578369718174,
                    -1.0
                ],
                [
                    0.3465348536309235,
                    0.4191603535353535,
                    0.25859885981407776,
                    0.42742857142857144,
                    0.36129669435891476,
                    0.4695292029414251,
                    0.4438622754491018,
                    0.4148591373722264,
                    0.4408352668213457,
                    0.3413082584898771,
                    -1.0
                ],
                [
                    0.3485595584667637,
                    0.25782828282828285,
                    0.3488780103044646,
                    0.43066666666666664,
                    0.49889618311741124,
                    0.4433691150367678,
                    0.42440119760479045,
                    0.22745263026676638,
                    0.3329466357308585,
                    0.33796595781294114,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "demon's souls": 0.2698071524328574,
                "beyond: two souls": 0.2153173052316366,
                "dark souls": 0.514875542335506
            },
            "question": "which of these video games was not produced by fromsoftware?",
            "rate_limited": false,
            "answers": [
                "dark souls",
                "beyond: two souls",
                "demon's souls"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "demon's souls": 0.25573871030826667,
                "beyond: two souls": 0.6643471899651375,
                "dark souls": 0.3146435910416931
            },
            "negative_question": true,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.434193730422546,
                    1.269533932080983,
                    1.2962723374964709
                ],
                "result_count_important_words": [
                    977000.0,
                    72100.0,
                    134000.0
                ],
                "wikipedia_search": [
                    0.8538706058339567,
                    0.5108451757666417,
                    1.6352842183994016
                ],
                "answer_relation_to_question": [
                    1.1705664725861231,
                    0.9207908782144589,
                    0.9086426491994177
                ],
                "answer_relation_to_question_bing": [
                    1.415909090909091,
                    0.6467171717171717,
                    1.9373737373737374
                ],
                "result_count_noun_chunks": [
                    246000.0,
                    37500.0,
                    50500.0
                ],
                "question_answer_similarity": [
                    4.964029252529144,
                    11.149583349004388,
                    6.979864381253719
                ],
                "result_count_bing": [
                    49600000.0,
                    19100000.0,
                    152000.0
                ],
                "word_count_appended": [
                    236.0,
                    51.0,
                    144.0
                ],
                "result_count": [
                    188000.0,
                    38100.0,
                    36400.0
                ]
            },
            "integer_answers": {
                "demon's souls": 2,
                "beyond: two souls": 1,
                "dark souls": 7
            }
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Which NBA franchise has NOT retired any jersey numbers?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "brooklyn nets"
            ],
            "lines": [
                [
                    0.3957889733840304,
                    0.2764675052410902,
                    0.3569612677629822,
                    0.00022403750043081816,
                    0.4086181277860327,
                    0.49980902335702215,
                    0.2501484091143676,
                    0.36394707455711417,
                    0.3130841121495327,
                    0.3192981638743835,
                    -1.0
                ],
                [
                    0.30436311787072245,
                    0.33490566037735847,
                    0.3592748944801212,
                    0.4998965980767242,
                    0.39895988112927194,
                    0.49981673958502126,
                    0.49997624361922727,
                    0.3047349146498657,
                    0.3247663551401869,
                    0.34894836821747793,
                    -1.0
                ],
                [
                    0.29984790874524714,
                    0.3886268343815514,
                    0.2837638377568966,
                    0.4998793644228449,
                    0.19242199108469538,
                    0.00037423705795658346,
                    0.24987534726640515,
                    0.33131801079302015,
                    0.3621495327102804,
                    0.3317534679081386,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "dallas mavericks": 0.22487144537080453,
                "brooklyn nets": 0.3631306610546028,
                "los angeles clippers": 0.41199789357459277
            },
            "question": "which nba franchise has not retired any jersey numbers?",
            "rate_limited": false,
            "answers": [
                "brooklyn nets",
                "dallas mavericks",
                "los angeles clippers"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "dallas mavericks": 0.28625748112741217,
                "brooklyn nets": 0.38681758383785203,
                "los angeles clippers": 0.25111793905150304
            },
            "integer_answers": {
                "dallas mavericks": 1,
                "brooklyn nets": 4,
                "los angeles clippers": 5
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.8070183612561652,
                    1.5105163178252206,
                    1.6824653209186142
                ],
                "result_count_important_words": [
                    99.0,
                    95.0,
                    259000.0
                ],
                "wikipedia_search": [
                    1.360529254428858,
                    1.9526508535013432,
                    1.6868198920697985
                ],
                "answer_relation_to_question": [
                    0.8336882129277567,
                    1.5650950570342206,
                    1.601216730038023
                ],
                "answer_relation_to_question_bing": [
                    1.341194968553459,
                    0.990566037735849,
                    0.6682389937106918
                ],
                "result_count_noun_chunks": [
                    915000.0,
                    87.0,
                    916000.0
                ],
                "question_answer_similarity": [
                    2.967781642335467,
                    2.9197782883420587,
                    4.486489097587764
                ],
                "result_count_bing": [
                    1230000.0,
                    1360000.0,
                    4140000.0
                ],
                "result_count": [
                    406000.0,
                    84.0,
                    98.0
                ],
                "word_count_appended": [
                    80.0,
                    75.0,
                    59.0
                ]
            },
            "negative_question": true
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which of these is NOT a marsupial?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "quintana roo"
            ],
            "lines": [
                [
                    0.5,
                    0.5,
                    0.18376836484494402,
                    0.4693859649122807,
                    0.3386809269162211,
                    0.4927878532264867,
                    0.4999615709784029,
                    0.5,
                    0.46716541978387366,
                    0.40899581589958156,
                    -1.0
                ],
                [
                    0.2246376811594203,
                    0.3214285714285714,
                    0.17720885310834011,
                    0.47271929824561404,
                    0.3823529411764706,
                    0.47958667229017293,
                    0.48424410114518485,
                    0.5,
                    0.285120532003325,
                    0.3043933054393305,
                    -1.0
                ],
                [
                    0.2753623188405797,
                    0.17857142857142855,
                    0.6390227820467158,
                    0.05789473684210528,
                    0.2789661319073084,
                    0.02762547448334035,
                    0.015794327876412273,
                    0.0,
                    0.24771404821280135,
                    0.28661087866108786,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "cuscus": 0.2736616088007141,
                "quintana roo": 0.12785081668764192,
                "wombat": 0.5984875745116441
            },
            "question": "which of these is not a marsupial?",
            "rate_limited": false,
            "answers": [
                "quintana roo",
                "cuscus",
                "wombat"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "cuscus": 0.13056406301425563,
                "quintana roo": 0.6885960801157887,
                "wombat": 0.1919097416827229
            },
            "negative_question": true,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    0.18200836820083682,
                    0.3912133891213389,
                    0.42677824267782427
                ],
                "result_count_important_words": [
                    17100.0,
                    48400.0,
                    1120000.0
                ],
                "wikipedia_search": [
                    0.0,
                    0.0,
                    1.0
                ],
                "answer_relation_to_question": [
                    0.0,
                    0.5507246376811594,
                    0.4492753623188406
                ],
                "answer_relation_to_question_bing": [
                    0.0,
                    0.35714285714285715,
                    0.6428571428571429
                ],
                "result_count_noun_chunks": [
                    100.0,
                    41000.0,
                    1260000.0
                ],
                "question_answer_similarity": [
                    -0.7520406674593687,
                    -0.7676400542259216,
                    0.33061456913128495
                ],
                "result_count_bing": [
                    1810000.0,
                    1320000.0,
                    2480000.0
                ],
                "word_count_appended": [
                    79.0,
                    517.0,
                    607.0
                ],
                "result_count": [
                    34900.0,
                    31100.0,
                    504000.0
                ]
            },
            "integer_answers": {
                "cuscus": 1,
                "quintana roo": 0,
                "wombat": 9
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which of these is NOT the title of a current TV show?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "chicago police"
            ],
            "lines": [
                [
                    0.26643889149416045,
                    0.33139776011817257,
                    0.37008623613989455,
                    0.40625,
                    0.37056504599211565,
                    0.3807884856070088,
                    0.39953271028037385,
                    0.36744209692349494,
                    0.16995073891625617,
                    0.33288579841318,
                    -1.0
                ],
                [
                    0.28424443402335814,
                    0.28896854649139625,
                    0.3478136998114085,
                    0.1728515625,
                    0.26784932106876913,
                    0.2346683354192741,
                    0.1378504672897196,
                    0.30074818079327664,
                    0.49507389162561577,
                    0.32593045432855294,
                    -1.0
                ],
                [
                    0.4493166744824814,
                    0.3796336933904311,
                    0.2821000640486969,
                    0.4208984375,
                    0.36158563293911516,
                    0.3845431789737172,
                    0.46261682242990654,
                    0.3318097222832285,
                    0.3349753694581281,
                    0.34118374725826706,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "chicago med": 0.3209324472230686,
                "chicago police": 0.2502673314472056,
                "chicage fire": 0.42880022132972584
            },
            "question": "which of these is not the title of a current tv show?",
            "rate_limited": false,
            "answers": [
                "chicago med",
                "chicage fire",
                "chicago police"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "chicago med": 0.33477599982204354,
                "chicago police": 0.5691183938609593,
                "chicage fire": 0.2641870050527286
            },
            "integer_answers": {
                "chicago med": 2,
                "chicago police": 1,
                "chicage fire": 7
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.0026852095209198,
                    1.0444172740286826,
                    0.9528975164503977
                ],
                "result_count_important_words": [
                    38100.0,
                    84800.0,
                    36900.0
                ],
                "wikipedia_search": [
                    0.7953474184590307,
                    1.1955109152403403,
                    1.0091416663006292
                ],
                "answer_relation_to_question": [
                    1.401366651035037,
                    1.294533395859851,
                    0.30409995310511156
                ],
                "answer_relation_to_question_bing": [
                    1.0116134392909644,
                    1.2661887210516225,
                    0.7221978396574131
                ],
                "result_count_noun_chunks": [
                    344000.0,
                    1240000.0,
                    128000.0
                ],
                "question_answer_similarity": [
                    3.1205909717828035,
                    3.655587986111641,
                    5.234061062335968
                ],
                "result_count_bing": [
                    591000.0,
                    1060000.0,
                    632000.0
                ],
                "result_count": [
                    76800.0,
                    268000.0,
                    64800.0
                ],
                "word_count_appended": [
                    134.0,
                    2.0,
                    67.0
                ]
            },
            "negative_question": true
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which of these things is NOT found inside an atom?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "neutron"
            ],
            "lines": [
                [
                    0.34338624338624335,
                    0.28043478260869564,
                    0.22103760256197258,
                    0.2822346169821397,
                    0.33312061263560944,
                    0.24318525996971224,
                    0.20153061224489796,
                    0.32073643410852715,
                    0.31973094170403593,
                    0.305561800770476,
                    -1.0
                ],
                [
                    0.2962962962962963,
                    0.4,
                    0.4966159294720301,
                    0.476769714590874,
                    0.3334396936821953,
                    0.44043412417970723,
                    0.4472789115646259,
                    0.29761904761904767,
                    0.3668161434977579,
                    0.3912377819989585,
                    -1.0
                ],
                [
                    0.36031746031746037,
                    0.31956521739130433,
                    0.28234646796599727,
                    0.24099566842698628,
                    0.3334396936821953,
                    0.3163806158505805,
                    0.3511904761904762,
                    0.38164451827242524,
                    0.3134529147982063,
                    0.30320041723056557,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "wonton": 0.2106984714197015,
                "neutron": 0.3594933099747605,
                "proton": 0.4298082186055381
            },
            "question": "which of these things is not found inside an atom?",
            "rate_limited": false,
            "answers": [
                "proton",
                "wonton",
                "neutron"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "wonton": 0.28625748112741217,
                "neutron": 0.6360853028012676,
                "proton": 0.20437404155322325
            },
            "negative_question": true,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.1666291953771442,
                    0.6525733080062492,
                    1.1807974966166068
                ],
                "result_count_important_words": [
                    407000.0,
                    94400.0,
                    291000.0
                ],
                "wikipedia_search": [
                    1.0755813953488373,
                    1.2142857142857142,
                    0.7101328903654485
                ],
                "answer_relation_to_question": [
                    0.9396825396825397,
                    1.2222222222222223,
                    0.838095238095238
                ],
                "answer_relation_to_question_bing": [
                    0.8782608695652174,
                    0.4,
                    0.7217391304347827
                ],
                "result_count_noun_chunks": [
                    702000.0,
                    124000.0,
                    350000.0
                ],
                "question_answer_similarity": [
                    1.5770087577402592,
                    0.019130567088723183,
                    1.2304221978411078
                ],
                "result_count_bing": [
                    52300000.0,
                    52200000.0,
                    52200000.0
                ],
                "word_count_appended": [
                    402.0,
                    297.0,
                    416.0
                ],
                "result_count": [
                    734000.0,
                    78300.0,
                    873000.0
                ]
            },
            "integer_answers": {
                "wonton": 2,
                "neutron": 3,
                "proton": 5
            }
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "What actor famously yelled \"Not the bees! Not the bees!\" in a 2006 film?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "oprah winfrey"
            ],
            "lines": [
                [
                    0.0892857142857143,
                    0.2583333333333333,
                    1.4907865878808582,
                    0.09523809523809523,
                    0.3116045845272206,
                    0.10254506177006684,
                    0.2601972209771403,
                    0.3038935430478885,
                    0.24,
                    0.2600967145586739,
                    1.0
                ],
                [
                    0.4217032967032967,
                    0.3052083333333333,
                    -1.1773369883279967,
                    0.47619047619047616,
                    0.26504297994269344,
                    0.4995611962465402,
                    0.47960555804571947,
                    0.3826627183370782,
                    0.46,
                    0.37737994429142163,
                    1.0
                ],
                [
                    0.489010989010989,
                    0.43645833333333334,
                    0.6865504004471386,
                    0.4285714285714286,
                    0.42335243553008595,
                    0.39789374198339295,
                    0.2601972209771403,
                    0.3134437386150333,
                    0.3,
                    0.3625233411499045,
                    1.0
                ]
            ],
            "fraction_answers": {
                "macauley culkin": 0.5019964970474875,
                "nicolas cage": 0.3176038288762018,
                "oprah winfrey": 0.1803996740763107
            },
            "question": "what actor famously yelled \"not the bees! not the bees!\" in a 2006 film?",
            "rate_limited": false,
            "answers": [
                "nicolas cage",
                "macauley culkin",
                "oprah winfrey"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "macauley culkin": 0.5454038481654745,
                "nicolas cage": 0.1694185985668459,
                "oprah winfrey": 0.5908590295680388
            },
            "integer_answers": {
                "macauley culkin": 1,
                "nicolas cage": 9,
                "oprah winfrey": 0
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    3.358645996178565,
                    1.7166807799200972,
                    1.9246732239013373
                ],
                "result_count_important_words": [
                    47100.0,
                    52.0,
                    12100.0
                ],
                "wikipedia_search": [
                    1.176638741712669,
                    0.7040236899775306,
                    1.1193375683098006
                ],
                "answer_relation_to_question": [
                    3.2857142857142856,
                    0.6263736263736264,
                    0.08791208791208792
                ],
                "answer_relation_to_question_bing": [
                    0.9666666666666667,
                    0.7791666666666667,
                    0.25416666666666665
                ],
                "result_count_noun_chunks": [
                    214000.0,
                    18200.0,
                    214000.0
                ],
                "question_answer_similarity": [
                    2.9484580010175705,
                    -4.991546841803938,
                    0.5551508544012904
                ],
                "result_count_bing": [
                    263000.0,
                    328000.0,
                    107000.0
                ],
                "word_count_appended": [
                    13.0,
                    2.0,
                    10.0
                ],
                "result_count": [
                    17.0,
                    1.0,
                    3.0
                ]
            },
            "negative_question": true
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "What form of transportation counts Jay-Z as a prominent investor?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "e-bikes"
            ],
            "lines": [
                [
                    0.38437196648658056,
                    0.3951688202162585,
                    0.21880172288869149,
                    0.8886914019106865,
                    0.5058236272878536,
                    0.8145918186647778,
                    0.24188270828089606,
                    0.16511018786127168,
                    0.4782608695652174,
                    0.41448673164504185,
                    1.0
                ],
                [
                    0.2960659975363687,
                    0.30863802021297276,
                    0.6017750880559021,
                    0.015218840257720507,
                    0.2905158069883527,
                    0.017472404226432914,
                    0.6216964510445507,
                    0.4782153179190752,
                    0.14066496163682865,
                    0.1944196213984306,
                    1.0
                ],
                [
                    0.31956203597705074,
                    0.2961931595707687,
                    0.17942318905540647,
                    0.09608975783159297,
                    0.20366056572379368,
                    0.16793577710878932,
                    0.13642084067455323,
                    0.35667449421965314,
                    0.38107416879795397,
                    0.3910936469565276,
                    1.0
                ]
            ],
            "fraction_answers": {
                "boats": 0.252812763591609,
                "aviation": 0.4507189854807276,
                "e-bikes": 0.29646825092766343
            },
            "question": "what form of transportation counts jay-z as a prominent investor?",
            "rate_limited": false,
            "answers": [
                "aviation",
                "e-bikes",
                "boats"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "boats": 0.3889320307775609,
                "aviation": 0.2967332498747608,
                "e-bikes": 0.4604522169832008
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    2.901407121515293,
                    1.3609373497890143,
                    2.737655528695693
                ],
                "result_count_important_words": [
                    2760000.0,
                    59200.0,
                    569000.0
                ],
                "wikipedia_search": [
                    0.6604407514450867,
                    1.9128612716763007,
                    1.4266979768786126
                ],
                "answer_relation_to_question": [
                    1.9218598324329028,
                    1.4803299876818434,
                    1.5978101798852538
                ],
                "answer_relation_to_question_bing": [
                    1.1855064606487755,
                    0.9259140606389182,
                    0.888579478712306
                ],
                "result_count_noun_chunks": [
                    961000.0,
                    2470000.0,
                    542000.0
                ],
                "question_answer_similarity": [
                    2.1645172073040158,
                    5.953118265373632,
                    1.7749612524639815
                ],
                "result_count_bing": [
                    152000.0,
                    87300.0,
                    61200.0
                ],
                "word_count_appended": [
                    187.0,
                    55.0,
                    149.0
                ],
                "result_count": [
                    1600000.0,
                    27400.0,
                    173000.0
                ]
            },
            "integer_answers": {
                "boats": 0,
                "aviation": 7,
                "e-bikes": 3
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Mardi Gras is celebrated right before what other observance?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "lent"
            ],
            "lines": [
                [
                    0.5038957001573825,
                    0.25962815405046474,
                    0.6132297093779424,
                    0.5813953488372093,
                    0.25074037512339586,
                    0.7600534340596066,
                    0.5838198498748958,
                    0.4016225749559083,
                    0.44675925925925924,
                    0.3974144399523257,
                    1.0
                ],
                [
                    0.2957623331455107,
                    0.450199203187251,
                    0.1351850487461589,
                    0.1527777777777778,
                    0.5972359328726555,
                    0.19853516974526694,
                    0.14428690575479566,
                    0.28557319223985894,
                    0.2986111111111111,
                    0.29904050310743713,
                    1.0
                ],
                [
                    0.20034196669710685,
                    0.29017264276228416,
                    0.2515852418758987,
                    0.26582687338501293,
                    0.15202369200394866,
                    0.041411396195126446,
                    0.2718932443703086,
                    0.3128042328042328,
                    0.25462962962962965,
                    0.30354505694023715,
                    1.0
                ]
            ],
            "fraction_answers": {
                "kwanzaa": 0.2857207177687824,
                "ramadan": 0.2344233976663786,
                "lent": 0.479855884564839
            },
            "question": "mardi gras is celebrated right before what other observance?",
            "rate_limited": false,
            "answers": [
                "lent",
                "kwanzaa",
                "ramadan"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "kwanzaa": 0.20331097052063726,
                "ramadan": 0.15593170683073307,
                "lent": 0.6508613888515377
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.9870721997616285,
                    1.4952025155371858,
                    1.5177252847011857
                ],
                "result_count_important_words": [
                    165000.0,
                    43100.0,
                    8990.0
                ],
                "wikipedia_search": [
                    1.2048677248677249,
                    0.8567195767195768,
                    0.9384126984126984
                ],
                "answer_relation_to_question": [
                    2.5194785007869123,
                    1.4788116657275536,
                    1.0017098334855343
                ],
                "answer_relation_to_question_bing": [
                    0.7788844621513944,
                    1.3505976095617531,
                    0.8705179282868526
                ],
                "result_count_noun_chunks": [
                    210000.0,
                    51900.0,
                    97800.0
                ],
                "question_answer_similarity": [
                    1.887045793235302,
                    0.4159948118031025,
                    0.774184396257624
                ],
                "result_count_bing": [
                    254000.0,
                    605000.0,
                    154000.0
                ],
                "word_count_appended": [
                    386.0,
                    258.0,
                    220.0
                ],
                "result_count": [
                    180000.0,
                    47300.0,
                    82300.0
                ]
            },
            "integer_answers": {
                "kwanzaa": 2,
                "ramadan": 0,
                "lent": 8
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "In which state is happy hour currently banned?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "illinois"
            ],
            "lines": [
                [
                    0.1691297208538588,
                    0.5303030303030303,
                    0.25970209133061684,
                    0.4334226988382484,
                    0.27912087912087913,
                    0.42750197005516155,
                    0.3945675482487491,
                    0.39244089834515367,
                    0.4957446808510638,
                    0.37901705763122334,
                    -1.0
                ],
                [
                    0.4074712643678161,
                    0.2708333333333333,
                    0.23225752984005626,
                    0.37042001787310097,
                    0.34725274725274724,
                    0.42750197005516155,
                    0.403145103645461,
                    0.2851418439716312,
                    0.41702127659574467,
                    0.2782523871139196,
                    -1.0
                ],
                [
                    0.4233990147783251,
                    0.19886363636363638,
                    0.5080403788293268,
                    0.1961572832886506,
                    0.37362637362637363,
                    0.1449960598896769,
                    0.20228734810578985,
                    0.32241725768321516,
                    0.08723404255319149,
                    0.34273055525485707,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "arizona": 0.3439297474048972,
                "illinois": 0.3760950575577985,
                "rhode island": 0.2799751950373043
            },
            "question": "in which state is happy hour currently banned?",
            "rate_limited": false,
            "answers": [
                "illinois",
                "arizona",
                "rhode island"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "arizona": 0.23378669542828112,
                "illinois": 0.6913883145531048,
                "rhode island": 0.2580843667224179
            },
            "integer_answers": {
                "arizona": 1,
                "illinois": 6,
                "rhode island": 3
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.8950852881561167,
                    1.3912619355695979,
                    1.7136527762742855
                ],
                "result_count_important_words": [
                    2170000.0,
                    2170000.0,
                    736000.0
                ],
                "wikipedia_search": [
                    1.5697635933806147,
                    1.140567375886525,
                    1.2896690307328607
                ],
                "answer_relation_to_question": [
                    0.6765188834154352,
                    1.6298850574712644,
                    1.6935960591133004
                ],
                "answer_relation_to_question_bing": [
                    1.5909090909090908,
                    0.8125,
                    0.5965909090909092
                ],
                "result_count_noun_chunks": [
                    5520000.0,
                    5640000.0,
                    2830000.0
                ],
                "question_answer_similarity": [
                    1.4304169341921806,
                    1.2792546339333057,
                    2.798243007622659
                ],
                "result_count_bing": [
                    1270000.0,
                    1580000.0,
                    1700000.0
                ],
                "result_count": [
                    970000.0,
                    829000.0,
                    439000.0
                ],
                "word_count_appended": [
                    466.0,
                    392.0,
                    82.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "In baking, yeast helps bread rise, but scientifically yeast is what?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "fungus"
            ],
            "lines": [
                [
                    0.8,
                    0.5,
                    0.3043206998380932,
                    0.1253452584506116,
                    0.2632030914555603,
                    0.20665829145728642,
                    0.10560961648540355,
                    0.8807241145950824,
                    0.3352192362093352,
                    0.33434869336213124,
                    1.0
                ],
                [
                    0.2,
                    0.0,
                    0.32993410956901953,
                    0.7418124424569249,
                    0.4001717475311292,
                    0.4899497487437186,
                    0.6897538637664568,
                    0.06468531468531469,
                    0.32390381895332393,
                    0.31833329588645404,
                    1.0
                ],
                [
                    0.0,
                    0.5,
                    0.3657451905928873,
                    0.1328422990924635,
                    0.3366251610133104,
                    0.30339195979899497,
                    0.20463651974813968,
                    0.05459057071960298,
                    0.3408769448373409,
                    0.3473180107514147,
                    1.0
                ]
            ],
            "fraction_answers": {
                "fungus": 0.38554290018535037,
                "plant": 0.35585443415923423,
                "bacteria": 0.25860266565541545
            },
            "question": "in baking, yeast helps bread rise, but scientifically yeast is what?",
            "rate_limited": false,
            "answers": [
                "fungus",
                "plant",
                "bacteria"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "fungus": 0.5083420003384725,
                "plant": 0.18240446188912832,
                "bacteria": 0.4951247706704361
            },
            "integer_answers": {
                "fungus": 3,
                "plant": 4,
                "bacteria": 3
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    2.340440853534919,
                    2.2283330712051783,
                    2.431226075259903
                ],
                "result_count_important_words": [
                    65800.0,
                    156000.0,
                    96600.0
                ],
                "wikipedia_search": [
                    3.5228964583803295,
                    0.25874125874125875,
                    0.21836228287841192
                ],
                "answer_relation_to_question": [
                    4.0,
                    1.0,
                    0.0
                ],
                "answer_relation_to_question_bing": [
                    2.0,
                    0.0,
                    2.0
                ],
                "result_count_noun_chunks": [
                    738000.0,
                    4820000.0,
                    1430000.0
                ],
                "question_answer_similarity": [
                    3.1372757628560066,
                    3.4013272374868393,
                    3.7705076336860657
                ],
                "result_count_bing": [
                    613000.0,
                    932000.0,
                    784000.0
                ],
                "word_count_appended": [
                    237.0,
                    229.0,
                    241.0
                ],
                "result_count": [
                    95300.0,
                    564000.0,
                    101000.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which of these is classified as a neurological condition or disorder?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "multiple sclerosis"
            ],
            "lines": [
                [
                    0.17177177177177175,
                    0.16556776556776556,
                    0.09134108998673256,
                    0.0037489254672227706,
                    0.15995115995115994,
                    0.6643132220795892,
                    0.004183446064823865,
                    0.28756674294431733,
                    0.5204081632653061,
                    0.3001563334551931,
                    -1.0
                ],
                [
                    0.22507507507507507,
                    0.35091575091575095,
                    0.3633260241673973,
                    0.03315132605304212,
                    0.221001221001221,
                    0.1245186136071887,
                    0.022285647261211246,
                    0.20404271548436306,
                    0.23809523809523808,
                    0.3109779922447229,
                    -1.0
                ],
                [
                    0.6031531531531532,
                    0.4835164835164835,
                    0.5453328858458701,
                    0.9630997484797351,
                    0.6190476190476191,
                    0.21116816431322208,
                    0.9735309066739649,
                    0.5083905415713196,
                    0.24149659863945577,
                    0.38886567430008406,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "halitosis": 0.2369008620553882,
                "cystic fibrosis": 0.20933896039052105,
                "multiple sclerosis": 0.5537601775540908
            },
            "question": "which of these is classified as a neurological condition or disorder?",
            "rate_limited": false,
            "answers": [
                "halitosis",
                "cystic fibrosis",
                "multiple sclerosis"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "halitosis": 0.16108938919998458,
                "cystic fibrosis": 0.1864687616495298,
                "multiple sclerosis": 0.4329226347021648
            },
            "integer_answers": {
                "halitosis": 2,
                "cystic fibrosis": 0,
                "multiple sclerosis": 8
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.2006253338207724,
                    1.2439119689788916,
                    1.5554626972003363
                ],
                "result_count_important_words": [
                    2070000.0,
                    388000.0,
                    658000.0
                ],
                "wikipedia_search": [
                    0.8627002288329519,
                    0.6121281464530892,
                    1.5251716247139586
                ],
                "answer_relation_to_question": [
                    0.5153153153153153,
                    0.6752252252252252,
                    1.8094594594594595
                ],
                "answer_relation_to_question_bing": [
                    0.4967032967032967,
                    1.0527472527472528,
                    1.4505494505494505
                ],
                "result_count_noun_chunks": [
                    107000.0,
                    570000.0,
                    24900000.0
                ],
                "question_answer_similarity": [
                    1.1146197230555117,
                    4.433605428785086,
                    6.654604081064463
                ],
                "result_count_bing": [
                    1310000.0,
                    1810000.0,
                    5070000.0
                ],
                "result_count": [
                    94200.0,
                    833000.0,
                    24200000.0
                ],
                "word_count_appended": [
                    306.0,
                    140.0,
                    142.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which of these Uranus moons is NOT named after a Shakespearean character?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "oberon"
            ],
            "lines": [
                [
                    0.46827651515151514,
                    0.32916666666666666,
                    0.0,
                    0.12608695652173912,
                    0.11340206185567009,
                    0.11682059343682455,
                    0.11268078628039224,
                    0.4713541666666667,
                    0.27600554785020803,
                    0.3218553140139851,
                    -1.0
                ],
                [
                    0.2081168831168831,
                    0.22916666666666669,
                    0.5,
                    0.40217391304347827,
                    0.4520618556701031,
                    0.39565730005895067,
                    0.39858057582949,
                    0.20208333333333334,
                    0.3321775312066574,
                    0.32931574154584226,
                    -1.0
                ],
                [
                    0.3236066017316017,
                    0.44166666666666665,
                    0.5,
                    0.4717391304347826,
                    0.4345360824742268,
                    0.4875221065042248,
                    0.4887386378901178,
                    0.3265625,
                    0.39181692094313453,
                    0.34882894444017265,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "oberon": 0.5328702783112665,
                "trinculo": 0.15699648178301448,
                "umbriel": 0.31013323990571895
            },
            "question": "which of these uranus moons is not named after a shakespearean character?",
            "rate_limited": false,
            "answers": [
                "oberon",
                "umbriel",
                "trinculo"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "oberon": 0.4727941863905904,
                "trinculo": 0.3094541788260157,
                "umbriel": 0.22915511860866647
            },
            "integer_answers": {
                "oberon": 6,
                "trinculo": 0,
                "umbriel": 3
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.7814468598601492,
                    1.7068425845415776,
                    1.5117105555982735
                ],
                "result_count_important_words": [
                    19500.0,
                    5310.0,
                    635.0
                ],
                "wikipedia_search": [
                    0.22916666666666666,
                    2.3833333333333333,
                    1.3875
                ],
                "answer_relation_to_question": [
                    0.3172348484848485,
                    2.918831168831169,
                    1.7639339826839826
                ],
                "answer_relation_to_question_bing": [
                    1.3666666666666667,
                    2.1666666666666665,
                    0.4666666666666667
                ],
                "result_count_noun_chunks": [
                    17300.0,
                    4530.0,
                    503.0
                ],
                "question_answer_similarity": [
                    -0.7806879468262196,
                    0.0,
                    0.0
                ],
                "result_count_bing": [
                    225000.0,
                    27900.0,
                    38100.0
                ],
                "result_count": [
                    17200.0,
                    4500.0,
                    1300.0
                ],
                "word_count_appended": [
                    323.0,
                    242.0,
                    156.0
                ]
            },
            "negative_question": true
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Which of these knots is typically used to add another line to a rope?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "bowline"
            ],
            "lines": [
                [
                    0.5212026704876874,
                    0.35582154502094077,
                    0.009768658477227432,
                    0.6923837784371909,
                    0.6764111335717617,
                    0.3759124087591241,
                    0.9068574914672954,
                    0.5455273736757995,
                    0.601593625498008,
                    0.45444198713923906,
                    -1.0
                ],
                [
                    0.3620178535885087,
                    0.4374469940935198,
                    0.9902313415227726,
                    0.19386745796241345,
                    0.17882133416264967,
                    0.38047445255474455,
                    0.09233458094939735,
                    0.39576091075341446,
                    0.16533864541832669,
                    0.3435157180517906,
                    -1.0
                ],
                [
                    0.116779475923804,
                    0.20673146088553945,
                    0.0,
                    0.11374876360039565,
                    0.14476753226558856,
                    0.24361313868613138,
                    0.0008079275833072268,
                    0.058711715570786034,
                    0.23306772908366533,
                    0.20204229480897035,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "grantchester": 0.13202700384081884,
                "rolling hitch": 0.35398092890575383,
                "bowline": 0.5139920672534275
            },
            "question": "which of these knots is typically used to add another line to a rope?",
            "rate_limited": false,
            "answers": [
                "bowline",
                "rolling hitch",
                "grantchester"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "grantchester": 0.18601794534443725,
                "rolling hitch": 0.4245084753101353,
                "bowline": 0.5912514495960509
            },
            "integer_answers": {
                "grantchester": 0,
                "rolling hitch": 3,
                "bowline": 7
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    2.2722099356961953,
                    1.7175785902589529,
                    1.0102114740448518
                ],
                "result_count_important_words": [
                    41200.0,
                    41700.0,
                    26700.0
                ],
                "wikipedia_search": [
                    2.182109494703198,
                    1.5830436430136579,
                    0.23484686228314414
                ],
                "answer_relation_to_question": [
                    2.0848106819507493,
                    1.4480714143540345,
                    0.46711790369521594
                ],
                "answer_relation_to_question_bing": [
                    1.423286180083763,
                    1.7497879763740791,
                    0.8269258435421578
                ],
                "result_count_noun_chunks": [
                    110000.0,
                    11200.0,
                    98.0
                ],
                "question_answer_similarity": [
                    0.07064885040745139,
                    7.161546908318996,
                    0.0
                ],
                "result_count_bing": [
                    435000.0,
                    115000.0,
                    93100.0
                ],
                "word_count_appended": [
                    302.0,
                    83.0,
                    117.0
                ],
                "result_count": [
                    140000.0,
                    39200.0,
                    23000.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Which of these celebrities is known for having aviophobia?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "angelina jolie"
            ],
            "lines": [
                [
                    0.22905982905982905,
                    0.0,
                    0.26241121544127877,
                    0.4444444444444444,
                    0.2983159582999198,
                    0.4043478260869565,
                    0.4256410256410256,
                    0.8344907407407408,
                    0.4864864864864865,
                    0.39277492985335904,
                    -1.0
                ],
                [
                    0.4615384615384615,
                    0.7857142857142857,
                    0.4589561755030482,
                    0.2698412698412698,
                    0.34562951082598237,
                    0.30434782608695654,
                    0.28717948717948716,
                    0.07423941798941798,
                    0.35135135135135137,
                    0.3720364985853357,
                    -1.0
                ],
                [
                    0.3094017094017094,
                    0.21428571428571427,
                    0.27863260905567305,
                    0.2857142857142857,
                    0.35605453087409783,
                    0.29130434782608694,
                    0.28717948717948716,
                    0.09126984126984126,
                    0.16216216216216217,
                    0.2351885715613053,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "angelina jolie": 0.37779724560540406,
                "john travolta": 0.2511193259330363,
                "john madden": 0.3710834284615597
            },
            "question": "which of these celebrities is known for having aviophobia?",
            "rate_limited": false,
            "answers": [
                "angelina jolie",
                "john madden",
                "john travolta"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "angelina jolie": 0.6391307395823449,
                "john travolta": 0.15618747616637094,
                "john madden": 0.293173727978617
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.5710997194134362,
                    1.4881459943413429,
                    0.9407542862452212
                ],
                "result_count_important_words": [
                    93.0,
                    70.0,
                    67.0
                ],
                "wikipedia_search": [
                    2.5034722222222223,
                    0.22271825396825395,
                    0.2738095238095238
                ],
                "answer_relation_to_question": [
                    0.6871794871794872,
                    1.3846153846153846,
                    0.9282051282051282
                ],
                "answer_relation_to_question_bing": [
                    0.0,
                    1.5714285714285714,
                    0.42857142857142855
                ],
                "result_count_noun_chunks": [
                    83.0,
                    56.0,
                    56.0
                ],
                "question_answer_similarity": [
                    1.0088321383518633,
                    1.7644434105604887,
                    1.0711948052048683
                ],
                "result_count_bing": [
                    3720000.0,
                    4310000.0,
                    4440000.0
                ],
                "word_count_appended": [
                    36.0,
                    26.0,
                    12.0
                ],
                "result_count": [
                    84.0,
                    51.0,
                    54.0
                ]
            },
            "integer_answers": {
                "angelina jolie": 6,
                "john travolta": 1,
                "john madden": 3
            }
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "By definition, an Anglophile would be most interested in which of these things?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "geometry"
            ],
            "lines": [
                [
                    0.5,
                    1.0,
                    0.3023327550698545,
                    0.9932645579333277,
                    0.9502015403022523,
                    0.012015696504867526,
                    0.007859304043182929,
                    0.26666666666666666,
                    0.68,
                    0.4033161396459144,
                    -1.0
                ],
                [
                    0.5,
                    0.0,
                    0.011893953872856482,
                    0.0029840566118168642,
                    0.005889390964954058,
                    0.9879572681779966,
                    0.991851034270684,
                    0.7333333333333334,
                    0.28444444444444444,
                    0.34435285251990166,
                    -1.0
                ],
                [
                    0.0,
                    0.0,
                    0.685773291057289,
                    0.0037513854548554865,
                    0.04390906873279357,
                    2.703531713595193e-05,
                    0.0002896616861330302,
                    0.0,
                    0.035555555555555556,
                    0.2523310078341839,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "geometry": 0.5115656660166066,
                "downton abbey": 0.38627063341959866,
                "trout fishing": 0.10216370056379463
            },
            "question": "by definition, an anglophile would be most interested in which of these things?",
            "rate_limited": false,
            "answers": [
                "geometry",
                "downton abbey",
                "trout fishing"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "geometry": 0.6848730484950235,
                "downton abbey": 0.5235606111686657,
                "trout fishing": 0.16982491837610653
            },
            "integer_answers": {
                "geometry": 6,
                "downton abbey": 3,
                "trout fishing": 1
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.6132645585836576,
                    1.3774114100796067,
                    1.0093240313367355
                ],
                "result_count_important_words": [
                    36000.0,
                    2960000.0,
                    81.0
                ],
                "wikipedia_search": [
                    0.8,
                    2.2,
                    0.0
                ],
                "answer_relation_to_question": [
                    1.5,
                    1.5,
                    0.0
                ],
                "answer_relation_to_question_bing": [
                    1.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    22900.0,
                    2890000.0,
                    844.0
                ],
                "question_answer_similarity": [
                    2.0908243283629417,
                    0.08225429663434625,
                    4.74256082624197
                ],
                "result_count_bing": [
                    8180000.0,
                    50700.0,
                    378000.0
                ],
                "result_count": [
                    23300.0,
                    70.0,
                    88.0
                ],
                "word_count_appended": [
                    153.0,
                    64.0,
                    8.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Who wrote a #1 hit song for the Monkees?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "james taylor"
            ],
            "lines": [
                [
                    0.24932139584650087,
                    0.29323895202759714,
                    0.4592827845818843,
                    0.3345132743362832,
                    0.33294255568581477,
                    0.24646781789638933,
                    0.3333333333333333,
                    0.5366170441366657,
                    0,
                    0.33508395221356657,
                    0.0
                ],
                [
                    0.29729604208994287,
                    0.33525008170785425,
                    0.3607110767257043,
                    0.3327433628318584,
                    0.3335287221570926,
                    0.5677655677655677,
                    0.3333333333333333,
                    0.2946559946743365,
                    0,
                    0.3423255647013516,
                    0.0
                ],
                [
                    0.4533825620635563,
                    0.3715109662645486,
                    0.1800061386924114,
                    0.3327433628318584,
                    0.3335287221570926,
                    0.1857666143380429,
                    0.3333333333333333,
                    0.16872696118899783,
                    0,
                    0.32259048308508187,
                    0.0
                ]
            ],
            "fraction_answers": {
                "neil diamond": 0.3552899717763379,
                "james taylor": 0.34675567889533726,
                "jackson browne": 0.2979543493283248
            },
            "question": "who wrote a #1 hit song for the monkees?",
            "rate_limited": false,
            "answers": [
                "james taylor",
                "neil diamond",
                "jackson browne"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "neil diamond": 0.21899255757709032,
                "james taylor": 0.4464813178581922,
                "jackson browne": 0.36053323485718
            },
            "integer_answers": {
                "neil diamond": 3,
                "james taylor": 4,
                "jackson browne": 2
            },
            "categorical_data": {
                "question_type": 0
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.3403358088542663,
                    1.3693022588054065,
                    1.2903619323403275
                ],
                "result_count_important_words": [
                    94200.0,
                    217000.0,
                    71000.0
                ],
                "wikipedia_search": [
                    2.1464681765466627,
                    1.178623978697346,
                    0.6749078447559913
                ],
                "answer_relation_to_question": [
                    0.9972855833860035,
                    1.1891841683597715,
                    1.8135302482542253
                ],
                "answer_relation_to_question_bing": [
                    0.8797168560827915,
                    1.0057502451235627,
                    1.1145328987936458
                ],
                "result_count_noun_chunks": [
                    451000000.0,
                    451000000.0,
                    451000000.0
                ],
                "question_answer_similarity": [
                    3.3408411890268326,
                    2.623826676979661,
                    1.309371791430749
                ],
                "result_count_bing": [
                    56800000.0,
                    56900000.0,
                    56900000.0
                ],
                "word_count_appended": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count": [
                    37800000.0,
                    37600000.0,
                    37600000.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Anne of Green Gables literally means Anne of what?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "green walls"
            ],
            "lines": [
                [
                    0.47571766295170553,
                    0.3261183261183261,
                    0.29398007696491074,
                    0.5869565217391305,
                    0.3342911877394636,
                    0.6016260162601627,
                    0.1771492903864081,
                    0.08333333333333333,
                    0.5,
                    0.5170291486454773,
                    1.0
                ],
                [
                    0.3574636946977373,
                    0.32265512265512264,
                    0.31345494110442695,
                    0.043478260869565216,
                    0.33524904214559387,
                    0.04065040650406504,
                    2.613678054881431e-05,
                    0.430952380952381,
                    0.07142857142857142,
                    0.13208565400446648,
                    1.0
                ],
                [
                    0.16681864235055724,
                    0.35122655122655116,
                    0.3925649819306623,
                    0.3695652173913043,
                    0.33045977011494254,
                    0.35772357723577236,
                    0.8228245728330431,
                    0.4857142857142857,
                    0.42857142857142855,
                    0.3508851973500562,
                    1.0
                ]
            ],
            "fraction_answers": {
                "green pastures": 0.3896201564138918,
                "green walls": 0.40563542247186035,
                "green jars": 0.20474442111424782
            },
            "question": "anne of green gables literally means anne of what?",
            "rate_limited": false,
            "answers": [
                "green pastures",
                "green jars",
                "green walls"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "green pastures": 0.26020608592553657,
                "green walls": 0.699769386648072,
                "green jars": 0.3889320307775609
            },
            "integer_answers": {
                "green pastures": 5,
                "green walls": 4,
                "green jars": 1
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    3.102174891872864,
                    0.7925139240267989,
                    2.105311184100337
                ],
                "result_count_important_words": [
                    74.0,
                    5.0,
                    44.0
                ],
                "wikipedia_search": [
                    0.3333333333333333,
                    1.723809523809524,
                    1.9428571428571428
                ],
                "answer_relation_to_question": [
                    1.902870651806822,
                    1.429854778790949,
                    0.6672745694022288
                ],
                "answer_relation_to_question_bing": [
                    0.9783549783549783,
                    0.9679653679653679,
                    1.0536796536796535
                ],
                "result_count_noun_chunks": [
                    183000.0,
                    27.0,
                    850000.0
                ],
                "question_answer_similarity": [
                    4.595996670424938,
                    4.900460876524448,
                    6.137243613600731
                ],
                "result_count_bing": [
                    349000.0,
                    350000.0,
                    345000.0
                ],
                "result_count": [
                    54.0,
                    4.0,
                    34.0
                ],
                "word_count_appended": [
                    21.0,
                    3.0,
                    18.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "What Japanese word means \u201cempty orchestra\u201d?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "anime"
            ],
            "lines": [
                [
                    0.2423076923076923,
                    0.373015873015873,
                    0.44658484516116204,
                    0.10248112189859762,
                    0.2289639381797367,
                    0.3282828282828283,
                    0.35703703703703704,
                    0.15625,
                    0.19655172413793104,
                    0.3103835733338717,
                    1.0
                ],
                [
                    0.3857142857142857,
                    0.19047619047619047,
                    0.29825212549289426,
                    0.1387989931679252,
                    0.06697195191757298,
                    0.2777777777777778,
                    0.37777777777777777,
                    0.4270833333333333,
                    0.2218390804597701,
                    0.3085578618668118,
                    1.0
                ],
                [
                    0.371978021978022,
                    0.4365079365079365,
                    0.2551630293459437,
                    0.7587198849334772,
                    0.7040641099026903,
                    0.3939393939393939,
                    0.2651851851851852,
                    0.4166666666666667,
                    0.5816091954022988,
                    0.38105856479931655,
                    1.0
                ]
            ],
            "fraction_answers": {
                "sake": 0.27418586333547296,
                "anime": 0.26932493779843397,
                "karaoke": 0.4564891988660931
            },
            "question": "what japanese word means \u201cempty orchestra\u201d?",
            "rate_limited": false,
            "answers": [
                "sake",
                "anime",
                "karaoke"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "sake": 0.2532350023382388,
                "anime": 0.6466700040512644,
                "karaoke": 0.5071137307296453
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.2415342933354867,
                    1.2342314474672471,
                    1.5242342591972662
                ],
                "result_count_important_words": [
                    455000.0,
                    385000.0,
                    546000.0
                ],
                "wikipedia_search": [
                    0.625,
                    1.7083333333333333,
                    1.6666666666666667
                ],
                "answer_relation_to_question": [
                    0.9692307692307692,
                    1.5428571428571427,
                    1.487912087912088
                ],
                "answer_relation_to_question_bing": [
                    1.119047619047619,
                    0.5714285714285714,
                    1.3095238095238095
                ],
                "result_count_noun_chunks": [
                    241000.0,
                    255000.0,
                    179000.0
                ],
                "question_answer_similarity": [
                    2.953303724527359,
                    1.9723667800426483,
                    1.6874149069190025
                ],
                "result_count_bing": [
                    800000.0,
                    234000.0,
                    2460000.0
                ],
                "result_count": [
                    2850.0,
                    3860.0,
                    21100.0
                ],
                "word_count_appended": [
                    171.0,
                    193.0,
                    506.0
                ]
            },
            "integer_answers": {
                "sake": 1,
                "anime": 3,
                "karaoke": 6
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "What is Telluride, Colorado named after?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "an element"
            ],
            "lines": [
                [
                    0.45454545454545453,
                    0,
                    0.27549462008946013,
                    0.5595182163755179,
                    0.7661290322580645,
                    0.6238927828699068,
                    0.789838337182448,
                    0,
                    0.5210084033613446,
                    0.4826070605280739,
                    1.0
                ],
                [
                    0.36363636363636365,
                    0,
                    0.2947672410525409,
                    0.43992653653952934,
                    0.1174731182795699,
                    0.3754910267272587,
                    0.16474210931485758,
                    0,
                    0.3949579831932773,
                    0.4281680100687723,
                    1.0
                ],
                [
                    0.18181818181818182,
                    0,
                    0.429738138857999,
                    0.000555247084952804,
                    0.11639784946236559,
                    0.0006161904028344758,
                    0.04541955350269438,
                    0,
                    0.08403361344537816,
                    0.0892249294031539,
                    1.0
                ]
            ],
            "fraction_answers": {
                "a european city": 0.11847546299719501,
                "an element": 0.5591292384012838,
                "a governor": 0.3223952986015213
            },
            "question": "what is telluride, colorado named after?",
            "rate_limited": false,
            "answers": [
                "an element",
                "a governor",
                "a european city"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "a european city": 0.18431518776867642,
                "an element": 0.5053654822268607,
                "a governor": 0.4282802425733209
            },
            "integer_answers": {
                "a european city": 1,
                "an element": 7,
                "a governor": 0
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.4478211815842217,
                    1.2845040302063169,
                    0.26767478820946167
                ],
                "result_count_important_words": [
                    32400.0,
                    19500.0,
                    32.0
                ],
                "wikipedia_search": [
                    0.0,
                    0.0,
                    0.0
                ],
                "answer_relation_to_question": [
                    0.45454545454545453,
                    0.36363636363636365,
                    0.18181818181818182
                ],
                "answer_relation_to_question_bing": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    5130000.0,
                    1070000.0,
                    295000.0
                ],
                "question_answer_similarity": [
                    3.8979606702923775,
                    4.170648095197976,
                    6.08034510165453
                ],
                "result_count_bing": [
                    2850000.0,
                    437000.0,
                    433000.0
                ],
                "result_count": [
                    26200.0,
                    20600.0,
                    26.0
                ],
                "word_count_appended": [
                    62.0,
                    47.0,
                    10.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which of these is NOT a suit in a traditional Tarot deck?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "cups"
            ],
            "lines": [
                [
                    0.42105263157894735,
                    0,
                    0.32013387901234147,
                    0.056347376510864244,
                    0.30283381364073003,
                    0.39621981099054954,
                    0.4096153846153846,
                    0.24043062200956938,
                    0.4088114754098361,
                    0.3806605716408486,
                    -1.0
                ],
                [
                    0.2178362573099415,
                    0,
                    0.3262927253056208,
                    0.4727869768741703,
                    0.40297790585975024,
                    0.33304165208260417,
                    0.3153846153846154,
                    0.3181818181818182,
                    0.28125,
                    0.3091313932690446,
                    -1.0
                ],
                [
                    0.3611111111111111,
                    0,
                    0.3535733956820377,
                    0.47086564661496544,
                    0.2941882804995197,
                    0.27073853692684635,
                    0.275,
                    0.44138755980861244,
                    0.3099385245901639,
                    0.31020803509010686,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "gloves": 0.347532096575762,
                "cups": 0.3139975354836969,
                "swords": 0.3384703679405411
            },
            "question": "which of these is not a suit in a traditional tarot deck?",
            "rate_limited": false,
            "answers": [
                "gloves",
                "swords",
                "cups"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "gloves": 0.23378669542828112,
                "cups": 0.42348327208126574,
                "swords": 0.2042606275213018
            },
            "integer_answers": {
                "gloves": 3,
                "cups": 3,
                "swords": 3
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    0.9547154268732113,
                    1.5269488538476435,
                    1.5183357192791451
                ],
                "result_count_important_words": [
                    593000.0,
                    954000.0,
                    1310000.0
                ],
                "wikipedia_search": [
                    1.0382775119617225,
                    0.7272727272727273,
                    0.23444976076555024
                ],
                "answer_relation_to_question": [
                    0.631578947368421,
                    2.257309941520468,
                    1.1111111111111112
                ],
                "answer_relation_to_question_bing": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    470000.0,
                    960000.0,
                    1170000.0
                ],
                "question_answer_similarity": [
                    2.3634153008461,
                    2.2824889346957207,
                    1.924024797976017
                ],
                "result_count_bing": [
                    821000.0,
                    404000.0,
                    857000.0
                ],
                "result_count": [
                    12700000.0,
                    779000.0,
                    834000.0
                ],
                "word_count_appended": [
                    178.0,
                    427.0,
                    371.0
                ]
            },
            "negative_question": true
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Table tennis is also known as what?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "hunky-dory"
            ],
            "lines": [
                [
                    0.72,
                    0.8577319587628865,
                    0.7563207514471897,
                    0.8467899422230004,
                    0.3683187560738581,
                    0.9301672769959042,
                    0.9911619754937655,
                    0.20535714285714285,
                    0.5016949152542373,
                    0.6242947469435474,
                    1.0
                ],
                [
                    0.14444444444444443,
                    0.10790378006872853,
                    0.3266652415397998,
                    0.15235485043972471,
                    0.2633624878522838,
                    0.06341469638778661,
                    0.007850787924703093,
                    0.6785714285714286,
                    0.2830508474576271,
                    0.2089331954527179,
                    1.0
                ],
                [
                    0.13555555555555554,
                    0.034364261168384876,
                    -0.08298599298698954,
                    0.0008552073372749189,
                    0.3683187560738581,
                    0.006418026616309188,
                    0.000987236581531414,
                    0.11607142857142858,
                    0.21525423728813559,
                    0.1667720576037348,
                    1.0
                ]
            ],
            "fraction_answers": {
                "hunky-dory": 0.22365517601392443,
                "argle-bargle": 0.09616107738092235,
                "ping-pong": 0.6801837466051532
            },
            "question": "table tennis is also known as what?",
            "rate_limited": false,
            "answers": [
                "ping-pong",
                "hunky-dory",
                "argle-bargle"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "hunky-dory": 0.3931173256449866,
                "argle-bargle": 0.1844517795915823,
                "ping-pong": 0.2998502181204233
            },
            "integer_answers": {
                "hunky-dory": 1,
                "argle-bargle": 0,
                "ping-pong": 9
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.872884240830642,
                    0.6267995863581537,
                    0.5003161728112044
                ],
                "result_count_important_words": [
                    729000.0,
                    49700.0,
                    5030.0
                ],
                "wikipedia_search": [
                    0.4107142857142857,
                    1.3571428571428572,
                    0.23214285714285715
                ],
                "answer_relation_to_question": [
                    2.16,
                    0.43333333333333335,
                    0.4066666666666667
                ],
                "answer_relation_to_question_bing": [
                    2.5731958762886595,
                    0.3237113402061856,
                    0.10309278350515463
                ],
                "result_count_noun_chunks": [
                    5050000.0,
                    40000.0,
                    5030.0
                ],
                "question_answer_similarity": [
                    3.905524665489793,
                    1.6868493370711803,
                    -0.4285269733518362
                ],
                "result_count_bing": [
                    3790000.0,
                    2710000.0,
                    3790000.0
                ],
                "word_count_appended": [
                    296.0,
                    167.0,
                    127.0
                ],
                "result_count": [
                    5030000.0,
                    905000.0,
                    5080.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which of these countries is closest to the International Date Line?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "brazil"
            ],
            "lines": [
                [
                    0.35974513596541136,
                    0.17734778121775024,
                    0.4010674837634104,
                    0.49560269011898606,
                    0.33414239482200647,
                    0.30503380916604056,
                    0.16691394658753708,
                    0.32252483171803087,
                    0.3070624360286592,
                    0.3559989472362301,
                    -1.0
                ],
                [
                    0.3319132682086374,
                    0.4060887512899897,
                    0.2642045304237973,
                    0.16658044490429386,
                    0.33171521035598706,
                    0.2637114951164538,
                    0.33902077151335314,
                    0.37791367531208453,
                    0.34493346980552714,
                    0.3195620580413808,
                    -1.0
                ],
                [
                    0.3083415958259513,
                    0.41656346749226003,
                    0.3347279858127923,
                    0.33781686497672014,
                    0.33414239482200647,
                    0.43125469571750563,
                    0.4940652818991098,
                    0.2995614929698846,
                    0.34800409416581374,
                    0.3244389947223891,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "brazil": 0.31456436749715044,
                "japan": 0.32254394566240624,
                "spain": 0.3628916868404433
            },
            "question": "which of these countries is closest to the international date line?",
            "rate_limited": false,
            "answers": [
                "japan",
                "brazil",
                "spain"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "brazil": 0.5013911317004127,
                "japan": 0.1567077513257375,
                "spain": 0.28625748112741217
            },
            "integer_answers": {
                "brazil": 1,
                "japan": 5,
                "spain": 4
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.7799947361811506,
                    1.5978102902069042,
                    1.6221949736119454
                ],
                "result_count_important_words": [
                    4060000.0,
                    3510000.0,
                    5740000.0
                ],
                "wikipedia_search": [
                    1.2900993268721235,
                    1.5116547012483381,
                    1.1982459718795384
                ],
                "answer_relation_to_question": [
                    1.4389805438616454,
                    1.3276530728345497,
                    1.233366383303805
                ],
                "answer_relation_to_question_bing": [
                    0.709391124871001,
                    1.624355005159959,
                    1.6662538699690401
                ],
                "result_count_noun_chunks": [
                    2250000.0,
                    4570000.0,
                    6660000.0
                ],
                "question_answer_similarity": [
                    1.9795766919851303,
                    1.3040526881814003,
                    1.6521402150392532
                ],
                "result_count_bing": [
                    82600000.0,
                    82000000.0,
                    82600000.0
                ],
                "word_count_appended": [
                    300.0,
                    337.0,
                    340.0
                ],
                "result_count": [
                    9580000.0,
                    3220000.0,
                    6530000.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "The '70s sitcom \u201cThree's Company\u201d was about three people who were what?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "panda bears"
            ],
            "lines": [
                [
                    0.3535714285714286,
                    0.6666666666666666,
                    0.12018798833433601,
                    0.9990057288954122,
                    0.4916256978585118,
                    0.7413460207840475,
                    0.999952057093153,
                    0.28205128205128205,
                    0.95260663507109,
                    0.8090804840668975,
                    1.0
                ],
                [
                    0.5178571428571429,
                    0.0,
                    0.6151645829190068,
                    0.0,
                    0.4332972252312307,
                    6.589742406969312e-06,
                    0.0,
                    0.3333333333333333,
                    0.018957345971563982,
                    0.06396282419517228,
                    1.0
                ],
                [
                    0.1285714285714286,
                    0.3333333333333333,
                    0.2646474287466572,
                    0.0009942711045878509,
                    0.07507707691025747,
                    0.2586473894735455,
                    4.7942906846931996e-05,
                    0.3846153846153846,
                    0.02843601895734597,
                    0.12695669173793026,
                    1.0
                ]
            ],
            "fraction_answers": {
                "trivia show hosts": 0.19825790442498567,
                "roommates": 0.6416093989392826,
                "panda bears": 0.16013269663573176
            },
            "question": "the '70s sitcom \u201cthree's company\u201d was about three people who were what?",
            "rate_limited": false,
            "answers": [
                "roommates",
                "trivia show hosts",
                "panda bears"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "trivia show hosts": 0.26940956820962675,
                "roommates": 0.28660898814788266,
                "panda bears": 0.5022645427182497
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    2.4272414522006924,
                    0.19188847258551683,
                    0.38087007521379074
                ],
                "result_count_important_words": [
                    450000.0,
                    4.0,
                    157000.0
                ],
                "wikipedia_search": [
                    0.8461538461538461,
                    1.0,
                    1.1538461538461537
                ],
                "answer_relation_to_question": [
                    0.7071428571428571,
                    1.0357142857142856,
                    0.2571428571428571
                ],
                "answer_relation_to_question_bing": [
                    0.6666666666666666,
                    0.0,
                    0.3333333333333333
                ],
                "result_count_noun_chunks": [
                    730000.0,
                    0,
                    35.0
                ],
                "question_answer_similarity": [
                    2.478737026453018,
                    12.687051760964096,
                    5.458044432569295
                ],
                "result_count_bing": [
                    59000000.0,
                    52000000.0,
                    9010000.0
                ],
                "word_count_appended": [
                    201.0,
                    4.0,
                    6.0
                ],
                "result_count": [
                    21100.0,
                    0,
                    21.0
                ]
            },
            "integer_answers": {
                "trivia show hosts": 2,
                "roommates": 7,
                "panda bears": 1
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "How did Mason jars get their name?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "masons used them"
            ],
            "lines": [
                [
                    0.0,
                    0.0,
                    0.25523113929291164,
                    3.846137080940929e-06,
                    0.3146067415730337,
                    3.6468176142058516e-06,
                    3.787862526852789e-06,
                    0.0,
                    0.47619047619047616,
                    0.05774415073993672,
                    5.0
                ],
                [
                    0.3548255538599169,
                    0.3986013986013986,
                    0.39869682594891903,
                    0.9999956410446416,
                    0.31235955056179776,
                    0.9999957773690783,
                    0.9999957070891362,
                    0.0,
                    0.2857142857142857,
                    0.8750266036691781,
                    5.0
                ],
                [
                    0.6451744461400831,
                    0.6013986013986014,
                    0.34607203475816933,
                    5.128182774587905e-07,
                    0.37303370786516854,
                    5.758133075061872e-07,
                    5.050483369137052e-07,
                    1.0,
                    0.23809523809523808,
                    0.06722924559088522,
                    5.0
                ]
            ],
            "fraction_answers": {
                "named after inventor": 0.11037837886135801,
                "invented in mason, al": 0.5625211343858353,
                "masons used them": 0.3271004867528068
            },
            "question": "how did mason jars get their name?",
            "rate_limited": false,
            "answers": [
                "named after inventor",
                "invented in mason, al",
                "masons used them"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "named after inventor": 0.17566356090114896,
                "invented in mason, al": 0.2776220188745455,
                "masons used them": 0.4727941863905904
            },
            "integer_answers": {
                "named after inventor": 1,
                "invented in mason, al": 5,
                "masons used them": 4
            },
            "categorical_data": {
                "question_type": 5
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    0.11548830147987343,
                    1.7500532073383561,
                    0.13445849118177045
                ],
                "result_count_important_words": [
                    19.0,
                    5210000.0,
                    3.0
                ],
                "wikipedia_search": [
                    0.0,
                    0.0,
                    1.0
                ],
                "answer_relation_to_question": [
                    0.0,
                    0.7096511077198338,
                    1.2903488922801662
                ],
                "answer_relation_to_question_bing": [
                    0.0,
                    0.3986013986013986,
                    0.6013986013986014
                ],
                "result_count_noun_chunks": [
                    15.0,
                    3960000.0,
                    2.0
                ],
                "question_answer_similarity": [
                    6.142987018451095,
                    9.59596635773778,
                    8.329375572502613
                ],
                "result_count_bing": [
                    1400000.0,
                    1390000.0,
                    1660000.0
                ],
                "word_count_appended": [
                    10.0,
                    6.0,
                    5.0
                ],
                "result_count": [
                    15.0,
                    3900000.0,
                    2.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Who is NOT considered an official member of the Eagles?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "j.d. souther"
            ],
            "lines": [
                [
                    0.3432602440417508,
                    0.41581228640493456,
                    0.6971256234132697,
                    0.3611111111111111,
                    0.32194244604316546,
                    0.3805970149253731,
                    0.3830386881885729,
                    0.33333333333333337,
                    0.42727272727272725,
                    0.36964777712235963,
                    0.0
                ],
                [
                    0.3579641703049935,
                    0.2944694506960074,
                    0.0861530535134809,
                    0.33333333333333337,
                    0.34292565947242204,
                    0.29850746268656714,
                    0.27965667435306174,
                    0.2691658223573117,
                    0.28181818181818186,
                    0.32037579571624597,
                    0.0
                ],
                [
                    0.2987755856532557,
                    0.2897182628990581,
                    0.21672132307324943,
                    0.3055555555555556,
                    0.3351318944844125,
                    0.32089552238805974,
                    0.33730463745836536,
                    0.39750084430935495,
                    0.2909090909090909,
                    0.30997642716139434,
                    0.0
                ]
            ],
            "fraction_answers": {
                "j.d. souther": 0.1933717496286804,
                "randy meisner": 0.42712607914967887,
                "bernie leadon": 0.3795021712216407
            },
            "question": "who is not considered an official member of the eagles?",
            "rate_limited": false,
            "answers": [
                "j.d. souther",
                "randy meisner",
                "bernie leadon"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "j.d. souther": 0.564449004605831,
                "randy meisner": 0.09672420211921047,
                "bernie leadon": 0.1191077747639578
            },
            "negative_question": true,
            "categorical_data": {
                "question_type": 0
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.0428177830211227,
                    1.436993634270032,
                    1.5201885827088453
                ],
                "result_count_important_words": [
                    16.0,
                    27.0,
                    24.0
                ],
                "wikipedia_search": [
                    1.0,
                    1.3850050658561297,
                    0.6149949341438703
                ],
                "answer_relation_to_question": [
                    1.2539180476659937,
                    1.136286637560052,
                    1.6097953147739543
                ],
                "answer_relation_to_question_bing": [
                    0.5051262815703926,
                    1.233183295823956,
                    1.2616904226056513
                ],
                "result_count_noun_chunks": [
                    91300.0,
                    172000.0,
                    127000.0
                ],
                "question_answer_similarity": [
                    0.4345264742150903,
                    -0.9122479939833283,
                    -0.6244347263127565
                ],
                "result_count_bing": [
                    2970000.0,
                    2620000.0,
                    2750000.0
                ],
                "result_count": [
                    15.0,
                    18.0,
                    21.0
                ],
                "word_count_appended": [
                    16.0,
                    48.0,
                    46.0
                ]
            },
            "integer_answers": {
                "j.d. souther": 2,
                "randy meisner": 4,
                "bernie leadon": 4
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Catherine O'Hara and Eugene Levy do NOT kiss in which Christopher Guest film?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "waiting for guffman"
            ],
            "lines": [
                [
                    0.3960100694265515,
                    0.357364677377526,
                    0.28663031782274806,
                    0.4025670945157526,
                    0.08933107535986451,
                    0.4062863795110594,
                    0.22483766233766234,
                    0.4393939393939394,
                    0.3619528619528619,
                    0.3273588133893169,
                    -1.0
                ],
                [
                    0.3024394681981607,
                    0.3200735569870432,
                    0.34781547124473333,
                    0.35180863477246205,
                    0.4370589895568727,
                    0.34749708963911524,
                    0.40909090909090906,
                    0.0896464646464647,
                    0.26262626262626265,
                    0.33690079522534766,
                    -1.0
                ],
                [
                    0.3015504623752878,
                    0.3225617656354308,
                    0.3655542109325186,
                    0.24562427071178528,
                    0.47360993508326277,
                    0.24621653084982537,
                    0.3660714285714286,
                    0.47095959595959597,
                    0.37542087542087543,
                    0.3357403913853354,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "a mighty wind": 0.3590084716025258,
                "best in show": 0.34165342178254343,
                "waiting for guffman": 0.2993381066149308
            },
            "question": "catherine o'hara and eugene levy do not kiss in which christopher guest film?",
            "rate_limited": false,
            "answers": [
                "best in show",
                "a mighty wind",
                "waiting for guffman"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "a mighty wind": 0.2829987578138037,
                "best in show": 0.21092861003165136,
                "waiting for guffman": 0.33701872721215437
            },
            "integer_answers": {
                "a mighty wind": 3,
                "best in show": 4,
                "waiting for guffman": 3
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    2.76225898577093,
                    2.6095872763944374,
                    2.628153737834633
                ],
                "result_count_important_words": [
                    16100.0,
                    26200.0,
                    43600.0
                ],
                "wikipedia_search": [
                    0.36363636363636365,
                    2.462121212121212,
                    0.17424242424242425
                ],
                "answer_relation_to_question": [
                    1.663838889175176,
                    3.160968508829429,
                    3.175192601995394
                ],
                "answer_relation_to_question_bing": [
                    1.9968945167146366,
                    2.5189702021813947,
                    2.4841352811039688
                ],
                "result_count_noun_chunks": [
                    33900.0,
                    11200.0,
                    16500.0
                ],
                "question_answer_similarity": [
                    10.79942603642121,
                    7.702619910240173,
                    6.8047969145700336
                ],
                "result_count_bing": [
                    582000.0,
                    89200.0,
                    37400.0
                ],
                "result_count": [
                    16700.0,
                    25400.0,
                    43600.0
                ],
                "word_count_appended": [
                    82.0,
                    141.0,
                    74.0
                ]
            },
            "negative_question": true
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "What SportsCenter anchor shares their last name with Linus & Lucy from \u201cPeanuts\u201d?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "jemele hill"
            ],
            "lines": [
                [
                    0.3650502197112367,
                    0.3460346034603461,
                    0.2873738733448794,
                    0.3333333333333333,
                    0.3333333333333333,
                    0.4606741573033708,
                    0.0033024741486654755,
                    0.34523809523809523,
                    0.25,
                    0.3342475840601737,
                    1.0
                ],
                [
                    0.21142498430634024,
                    0.36223622362236224,
                    0.5281511140389037,
                    0.3333333333333333,
                    0.3333333333333333,
                    0.33707865168539325,
                    0.25499431541335066,
                    0.19047619047619047,
                    0.5,
                    0.3342475840601737,
                    1.0
                ],
                [
                    0.4235247959824231,
                    0.2917291729172918,
                    0.18447501261621685,
                    0.3333333333333333,
                    0.3333333333333333,
                    0.20224719101123595,
                    0.7417032104379838,
                    0.4642857142857143,
                    0.25,
                    0.33150483187965263,
                    1.0
                ]
            ],
            "fraction_answers": {
                "jemele hill": 0.3058587673933434,
                "kenny mayne": 0.35561365957971847,
                "scott van pelt": 0.33852757302693803
            },
            "question": "what sportscenter anchor shares their last name with linus & lucy from \u201cpeanuts\u201d?",
            "rate_limited": false,
            "answers": [
                "jemele hill",
                "scott van pelt",
                "kenny mayne"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "jemele hill": 0.47372789390021197,
                "kenny mayne": 0.4426912566568178,
                "scott van pelt": 0.20118703743149557
            },
            "integer_answers": {
                "jemele hill": 4,
                "kenny mayne": 3,
                "scott van pelt": 3
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    2.005485504361042,
                    2.005485504361042,
                    1.9890289912779158
                ],
                "result_count_important_words": [
                    41.0,
                    30.0,
                    18.0
                ],
                "wikipedia_search": [
                    0.6904761904761905,
                    0.38095238095238093,
                    0.9285714285714286
                ],
                "answer_relation_to_question": [
                    1.0951506591337101,
                    0.6342749529190207,
                    1.2705743879472693
                ],
                "answer_relation_to_question_bing": [
                    1.038103810381038,
                    1.0867086708670866,
                    0.8751875187518752
                ],
                "result_count_noun_chunks": [
                    61.0,
                    4710.0,
                    13700.0
                ],
                "question_answer_similarity": [
                    2.472496133297682,
                    4.544085974339396,
                    1.5871789250522852
                ],
                "result_count_bing": [
                    244000.0,
                    244000.0,
                    244000.0
                ],
                "result_count": [
                    174000.0,
                    174000.0,
                    174000.0
                ],
                "word_count_appended": [
                    2.0,
                    4.0,
                    2.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "How do you let someone on Tinder know you're interested?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "swipe right"
            ],
            "lines": [
                [
                    0.4761904761904761,
                    0.5,
                    0.2599849600624926,
                    0.9998873644668486,
                    0.2727272727272727,
                    0.9983076899191107,
                    0.9998860999312252,
                    0.9128571428571428,
                    0.8333333333333334,
                    0.7084357898270942,
                    5.0
                ],
                [
                    0.21740362811791383,
                    0.1111111111111111,
                    0.5174167924346847,
                    0.0,
                    0.5365853658536586,
                    0.0008073405890481144,
                    2.782291756330366e-05,
                    0.06469387755102039,
                    0.027777777777777776,
                    0.07016436092650927,
                    5.0
                ],
                [
                    0.30640589569161,
                    0.3888888888888889,
                    0.22259824750282267,
                    0.00011263553315140389,
                    0.19068736141906872,
                    0.0008849694918412023,
                    8.60771512114707e-05,
                    0.02244897959183673,
                    0.1388888888888889,
                    0.22139984924639658,
                    5.0
                ]
            ],
            "fraction_answers": {
                "draw circle around face": 0.1545988077279287,
                "shake phone": 0.14924017934057165,
                "swipe right": 0.6961610129314997
            },
            "question": "how do you let someone on tinder know you're interested?",
            "rate_limited": false,
            "answers": [
                "swipe right",
                "draw circle around face",
                "shake phone"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "draw circle around face": 0.19816124821607126,
                "shake phone": 0.17784088019157332,
                "swipe right": 0.6088752263191174
            },
            "integer_answers": {
                "draw circle around face": 2,
                "shake phone": 0,
                "swipe right": 8
            },
            "categorical_data": {
                "question_type": 5
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    3.542178949135471,
                    0.3508218046325463,
                    1.1069992462319829
                ],
                "result_count_important_words": [
                    64300.0,
                    52.0,
                    57.0
                ],
                "wikipedia_search": [
                    4.564285714285715,
                    0.32346938775510203,
                    0.11224489795918367
                ],
                "answer_relation_to_question": [
                    1.9047619047619044,
                    0.8696145124716553,
                    1.22562358276644
                ],
                "answer_relation_to_question_bing": [
                    1.5,
                    0.3333333333333333,
                    1.1666666666666667
                ],
                "result_count_noun_chunks": [
                    1150000.0,
                    32.0,
                    99.0
                ],
                "question_answer_similarity": [
                    8.666833512485027,
                    17.248556206934154,
                    7.420513674383983
                ],
                "result_count_bing": [
                    4920000.0,
                    9680000.0,
                    3440000.0
                ],
                "word_count_appended": [
                    90.0,
                    3.0,
                    15.0
                ],
                "result_count": [
                    506000.0,
                    0,
                    57.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Blue spruce, red cedar & white pine are all kinds of what?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "evergreen trees"
            ],
            "lines": [
                [
                    0.26118800010425625,
                    0.1706267044479807,
                    0.24184512436559077,
                    0.3333333333333333,
                    0.2755102040816326,
                    0.0,
                    0.0,
                    0.26850152905198776,
                    0.0,
                    0.3333333333333333,
                    1.0
                ],
                [
                    0.048915734876326014,
                    0.1249149624651716,
                    0.13596316450215923,
                    0.3333333333333333,
                    0.2743764172335601,
                    4.132060658650469e-05,
                    0.0002962085308056872,
                    0.08402504732779963,
                    0.0,
                    0.3333333333333333,
                    1.0
                ],
                [
                    0.6898962650194177,
                    0.7044583330868477,
                    0.62219171113225,
                    0.3333333333333333,
                    0.4501133786848073,
                    0.9999586793934135,
                    0.9997037914691943,
                    0.6474734236202127,
                    1.0,
                    0.3333333333333333,
                    1.0
                ]
            ],
            "fraction_answers": {
                "marvel supervillains": 0.13351995222090757,
                "evergreen trees": 0.678046224907281,
                "colgate flavors": 0.18843382287181148
            },
            "question": "blue spruce, red cedar & white pine are all kinds of what?",
            "rate_limited": false,
            "answers": [
                "colgate flavors",
                "marvel supervillains",
                "evergreen trees"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "marvel supervillains": 0.21356765331609567,
                "evergreen trees": 0.6329514762382664,
                "colgate flavors": 0.1800286910837833
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    2.333333333333333,
                    2.333333333333333,
                    2.333333333333333
                ],
                "result_count_important_words": [
                    0.0,
                    10.0,
                    242000.0
                ],
                "wikipedia_search": [
                    1.8795107033639145,
                    0.5881753312945974,
                    4.532313965341489
                ],
                "answer_relation_to_question": [
                    1.8283160007297938,
                    0.3424101441342821,
                    4.8292738551359236
                ],
                "answer_relation_to_question_bing": [
                    1.1943869311358648,
                    0.8744047372562012,
                    4.931208331607934
                ],
                "result_count_noun_chunks": [
                    0.0,
                    32.0,
                    108000.0
                ],
                "question_answer_similarity": [
                    3.01923155086115,
                    1.6973849569913,
                    7.76753655821085
                ],
                "result_count_bing": [
                    243000.0,
                    242000.0,
                    397000.0
                ],
                "word_count_appended": [
                    0.0,
                    0.0,
                    9.0
                ],
                "result_count": [
                    3700000.0,
                    3700000.0,
                    3700000.0
                ]
            },
            "integer_answers": {
                "marvel supervillains": 0,
                "evergreen trees": 8,
                "colgate flavors": 2
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which of these actors was a high school cheerleader?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "george clooney"
            ],
            "lines": [
                [
                    0.5580808080808081,
                    0.175,
                    0.2644841029754693,
                    0.42573623559539053,
                    0.3333333333333333,
                    0.4718792866941015,
                    0.46309289924221164,
                    0.36481481481481487,
                    0.35555555555555557,
                    0.3417498115535661,
                    -1.0
                ],
                [
                    0.12121212121212122,
                    0.3,
                    0.4041569489050635,
                    0.21895006402048656,
                    0.3333333333333333,
                    0.33607681755829905,
                    0.2057255122088128,
                    0.10555555555555556,
                    0.2740740740740741,
                    0.3226908782527589,
                    -1.0
                ],
                [
                    0.3207070707070707,
                    0.525,
                    0.3313589481194672,
                    0.3553137003841229,
                    0.3333333333333333,
                    0.19204389574759945,
                    0.33118158854897556,
                    0.5296296296296297,
                    0.37037037037037035,
                    0.33555931019367496,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "john travolta": 0.3624497847034244,
                "george clooney": 0.3753726847845251,
                "michael douglas": 0.2621775305120505
            },
            "question": "which of these actors was a high school cheerleader?",
            "rate_limited": false,
            "answers": [
                "george clooney",
                "michael douglas",
                "john travolta"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "john travolta": 0.3142539676838528,
                "george clooney": 0.572484251260286,
                "michael douglas": 0.23970605428840544
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.3669992462142644,
                    1.2907635130110355,
                    1.3422372407746999
                ],
                "result_count_important_words": [
                    344000.0,
                    245000.0,
                    140000.0
                ],
                "wikipedia_search": [
                    1.0944444444444446,
                    0.31666666666666665,
                    1.588888888888889
                ],
                "answer_relation_to_question": [
                    1.6742424242424243,
                    0.36363636363636365,
                    0.9621212121212122
                ],
                "answer_relation_to_question_bing": [
                    0.35,
                    0.6,
                    1.05
                ],
                "result_count_noun_chunks": [
                    165000.0,
                    73300.0,
                    118000.0
                ],
                "question_answer_similarity": [
                    1.4658440416678786,
                    2.239949580281973,
                    1.8364829276688397
                ],
                "result_count_bing": [
                    21900000.0,
                    21900000.0,
                    21900000.0
                ],
                "word_count_appended": [
                    48.0,
                    37.0,
                    50.0
                ],
                "result_count": [
                    133000.0,
                    68400.0,
                    111000.0
                ]
            },
            "integer_answers": {
                "john travolta": 3,
                "george clooney": 6,
                "michael douglas": 1
            }
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Which of these restaurant brands has its original location in Europe?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "benihana"
            ],
            "lines": [
                [
                    0.17345661846496108,
                    0.39693256647495206,
                    -0.09341174832817872,
                    0.2272366121086922,
                    0.33360723089564503,
                    0.5464216634429401,
                    0.23323118828736805,
                    0.6653508771929825,
                    0.8151447661469933,
                    0.3667544910338699,
                    -1.0
                ],
                [
                    0.49275548330053337,
                    0.31591231141118614,
                    0.6188005737291824,
                    0.641983155887494,
                    0.33278553820870993,
                    0.15570599613152805,
                    0.6332992849846782,
                    0.2655701754385965,
                    0.11358574610244988,
                    0.31781036804418134,
                    -1.0
                ],
                [
                    0.3337878982345056,
                    0.2871551221138618,
                    0.4746111745989963,
                    0.13078023200381375,
                    0.33360723089564503,
                    0.2978723404255319,
                    0.1334695267279537,
                    0.06907894736842105,
                    0.07126948775055679,
                    0.3154351409219488,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "mr. chow": 0.24470671010412345,
                "benihana": 0.3664724265720225,
                "p.f. chang's": 0.388820863323854
            },
            "question": "which of these restaurant brands has its original location in europe?",
            "rate_limited": false,
            "answers": [
                "benihana",
                "p.f. chang's",
                "mr. chow"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "mr. chow": 0.17205802534291176,
                "benihana": 0.4785353019798712,
                "p.f. chang's": 0.37636173294518993
            },
            "integer_answers": {
                "mr. chow": 0,
                "benihana": 6,
                "p.f. chang's": 4
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.8337724551693495,
                    1.5890518402209066,
                    1.5771757046097439
                ],
                "result_count_important_words": [
                    113000.0,
                    32200.0,
                    61600.0
                ],
                "wikipedia_search": [
                    2.66140350877193,
                    1.062280701754386,
                    0.2763157894736842
                ],
                "answer_relation_to_question": [
                    0.6938264738598443,
                    1.9710219332021335,
                    1.3351515929380224
                ],
                "answer_relation_to_question_bing": [
                    1.1907976994248561,
                    0.9477369342335584,
                    0.8614653663415854
                ],
                "result_count_noun_chunks": [
                    137000.0,
                    372000.0,
                    78400.0
                ],
                "question_answer_similarity": [
                    -1.2132769133895636,
                    8.037280786782503,
                    6.164479214698076
                ],
                "result_count_bing": [
                    406000.0,
                    405000.0,
                    406000.0
                ],
                "result_count": [
                    143000.0,
                    404000.0,
                    82300.0
                ],
                "word_count_appended": [
                    366.0,
                    51.0,
                    32.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "In which of these movies is the title NOT spoken by any character?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "gravity"
            ],
            "lines": [
                [
                    0.1514056224899598,
                    0.15505268199233718,
                    0.35123211291886114,
                    0.49999443000395666,
                    0.2665320545179203,
                    0.4125,
                    0.4552238805970149,
                    0.10241739211831885,
                    0.3276633840644584,
                    0.33013328255858804,
                    -1.0
                ],
                [
                    0.41244979919678715,
                    0.41391283524904215,
                    0.34398438693097644,
                    0.4999946265920523,
                    0.4757698132256436,
                    0.375,
                    0.2582918739635157,
                    0.42334784236637646,
                    0.3084153983885407,
                    0.3478081840412089,
                    -1.0
                ],
                [
                    0.436144578313253,
                    0.43103448275862066,
                    0.3047835001501624,
                    1.0943403991048317e-05,
                    0.2576981322564361,
                    0.21250000000000002,
                    0.2864842454394693,
                    0.4742347655153047,
                    0.3639212175470009,
                    0.3220585334002031,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "inception": 0.3895690317477169,
                "speed": 0.38222592024311175,
                "gravity": 0.2282050480091713
            },
            "question": "in which of these movies is the title not spoken by any character?",
            "rate_limited": false,
            "answers": [
                "inception",
                "gravity",
                "speed"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "inception": 0.22915511860866647,
                "speed": 0.45583458064806415,
                "gravity": 0.5087048089426612
            },
            "negative_question": true,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.3589337395312957,
                    1.2175345276703289,
                    1.4235317327983752
                ],
                "result_count_important_words": [
                    1120000.0,
                    1600000.0,
                    3680000.0
                ],
                "wikipedia_search": [
                    2.385495647290087,
                    0.4599129458017411,
                    0.15459140690817186
                ],
                "answer_relation_to_question": [
                    2.0915662650602407,
                    0.5253012048192771,
                    0.383132530120482
                ],
                "answer_relation_to_question_bing": [
                    1.3797892720306513,
                    0.3443486590038314,
                    0.27586206896551724
                ],
                "result_count_noun_chunks": [
                    1080000.0,
                    5830000.0,
                    5150000.0
                ],
                "question_answer_similarity": [
                    2.5318306535482407,
                    2.655177265405655,
                    3.322323977947235
                ],
                "result_count_bing": [
                    18500000.0,
                    1920000.0,
                    19200000.0
                ],
                "result_count": [
                    85.0,
                    82.0,
                    7630000.0
                ],
                "word_count_appended": [
                    385.0,
                    428.0,
                    304.0
                ]
            },
            "integer_answers": {
                "inception": 3,
                "speed": 5,
                "gravity": 2
            }
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "The creator of Wonder Woman also created an early version of what device?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "lie detector"
            ],
            "lines": [
                [
                    0.21538461538461537,
                    0.4920634920634921,
                    0.31936832344364147,
                    0.3333333333333333,
                    0.11429776465626318,
                    0.9935438976301851,
                    0.9953740628489393,
                    0.03469387755102041,
                    0.12307692307692308,
                    0.2738928515212818,
                    1.0
                ],
                [
                    0.45384615384615384,
                    0.30158730158730157,
                    0.3882621007823312,
                    0.15555555555555556,
                    0.4639392661324336,
                    0.0031314029458383266,
                    0.002392726112617642,
                    0.3508967223252938,
                    0.38461538461538464,
                    0.20999648190110656,
                    1.0
                ],
                [
                    0.33076923076923076,
                    0.2063492063492064,
                    0.2923695757740273,
                    0.5111111111111111,
                    0.42176296921130324,
                    0.003324699423976495,
                    0.002233211038443133,
                    0.6144094001236857,
                    0.49230769230769234,
                    0.5161106665776117,
                    1.0
                ]
            ],
            "fraction_answers": {
                "lie detector": 0.33907477626862886,
                "hearing aid": 0.27142230958040164,
                "magic marker": 0.3895029141509695
            },
            "question": "the creator of wonder woman also created an early version of what device?",
            "rate_limited": false,
            "answers": [
                "magic marker",
                "hearing aid",
                "lie detector"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "lie detector": 0.4219041519888127,
                "hearing aid": 0.22161469137302633,
                "magic marker": 0.16572223418065904
            },
            "integer_answers": {
                "lie detector": 4,
                "hearing aid": 3,
                "magic marker": 3
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.9172499606489726,
                    1.4699753733077459,
                    3.612774666043282
                ],
                "result_count_important_words": [
                    25700.0,
                    81.0,
                    86.0
                ],
                "wikipedia_search": [
                    0.24285714285714285,
                    2.4562770562770564,
                    4.3008658008658
                ],
                "answer_relation_to_question": [
                    1.0769230769230769,
                    2.269230769230769,
                    1.6538461538461537
                ],
                "answer_relation_to_question_bing": [
                    1.476190476190476,
                    0.9047619047619047,
                    0.6190476190476191
                ],
                "result_count_noun_chunks": [
                    31200.0,
                    75.0,
                    70.0
                ],
                "question_answer_similarity": [
                    6.546491540968418,
                    7.958693370223045,
                    5.9930644780397415
                ],
                "result_count_bing": [
                    271000.0,
                    1100000.0,
                    1000000.0
                ],
                "word_count_appended": [
                    16.0,
                    50.0,
                    64.0
                ],
                "result_count": [
                    45.0,
                    21.0,
                    69.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which player won Rookie of the Year in their sport most recently?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "blake griffin"
            ],
            "lines": [
                [
                    0.45514195843143207,
                    0.20303807303807303,
                    0.5754058205595037,
                    0.2440944881889764,
                    0.375,
                    0.32926829268292684,
                    5.955571437079388e-05,
                    0.39216705261113155,
                    0.1941747572815534,
                    0.2986936187286241,
                    -1.0
                ],
                [
                    0.18470207505295225,
                    0.1641724941724942,
                    0.300034466776248,
                    0.3543307086614173,
                    0.28308823529411764,
                    0.2804878048780488,
                    0.10064915728664166,
                    0.16188290419375945,
                    0.4368932038834951,
                    0.3159170100463626,
                    -1.0
                ],
                [
                    0.3601559665156156,
                    0.6327894327894328,
                    0.12455971266424831,
                    0.4015748031496063,
                    0.34191176470588236,
                    0.3902439024390244,
                    0.8992912869989875,
                    0.445950043195109,
                    0.36893203883495146,
                    0.3853893712250133,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "mike trout": 0.3067043617236592,
                "von miller": 0.25821580602455374,
                "blake griffin": 0.43507983225178715
            },
            "question": "which player won rookie of the year in their sport most recently?",
            "rate_limited": false,
            "answers": [
                "mike trout",
                "von miller",
                "blake griffin"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "mike trout": 0.21130006784269903,
                "von miller": 0.25103914643929315,
                "blake griffin": 0.5932336854143451
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.7921617123717446,
                    1.8955020602781754,
                    2.31233622735008
                ],
                "result_count_important_words": [
                    27.0,
                    23.0,
                    32.0
                ],
                "wikipedia_search": [
                    1.9608352630556578,
                    0.8094145209687973,
                    2.229750215975545
                ],
                "answer_relation_to_question": [
                    2.7308517505885925,
                    1.1082124503177135,
                    2.1609357990936937
                ],
                "answer_relation_to_question_bing": [
                    1.015190365190365,
                    0.8208624708624709,
                    3.1639471639471637
                ],
                "result_count_noun_chunks": [
                    100.0,
                    169000.0,
                    1510000.0
                ],
                "question_answer_similarity": [
                    3.5639198571443558,
                    1.858338507823646,
                    0.7714917324483395
                ],
                "result_count_bing": [
                    612000.0,
                    462000.0,
                    558000.0
                ],
                "word_count_appended": [
                    40.0,
                    90.0,
                    76.0
                ],
                "result_count": [
                    31.0,
                    45.0,
                    51.0
                ]
            },
            "integer_answers": {
                "mike trout": 3,
                "von miller": 1,
                "blake griffin": 6
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "In computing, what unit is half a byte?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "nibble"
            ],
            "lines": [
                [
                    0.33592582495254253,
                    0.2793906810035842,
                    0.5522246340505271,
                    0.4772727272727273,
                    0.35125448028673834,
                    0.4774774774774775,
                    0.4774774774774775,
                    1.0,
                    0.6602708803611738,
                    0.4982077769275056,
                    1.0
                ],
                [
                    0.25088604143947657,
                    0.10976702508960574,
                    0.0,
                    0.0,
                    0.3064516129032258,
                    0.0,
                    0.0,
                    0.0,
                    0.01805869074492099,
                    0.02973073586228632,
                    1.0
                ],
                [
                    0.41318813360798096,
                    0.6108422939068101,
                    0.44777536594947287,
                    0.5227272727272727,
                    0.34229390681003585,
                    0.5225225225225225,
                    0.5225225225225225,
                    0.0,
                    0.3216704288939052,
                    0.47206148721020796,
                    1.0
                ]
            ],
            "fraction_answers": {
                "demibyte": 0.07148941060395154,
                "octet": 0.41756039341507306,
                "nibble": 0.5109501959809755
            },
            "question": "in computing, what unit is half a byte?",
            "rate_limited": false,
            "answers": [
                "nibble",
                "demibyte",
                "octet"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "demibyte": 0.1844517795915823,
                "octet": 0.2998502181204233,
                "nibble": 0.6874866009609402
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.9928311077100225,
                    0.11892294344914528,
                    1.8882459488408319
                ],
                "result_count_important_words": [
                    1060000.0,
                    0,
                    1160000.0
                ],
                "wikipedia_search": [
                    4.0,
                    0.0,
                    0.0
                ],
                "answer_relation_to_question": [
                    1.3437032998101701,
                    1.0035441657579063,
                    1.6527525344319238
                ],
                "answer_relation_to_question_bing": [
                    1.1175627240143369,
                    0.439068100358423,
                    2.4433691756272404
                ],
                "result_count_noun_chunks": [
                    1060000.0,
                    0,
                    1160000.0
                ],
                "question_answer_similarity": [
                    0.9009848218411207,
                    0.0,
                    0.7305701039731503
                ],
                "result_count_bing": [
                    1960000.0,
                    1710000.0,
                    1910000.0
                ],
                "word_count_appended": [
                    585.0,
                    16.0,
                    285.0
                ],
                "result_count": [
                    1050000.0,
                    0,
                    1150000.0
                ]
            },
            "integer_answers": {
                "demibyte": 0,
                "octet": 5,
                "nibble": 5
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which of these has NEVER been named Pantone\u2019s Color of the Year?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "sand dollar"
            ],
            "lines": [
                [
                    0.41409043112513144,
                    0.4222011385199241,
                    0.4497752310993193,
                    0.40256343791370036,
                    0.2784727651811311,
                    0.22636815920398012,
                    0.24181360201511337,
                    0.3277777777777778,
                    0.1823104693140794,
                    0.3772296366886039,
                    -1.0
                ],
                [
                    0.31198738170347007,
                    0.1636622390891841,
                    0.22207050061374806,
                    0.0996074764624742,
                    0.44305446963773787,
                    0.3830845771144279,
                    0.4345088161209068,
                    0.40416666666666673,
                    0.40974729241877256,
                    0.310962343024314,
                    -1.0
                ],
                [
                    0.2739221871713985,
                    0.41413662239089183,
                    0.32815426828693267,
                    0.49782908562382544,
                    0.2784727651811311,
                    0.39054726368159204,
                    0.3236775818639799,
                    0.26805555555555555,
                    0.40794223826714804,
                    0.3118080202870821,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "chili pepper": 0.30109088233809256,
                "cucumber": 0.33547947023224783,
                "sand dollar": 0.3634296474296596
            },
            "question": "which of these has never been named pantone\u2019s color of the year?",
            "rate_limited": false,
            "answers": [
                "cucumber",
                "sand dollar",
                "chili pepper"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "chili pepper": 0.18184453529811775,
                "cucumber": 0.422930008679457,
                "sand dollar": 0.544543227490887
            },
            "integer_answers": {
                "chili pepper": 2,
                "cucumber": 4,
                "sand dollar": 4
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    0.9821629064911688,
                    1.5123012558054878,
                    1.5055358377033434
                ],
                "result_count_important_words": [
                    330000.0,
                    141000.0,
                    132000.0
                ],
                "wikipedia_search": [
                    1.0333333333333334,
                    0.575,
                    1.3916666666666668
                ],
                "answer_relation_to_question": [
                    0.5154574132492113,
                    1.1280757097791798,
                    1.3564668769716088
                ],
                "answer_relation_to_question_bing": [
                    0.3111954459203036,
                    1.3453510436432636,
                    0.34345351043643263
                ],
                "result_count_noun_chunks": [
                    24600000.0,
                    6240000.0,
                    16800000.0
                ],
                "question_answer_similarity": [
                    1.1156974867917597,
                    6.173950637457892,
                    3.817396380007267
                ],
                "result_count_bing": [
                    17000000.0,
                    4370000.0,
                    17000000.0
                ],
                "word_count_appended": [
                    176.0,
                    50.0,
                    51.0
                ],
                "result_count": [
                    4210000.0,
                    17300000.0,
                    93800.0
                ]
            },
            "negative_question": true
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which of these best-selling authors uses his/her given last name?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "r.l. stine"
            ],
            "lines": [
                [
                    0.325139353400223,
                    0.5132275132275133,
                    0.1085123983363008,
                    0.18700475435816163,
                    0.03007302075326672,
                    0.1285140562248996,
                    0.0021034875213397286,
                    0.265625,
                    0.24107142857142858,
                    0.33698144888176806,
                    -1.0
                ],
                [
                    0.3437265632917807,
                    0.28359788359788357,
                    -0.062449521878158214,
                    0.2076069730586371,
                    0.9127594158339739,
                    0.14156626506024098,
                    0.0020425168685472726,
                    0.5587121212121212,
                    0.41964285714285715,
                    0.31928267186993914,
                    -1.0
                ],
                [
                    0.3311340833079964,
                    0.2031746031746032,
                    0.9539371235418574,
                    0.6053882725832013,
                    0.057167563412759415,
                    0.7299196787148594,
                    0.995853995610113,
                    0.17566287878787878,
                    0.3392857142857143,
                    0.3437358792482928,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "r.l. stine": 0.3126487746057822,
                "e.l. james": 0.47352597926672757,
                "j.d. robb": 0.21382524612749015
            },
            "question": "which of these best-selling authors uses his/her given last name?",
            "rate_limited": false,
            "answers": [
                "j.d. robb",
                "r.l. stine",
                "e.l. james"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "r.l. stine": 0.3889320307775609,
                "e.l. james": 0.250265656109275,
                "j.d. robb": 0.1721797776531248
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.6849072444088402,
                    1.5964133593496956,
                    1.718679396241464
                ],
                "result_count_important_words": [
                    128000.0,
                    141000.0,
                    727000.0
                ],
                "wikipedia_search": [
                    1.0625,
                    2.234848484848485,
                    0.7026515151515151
                ],
                "answer_relation_to_question": [
                    1.6256967670011149,
                    1.7186328164589035,
                    1.6556704165399818
                ],
                "answer_relation_to_question_bing": [
                    1.5396825396825398,
                    0.8507936507936508,
                    0.6095238095238096
                ],
                "result_count_noun_chunks": [
                    82800.0,
                    80400.0,
                    39200000.0
                ],
                "question_answer_similarity": [
                    0.731094989401754,
                    -0.4207494556903839,
                    6.427087244577706
                ],
                "result_count_bing": [
                    62600.0,
                    1900000.0,
                    119000.0
                ],
                "word_count_appended": [
                    27.0,
                    47.0,
                    38.0
                ],
                "result_count": [
                    11800.0,
                    13100.0,
                    38200.0
                ]
            },
            "integer_answers": {
                "r.l. stine": 4,
                "e.l. james": 5,
                "j.d. robb": 1
            }
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Which of these things was created by a person who chose to remain anonymous?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "bitcoin"
            ],
            "lines": [
                [
                    0.5333333333333333,
                    0.6583333333333333,
                    0.24620562545757632,
                    0.9384965831435079,
                    0.46956521739130436,
                    0.9711894022512089,
                    0.7114624505928854,
                    0.8973684210526316,
                    0.7698334965719883,
                    0.4153596683673533,
                    0.0
                ],
                [
                    0.225,
                    0.2333333333333333,
                    0.7823076718961841,
                    0.025876993166287016,
                    0.4543478260869565,
                    0.014994514202121174,
                    0.11363636363636363,
                    0.08947368421052632,
                    0.15964740450538686,
                    0.3222939968438177,
                    0.0
                ],
                [
                    0.24166666666666664,
                    0.10833333333333334,
                    -0.02851329735376043,
                    0.03562642369020501,
                    0.07608695652173914,
                    0.013816083546669918,
                    0.17490118577075098,
                    0.013157894736842105,
                    0.07051909892262488,
                    0.2623463347888291,
                    0.0
                ]
            ],
            "fraction_answers": {
                "hoverboards": 0.24209117878809772,
                "fidget spinners": 0.09679406806239008,
                "bitcoin": 0.6611147531495123
            },
            "question": "which of these things was created by a person who chose to remain anonymous?",
            "rate_limited": false,
            "answers": [
                "bitcoin",
                "hoverboards",
                "fidget spinners"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "hoverboards": 0.18591099076218698,
                "fidget spinners": 0.14864682099386586,
                "bitcoin": 0.6176644697293239
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 0
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    2.492158010204119,
                    1.933763981062906,
                    1.5740780087329747
                ],
                "result_count_important_words": [
                    2390000.0,
                    36900.0,
                    34000.0
                ],
                "wikipedia_search": [
                    3.5894736842105264,
                    0.35789473684210527,
                    0.05263157894736842
                ],
                "answer_relation_to_question": [
                    2.6666666666666665,
                    1.125,
                    1.2083333333333333
                ],
                "answer_relation_to_question_bing": [
                    1.975,
                    0.7,
                    0.325
                ],
                "result_count_noun_chunks": [
                    1440000.0,
                    230000.0,
                    354000.0
                ],
                "question_answer_similarity": [
                    -0.5448476430028677,
                    -1.7312297001481056,
                    0.0630993009544909
                ],
                "result_count_bing": [
                    2160000.0,
                    2090000.0,
                    350000.0
                ],
                "word_count_appended": [
                    786.0,
                    163.0,
                    72.0
                ],
                "result_count": [
                    1030000.0,
                    28400.0,
                    39100.0
                ]
            },
            "integer_answers": {
                "hoverboards": 0,
                "fidget spinners": 1,
                "bitcoin": 9
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "In which town were a President, Governor, Senator, NFL owner and late night host all born?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "brookline, ma"
            ],
            "lines": [
                [
                    0.22769492412349557,
                    0.32666666666666666,
                    0.22482535151494046,
                    0.7649253731343284,
                    0.3329355608591885,
                    0.7965003507903099,
                    0.7930667974818085,
                    0.38285929032272115,
                    0.25,
                    0.3705364253578646,
                    -1.0
                ],
                [
                    0.35262951334379905,
                    0.27999999999999997,
                    0.425805971447376,
                    0.06604477611940299,
                    0.34844868735083534,
                    0.016961743221493127,
                    0.018068841468399967,
                    0.17637664562531583,
                    0.4,
                    0.2894862090868788,
                    -1.0
                ],
                [
                    0.4196755625327054,
                    0.3933333333333333,
                    0.34936867703768354,
                    0.16902985074626867,
                    0.31861575178997614,
                    0.18653790598819694,
                    0.1888643610497915,
                    0.44076406405196294,
                    0.35,
                    0.3399773655552566,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "muncie, in": 0.3156166872085175,
                "hope, ar": 0.2373822387663501,
                "brookline, ma": 0.44700107402513245
            },
            "question": "in which town were a president, governor, senator, nfl owner and late night host all born?",
            "rate_limited": false,
            "answers": [
                "brookline, ma",
                "hope, ar",
                "muncie, in"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "muncie, in": 0.3568402245066084,
                "hope, ar": 0.1882332369850112,
                "brookline, ma": 0.6871476592945055
            },
            "integer_answers": {
                "muncie, in": 3,
                "hope, ar": 3,
                "brookline, ma": 4
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    3.7053642535786455,
                    2.894862090868788,
                    3.399773655552566
                ],
                "result_count_important_words": [
                    19300.0,
                    411.0,
                    4520.0
                ],
                "wikipedia_search": [
                    3.062874322581769,
                    1.4110131650025266,
                    3.5261125124157036
                ],
                "answer_relation_to_question": [
                    1.593864468864469,
                    2.4684065934065935,
                    2.9377289377289375
                ],
                "answer_relation_to_question_bing": [
                    1.6333333333333333,
                    1.4,
                    1.9666666666666666
                ],
                "result_count_noun_chunks": [
                    19400.0,
                    442.0,
                    4620.0
                ],
                "question_answer_similarity": [
                    8.583991593215615,
                    16.25757439993322,
                    13.33914421312511
                ],
                "result_count_bing": [
                    279000.0,
                    292000.0,
                    267000.0
                ],
                "word_count_appended": [
                    5.0,
                    8.0,
                    7.0
                ],
                "result_count": [
                    20500.0,
                    1770.0,
                    4530.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Though it now conveys something different, which of these words originally meant \u201cparrot\u201d?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "popinjay"
            ],
            "lines": [
                [
                    0.13333333333333333,
                    0.0,
                    0.009540421605749829,
                    0.44715447154471544,
                    0.3475177304964539,
                    0.3448905109489051,
                    0.2729945401091978,
                    0.0,
                    0.36243386243386244,
                    0.36853362477895363,
                    -1.0
                ],
                [
                    0.2763888888888889,
                    0.0,
                    -0.04067507928221927,
                    0.3546747967479675,
                    0.3432624113475177,
                    0.2281021897810219,
                    0.6425871482570349,
                    0.041666666666666664,
                    0.30687830687830686,
                    0.30694098925243174,
                    -1.0
                ],
                [
                    0.5902777777777778,
                    1.0,
                    1.0311346576764695,
                    0.19817073170731708,
                    0.30921985815602837,
                    0.42700729927007297,
                    0.08441831163376733,
                    0.9583333333333334,
                    0.3306878306878307,
                    0.32452538596861463,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "thespian": 0.24598263185376168,
                "popinjay": 0.5253775186211211,
                "warble": 0.22863984952511718
            },
            "question": "though it now conveys something different, which of these words originally meant \u201cparrot\u201d?",
            "rate_limited": false,
            "answers": [
                "warble",
                "thespian",
                "popinjay"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "thespian": 0.3247511322710112,
                "popinjay": 0.5666428659357521,
                "warble": 0.20171809959110978
            },
            "integer_answers": {
                "thespian": 2,
                "popinjay": 4,
                "warble": 4
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    2.2112017486737217,
                    1.8416459355145904,
                    1.947152315811688
                ],
                "result_count_important_words": [
                    18900.0,
                    12500.0,
                    23400.0
                ],
                "wikipedia_search": [
                    0.0,
                    0.125,
                    2.875
                ],
                "answer_relation_to_question": [
                    0.5333333333333333,
                    1.1055555555555556,
                    2.361111111111111
                ],
                "answer_relation_to_question_bing": [
                    0.0,
                    0.0,
                    2.0
                ],
                "result_count_noun_chunks": [
                    650000.0,
                    1530000.0,
                    201000.0
                ],
                "question_answer_similarity": [
                    -0.01999802637146786,
                    0.08526052010711282,
                    -2.161399037577212
                ],
                "result_count_bing": [
                    24500.0,
                    24200.0,
                    21800.0
                ],
                "result_count": [
                    44000.0,
                    34900.0,
                    19500.0
                ],
                "word_count_appended": [
                    137.0,
                    116.0,
                    125.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "What gargantuan fruit is the subject of a Roald Dahl children's book?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "peach"
            ],
            "lines": [
                [
                    0.27720012055455096,
                    0.38467614533965244,
                    -0.798390738273242,
                    0.0013959981386691485,
                    0.014555589965933726,
                    0.0011762576909156715,
                    0.0015529368776833836,
                    0.18108318034175963,
                    0.23076923076923078,
                    0.17115543668410596,
                    1.0
                ],
                [
                    0.20125075346594334,
                    0.22169562927856767,
                    -0.6644885296576125,
                    0.002791996277338297,
                    0.009910188912976153,
                    0.003528773072747014,
                    0.0027404768429706767,
                    0.33319799463352634,
                    0.16483516483516483,
                    0.2003541404291226,
                    1.0
                ],
                [
                    0.5215491259795058,
                    0.3936282253817799,
                    2.4628792679308544,
                    0.9958120055839925,
                    0.9755342211210901,
                    0.9952949692363373,
                    0.9957065862793459,
                    0.48571882502471403,
                    0.6043956043956044,
                    0.6284904228867714,
                    1.0
                ]
            ],
            "fraction_answers": {
                "loquat": 0.04758165880907444,
                "dragonfruit": 0.04651741580892597,
                "peach": 0.9059009253819996
            },
            "question": "what gargantuan fruit is the subject of a roald dahl children's book?",
            "rate_limited": false,
            "answers": [
                "dragonfruit",
                "loquat",
                "peach"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "loquat": 0.1917205017227768,
                "dragonfruit": 0.1565410916350107,
                "peach": 0.632495121188738
            },
            "integer_answers": {
                "loquat": 0,
                "dragonfruit": 0,
                "peach": 10
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.1980880567887418,
                    1.4024789830038582,
                    4.3994329602074
                ],
                "result_count_important_words": [
                    13.0,
                    39.0,
                    11000.0
                ],
                "wikipedia_search": [
                    0.7243327213670385,
                    1.3327919785341054,
                    1.9428753000988561
                ],
                "answer_relation_to_question": [
                    0.8316003616636528,
                    0.60375226039783,
                    1.5646473779385173
                ],
                "answer_relation_to_question_bing": [
                    1.5387045813586098,
                    0.8867825171142707,
                    1.5745129015271195
                ],
                "result_count_noun_chunks": [
                    17.0,
                    30.0,
                    10900.0
                ],
                "question_answer_similarity": [
                    -0.7061498463153839,
                    -0.5877178311347961,
                    2.1783341579139233
                ],
                "result_count_bing": [
                    1880.0,
                    1280.0,
                    126000.0
                ],
                "result_count": [
                    15.0,
                    30.0,
                    10700.0
                ],
                "word_count_appended": [
                    63.0,
                    45.0,
                    165.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "The only person who owns more U.S. land than Ted Turner made his fortune in what business?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "pharmaceuticals"
            ],
            "lines": [
                [
                    0.19894345756414722,
                    0.38371559633027524,
                    0.13011617462424702,
                    0.4324734446130501,
                    0.5426755967714236,
                    0.3336980306345733,
                    0.4056795131845842,
                    0.34123238463663996,
                    0.8604651162790697,
                    0.32015729350958594,
                    1.0
                ],
                [
                    0.5767983612811199,
                    0.20237003058103972,
                    0.34588049508251706,
                    0.21927162367223066,
                    0.3486175510905032,
                    0.2286652078774617,
                    0.20892494929006086,
                    0.3936787326149028,
                    0.06395348837209303,
                    0.364217032013369,
                    1.0
                ],
                [
                    0.22425818115473287,
                    0.41391437308868506,
                    0.524003330293236,
                    0.3482549317147193,
                    0.10870685213807316,
                    0.437636761487965,
                    0.385395537525355,
                    0.2650888827484572,
                    0.0755813953488372,
                    0.31562567447704504,
                    1.0
                ]
            ],
            "fraction_answers": {
                "pharmaceuticals": 0.39491566081475965,
                "cable tv": 0.2952377471875298,
                "fast food": 0.3098465919977106
            },
            "question": "the only person who owns more u.s. land than ted turner made his fortune in what business?",
            "rate_limited": false,
            "answers": [
                "pharmaceuticals",
                "cable tv",
                "fast food"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "pharmaceuticals": 0.5731499327082887,
                "cable tv": 0.4369969593082462,
                "fast food": 0.24545688603408383
            },
            "integer_answers": {
                "pharmaceuticals": 4,
                "cable tv": 3,
                "fast food": 3
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    2.2411010545671015,
                    2.5495192240935833,
                    2.209379721339315
                ],
                "result_count_important_words": [
                    91500.0,
                    62700.0,
                    120000.0
                ],
                "wikipedia_search": [
                    1.7061619231831997,
                    1.968393663074514,
                    1.325444413742286
                ],
                "answer_relation_to_question": [
                    1.1936607453848833,
                    3.4607901676867194,
                    1.3455490869283973
                ],
                "answer_relation_to_question_bing": [
                    1.9185779816513762,
                    1.0118501529051986,
                    2.069571865443425
                ],
                "result_count_noun_chunks": [
                    200000.0,
                    103000.0,
                    190000.0
                ],
                "question_answer_similarity": [
                    2.6720909513533115,
                    7.103068806231022,
                    10.761033833026886
                ],
                "result_count_bing": [
                    316000.0,
                    203000.0,
                    63300.0
                ],
                "result_count": [
                    114000.0,
                    57800.0,
                    91800.0
                ],
                "word_count_appended": [
                    148.0,
                    11.0,
                    13.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Which game is an example of combinatorics?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "sudoku"
            ],
            "lines": [
                [
                    0.609271523178808,
                    0.5604395604395604,
                    0.42868967912442885,
                    0.8879363135333742,
                    0.00919091280218022,
                    0.8876500857632933,
                    0.913664394677053,
                    0.14516129032258066,
                    0.31370558375634516,
                    0.3876219804423416,
                    -1.0
                ],
                [
                    0.13024282560706402,
                    0.31868131868131866,
                    0.4580737238810853,
                    0.02980200040824658,
                    0.4965078944755222,
                    0.029588336192109776,
                    0.024991885751379422,
                    0.3544142614601019,
                    0.07309644670050762,
                    0.28713232712354814,
                    -1.0
                ],
                [
                    0.26048565121412803,
                    0.12087912087912088,
                    0.11323659699448582,
                    0.08226168605837926,
                    0.4943011927222976,
                    0.08276157804459691,
                    0.06134371957156767,
                    0.5004244482173175,
                    0.6131979695431472,
                    0.3252456924341102,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "sudoku": 0.26541376556791507,
                "risk": 0.5143331324039966,
                "crossword puzzles": 0.22025310202808832
            },
            "question": "which game is an example of combinatorics?",
            "rate_limited": false,
            "answers": [
                "risk",
                "crossword puzzles",
                "sudoku"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "sudoku": 0.3931173256449866,
                "risk": 0.2998502181204233,
                "crossword puzzles": 0.3146435910416931
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.1628659413270248,
                    0.8613969813706444,
                    0.9757370773023306
                ],
                "result_count_important_words": [
                    414000.0,
                    13800.0,
                    38600.0
                ],
                "wikipedia_search": [
                    0.2903225806451613,
                    0.7088285229202038,
                    1.000848896434635
                ],
                "answer_relation_to_question": [
                    1.218543046357616,
                    0.26048565121412803,
                    0.5209713024282561
                ],
                "answer_relation_to_question_bing": [
                    0.5604395604395604,
                    0.31868131868131866,
                    0.12087912087912088
                ],
                "result_count_noun_chunks": [
                    563000.0,
                    15400.0,
                    37800.0
                ],
                "question_answer_similarity": [
                    2.276065156329423,
                    2.4320754446089268,
                    0.6012131511233747
                ],
                "result_count_bing": [
                    833000.0,
                    45000000.0,
                    44800000.0
                ],
                "word_count_appended": [
                    309.0,
                    72.0,
                    604.0
                ],
                "result_count": [
                    435000.0,
                    14600.0,
                    40300.0
                ]
            },
            "integer_answers": {
                "sudoku": 2,
                "risk": 6,
                "crossword puzzles": 2
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which of these mammals averages the largest litter?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "naked mole rat"
            ],
            "lines": [
                [
                    0.2916666666666667,
                    0.27777777777777773,
                    0.687111442664507,
                    0.943769598441258,
                    0.3505933117583603,
                    0.6847935548841894,
                    0.23915638678869877,
                    0.7863247863247863,
                    0.15265486725663716,
                    0.34878523252024596,
                    -1.0
                ],
                [
                    0.07638888888888888,
                    0.0,
                    0.319605813404062,
                    0.00041607046813001695,
                    0.3586839266450917,
                    0.12118160456529037,
                    0.29128531635495425,
                    0.1111111111111111,
                    0.09292035398230089,
                    0.22209178894400328,
                    -1.0
                ],
                [
                    0.6319444444444445,
                    0.7222222222222222,
                    -0.006717256068568913,
                    0.05581433109061203,
                    0.29072276159654803,
                    0.1940248405505203,
                    0.469558296856347,
                    0.10256410256410257,
                    0.754424778761062,
                    0.4291229785357507,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "naked mole rat": 0.47626336250831275,
                "burmese cat": 0.15936848743638327,
                "jackrabbit": 0.36436815005530404
            },
            "question": "which of these mammals averages the largest litter?",
            "rate_limited": false,
            "answers": [
                "naked mole rat",
                "burmese cat",
                "jackrabbit"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "naked mole rat": 0.4379856887397746,
                "burmese cat": 0.16831436833592386,
                "jackrabbit": 0.35643962845557664
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.3951409300809838,
                    0.8883671557760131,
                    1.7164919141430028
                ],
                "result_count_important_words": [
                    204000.0,
                    36100.0,
                    57800.0
                ],
                "wikipedia_search": [
                    2.358974358974359,
                    0.3333333333333333,
                    0.3076923076923077
                ],
                "answer_relation_to_question": [
                    0.875,
                    0.22916666666666666,
                    1.8958333333333335
                ],
                "answer_relation_to_question_bing": [
                    0.8333333333333334,
                    0.0,
                    2.166666666666667
                ],
                "result_count_noun_chunks": [
                    60100.0,
                    73200.0,
                    118000.0
                ],
                "question_answer_similarity": [
                    4.587753164814785,
                    2.133966182038421,
                    -0.04485023953020573
                ],
                "result_count_bing": [
                    650000.0,
                    665000.0,
                    539000.0
                ],
                "word_count_appended": [
                    69.0,
                    42.0,
                    341.0
                ],
                "result_count": [
                    186000.0,
                    82.0,
                    11000.0
                ]
            },
            "integer_answers": {
                "naked mole rat": 4,
                "burmese cat": 1,
                "jackrabbit": 5
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Queen Victoria is credited with starting what fashion trend?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "white wedding dress"
            ],
            "lines": [
                [
                    0.1803025191183086,
                    0.3055555555555555,
                    0.22234368675636973,
                    0.30864197530864196,
                    0.25880923450789795,
                    0.31851851851851853,
                    0.6638343069569835,
                    0.5936507936507937,
                    0.29577464788732394,
                    0.3298618849733337,
                    1.0
                ],
                [
                    0.2972181327444485,
                    0.34444444444444444,
                    0.40554760076526175,
                    0.32098765432098764,
                    0.402187120291616,
                    0.4148148148148148,
                    0.25225703664365373,
                    0.11904761904761905,
                    0.23943661971830985,
                    0.2583797898814206,
                    1.0
                ],
                [
                    0.5224793481372428,
                    0.35,
                    0.3721087124783685,
                    0.37037037037037035,
                    0.33900364520048604,
                    0.26666666666666666,
                    0.08390865639936272,
                    0.2873015873015873,
                    0.4647887323943662,
                    0.41175832514524585,
                    1.0
                ]
            ],
            "fraction_answers": {
                "white wedding dress": 0.3468386044093696,
                "mini dress": 0.34772931232337273,
                "little black dress": 0.3054320832672577
            },
            "question": "queen victoria is credited with starting what fashion trend?",
            "rate_limited": false,
            "answers": [
                "mini dress",
                "little black dress",
                "white wedding dress"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "white wedding dress": 0.6614538162845178,
                "mini dress": 0.1728760406583799,
                "little black dress": 0.12759173018106915
            },
            "integer_answers": {
                "white wedding dress": 5,
                "mini dress": 2,
                "little black dress": 3
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.9791713098400021,
                    1.5502787392885233,
                    2.470549950871475
                ],
                "result_count_important_words": [
                    43.0,
                    56.0,
                    36.0
                ],
                "wikipedia_search": [
                    2.3746031746031746,
                    0.4761904761904762,
                    1.1492063492063491
                ],
                "answer_relation_to_question": [
                    1.0818151147098516,
                    1.7833087964666912,
                    3.1348760888234573
                ],
                "answer_relation_to_question_bing": [
                    1.833333333333333,
                    2.0666666666666664,
                    2.0999999999999996
                ],
                "result_count_noun_chunks": [
                    12500000.0,
                    4750000.0,
                    1580000.0
                ],
                "question_answer_similarity": [
                    4.946093179285526,
                    9.021511927247047,
                    8.277655154466629
                ],
                "result_count_bing": [
                    213000.0,
                    331000.0,
                    279000.0
                ],
                "word_count_appended": [
                    21.0,
                    17.0,
                    33.0
                ],
                "result_count": [
                    25.0,
                    26.0,
                    30.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Who is the only actor to appear as both a student and a guest on \u201cInside the Actors Studio\u201d?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "bradley cooper"
            ],
            "lines": [
                [
                    0.39560567779064465,
                    0.25544425087108014,
                    -0.5029677575685773,
                    0.22018348623853212,
                    0.32532751091703055,
                    0.05435946235280124,
                    0.022720858029918148,
                    0.288332481689661,
                    0.21052631578947367,
                    0.2186285569784654,
                    0.0
                ],
                [
                    0.4054382917500088,
                    0.14372822299651566,
                    1.9558769515532988,
                    0.30275229357798167,
                    0.34934497816593885,
                    0.23670750565005352,
                    0.4057296076771098,
                    0.12284321239993186,
                    0.14035087719298245,
                    0.27835438882704816,
                    0.0
                ],
                [
                    0.1989560304593466,
                    0.6008275261324042,
                    -0.45290919398472157,
                    0.47706422018348627,
                    0.32532751091703055,
                    0.7089330319971452,
                    0.5715495342929721,
                    0.5888243059104071,
                    0.6491228070175439,
                    0.5030170541944864,
                    0.0
                ]
            ],
            "fraction_answers": {
                "tobey maguire": 0.43411263297908703,
                "bradley cooper": 0.4170712827120101,
                "ryan gosling": 0.14881608430890297
            },
            "question": "who is the only actor to appear as both a student and a guest on \u201cinside the actors studio\u201d?",
            "rate_limited": false,
            "answers": [
                "ryan gosling",
                "tobey maguire",
                "bradley cooper"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "tobey maguire": 0.3591547276416595,
                "bradley cooper": 0.7167011188352742,
                "ryan gosling": 0.23305462515612835
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 0
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.3117713418707924,
                    1.670126332962289,
                    3.0181023251669186
                ],
                "result_count_important_words": [
                    45700.0,
                    199000.0,
                    596000.0
                ],
                "wikipedia_search": [
                    1.7299948901379663,
                    0.7370592743995912,
                    3.5329458354624426
                ],
                "answer_relation_to_question": [
                    2.373634066743868,
                    2.4326297505000527,
                    1.1937361827560795
                ],
                "answer_relation_to_question_bing": [
                    1.0217770034843205,
                    0.5749128919860627,
                    2.403310104529617
                ],
                "result_count_noun_chunks": [
                    64400.0,
                    1150000.0,
                    1620000.0
                ],
                "question_answer_similarity": [
                    1.295287961140275,
                    -5.0369508396834135,
                    1.1663726305123419
                ],
                "result_count_bing": [
                    149000.0,
                    160000.0,
                    149000.0
                ],
                "result_count": [
                    24.0,
                    33.0,
                    52.0
                ],
                "word_count_appended": [
                    12.0,
                    8.0,
                    37.0
                ]
            },
            "integer_answers": {
                "tobey maguire": 2,
                "bradley cooper": 7,
                "ryan gosling": 1
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "According to the old saying, what kind of animal can NOT change its spots?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "leopard"
            ],
            "lines": [
                [
                    0.3841868823000899,
                    0.4326470588235294,
                    0.3649204933253706,
                    0.4999965254678966,
                    0.37120470127326155,
                    0.2815624976090466,
                    0.20911722141823447,
                    0.4863121874177415,
                    0.34941520467836257,
                    0.3298794018305334,
                    1.0
                ],
                [
                    0.17678170324733666,
                    0.16512254901960788,
                    0.3445936692250927,
                    0.49999711868069474,
                    0.3667972575905975,
                    0.49999617447456407,
                    0.4256150506512301,
                    0.3476472195281712,
                    0.32651072124756336,
                    0.3497975037084144,
                    1.0
                ],
                [
                    0.4390314144525735,
                    0.40223039215686274,
                    0.2904858374495367,
                    6.355851408679225e-06,
                    0.26199804113614106,
                    0.21844132791638932,
                    0.36526772793053547,
                    0.1660405930540873,
                    0.32407407407407407,
                    0.3203230944610522,
                    1.0
                ]
            ],
            "fraction_answers": {
                "tiger": 0.4424202283034678,
                "leopard": 0.2994282065253454,
                "zebra": 0.25815156517118676
            },
            "question": "according to the old saying, what kind of animal can not change its spots?",
            "rate_limited": false,
            "answers": [
                "zebra",
                "leopard",
                "tiger"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "tiger": 0.36053323485718,
                "leopard": 0.6194873496610481,
                "zebra": 0.4697800891525014
            },
            "integer_answers": {
                "tiger": 7,
                "leopard": 2,
                "zebra": 1
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    2.3816883743725326,
                    2.1028349480821986,
                    2.515476677545269
                ],
                "result_count_important_words": [
                    5710000.0,
                    100.0,
                    7360000.0
                ],
                "wikipedia_search": [
                    0.16425375098710188,
                    1.8282333656619458,
                    4.007512883350953
                ],
                "answer_relation_to_question": [
                    1.621383647798742,
                    4.525056154537287,
                    0.8535601976639712
                ],
                "answer_relation_to_question_bing": [
                    0.6735294117647059,
                    3.3487745098039214,
                    0.9776960784313726
                ],
                "result_count_noun_chunks": [
                    20100000.0,
                    5140000.0,
                    9310000.0
                ],
                "question_answer_similarity": [
                    2.0059347860515118,
                    2.3077887427061796,
                    3.111291691660881
                ],
                "result_count_bing": [
                    26300000.0,
                    27200000.0,
                    48600000.0
                ],
                "word_count_appended": [
                    309.0,
                    356.0,
                    361.0
                ],
                "result_count": [
                    82.0,
                    68.0,
                    11800000.0
                ]
            },
            "negative_question": true
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Which of these astronomical objects orbits the Earth?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "moon"
            ],
            "lines": [
                [
                    0.35460614152202935,
                    0.6666666666666666,
                    0.28026798016523896,
                    0.3728506787330317,
                    0.11723254324151185,
                    0.3470319634703196,
                    0.2718676122931442,
                    0.40514200711569137,
                    0.48468271334792123,
                    0.33303834654432596,
                    -1.0
                ],
                [
                    0.467890520694259,
                    0.30952380952380953,
                    0.4728802127287828,
                    0.22624434389140272,
                    0.29276105060858426,
                    0.1689497716894977,
                    0.2907801418439716,
                    0.3276821862348178,
                    0.087527352297593,
                    0.32012159302779786,
                    -1.0
                ],
                [
                    0.1775033377837116,
                    0.023809523809523808,
                    0.2468518071059783,
                    0.40090497737556563,
                    0.590006406149904,
                    0.4840182648401826,
                    0.4373522458628842,
                    0.26717580664949087,
                    0.42778993435448576,
                    0.34684006042787613,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "sun": 0.3402252364359603,
                "milky way": 0.29643609825405165,
                "moon": 0.3633386653099881
            },
            "question": "which of these astronomical objects orbits the earth?",
            "rate_limited": false,
            "answers": [
                "moon",
                "milky way",
                "sun"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "sun": 0.4107154410809851,
                "milky way": 0.23782736128463966,
                "moon": 0.49668442960196063
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.3321533861773038,
                    1.2804863721111914,
                    1.3873602417115045
                ],
                "result_count_important_words": [
                    1140000.0,
                    555000.0,
                    1590000.0
                ],
                "wikipedia_search": [
                    1.6205680284627655,
                    1.3107287449392713,
                    1.0687032265979635
                ],
                "answer_relation_to_question": [
                    1.4184245660881174,
                    1.871562082777036,
                    0.7100133511348464
                ],
                "answer_relation_to_question_bing": [
                    2.6666666666666665,
                    1.2380952380952381,
                    0.09523809523809523
                ],
                "result_count_noun_chunks": [
                    1150000.0,
                    1230000.0,
                    1850000.0
                ],
                "question_answer_similarity": [
                    3.1645723432302475,
                    5.3394028171896935,
                    2.7872623950242996
                ],
                "result_count_bing": [
                    183000.0,
                    457000.0,
                    921000.0
                ],
                "word_count_appended": [
                    443.0,
                    80.0,
                    391.0
                ],
                "result_count": [
                    824000.0,
                    500000.0,
                    886000.0
                ]
            },
            "integer_answers": {
                "sun": 5,
                "milky way": 2,
                "moon": 3
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "What soda is named for a medical condition?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "pepsi"
            ],
            "lines": [
                [
                    0.3847222222222222,
                    0.7435897435897436,
                    4.749959552994105,
                    0.29882092851879144,
                    0.005971588590927637,
                    0.06739679865206402,
                    0.06940149172275786,
                    0.024390243902439025,
                    0.2926315789473684,
                    0.2937116108528034,
                    1.0
                ],
                [
                    0.49652777777777773,
                    0.02564102564102564,
                    -6.197112683480115,
                    0.5600589535740604,
                    0.5489410630169504,
                    0.7497893850042123,
                    0.8531926505366564,
                    0.8048780487804879,
                    0.44842105263157894,
                    0.3828367097538674,
                    1.0
                ],
                [
                    0.11875000000000001,
                    0.23076923076923078,
                    2.4471531304860106,
                    0.14112011790714812,
                    0.44508734839212194,
                    0.18281381634372368,
                    0.07740585774058577,
                    0.17073170731707318,
                    0.25894736842105265,
                    0.3234516793933292,
                    1.0
                ]
            ],
            "fraction_answers": {
                "fanta": 0.4396230256770276,
                "pepsi": -0.13268260167634988,
                "faygo": 0.6930595759993222
            },
            "question": "what soda is named for a medical condition?",
            "rate_limited": false,
            "answers": [
                "faygo",
                "pepsi",
                "fanta"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "fanta": 0.314917104111684,
                "pepsi": 0.559169674281204,
                "faygo": 0.2014582927351108
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.1748464434112136,
                    1.5313468390154696,
                    1.2938067175733168
                ],
                "result_count_important_words": [
                    16000.0,
                    178000.0,
                    43400.0
                ],
                "wikipedia_search": [
                    0.04878048780487805,
                    1.6097560975609757,
                    0.34146341463414637
                ],
                "answer_relation_to_question": [
                    1.1541666666666666,
                    1.4895833333333333,
                    0.35625
                ],
                "answer_relation_to_question_bing": [
                    0.7435897435897436,
                    0.02564102564102564,
                    0.23076923076923078
                ],
                "result_count_noun_chunks": [
                    76300.0,
                    938000.0,
                    85100.0
                ],
                "question_answer_similarity": [
                    -0.7330479547381401,
                    0.9563830443657935,
                    -0.3776622889563441
                ],
                "result_count_bing": [
                    161000.0,
                    14800000.0,
                    12000000.0
                ],
                "result_count": [
                    81100.0,
                    152000.0,
                    38300.0
                ],
                "word_count_appended": [
                    278.0,
                    426.0,
                    246.0
                ]
            },
            "integer_answers": {
                "fanta": 0,
                "pepsi": 9,
                "faygo": 1
            }
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Which of these is NOT a geometric shape?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "tarragon"
            ],
            "lines": [
                [
                    0.4,
                    0.26666666666666666,
                    0.24774906815628073,
                    0.41250854408749144,
                    0.22663915392028744,
                    0.4171050534034752,
                    0.41379310344827586,
                    0.35,
                    0.3348968105065666,
                    0.2844020188808692,
                    -1.0
                ],
                [
                    0.5,
                    0.5,
                    0.5086250853281601,
                    0.49008885850991113,
                    0.2733615434288097,
                    0.4893990116371752,
                    0.4915183537263626,
                    0.4,
                    0.3944652908067542,
                    0.40785225097995165,
                    -1.0
                ],
                [
                    0.09999999999999998,
                    0.23333333333333334,
                    0.24362584651555919,
                    0.09740259740259738,
                    0.49999930265090287,
                    0.0934959349593496,
                    0.09468854282536149,
                    0.25,
                    0.2706378986866792,
                    0.3077457301391792,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "hexagon": 0.5618141626974075,
                "octagon": 0.3292479161860174,
                "tarragon": 0.1089379211165751
            },
            "question": "which of these is not a geometric shape?",
            "rate_limited": false,
            "answers": [
                "octagon",
                "tarragon",
                "hexagon"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "hexagon": 0.16566826183273423,
                "octagon": 0.6595885692947471,
                "tarragon": 0.7005312367219073
            },
            "integer_answers": {
                "hexagon": 8,
                "octagon": 2,
                "tarragon": 0
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    0.8623919244765232,
                    0.3685909960801935,
                    0.7690170794432831
                ],
                "result_count_important_words": [
                    1040000.0,
                    133000.0,
                    5100000.0
                ],
                "wikipedia_search": [
                    0.3,
                    0.2,
                    0.5
                ],
                "answer_relation_to_question": [
                    0.4,
                    0.0,
                    1.6
                ],
                "answer_relation_to_question_bing": [
                    0.4666666666666667,
                    0.0,
                    0.5333333333333333
                ],
                "result_count_noun_chunks": [
                    1240000.0,
                    122000.0,
                    5830000.0
                ],
                "question_answer_similarity": [
                    0.9916807818226516,
                    -0.03390802681678906,
                    1.0078905124682933
                ],
                "result_count_bing": [
                    3920000.0,
                    3250000.0,
                    10.0
                ],
                "result_count": [
                    1280000.0,
                    145000.0,
                    5890000.0
                ],
                "word_count_appended": [
                    352.0,
                    225.0,
                    489.0
                ]
            },
            "negative_question": true
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "What tech mogul became a billionaire the youngest?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "mark zuckerberg"
            ],
            "lines": [
                [
                    0.5905246069719754,
                    0.7131048387096774,
                    -0.03201012515269249,
                    0.16084558823529413,
                    0.20620581304006286,
                    0.2366345311130587,
                    0.07888805409466566,
                    0.4163832199546485,
                    0.4251012145748988,
                    0.31351516758165165,
                    1.0
                ],
                [
                    0.3006486386420597,
                    0.1523185483870968,
                    0.4607635381042576,
                    0.39889705882352944,
                    0.6048703849175177,
                    0.32602979842243646,
                    0.7888805409466566,
                    0.34268707482993194,
                    0.3684210526315789,
                    0.3635243231788603,
                    1.0
                ],
                [
                    0.10882675438596491,
                    0.1345766129032258,
                    0.5712465870484349,
                    0.44025735294117646,
                    0.1889238020424195,
                    0.43733567046450483,
                    0.1322314049586777,
                    0.24092970521541948,
                    0.20647773279352227,
                    0.3229605092394881,
                    1.0
                ]
            ],
            "fraction_answers": {
                "mark zuckerberg": 0.4107040958883926,
                "evan spiegel": 0.31091929091232406,
                "larry page": 0.27837661319928336
            },
            "question": "what tech mogul became a billionaire the youngest?",
            "rate_limited": false,
            "answers": [
                "evan spiegel",
                "mark zuckerberg",
                "larry page"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "mark zuckerberg": 0.5959446019148341,
                "evan spiegel": 0.5852532873134423,
                "larry page": 0.15064058787906306
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.2540606703266066,
                    1.4540972927154412,
                    1.2918420369579524
                ],
                "result_count_important_words": [
                    27000.0,
                    37200.0,
                    49900.0
                ],
                "wikipedia_search": [
                    1.2491496598639455,
                    1.0280612244897958,
                    0.7227891156462585
                ],
                "answer_relation_to_question": [
                    2.3620984278879016,
                    1.2025945545682388,
                    0.43530701754385964
                ],
                "answer_relation_to_question_bing": [
                    2.85241935483871,
                    0.6092741935483872,
                    0.5383064516129032
                ],
                "result_count_noun_chunks": [
                    10500.0,
                    105000.0,
                    17600.0
                ],
                "question_answer_similarity": [
                    -0.14885316602885723,
                    2.1426380281336606,
                    2.6564052049070597
                ],
                "result_count_bing": [
                    52500.0,
                    154000.0,
                    48100.0
                ],
                "result_count": [
                    17500.0,
                    43400.0,
                    47900.0
                ],
                "word_count_appended": [
                    105.0,
                    91.0,
                    51.0
                ]
            },
            "integer_answers": {
                "mark zuckerberg": 3,
                "evan spiegel": 4,
                "larry page": 3
            }
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Which actor currently stars in a show that is both one word long and pluralized?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "paul giamatti"
            ],
            "lines": [
                [
                    0.44491129785247435,
                    0.3548218029350105,
                    4.467772566598791,
                    0.09431524547803617,
                    0.29130052724077327,
                    0.011269117252481888,
                    0.22737169517884914,
                    0.30431887366818877,
                    0.34545454545454546,
                    0.29469717317392136,
                    -1.0
                ],
                [
                    0.3145035792094616,
                    0.24868972746331236,
                    -3.6608373768337805,
                    0.09819121447028424,
                    0.19463971880492092,
                    0.010732492621411323,
                    0.4727838258164852,
                    0.33656773211567736,
                    0.32727272727272727,
                    0.27337428338113096,
                    -1.0
                ],
                [
                    0.24058512293806414,
                    0.39648846960167716,
                    0.19306481023498973,
                    0.8074935400516796,
                    0.5140597539543058,
                    0.9779983901261068,
                    0.29984447900466565,
                    0.359113394216134,
                    0.32727272727272727,
                    0.4319285434449478,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "william h. macy": 0.6836232844833071,
                "taraji p. henson": -0.13840820756783695,
                "paul giamatti": 0.4547849230845298
            },
            "question": "which actor currently stars in a show that is both one word long and pluralized?",
            "rate_limited": false,
            "answers": [
                "william h. macy",
                "taraji p. henson",
                "paul giamatti"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "william h. macy": 0.340076873429451,
                "taraji p. henson": 0.44869965429553443,
                "paul giamatti": 0.49543571864651936
            },
            "integer_answers": {
                "william h. macy": 3,
                "taraji p. henson": 1,
                "paul giamatti": 6
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.768183039043528,
                    1.6402457002867856,
                    2.591571260669687
                ],
                "result_count_important_words": [
                    84.0,
                    80.0,
                    7290.0
                ],
                "wikipedia_search": [
                    1.217275494672755,
                    1.3462709284627095,
                    1.436453576864536
                ],
                "answer_relation_to_question": [
                    2.2245564892623713,
                    1.5725178960473076,
                    1.2029256146903204
                ],
                "answer_relation_to_question_bing": [
                    0.709643605870021,
                    0.4973794549266247,
                    0.7929769392033543
                ],
                "result_count_noun_chunks": [
                    73100.0,
                    152000.0,
                    96400.0
                ],
                "question_answer_similarity": [
                    2.2620009689126164,
                    -1.8534555127844214,
                    0.0977473184466362
                ],
                "result_count_bing": [
                    66300.0,
                    44300.0,
                    117000.0
                ],
                "word_count_appended": [
                    19.0,
                    18.0,
                    18.0
                ],
                "result_count": [
                    73.0,
                    76.0,
                    625.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which animal is specifically mentioned in the Judeo-Christian Ten Commandments?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "ox"
            ],
            "lines": [
                [
                    0.25877192982456143,
                    0.38461538461538464,
                    0.41750905911607317,
                    0.35232067510548526,
                    0.3218982275586049,
                    0.3483606557377049,
                    0.3232,
                    0.10144927536231885,
                    0.3390151515151515,
                    0.3275960767342701,
                    -1.0
                ],
                [
                    0.04824561403508772,
                    0.5,
                    0.23465756019265496,
                    0.2552742616033755,
                    0.3184676958261864,
                    0.33401639344262296,
                    0.2992,
                    0.05434782608695652,
                    0.3541666666666667,
                    0.35320445689940777,
                    -1.0
                ],
                [
                    0.6929824561403508,
                    0.11538461538461539,
                    0.3478333806912719,
                    0.3924050632911392,
                    0.3596340766152087,
                    0.3176229508196721,
                    0.3776,
                    0.8442028985507246,
                    0.3068181818181818,
                    0.3191994663663221,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "ox": 0.2751580474752958,
                "goat": 0.40736830896774867,
                "pig": 0.3174736435569555
            },
            "question": "which animal is specifically mentioned in the judeo-christian ten commandments?",
            "rate_limited": false,
            "answers": [
                "pig",
                "ox",
                "goat"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "ox": 0.4727451688215379,
                "goat": 0.11780157279004744,
                "pig": 0.22726407958159306
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.9655764604056205,
                    2.1192267413964467,
                    1.9151967981979328
                ],
                "result_count_important_words": [
                    17000.0,
                    16300.0,
                    15500.0
                ],
                "wikipedia_search": [
                    0.30434782608695654,
                    0.16304347826086957,
                    2.532608695652174
                ],
                "answer_relation_to_question": [
                    0.5175438596491229,
                    0.09649122807017543,
                    1.3859649122807016
                ],
                "answer_relation_to_question_bing": [
                    0.38461538461538464,
                    0.5,
                    0.11538461538461539
                ],
                "result_count_noun_chunks": [
                    20200.0,
                    18700.0,
                    23600.0
                ],
                "question_answer_similarity": [
                    2.6946067265234888,
                    1.5144817251712084,
                    2.244919354096055
                ],
                "result_count_bing": [
                    56300.0,
                    55700.0,
                    62900.0
                ],
                "word_count_appended": [
                    179.0,
                    187.0,
                    162.0
                ],
                "result_count": [
                    16700.0,
                    12100.0,
                    18600.0
                ]
            },
            "integer_answers": {
                "ox": 3,
                "goat": 5,
                "pig": 2
            }
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Which human sense is most closely associated with the bony labyrinth?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "touch"
            ],
            "lines": [
                [
                    0.30701754385964913,
                    0.14583333333333331,
                    0.3330204235621606,
                    0.28312788906009245,
                    0.3108003108003108,
                    0.4580007601672368,
                    0.3634053367217281,
                    0.3904761904761905,
                    0.28998505231689087,
                    0.33134198183511354,
                    -1.0
                ],
                [
                    0.5279605263157895,
                    0.6979166666666667,
                    0.3099602330094307,
                    0.3697996918335901,
                    0.3741258741258741,
                    0.42949448878753327,
                    0.33799237611181704,
                    0.5,
                    0.4080717488789238,
                    0.3436343119696019,
                    -1.0
                ],
                [
                    0.1650219298245614,
                    0.15625,
                    0.3570193434284087,
                    0.3470724191063174,
                    0.3150738150738151,
                    0.11250475104522994,
                    0.29860228716645487,
                    0.10952380952380951,
                    0.30194319880418535,
                    0.3250237061952846,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "touch": 0.3213008822132706,
                "sight": 0.24880352601680672,
                "hearing": 0.4298955917699227
            },
            "question": "which human sense is most closely associated with the bony labyrinth?",
            "rate_limited": false,
            "answers": [
                "touch",
                "hearing",
                "sight"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "touch": 0.6402705976686933,
                "sight": 0.22135570515471556,
                "hearing": 0.565051787722736
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.9880518910106812,
                    2.0618058718176115,
                    1.9501422371717074
                ],
                "result_count_important_words": [
                    241000.0,
                    226000.0,
                    59200.0
                ],
                "wikipedia_search": [
                    1.9523809523809523,
                    2.5,
                    0.5476190476190476
                ],
                "answer_relation_to_question": [
                    1.2280701754385965,
                    2.111842105263158,
                    0.6600877192982456
                ],
                "answer_relation_to_question_bing": [
                    0.29166666666666663,
                    1.3958333333333335,
                    0.3125
                ],
                "result_count_noun_chunks": [
                    286000000.0,
                    266000000.0,
                    235000000.0
                ],
                "question_answer_similarity": [
                    3.739047773182392,
                    3.4801352620124817,
                    4.008500039577484
                ],
                "result_count_bing": [
                    80000.0,
                    96300.0,
                    81100.0
                ],
                "word_count_appended": [
                    194.0,
                    273.0,
                    202.0
                ],
                "result_count": [
                    73500.0,
                    96000.0,
                    90100.0
                ]
            },
            "integer_answers": {
                "touch": 2,
                "sight": 1,
                "hearing": 7
            }
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Which of these utensils is tined?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "spoon"
            ],
            "lines": [
                [
                    0.0,
                    0.0,
                    0.32500422247505123,
                    0.0019318596597434276,
                    0.17393976644130302,
                    0.5292652552926526,
                    0.22460776218001652,
                    0.8333333333333334,
                    0.40239043824701193,
                    0.3352946365561045,
                    -1.0
                ],
                [
                    0.2,
                    1.0,
                    0.35042849358865497,
                    0.009881862775646105,
                    0.21204671173939765,
                    0.17310087173100872,
                    0.4269199009083402,
                    0.16666666666666669,
                    0.2621513944223108,
                    0.32279463655610446,
                    -1.0
                ],
                [
                    0.8,
                    0.0,
                    0.3245672839362938,
                    0.9881862775646104,
                    0.6140135218192994,
                    0.29763387297633875,
                    0.34847233691164325,
                    0.0,
                    0.3354581673306773,
                    0.3419107268877911,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "fork": 0.2825767274185217,
                "spoon": 0.40502421874266537,
                "knife": 0.31239905383881295
            },
            "question": "which of these utensils is tined?",
            "rate_limited": false,
            "answers": [
                "fork",
                "knife",
                "spoon"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "fork": 0.29804202925344286,
                "spoon": 0.520828807069629,
                "knife": 0.19115935840298787
            },
            "integer_answers": {
                "fork": 3,
                "spoon": 4,
                "knife": 3
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    0.670589273112209,
                    0.6455892731122089,
                    0.6838214537755822
                ],
                "result_count_important_words": [
                    425000.0,
                    139000.0,
                    239000.0
                ],
                "wikipedia_search": [
                    1.6666666666666665,
                    0.3333333333333333,
                    0.0
                ],
                "answer_relation_to_question": [
                    0.0,
                    0.2,
                    0.8
                ],
                "answer_relation_to_question_bing": [
                    0.0,
                    1.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    2720000.0,
                    5170000.0,
                    4220000.0
                ],
                "question_answer_similarity": [
                    1.3906403183937073,
                    1.4994266480207443,
                    1.38877072930336
                ],
                "result_count_bing": [
                    2830000.0,
                    3450000.0,
                    9990000.0
                ],
                "result_count": [
                    217000.0,
                    1110000.0,
                    111000000.0
                ],
                "word_count_appended": [
                    505.0,
                    329.0,
                    421.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which TV comedy centers on a vice president?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "veep"
            ],
            "lines": [
                [
                    0.15142211074373885,
                    0.20366170735230393,
                    0.6525233818279421,
                    0.060837381448068474,
                    0.0918958031837916,
                    0.3281746031746032,
                    0.06348353419820373,
                    0.31792355371900827,
                    0.06976744186046512,
                    0.29622428932715333,
                    -1.0
                ],
                [
                    0.1513412546054206,
                    0.16372237469305215,
                    0.17565075979398295,
                    0.8558871154291001,
                    0.8936324167872648,
                    0.23531746031746031,
                    0.8520764565901588,
                    0.02706611570247934,
                    0.273784355179704,
                    0.324696706013472,
                    -1.0
                ],
                [
                    0.6972366346508405,
                    0.632615917954644,
                    0.17182585837807487,
                    0.08327550312283137,
                    0.01447178002894356,
                    0.4365079365079365,
                    0.08444000921163737,
                    0.6550103305785124,
                    0.6564482029598309,
                    0.3790790046593746,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "veep": 0.3810911178052626,
                "young sheldon": 0.22359138068352785,
                "superstore": 0.3953175015112095
            },
            "question": "which tv comedy centers on a vice president?",
            "rate_limited": false,
            "answers": [
                "young sheldon",
                "superstore",
                "veep"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "veep": 0.565051787722736,
                "young sheldon": 0.1513368190610226,
                "superstore": 0.3427816109273032
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.4811214466357667,
                    1.62348353006736,
                    1.895395023296873
                ],
                "result_count_important_words": [
                    82700.0,
                    59300.0,
                    110000.0
                ],
                "wikipedia_search": [
                    1.271694214876033,
                    0.10826446280991736,
                    2.6200413223140497
                ],
                "answer_relation_to_question": [
                    0.7571105537186942,
                    0.756706273027103,
                    3.4861831732542026
                ],
                "answer_relation_to_question_bing": [
                    0.8146468294092157,
                    0.6548894987722086,
                    2.530463671818576
                ],
                "result_count_noun_chunks": [
                    82700.0,
                    1110000.0,
                    110000.0
                ],
                "question_answer_similarity": [
                    2.3016564340214245,
                    0.6195758078247309,
                    0.6060841702856123
                ],
                "result_count_bing": [
                    2540000.0,
                    24700000.0,
                    400000.0
                ],
                "word_count_appended": [
                    66.0,
                    259.0,
                    621.0
                ],
                "result_count": [
                    78900.0,
                    1110000.0,
                    108000.0
                ]
            },
            "integer_answers": {
                "veep": 6,
                "young sheldon": 1,
                "superstore": 3
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which organization began as the North West Police Agency?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "pinkerton"
            ],
            "lines": [
                [
                    0.1759722222222222,
                    0.07142857142857144,
                    4.226847840769482,
                    0.6321493076459964,
                    0.28672985781990523,
                    0.5991735537190083,
                    0.8607198748043818,
                    1.0,
                    0.32546842470506593,
                    0.35430322035792766,
                    -1.0
                ],
                [
                    0.17319444444444443,
                    0.28571428571428575,
                    0.2703570749405698,
                    0.25225767609873573,
                    0.36729857819905215,
                    0.31074380165289256,
                    0.0856248602727476,
                    0.0,
                    0.30881332408049966,
                    0.29014708465604194,
                    -1.0
                ],
                [
                    0.6508333333333334,
                    0.6428571428571429,
                    -3.4972049157100518,
                    0.11559301625526791,
                    0.3459715639810427,
                    0.09008264462809917,
                    0.05365526492287056,
                    0.0,
                    0.3657182512144344,
                    0.3555496949860304,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "pinkerton": -0.08769440035318304,
                "fbi": 0.853279287347256,
                "nra": 0.23441511300592702
            },
            "question": "which organization began as the north west police agency?",
            "rate_limited": false,
            "answers": [
                "fbi",
                "nra",
                "pinkerton"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "pinkerton": 0.699574803000301,
                "fbi": 0.3112655414117316,
                "nra": 0.16477265873312696
            },
            "integer_answers": {
                "pinkerton": 4,
                "fbi": 5,
                "nra": 1
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    2.125819322147566,
                    1.7408825079362518,
                    2.1332981699161824
                ],
                "result_count_important_words": [
                    1450000.0,
                    752000.0,
                    218000.0
                ],
                "wikipedia_search": [
                    5.0,
                    0.0,
                    0.0
                ],
                "answer_relation_to_question": [
                    1.0558333333333332,
                    1.0391666666666666,
                    3.9050000000000002
                ],
                "answer_relation_to_question_bing": [
                    0.14285714285714285,
                    0.5714285714285714,
                    1.2857142857142856
                ],
                "result_count_noun_chunks": [
                    3850000.0,
                    383000.0,
                    240000.0
                ],
                "question_answer_similarity": [
                    1.0856999319512397,
                    0.06944339349865913,
                    -0.8982852664776146
                ],
                "result_count_bing": [
                    1210000.0,
                    1550000.0,
                    1460000.0
                ],
                "word_count_appended": [
                    469.0,
                    445.0,
                    527.0
                ],
                "result_count": [
                    1050000.0,
                    419000.0,
                    192000.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Mount Rushmore was named after a person with what profession?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "lawyer"
            ],
            "lines": [
                [
                    0.2390625,
                    0.20000000000000004,
                    0.15028102021251624,
                    0.04239766081871345,
                    0.11916529379461833,
                    0.04725897920604915,
                    0.04206077681626082,
                    0.265625,
                    0.2733516483516483,
                    0.297191730598507,
                    1.0
                ],
                [
                    0.178125,
                    0.4444444444444445,
                    0.4813700883683983,
                    0.39473684210526316,
                    0.07358594179022515,
                    0.5217391304347826,
                    0.8150533306500302,
                    0.6437190594059405,
                    0.3516483516483517,
                    0.383066040841835,
                    1.0
                ],
                [
                    0.5828125,
                    0.35555555555555557,
                    0.36834889141908544,
                    0.5628654970760234,
                    0.8072487644151565,
                    0.43100189035916825,
                    0.142885892533709,
                    0.0906559405940594,
                    0.375,
                    0.31974222855965795,
                    1.0
                ]
            ],
            "fraction_answers": {
                "architect": 0.4036117160512416,
                "prospector": 0.16763946097983135,
                "lawyer": 0.4287488229689272
            },
            "question": "mount rushmore was named after a person with what profession?",
            "rate_limited": false,
            "answers": [
                "prospector",
                "lawyer",
                "architect"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "architect": 0.2842607014813976,
                "prospector": 0.17474525007858205,
                "lawyer": 0.39190888961839443
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.485958652992535,
                    1.9153302042091749,
                    1.5987111427982899
                ],
                "result_count_important_words": [
                    12500.0,
                    138000.0,
                    114000.0
                ],
                "wikipedia_search": [
                    1.0625,
                    2.574876237623762,
                    0.3626237623762376
                ],
                "answer_relation_to_question": [
                    0.95625,
                    0.7125,
                    2.33125
                ],
                "answer_relation_to_question_bing": [
                    0.4,
                    0.8888888888888888,
                    0.711111111111111
                ],
                "result_count_noun_chunks": [
                    418000.0,
                    8100000.0,
                    1420000.0
                ],
                "question_answer_similarity": [
                    0.9013332910835743,
                    2.887090368196368,
                    2.209228537976742
                ],
                "result_count_bing": [
                    217000.0,
                    134000.0,
                    1470000.0
                ],
                "word_count_appended": [
                    199.0,
                    256.0,
                    273.0
                ],
                "result_count": [
                    11600.0,
                    108000.0,
                    154000.0
                ]
            },
            "integer_answers": {
                "architect": 4,
                "prospector": 0,
                "lawyer": 6
            }
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "What is the total cost of all the vowels on \u201cWheel of Fortune\u201d?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "$2,500"
            ],
            "lines": [
                [
                    0.05787037037037037,
                    0.39743589743589747,
                    0.29829337871079203,
                    0.026636440918107112,
                    0.3333333333333333,
                    0.09472551130247578,
                    0.08836091831286706,
                    0.75,
                    0.30952380952380953,
                    0.33232487350760753,
                    1.0
                ],
                [
                    0.6064814814814815,
                    0.24358974358974358,
                    0.4713793088949262,
                    0.9606120714083309,
                    0.3333333333333333,
                    0.8665231431646933,
                    0.8729311265349706,
                    0.25,
                    0.42857142857142855,
                    0.5039491112334341,
                    1.0
                ],
                [
                    0.3356481481481482,
                    0.358974358974359,
                    0.2303273123942818,
                    0.012751487673561915,
                    0.3333333333333333,
                    0.038751345532831,
                    0.038707955152162306,
                    0.0,
                    0.2619047619047619,
                    0.1637260152589583,
                    1.0
                ]
            ],
            "fraction_answers": {
                "$2,500": 0.5537370748212342,
                "$1,250": 0.268850453341526,
                "$2,900": 0.17741247183723977
            },
            "question": "what is the total cost of all the vowels on \u201cwheel of fortune\u201d?",
            "rate_limited": false,
            "answers": [
                "$1,250",
                "$2,500",
                "$2,900"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "$2,500": 0.5698989159220088,
                "$1,250": 0.333197701149012,
                "$2,900": 0.17023702082831188
            },
            "integer_answers": {
                "$2,500": 7,
                "$1,250": 3,
                "$2,900": 0
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.6616243675380375,
                    2.5197455561671704,
                    0.8186300762947916
                ],
                "result_count_important_words": [
                    3520.0,
                    32200.0,
                    1440.0
                ],
                "wikipedia_search": [
                    2.25,
                    0.75,
                    0.0
                ],
                "answer_relation_to_question": [
                    0.23148148148148145,
                    2.4259259259259256,
                    1.3425925925925926
                ],
                "answer_relation_to_question_bing": [
                    0.7948717948717949,
                    0.48717948717948717,
                    0.717948717948718
                ],
                "result_count_noun_chunks": [
                    3310.0,
                    32700.0,
                    1450.0
                ],
                "question_answer_similarity": [
                    2.751216939795995,
                    4.34762161099934,
                    2.1243528981285635
                ],
                "result_count_bing": [
                    367000.0,
                    367000.0,
                    367000.0
                ],
                "result_count": [
                    94.0,
                    3390.0,
                    45.0
                ],
                "word_count_appended": [
                    13.0,
                    18.0,
                    11.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which brand mascot was NOT a real person?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "sara lee"
            ],
            "lines": [
                [
                    0.41138618724825626,
                    0.24790919952210272,
                    0.18523063987353944,
                    0.47710205939242234,
                    0.2624592454587797,
                    0.4156050955414013,
                    0.47710205939242234,
                    0.3032407407407408,
                    0.2846820809248555,
                    0.3269028310828127,
                    -1.0
                ],
                [
                    0.3261698922618463,
                    0.30824372759856633,
                    0.36753576994789994,
                    0.4865456821026283,
                    0.3612016767582673,
                    0.4304670912951168,
                    0.4865456821026283,
                    0.4207175925925926,
                    0.34826589595375723,
                    0.3753730521721532,
                    -1.0
                ],
                [
                    0.26244392048989756,
                    0.44384707287933095,
                    0.4472335901785606,
                    0.036352258504949386,
                    0.37633907778295295,
                    0.15392781316348197,
                    0.036352258504949386,
                    0.2760416666666667,
                    0.3670520231213873,
                    0.2977241167450341,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "betty crocker": 0.46053724039255783,
                "sara lee": 0.21778678744290877,
                "little debbie": 0.32167597216453336
            },
            "question": "which brand mascot was not a real person?",
            "rate_limited": false,
            "answers": [
                "little debbie",
                "sara lee",
                "betty crocker"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "betty crocker": 0.19414123001326766,
                "sara lee": 0.6874866009609402,
                "little debbie": 0.25489723292888966
            },
            "negative_question": true,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.3847773513374986,
                    0.9970155826227742,
                    1.6182070660397272
                ],
                "result_count_important_words": [
                    159000.0,
                    131000.0,
                    652000.0
                ],
                "wikipedia_search": [
                    1.574074074074074,
                    0.6342592592592593,
                    1.7916666666666667
                ],
                "answer_relation_to_question": [
                    0.5316828765104626,
                    1.0429806464289224,
                    1.425336477060615
                ],
                "answer_relation_to_question_bing": [
                    1.5125448028673834,
                    1.150537634408602,
                    0.3369175627240143
                ],
                "result_count_noun_chunks": [
                    161000.0,
                    94600.0,
                    3260000.0
                ],
                "question_answer_similarity": [
                    4.103627513162792,
                    1.7269274834543467,
                    0.6879122257232666
                ],
                "result_count_bing": [
                    1020000.0,
                    596000.0,
                    531000.0
                ],
                "word_count_appended": [
                    149.0,
                    105.0,
                    92.0
                ],
                "result_count": [
                    161000.0,
                    94600.0,
                    3260000.0
                ]
            },
            "integer_answers": {
                "betty crocker": 6,
                "sara lee": 0,
                "little debbie": 4
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "What iconic painting once hung in Napoleon's bedroom?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "mona lisa"
            ],
            "lines": [
                [
                    0.3394878706199461,
                    0.22972972972972974,
                    0.4054201490299891,
                    0.7252957342573784,
                    0.421130402659771,
                    0.8896797153024911,
                    0.6343564889606893,
                    0.7300724637681159,
                    0.13649851632047477,
                    0.2832793777447641,
                    1.0
                ],
                [
                    0.12035040431266845,
                    0.13513513513513514,
                    0.10499486390772106,
                    0.022583343290715735,
                    0.17251570003694125,
                    0.04329774614472123,
                    0.031771674744211095,
                    0.20591787439613526,
                    0.6261127596439169,
                    0.39607789887243083,
                    1.0
                ],
                [
                    0.5401617250673855,
                    0.6351351351351351,
                    0.48958498706228987,
                    0.2521209224519058,
                    0.40635389730328775,
                    0.06702253855278767,
                    0.33387183629509964,
                    0.06400966183574879,
                    0.23738872403560832,
                    0.3206427233828051,
                    1.0
                ]
            ],
            "fraction_answers": {
                "the birth of venus": 0.33462921511220534,
                "mona lisa": 0.1858757400484597,
                "the starry night": 0.479495044839335
            },
            "question": "what iconic painting once hung in napoleon's bedroom?",
            "rate_limited": false,
            "answers": [
                "the starry night",
                "mona lisa",
                "the birth of venus"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "the birth of venus": 0.23480339033994968,
                "mona lisa": 0.30312106841855546,
                "the starry night": 0.1117093620487235
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.4163968887238203,
                    1.9803894943621543,
                    1.6032136169140254
                ],
                "result_count_important_words": [
                    3000000.0,
                    146000.0,
                    226000.0
                ],
                "wikipedia_search": [
                    2.1902173913043477,
                    0.6177536231884058,
                    0.19202898550724637
                ],
                "answer_relation_to_question": [
                    1.6974393530997305,
                    0.6017520215633423,
                    2.7008086253369274
                ],
                "answer_relation_to_question_bing": [
                    0.4594594594594595,
                    0.2702702702702703,
                    1.2702702702702702
                ],
                "result_count_noun_chunks": [
                    5890000.0,
                    295000.0,
                    3100000.0
                ],
                "question_answer_similarity": [
                    8.063914388883859,
                    2.0883757155388594,
                    9.737975360127166
                ],
                "result_count_bing": [
                    114000.0,
                    46700.0,
                    110000.0
                ],
                "word_count_appended": [
                    46.0,
                    211.0,
                    80.0
                ],
                "result_count": [
                    6070000.0,
                    189000.0,
                    2110000.0
                ]
            },
            "integer_answers": {
                "the birth of venus": 3,
                "mona lisa": 2,
                "the starry night": 5
            }
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Which of these is NOT among the four \u201cC\u2019s\u201d of diamond buying?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "cut"
            ],
            "lines": [
                [
                    0.31625775521714605,
                    0.36880020080321285,
                    0.35298536436153694,
                    0.2838882282996433,
                    0.33168316831683164,
                    0.2748713550600343,
                    0.2614107883817427,
                    0.15657439199123635,
                    0.26988636363636365,
                    0.33170286909344615,
                    -1.0
                ],
                [
                    0.2858877166207713,
                    0.28350903614457834,
                    0.3104077788750854,
                    0.27645659928656363,
                    0.33353960396039606,
                    0.3711406518010292,
                    0.3976486860304288,
                    0.45210846887589246,
                    0.31477272727272726,
                    0.31700011904734926,
                    -1.0
                ],
                [
                    0.39785452816208267,
                    0.3476907630522088,
                    0.3366068567633777,
                    0.4396551724137931,
                    0.3347772277227723,
                    0.35398799313893653,
                    0.3409405255878285,
                    0.39131713913287125,
                    0.4153409090909091,
                    0.3512970118592046,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "color": 0.41038790296776123,
                "core": 0.2581063746152031,
                "cut": 0.3315057224170357
            },
            "question": "which of these is not among the four \u201cc\u2019s\u201d of diamond buying?",
            "rate_limited": false,
            "answers": [
                "color",
                "cut",
                "core"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "color": 0.2124088185142459,
                "core": 0.47220771678300366,
                "cut": 0.6595885692947471
            },
            "integer_answers": {
                "color": 5,
                "core": 0,
                "cut": 5
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.0097827854393229,
                    1.0979992857159047,
                    0.8922179288447724
                ],
                "result_count_important_words": [
                    10500000.0,
                    6010000.0,
                    6810000.0
                ],
                "wikipedia_search": [
                    1.3737024320350546,
                    0.19156612449643015,
                    0.4347314434685151
                ],
                "answer_relation_to_question": [
                    1.1024534686971235,
                    1.2846737002753725,
                    0.612872831027504
                ],
                "answer_relation_to_question_bing": [
                    0.2623995983935743,
                    0.4329819277108434,
                    0.30461847389558233
                ],
                "result_count_noun_chunks": [
                    3450000.0,
                    1480000.0,
                    2300000.0
                ],
                "question_answer_similarity": [
                    3.8351904675364494,
                    4.945917636156082,
                    4.26245878636837
                ],
                "result_count_bing": [
                    54400000.0,
                    53800000.0,
                    53400000.0
                ],
                "word_count_appended": [
                    405.0,
                    326.0,
                    149.0
                ],
                "result_count": [
                    727000.0,
                    752000.0,
                    203000.0
                ]
            },
            "negative_question": true
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "What is the correct pronunciation of the performer who sings \u201cSmooth Operator\u201d?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "shah-day"
            ],
            "lines": [
                [
                    0.5,
                    0.3333333333333333,
                    0.44677802128757055,
                    0.9986801583809943,
                    0.22736093143596378,
                    0.011940298507462687,
                    0.6559849198868991,
                    0.0,
                    0.771551724137931,
                    0.7172849560250572,
                    1.0
                ],
                [
                    0.25,
                    0.3333333333333333,
                    -0.02854204455048535,
                    0.0009238891333040035,
                    0.5756791720569211,
                    0.9731343283582089,
                    0.33459000942507067,
                    0.0,
                    0.1336206896551724,
                    0.17079231211551685,
                    1.0
                ],
                [
                    0.25,
                    0.3333333333333333,
                    0.5817640232629148,
                    0.0003959524857017158,
                    0.19695989650711512,
                    0.014925373134328358,
                    0.00942507068803016,
                    1.0,
                    0.09482758620689655,
                    0.11192273185942615,
                    1.0
                ]
            ],
            "fraction_answers": {
                "sayd": 0.2743531689527042,
                "shah-day": 0.46629143429952113,
                "say-dee": 0.25935539674777464
            },
            "question": "what is the correct pronunciation of the performer who sings \u201csmooth operator\u201d?",
            "rate_limited": false,
            "answers": [
                "shah-day",
                "sayd",
                "say-dee"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "sayd": 0.2098436184432403,
                "shah-day": 0.6017637472366403,
                "say-dee": 0.17079281453602344
            },
            "integer_answers": {
                "sayd": 2,
                "shah-day": 6,
                "say-dee": 2
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    4.303709736150342,
                    1.024753872693101,
                    0.6715363911565568
                ],
                "result_count_important_words": [
                    40.0,
                    3260.0,
                    50.0
                ],
                "wikipedia_search": [
                    0.0,
                    0.0,
                    1.0
                ],
                "answer_relation_to_question": [
                    2.0,
                    1.0,
                    1.0
                ],
                "answer_relation_to_question_bing": [
                    0.3333333333333333,
                    0.3333333333333333,
                    0.3333333333333333
                ],
                "result_count_noun_chunks": [
                    6960.0,
                    3550.0,
                    100.0
                ],
                "question_answer_similarity": [
                    6.507756527513266,
                    -0.41574264597147703,
                    8.473958967253566
                ],
                "result_count_bing": [
                    70300.0,
                    178000.0,
                    60900.0
                ],
                "word_count_appended": [
                    179.0,
                    31.0,
                    22.0
                ],
                "result_count": [
                    22700.0,
                    21.0,
                    9.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "In which version of \u201cDragnet\u201d is the line \u201cJust the facts, ma\u2019am\u201d first said?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "'50s movie"
            ],
            "lines": [
                [
                    0.39289067739771966,
                    0.317351598173516,
                    0.4047773689742971,
                    0.2682926829268293,
                    0.1872852233676976,
                    0.20754716981132076,
                    0.398590021691974,
                    0.012077294685990338,
                    0.3333333333333333,
                    0.39050519440022324,
                    -1.0
                ],
                [
                    0.21882964453386985,
                    0.34063926940639266,
                    0.2857209373967589,
                    0.2682926829268293,
                    0.22508591065292097,
                    0.18867924528301888,
                    0.4121475054229935,
                    0.8140096618357487,
                    0.3333333333333333,
                    0.3112837581307818,
                    -1.0
                ],
                [
                    0.38827967806841046,
                    0.34200913242009134,
                    0.309501693628944,
                    0.4634146341463415,
                    0.5876288659793815,
                    0.6037735849056604,
                    0.18926247288503253,
                    0.17391304347826086,
                    0.3333333333333333,
                    0.298211047468995,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "'80s movie": 0.36893274863144515,
                "'50s movie": 0.33980219489226476,
                "'50s tv show": 0.2912650564762901
            },
            "question": "in which version of \u201cdragnet\u201d is the line \u201cjust the facts, ma\u2019am\u201d first said?",
            "rate_limited": false,
            "answers": [
                "'50s tv show",
                "'50s movie",
                "'80s movie"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "'80s movie": 0.26020608592553657,
                "'50s movie": 0.4312203527082986,
                "'50s tv show": 0.3552511954445814
            },
            "integer_answers": {
                "'80s movie": 4,
                "'50s movie": 2,
                "'50s tv show": 4
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.9525259720011163,
                    1.556418790653909,
                    1.491055237344975
                ],
                "result_count_important_words": [
                    11.0,
                    10.0,
                    32.0
                ],
                "wikipedia_search": [
                    0.036231884057971016,
                    2.442028985507246,
                    0.5217391304347826
                ],
                "answer_relation_to_question": [
                    1.9644533869885983,
                    1.0941482226693493,
                    1.9413983903420524
                ],
                "answer_relation_to_question_bing": [
                    0.634703196347032,
                    0.6812785388127853,
                    0.6840182648401827
                ],
                "result_count_noun_chunks": [
                    147000.0,
                    152000.0,
                    69800.0
                ],
                "question_answer_similarity": [
                    16.162886361591518,
                    11.408925983123481,
                    12.358498983085155
                ],
                "result_count_bing": [
                    109000.0,
                    131000.0,
                    342000.0
                ],
                "word_count_appended": [
                    3.0,
                    3.0,
                    3.0
                ],
                "result_count": [
                    11.0,
                    11.0,
                    19.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which of these companies went public first?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "facebook"
            ],
            "lines": [
                [
                    0.6888888888888889,
                    0.0,
                    1.1639659299124,
                    0.6332129963898917,
                    0.3532608695652174,
                    0.9797707706121587,
                    0.9845308659823623,
                    0.5581804281345565,
                    0.2761409589832467,
                    0.3583251861283898,
                    -1.0
                ],
                [
                    0.1377777777777778,
                    0.0,
                    0.3346810499462215,
                    0.1956678700361011,
                    0.3233695652173913,
                    0.016109438546453282,
                    0.009527251698713315,
                    0.12904106596767148,
                    0.340843443096476,
                    0.32813417195568223,
                    -1.0
                ],
                [
                    0.17333333333333337,
                    1.0,
                    -0.4986469798586215,
                    0.1711191335740072,
                    0.3233695652173913,
                    0.004119790841388053,
                    0.005941882318924389,
                    0.31277850589777195,
                    0.3830155979202773,
                    0.31354064191592795,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "ferrari": 0.1815151634242488,
                "facebook": 0.5996276894597112,
                "alibaba": 0.21885714711604
            },
            "question": "which of these companies went public first?",
            "rate_limited": false,
            "answers": [
                "facebook",
                "ferrari",
                "alibaba"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "ferrari": 0.32610728045417126,
                "facebook": 0.49813239523027014,
                "alibaba": 0.27278655197191104
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.0749755583851694,
                    0.9844025158670467,
                    0.9406219257477839
                ],
                "result_count_important_words": [
                    371000000.0,
                    6100000.0,
                    1560000.0
                ],
                "wikipedia_search": [
                    1.6745412844036696,
                    0.3871231979030144,
                    0.9383355176933159
                ],
                "answer_relation_to_question": [
                    2.0666666666666664,
                    0.41333333333333333,
                    0.52
                ],
                "answer_relation_to_question_bing": [
                    0.0,
                    0.0,
                    1.0
                ],
                "result_count_noun_chunks": [
                    681000000.0,
                    6590000.0,
                    4110000.0
                ],
                "question_answer_similarity": [
                    1.5726340487599373,
                    0.4521874748170376,
                    -0.6737217977643013
                ],
                "result_count_bing": [
                    130000000.0,
                    119000000.0,
                    119000000.0
                ],
                "word_count_appended": [
                    478.0,
                    590.0,
                    663.0
                ],
                "result_count": [
                    87700000.0,
                    27100000.0,
                    23700000.0
                ]
            },
            "integer_answers": {
                "ferrari": 0,
                "facebook": 8,
                "alibaba": 2
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "What topic would a herpetologist study?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "venereal disease"
            ],
            "lines": [
                [
                    0.1611111111111111,
                    0.6666666666666666,
                    0.326491276716233,
                    0.9692275486707138,
                    0.6684782608695652,
                    0.9292545614868073,
                    0.8580106302201974,
                    0.7333333333333334,
                    0.4358974358974359,
                    0.415309838833878,
                    1.0
                ],
                [
                    0.025,
                    0.0,
                    0.3448202958839333,
                    0.021980322378061544,
                    0.1766304347826087,
                    0.03350742725361188,
                    0.09870918754745633,
                    0.0,
                    0.3333333333333333,
                    0.2760991850309362,
                    1.0
                ],
                [
                    0.8138888888888889,
                    0.3333333333333333,
                    0.32868842739983367,
                    0.008792128951224618,
                    0.15489130434782608,
                    0.03723801125958082,
                    0.04328018223234624,
                    0.26666666666666666,
                    0.23076923076923078,
                    0.30859097613518577,
                    1.0
                ]
            ],
            "fraction_answers": {
                "venereal disease": 0.6163780663805942,
                "mushroom farming": 0.13100801862099415,
                "crocodile teeth": 0.2526139149984117
            },
            "question": "what topic would a herpetologist study?",
            "rate_limited": false,
            "answers": [
                "venereal disease",
                "mushroom farming",
                "crocodile teeth"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "venereal disease": 0.6354254300557068,
                "mushroom farming": 0.18236501519393916,
                "crocodile teeth": 0.32471375454250334
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.245929516501634,
                    0.8282975550928087,
                    0.9257729284055574
                ],
                "result_count_important_words": [
                    13700.0,
                    494.0,
                    549.0
                ],
                "wikipedia_search": [
                    1.4666666666666668,
                    0.0,
                    0.5333333333333333
                ],
                "answer_relation_to_question": [
                    0.3222222222222222,
                    0.05,
                    1.6277777777777778
                ],
                "answer_relation_to_question_bing": [
                    0.6666666666666666,
                    0.0,
                    0.3333333333333333
                ],
                "result_count_noun_chunks": [
                    226000.0,
                    26000.0,
                    11400.0
                ],
                "question_answer_similarity": [
                    2.05005219951272,
                    2.1651408672332764,
                    2.0638481993228197
                ],
                "result_count_bing": [
                    492000.0,
                    130000.0,
                    114000.0
                ],
                "result_count": [
                    9260.0,
                    210.0,
                    84.0
                ],
                "word_count_appended": [
                    34.0,
                    26.0,
                    18.0
                ]
            },
            "integer_answers": {
                "venereal disease": 8,
                "mushroom farming": 1,
                "crocodile teeth": 1
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "In the U.K., who appoints the Prime Minister?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "the queen"
            ],
            "lines": [
                [
                    0.08333333333333333,
                    0.0,
                    0.3687968130790466,
                    0.8071748878923767,
                    0.461961503208066,
                    0.4944547134935305,
                    0.27898550724637683,
                    0.0,
                    0.256198347107438,
                    0.32802084020431926,
                    0.0
                ],
                [
                    0.7424242424242424,
                    0.325,
                    0.33006858967631847,
                    0.10134529147982063,
                    0.2529789184234647,
                    0.17144177449168208,
                    0.17753623188405798,
                    0.393939393939394,
                    0.22727272727272727,
                    0.3278652063338847,
                    0.0
                ],
                [
                    0.17424242424242425,
                    0.675,
                    0.301134597244635,
                    0.09147982062780269,
                    0.2850595783684693,
                    0.33410351201478744,
                    0.5434782608695652,
                    0.6060606060606061,
                    0.5165289256198347,
                    0.344113953461796,
                    0.0
                ]
            ],
            "fraction_answers": {
                "the parliament": 0.3049872375925592,
                "the people": 0.30789259455644874,
                "the queen": 0.387120167850992
            },
            "question": "in the u.k., who appoints the prime minister?",
            "rate_limited": false,
            "answers": [
                "the people",
                "the parliament",
                "the queen"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "the parliament": 0.4727941863905904,
                "the people": 0.17759367929346728,
                "the queen": 0.724144258726577
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 0
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.312083360817277,
                    1.3114608253355389,
                    1.376455813847184
                ],
                "result_count_important_words": [
                    1070000.0,
                    371000.0,
                    723000.0
                ],
                "wikipedia_search": [
                    0.0,
                    0.7878787878787878,
                    1.212121212121212
                ],
                "answer_relation_to_question": [
                    0.16666666666666666,
                    1.4848484848484849,
                    0.3484848484848485
                ],
                "answer_relation_to_question_bing": [
                    0.0,
                    0.65,
                    1.35
                ],
                "result_count_noun_chunks": [
                    2310000.0,
                    1470000.0,
                    4500000.0
                ],
                "question_answer_similarity": [
                    7.725611565634608,
                    6.914326868951321,
                    6.308213207870722
                ],
                "result_count_bing": [
                    5040000.0,
                    2760000.0,
                    3110000.0
                ],
                "result_count": [
                    1800000.0,
                    226000.0,
                    204000.0
                ],
                "word_count_appended": [
                    62.0,
                    55.0,
                    125.0
                ]
            },
            "integer_answers": {
                "the parliament": 1,
                "the people": 4,
                "the queen": 5
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which writer has stated that his/her trademark series of books would never be adapted for film?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "jeff kinney"
            ],
            "lines": [
                [
                    0.37298028472721917,
                    0.3202547374961168,
                    0.15618529231671863,
                    0.4977717144156435,
                    0.31949152542372883,
                    0.4948453608247423,
                    0.49984861727591073,
                    0.1946872342902522,
                    0.30851063829787234,
                    0.31779575217934275,
                    -1.0
                ],
                [
                    0.29276405771429764,
                    0.33712488350419384,
                    0.24287744907648756,
                    0.00432014552069121,
                    0.32372881355932204,
                    0.011498810467882647,
                    0.2532175969563504,
                    0.30531276570974775,
                    0.3803191489361702,
                    0.33115802846598363,
                    -1.0
                ],
                [
                    0.33425565755848324,
                    0.34262037899968933,
                    0.6009372586067938,
                    0.4979081400636653,
                    0.35677966101694913,
                    0.4936558287073751,
                    0.2469337857677389,
                    0.5,
                    0.31117021276595747,
                    0.3510462193546736,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "jeff kinney": 0.19293857143173482,
                "sue grafton": 0.5035356600177746,
                "james patterson": 0.30352576855049057
            },
            "question": "which writer has stated that his/her trademark series of books would never be adapted for film?",
            "rate_limited": false,
            "answers": [
                "james patterson",
                "sue grafton",
                "jeff kinney"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "jeff kinney": 0.4202431437976948,
                "sue grafton": 0.3236088723617053,
                "james patterson": 0.1408248253891263
            },
            "negative_question": true,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    2.5508594694892017,
                    2.3637876014762296,
                    2.085352929034569
                ],
                "result_count_important_words": [
                    65.0,
                    6160.0,
                    80.0
                ],
                "wikipedia_search": [
                    3.6637531885169734,
                    2.3362468114830266,
                    0.0
                ],
                "answer_relation_to_question": [
                    1.5242365832733702,
                    2.4868313074284285,
                    1.9889321092982013
                ],
                "answer_relation_to_question_bing": [
                    1.4379621000310654,
                    1.3030009319664493,
                    1.2590369680024853
                ],
                "result_count_noun_chunks": [
                    53.0,
                    86400.0,
                    88600.0
                ],
                "question_answer_similarity": [
                    1.9795182928210124,
                    1.4803869109600782,
                    -0.5811477676033974
                ],
                "result_count_bing": [
                    42600.0,
                    41600.0,
                    33800.0
                ],
                "word_count_appended": [
                    72.0,
                    45.0,
                    71.0
                ],
                "result_count": [
                    98.0,
                    21800.0,
                    92.0
                ]
            },
            "integer_answers": {
                "jeff kinney": 1,
                "sue grafton": 3,
                "james patterson": 6
            }
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "In Harry Potter's Quidditch, what ALWAYS happens when one team catches the snitch?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "that team loses"
            ],
            "lines": [
                [
                    0.2555012224938875,
                    0.6129032258064516,
                    0.3338759673731476,
                    0.1810344827586207,
                    0.23088923556942278,
                    0.006562342251388188,
                    0.01317027281279398,
                    0.0625,
                    0.11864406779661017,
                    0.1684576152307795,
                    1.0
                ],
                [
                    0.4875713121434393,
                    0.34946236559139787,
                    0.34585338582943714,
                    0.04310344827586207,
                    0.23088923556942278,
                    0.001514386673397274,
                    0.0037629350893697085,
                    0.9375,
                    0.1016949152542373,
                    0.09853548275684276,
                    1.0
                ],
                [
                    0.2569274653626732,
                    0.03763440860215054,
                    0.32027064679741524,
                    0.7758620689655172,
                    0.5382215288611545,
                    0.9919232710752145,
                    0.9830667920978363,
                    0.0,
                    0.7796610169491526,
                    0.7330069020123776,
                    1.0
                ]
            ],
            "fraction_answers": {
                "the game ends": 0.5416574100723491,
                "that team loses": 0.25998874671834066,
                "that team wins": 0.1983538432093102
            },
            "question": "in harry potter's quidditch, what always happens when one team catches the snitch?",
            "rate_limited": false,
            "answers": [
                "that team wins",
                "that team loses",
                "the game ends"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "the game ends": 0.2592526253826121,
                "that team loses": 0.4727941863905904,
                "that team wins": 0.17001489362249236
            },
            "integer_answers": {
                "the game ends": 6,
                "that team loses": 3,
                "that team wins": 1
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.1792033066154566,
                    0.6897483792978993,
                    5.131048314086644
                ],
                "result_count_important_words": [
                    26.0,
                    6.0,
                    3930.0
                ],
                "wikipedia_search": [
                    0.0625,
                    0.9375,
                    0.0
                ],
                "answer_relation_to_question": [
                    0.511002444987775,
                    0.9751426242868786,
                    0.5138549307253464
                ],
                "answer_relation_to_question_bing": [
                    0.6129032258064516,
                    0.34946236559139787,
                    0.03763440860215054
                ],
                "result_count_noun_chunks": [
                    28.0,
                    8.0,
                    2090.0
                ],
                "question_answer_similarity": [
                    15.678421485237777,
                    16.240866923704743,
                    15.039531684014946
                ],
                "result_count_bing": [
                    29600.0,
                    29600.0,
                    69000.0
                ],
                "word_count_appended": [
                    7.0,
                    6.0,
                    46.0
                ],
                "result_count": [
                    21.0,
                    5.0,
                    90.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Laurie Metcalf, Amy Morton and Tracy Letts are members of a theatre company from what city?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "chicago"
            ],
            "lines": [
                [
                    0.462300473874548,
                    0.29198813056379824,
                    0.43169498387416644,
                    0.40260509177027826,
                    0.3707196029776675,
                    0.41456016177957533,
                    0.3847184986595174,
                    0.23854824469347158,
                    0.17052023121387283,
                    0.33920187057856444,
                    1.0
                ],
                [
                    0.10281440952737249,
                    0.4439169139465875,
                    0.3406846974583432,
                    0.20959147424511546,
                    0.430272952853598,
                    0.2012133468149646,
                    0.26273458445040215,
                    0.28420241234874344,
                    0.07514450867052024,
                    0.32163469268312295,
                    1.0
                ],
                [
                    0.43488511659807955,
                    0.26409495548961426,
                    0.2276203186674904,
                    0.38780343398460626,
                    0.1990074441687345,
                    0.38422649140546006,
                    0.35254691689008044,
                    0.47724934295778504,
                    0.7543352601156069,
                    0.3391634367383127,
                    1.0
                ]
            ],
            "fraction_answers": {
                "new york": 0.350685728998546,
                "los angeles": 0.26722099929987697,
                "chicago": 0.38209327170157703
            },
            "question": "laurie metcalf, amy morton and tracy letts are members of a theatre company from what city?",
            "rate_limited": false,
            "answers": [
                "new york",
                "los angeles",
                "chicago"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "new york": 0.23846475261106165,
                "los angeles": 0.20704512728251184,
                "chicago": 0.6671906255894267
            },
            "integer_answers": {
                "new york": 6,
                "los angeles": 2,
                "chicago": 2
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    3.3920187057856444,
                    3.2163469268312292,
                    3.391634367383127
                ],
                "result_count_important_words": [
                    12300.0,
                    5970.0,
                    11400.0
                ],
                "wikipedia_search": [
                    0.9541929787738863,
                    1.1368096493949738,
                    1.9089973718311402
                ],
                "answer_relation_to_question": [
                    2.773802843247288,
                    0.616886457164235,
                    2.609310699588477
                ],
                "answer_relation_to_question_bing": [
                    1.459940652818991,
                    2.2195845697329375,
                    1.3204747774480712
                ],
                "result_count_noun_chunks": [
                    28700.0,
                    19600.0,
                    26300.0
                ],
                "question_answer_similarity": [
                    8.457883653230965,
                    6.6747857658192515,
                    4.459598198533058
                ],
                "result_count_bing": [
                    74700.0,
                    86700.0,
                    40100.0
                ],
                "result_count": [
                    13600.0,
                    7080.0,
                    13100.0
                ],
                "word_count_appended": [
                    59.0,
                    26.0,
                    261.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which artist painted the ceiling of one of France's most iconic opera houses?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "marc chagall"
            ],
            "lines": [
                [
                    0.639584129106188,
                    0.4727272727272727,
                    -0.25652443449254586,
                    0.5129207553070878,
                    0.3392945851962245,
                    0.39643515673017826,
                    0.5200685266764562,
                    0.8431401931401932,
                    0.6355140186915887,
                    0.39621172743285976,
                    -1.0
                ],
                [
                    0.12661568415244887,
                    0.3704545454545454,
                    0.2935615048420961,
                    0.4863364478673912,
                    0.36860407352210633,
                    0.39028887523048555,
                    0.4792788383096753,
                    0.07062937062937064,
                    0.26635514018691586,
                    0.3080597941713664,
                    -1.0
                ],
                [
                    0.23380018674136321,
                    0.15681818181818183,
                    0.9629629296504498,
                    0.0007427968255209351,
                    0.29210134128166915,
                    0.2132759680393362,
                    0.0006526350138684941,
                    0.08623043623043623,
                    0.09813084112149532,
                    0.2957284783957738,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "marc chagall": 0.4499371930515504,
                "edgar degas": 0.31601842743664016,
                "auguste renoir": 0.23404437951180945
            },
            "question": "which artist painted the ceiling of one of france's most iconic opera houses?",
            "rate_limited": false,
            "answers": [
                "marc chagall",
                "edgar degas",
                "auguste renoir"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "marc chagall": 0.6742754817883374,
                "edgar degas": 0.13793577668027765,
                "auguste renoir": 0.18559471350607595
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    2.7734820920300183,
                    2.156418559199565,
                    2.070099348770417
                ],
                "result_count_important_words": [
                    64500.0,
                    63500.0,
                    34700.0
                ],
                "wikipedia_search": [
                    5.058841158841159,
                    0.4237762237762238,
                    0.5173826173826174
                ],
                "answer_relation_to_question": [
                    4.477088903743316,
                    0.886309789067142,
                    1.6366013071895424
                ],
                "answer_relation_to_question_bing": [
                    1.4181818181818182,
                    1.1113636363636363,
                    0.47045454545454546
                ],
                "result_count_noun_chunks": [
                    76500.0,
                    70500.0,
                    96.0
                ],
                "question_answer_similarity": [
                    0.3011175722349435,
                    -0.344593012414407,
                    -1.1303603888736689
                ],
                "result_count_bing": [
                    68300.0,
                    74200.0,
                    58800.0
                ],
                "word_count_appended": [
                    136.0,
                    57.0,
                    21.0
                ],
                "result_count": [
                    65600.0,
                    62200.0,
                    95.0
                ]
            },
            "integer_answers": {
                "marc chagall": 9,
                "edgar degas": 1,
                "auguste renoir": 0
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which of these two U.S. cities are in the same time zone?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "bismarck / cheyenne"
            ],
            "lines": [
                [
                    0.25989952718676124,
                    0.25954301075268815,
                    0.30697650259698,
                    0.14754098360655737,
                    0.33783783783783783,
                    0.14705882352941177,
                    0.13114754098360656,
                    0.014492753623188406,
                    0.3333333333333333,
                    0.21889196697157595,
                    -1.0
                ],
                [
                    0.47604412923561856,
                    0.4973118279569892,
                    0.11830706248428483,
                    0.6721311475409836,
                    0.32432432432432434,
                    0.75,
                    0.6885245901639344,
                    0.7671497584541062,
                    0.3333333333333333,
                    0.5176863987967341,
                    -1.0
                ],
                [
                    0.2640563435776202,
                    0.24314516129032254,
                    0.5747164349187351,
                    0.18032786885245902,
                    0.33783783783783783,
                    0.10294117647058823,
                    0.18032786885245902,
                    0.2183574879227053,
                    0.3333333333333333,
                    0.2634216342316901,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "el paso / pierre": 0.21567222804219402,
                "pensacola / sioux falls": 0.2698465147287751,
                "bismarck / cheyenne": 0.5144812572290309
            },
            "question": "which of these two u.s. cities are in the same time zone?",
            "rate_limited": false,
            "answers": [
                "el paso / pierre",
                "bismarck / cheyenne",
                "pensacola / sioux falls"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "el paso / pierre": 0.16830646759605408,
                "pensacola / sioux falls": 0.1740392997076612,
                "bismarck / cheyenne": 0.6800759067258717
            },
            "integer_answers": {
                "el paso / pierre": 2,
                "pensacola / sioux falls": 1,
                "bismarck / cheyenne": 7
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    0.8755678678863037,
                    2.070745595186936,
                    1.0536865369267603
                ],
                "result_count_important_words": [
                    10.0,
                    51.0,
                    7.0
                ],
                "wikipedia_search": [
                    0.043478260869565216,
                    2.3014492753623186,
                    0.6550724637681159
                ],
                "answer_relation_to_question": [
                    1.039598108747045,
                    1.9041765169424743,
                    1.0562253743104808
                ],
                "answer_relation_to_question_bing": [
                    1.0381720430107526,
                    1.9892473118279568,
                    0.9725806451612902
                ],
                "result_count_noun_chunks": [
                    8.0,
                    42.0,
                    11.0
                ],
                "question_answer_similarity": [
                    2.8946413625963032,
                    1.115578924305737,
                    5.419300663750619
                ],
                "result_count_bing": [
                    12500000.0,
                    12000000.0,
                    12500000.0
                ],
                "result_count": [
                    9.0,
                    41.0,
                    11.0
                ],
                "word_count_appended": [
                    3.0,
                    3.0,
                    3.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Until it was banned, lithium was a key ingredient in which of these brands?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "7up"
            ],
            "lines": [
                [
                    0.0625,
                    0.14919354838709678,
                    0.21936787856822487,
                    0.2193690783807063,
                    0.2649350649350649,
                    0.2193765624202847,
                    0.19868191509982555,
                    0.13513513513513514,
                    0.05235602094240838,
                    0.36670574416305757,
                    -1.0
                ],
                [
                    0.75,
                    0.625,
                    -0.05531387488783091,
                    0.7805770887166236,
                    0.2675324675324675,
                    0.7805724197745013,
                    0.8011888608903535,
                    0.8648648648648649,
                    0.9267015706806283,
                    0.5344392812827703,
                    -1.0
                ],
                [
                    0.1875,
                    0.22580645161290322,
                    0.8359459963196061,
                    5.383290267011197e-05,
                    0.4675324675324675,
                    5.101780521401969e-05,
                    0.00012922400982102474,
                    0.0,
                    0.020942408376963352,
                    0.09885497455417211,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "cracker jack": 0.1887620948031804,
                "7up": 0.6275562678854377,
                "good and plenty": 0.18368163731138168
            },
            "question": "until it was banned, lithium was a key ingredient in which of these brands?",
            "rate_limited": false,
            "answers": [
                "cracker jack",
                "7up",
                "good and plenty"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "cracker jack": 0.18947066906304544,
                "7up": 0.6800759067258717,
                "good and plenty": 0.18591099076218698
            },
            "integer_answers": {
                "cracker jack": 0,
                "7up": 8,
                "good and plenty": 2
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.833528720815288,
                    2.6721964064138515,
                    0.4942748727708606
                ],
                "result_count_important_words": [
                    8600.0,
                    30600.0,
                    2.0
                ],
                "wikipedia_search": [
                    0.40540540540540543,
                    2.5945945945945947,
                    0.0
                ],
                "answer_relation_to_question": [
                    0.25,
                    3.0,
                    0.75
                ],
                "answer_relation_to_question_bing": [
                    0.29838709677419356,
                    1.25,
                    0.45161290322580644
                ],
                "result_count_noun_chunks": [
                    12300.0,
                    49600.0,
                    8.0
                ],
                "question_answer_similarity": [
                    4.679841212928295,
                    -1.180027600377798,
                    17.833488434553146
                ],
                "result_count_bing": [
                    20400.0,
                    20600.0,
                    36000.0
                ],
                "result_count": [
                    8150.0,
                    29000.0,
                    2.0
                ],
                "word_count_appended": [
                    10.0,
                    177.0,
                    4.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Aside from blood cells, what would you also find inside your blood vessels?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "marrow"
            ],
            "lines": [
                [
                    0.3880188016851303,
                    0.5224358974358975,
                    0.579677638116903,
                    0.23595505617977527,
                    0.38289601554907676,
                    0.9344667510701151,
                    0.6741262605332228,
                    0.08711650922177237,
                    0.3684210526315789,
                    0.3383582454771268,
                    1.0
                ],
                [
                    0.45498517709471065,
                    0.2510683760683761,
                    0.5845872246652679,
                    0.25842696629213485,
                    0.35276967930029157,
                    0.054560800626997044,
                    0.3052907860201685,
                    0.8813045434098065,
                    0.31983805668016196,
                    0.3447140004508937,
                    1.0
                ],
                [
                    0.15699602122015915,
                    0.22649572649572652,
                    -0.1642648627821709,
                    0.5056179775280899,
                    0.26433430515063167,
                    0.010972448302887804,
                    0.020582953446608647,
                    0.031578947368421054,
                    0.3117408906882591,
                    0.3169277540719795,
                    1.0
                ]
            ],
            "fraction_answers": {
                "marrow": 0.3807545610608809,
                "plasma": 0.4511472227900599,
                "plastids": 0.16809821614905926
            },
            "question": "aside from blood cells, what would you also find inside your blood vessels?",
            "rate_limited": false,
            "answers": [
                "plasma",
                "marrow",
                "plastids"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "marrow": 0.4369969593082462,
                "plasma": 0.2868355282993238,
                "plastids": 0.2059955563633715
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    2.0301494728627607,
                    2.068284002705362,
                    1.901566524431877
                ],
                "result_count_important_words": [
                    3100000.0,
                    181000.0,
                    36400.0
                ],
                "wikipedia_search": [
                    0.4355825461088619,
                    4.406522717049032,
                    0.15789473684210525
                ],
                "answer_relation_to_question": [
                    1.5520752067405212,
                    1.8199407083788426,
                    0.6279840848806366
                ],
                "answer_relation_to_question_bing": [
                    2.0897435897435894,
                    1.0042735042735043,
                    0.905982905982906
                ],
                "result_count_noun_chunks": [
                    488000.0,
                    221000.0,
                    14900.0
                ],
                "question_answer_similarity": [
                    3.247341550886631,
                    3.2748449482023716,
                    -0.9202081970870495
                ],
                "result_count_bing": [
                    3940000.0,
                    3630000.0,
                    2720000.0
                ],
                "word_count_appended": [
                    91.0,
                    79.0,
                    77.0
                ],
                "result_count": [
                    21.0,
                    23.0,
                    45.0
                ]
            },
            "integer_answers": {
                "marrow": 4,
                "plasma": 5,
                "plastids": 1
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which of these Kentucky Derby winners was named for its trainer?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "clyde van dusen"
            ],
            "lines": [
                [
                    0.8471426060083859,
                    0.5648000579542162,
                    -0.07717610215685004,
                    0.54022587029922,
                    0.35205696202531644,
                    0.5342416636787379,
                    0.5399248205946008,
                    0.7333333333333334,
                    0.6,
                    0.40449855864622836,
                    -1.0
                ],
                [
                    0.030406290956749675,
                    0.14285714285714285,
                    0.6356224678306841,
                    0.45872627779718245,
                    0.5755537974683544,
                    0.4069558981713876,
                    0.45791092379542087,
                    0.0,
                    0.368,
                    0.39958404879903975,
                    -1.0
                ],
                [
                    0.12245110303486448,
                    0.292342799188641,
                    0.4415536343261659,
                    0.001047851903597625,
                    0.07238924050632911,
                    0.05880243814987451,
                    0.0021642556099783572,
                    0.26666666666666666,
                    0.032,
                    0.1959173925547319,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "lieut. gibson": 0.14853353819408494,
                "paul jones": 0.3475616847675961,
                "clyde van dusen": 0.5039047770383188
            },
            "question": "which of these kentucky derby winners was named for its trainer?",
            "rate_limited": false,
            "answers": [
                "clyde van dusen",
                "paul jones",
                "lieut. gibson"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "lieut. gibson": 0.14660861583208418,
                "paul jones": 0.3826110874872315,
                "clyde van dusen": 0.6654640323958914
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    2.022492793231142,
                    1.9979202439951986,
                    0.9795869627736595
                ],
                "result_count_important_words": [
                    29800.0,
                    22700.0,
                    3280.0
                ],
                "wikipedia_search": [
                    2.2,
                    0.0,
                    0.8
                ],
                "answer_relation_to_question": [
                    4.235713030041929,
                    0.15203145478374835,
                    0.6122555151743223
                ],
                "answer_relation_to_question_bing": [
                    2.2592002318168647,
                    0.5714285714285714,
                    1.169371196754564
                ],
                "result_count_noun_chunks": [
                    23700.0,
                    20100.0,
                    95.0
                ],
                "question_answer_similarity": [
                    -0.440953366458416,
                    3.6316924430429935,
                    2.5228607831522822
                ],
                "result_count_bing": [
                    356000.0,
                    582000.0,
                    73200.0
                ],
                "result_count": [
                    23200.0,
                    19700.0,
                    45.0
                ],
                "word_count_appended": [
                    75.0,
                    46.0,
                    4.0
                ]
            },
            "integer_answers": {
                "lieut. gibson": 0,
                "paul jones": 2,
                "clyde van dusen": 8
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which of these Hebrew texts does NOT form a significant part of the Christian Old Testament?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "ketuvim"
            ],
            "lines": [
                [
                    0.3662516519098987,
                    0.3114668870132742,
                    0.08249714013652126,
                    0.16244725738396626,
                    0.2938230383973289,
                    0.1656911301215669,
                    0.2611978830515038,
                    0.3473424212550529,
                    0.294151376146789,
                    0.32519426106929966,
                    -1.0
                ],
                [
                    0.35640706249491294,
                    0.31458655784034917,
                    0.5,
                    0.47233942803563056,
                    0.3681135225375626,
                    0.4570013507429086,
                    0.4801858784045437,
                    0.4468275234427879,
                    0.3652522935779816,
                    0.34293040829113486,
                    -1.0
                ],
                [
                    0.2773412855951883,
                    0.37394655514637676,
                    0.4175028598634788,
                    0.3652133145804032,
                    0.3380634390651085,
                    0.3773075191355245,
                    0.2586162385439525,
                    0.2058300553021592,
                    0.3405963302752294,
                    0.33187533063956554,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "talmud": 0.3427414143706026,
                "ketuvim": 0.1792711949264376,
                "torah": 0.47798739070295965
            },
            "question": "which of these hebrew texts does not form a significant part of the christian old testament?",
            "rate_limited": false,
            "answers": [
                "torah",
                "ketuvim",
                "talmud"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "talmud": 0.20118703743149557,
                "ketuvim": 0.6874866009609402,
                "torah": 0.3889320307775609
            },
            "integer_answers": {
                "talmud": 3,
                "ketuvim": 0,
                "torah": 7
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    2.447280345029805,
                    2.1989742839241124,
                    2.3537453710460827
                ],
                "result_count_important_words": [
                    297000.0,
                    38200.0,
                    109000.0
                ],
                "wikipedia_search": [
                    2.1372061024292597,
                    0.7444146718009689,
                    4.118379225769771
                ],
                "answer_relation_to_question": [
                    1.8724768732614179,
                    2.0103011250712184,
                    3.117222001667364
                ],
                "answer_relation_to_question_bing": [
                    2.26239735584071,
                    2.2249613059158104,
                    1.5126413382434793
                ],
                "result_count_noun_chunks": [
                    370000.0,
                    30700.0,
                    374000.0
                ],
                "question_answer_similarity": [
                    2.259939356474206,
                    0.0,
                    0.4465563034755178
                ],
                "result_count_bing": [
                    2470000.0,
                    1580000.0,
                    1940000.0
                ],
                "result_count": [
                    288000.0,
                    23600.0,
                    115000.0
                ],
                "word_count_appended": [
                    359.0,
                    235.0,
                    278.0
                ]
            },
            "negative_question": true
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "What dish is made with ham, poached eggs and Hollandaise sauce?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "eggs benedict"
            ],
            "lines": [
                [
                    0.051948051948051945,
                    0.044642857142857144,
                    0.3073641525418077,
                    0.005409904286308781,
                    0.2576020851433536,
                    0.005484281657036529,
                    0.009350113765642775,
                    0.0,
                    0.18092105263157895,
                    0.2764724819311999,
                    1.0
                ],
                [
                    0.8977272727272728,
                    0.8273809523809524,
                    0.5406156836881585,
                    0.9546889917015495,
                    0.4192006950477845,
                    0.9548526099304672,
                    0.8514647326507395,
                    0.8927489177489177,
                    0.6875,
                    0.4634162942891611,
                    1.0
                ],
                [
                    0.05032467532467533,
                    0.12797619047619047,
                    0.15202016377003377,
                    0.03990110401214168,
                    0.32319721980886185,
                    0.039663108412496324,
                    0.13918515358361774,
                    0.10725108225108224,
                    0.13157894736842105,
                    0.260111223779639,
                    1.0
                ]
            ],
            "fraction_answers": {
                "eggs benedict": 0.7489596150165004,
                "benedict cumberbatch": 0.13712088687871596,
                "pope benedict": 0.11391949810478375
            },
            "question": "what dish is made with ham, poached eggs and hollandaise sauce?",
            "rate_limited": false,
            "answers": [
                "pope benedict",
                "eggs benedict",
                "benedict cumberbatch"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "eggs benedict": 0.61925554794234,
                "benedict cumberbatch": 0.18830646759605404,
                "pope benedict": 0.17211758533290114
            },
            "integer_answers": {
                "eggs benedict": 10,
                "benedict cumberbatch": 0,
                "pope benedict": 0
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.6588348915871993,
                    2.7804977657349665,
                    1.5606673426778341
                ],
                "result_count_important_words": [
                    2240.0,
                    390000.0,
                    16200.0
                ],
                "wikipedia_search": [
                    0.0,
                    5.356493506493507,
                    0.6435064935064935
                ],
                "answer_relation_to_question": [
                    0.3116883116883117,
                    5.386363636363637,
                    0.30194805194805197
                ],
                "answer_relation_to_question_bing": [
                    0.26785714285714285,
                    4.964285714285714,
                    0.7678571428571428
                ],
                "result_count_noun_chunks": [
                    5260.0,
                    479000.0,
                    78300.0
                ],
                "question_answer_similarity": [
                    4.335982605989557,
                    7.626459304417949,
                    2.144546722236555
                ],
                "result_count_bing": [
                    593000.0,
                    965000.0,
                    744000.0
                ],
                "word_count_appended": [
                    55.0,
                    209.0,
                    40.0
                ],
                "result_count": [
                    2210.0,
                    390000.0,
                    16300.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Which of these athletes has a notably obscured glabella?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "michael phelps"
            ],
            "lines": [
                [
                    0.8666666666666667,
                    0.0,
                    0.5023348439272827,
                    0.6129032258064516,
                    0.7346514047866806,
                    0.6086956521739131,
                    0.6190476190476191,
                    0.45,
                    0.42857142857142855,
                    0.40147688356164385,
                    -1.0
                ],
                [
                    0.0,
                    0.5,
                    0.024076729717822265,
                    0.25806451612903225,
                    0.24141519250780438,
                    0.2608695652173913,
                    0.2857142857142857,
                    0.0,
                    0.35714285714285715,
                    0.31194020021074814,
                    -1.0
                ],
                [
                    0.13333333333333333,
                    0.5,
                    0.4735884263548951,
                    0.12903225806451613,
                    0.023933402705515087,
                    0.13043478260869565,
                    0.09523809523809523,
                    0.55,
                    0.21428571428571427,
                    0.286582916227608,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "anthony davis": 0.2536428928818373,
                "michael phelps": 0.5224347724541686,
                "michael strahan": 0.2239223346639941
            },
            "question": "which of these athletes has a notably obscured glabella?",
            "rate_limited": false,
            "answers": [
                "michael phelps",
                "michael strahan",
                "anthony davis"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "anthony davis": 0.3113317071921043,
                "michael phelps": 0.5308681005528857,
                "michael strahan": 0.18065166789587736
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.6059075342465754,
                    1.2477608008429926,
                    1.146331664910432
                ],
                "result_count_important_words": [
                    14.0,
                    6.0,
                    3.0
                ],
                "wikipedia_search": [
                    0.9,
                    0.0,
                    1.1
                ],
                "answer_relation_to_question": [
                    0.8666666666666667,
                    0.0,
                    0.13333333333333333
                ],
                "answer_relation_to_question_bing": [
                    0.0,
                    1.0,
                    1.0
                ],
                "result_count_noun_chunks": [
                    13.0,
                    6.0,
                    2.0
                ],
                "question_answer_similarity": [
                    0.7542836407665163,
                    0.036152545595541596,
                    0.7111192997545004
                ],
                "result_count_bing": [
                    353000.0,
                    116000.0,
                    11500.0
                ],
                "word_count_appended": [
                    6.0,
                    5.0,
                    3.0
                ],
                "result_count": [
                    19.0,
                    8.0,
                    4.0
                ]
            },
            "integer_answers": {
                "anthony davis": 1,
                "michael phelps": 8,
                "michael strahan": 1
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Tom from MySpace shares his name with a key character in what film franchise?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "the matrix"
            ],
            "lines": [
                [
                    0.30963352200034167,
                    0.3391275606312152,
                    0.2408913770840809,
                    0.00017530968268947433,
                    0.37601626016260165,
                    0.3398274174895472,
                    0.7482993197278912,
                    0.23463153875525009,
                    0.25,
                    0.3127044333690141,
                    1.0
                ],
                [
                    0.3678944641707532,
                    0.29788907000430337,
                    0.37857666352058394,
                    0.15684621610834884,
                    0.45121951219512196,
                    0.6333956053731874,
                    0.12489795918367347,
                    0.2946366297569047,
                    0.19607843137254902,
                    0.33437541584903235,
                    1.0
                ],
                [
                    0.32247201382890506,
                    0.36298336936448145,
                    0.38053195939533513,
                    0.8429784742089617,
                    0.17276422764227642,
                    0.026776977137265366,
                    0.12680272108843538,
                    0.4707318314878452,
                    0.553921568627451,
                    0.35292015078195343,
                    1.0
                ]
            ],
            "fraction_answers": {
                "the godfather": 0.32358099675344587,
                "the matrix": 0.361288329356291,
                "harry potter": 0.31513067389026317
            },
            "question": "tom from myspace shares his name with a key character in what film franchise?",
            "rate_limited": false,
            "answers": [
                "harry potter",
                "the godfather",
                "the matrix"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "the godfather": 0.37986221300785034,
                "the matrix": 0.415668989126513,
                "harry potter": 0.16955914509980188
            },
            "integer_answers": {
                "the godfather": 3,
                "the matrix": 6,
                "harry potter": 1
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    2.1889310335830987,
                    2.3406279109432266,
                    2.470441055473674
                ],
                "result_count_important_words": [
                    382000.0,
                    712000.0,
                    30100.0
                ],
                "wikipedia_search": [
                    1.1731576937762505,
                    1.4731831487845235,
                    2.353659157439226
                ],
                "answer_relation_to_question": [
                    1.5481676100017083,
                    1.8394723208537662,
                    1.6123600691445252
                ],
                "answer_relation_to_question_bing": [
                    2.0347653637872916,
                    1.7873344200258203,
                    2.177900216186889
                ],
                "result_count_noun_chunks": [
                    275000.0,
                    45900.0,
                    46600.0
                ],
                "question_answer_similarity": [
                    5.276467658113688,
                    8.292316418141127,
                    8.335145080462098
                ],
                "result_count_bing": [
                    185000.0,
                    222000.0,
                    85000.0
                ],
                "result_count": [
                    94.0,
                    84100.0,
                    452000.0
                ],
                "word_count_appended": [
                    51.0,
                    40.0,
                    113.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "The \u201cCC:\u201d feature in email stands for what?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "carbon copy"
            ],
            "lines": [
                [
                    0.14041954677104443,
                    0.17916666666666667,
                    0.34693977848371177,
                    0.0007185099209639087,
                    0.11016949152542373,
                    0.005923605909988425,
                    0.07841087297438579,
                    0.1873479318734793,
                    0.08536585365853659,
                    0.13923313072830767,
                    1.0
                ],
                [
                    0.37022334496170656,
                    0.4583333333333333,
                    0.33172066386817906,
                    0.3515171613331122,
                    0.4411764705882353,
                    0.26100179296883863,
                    0.8572922111866179,
                    0.25669099756691,
                    0.21951219512195122,
                    0.31180470792633286,
                    1.0
                ],
                [
                    0.489357108267249,
                    0.3625,
                    0.3213395576481092,
                    0.6477643287459238,
                    0.44865403788634095,
                    0.733074601121173,
                    0.06429691583899634,
                    0.5559610705596106,
                    0.6951219512195121,
                    0.5489621613453595,
                    1.0
                ]
            ],
            "fraction_answers": {
                "carbon copy": 0.4867031732632275,
                "copy chain": 0.12736953885125085,
                "copy contacts": 0.38592728788552166
            },
            "question": "the \u201ccc:\u201d feature in email stands for what?",
            "rate_limited": false,
            "answers": [
                "copy chain",
                "copy contacts",
                "carbon copy"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "carbon copy": 0.5240733364721716,
                "copy chain": 0.17823852239844912,
                "copy contacts": 0.2998502181204233
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    0.5569325229132307,
                    1.2472188317053314,
                    2.195848645381438
                ],
                "result_count_important_words": [
                    261.0,
                    11500.0,
                    32300.0
                ],
                "wikipedia_search": [
                    0.5620437956204379,
                    0.7700729927007299,
                    1.667883211678832
                ],
                "answer_relation_to_question": [
                    0.42125864031313326,
                    1.1106700348851197,
                    1.468071324801747
                ],
                "answer_relation_to_question_bing": [
                    0.5375,
                    1.375,
                    1.0875
                ],
                "result_count_noun_chunks": [
                    1500000.0,
                    16400000.0,
                    1230000.0
                ],
                "question_answer_similarity": [
                    5.126299988478422,
                    4.901425955817103,
                    4.748037189245224
                ],
                "result_count_bing": [
                    4420000.0,
                    17700000.0,
                    18000000.0
                ],
                "result_count": [
                    65.0,
                    31800.0,
                    58600.0
                ],
                "word_count_appended": [
                    21.0,
                    54.0,
                    171.0
                ]
            },
            "integer_answers": {
                "carbon copy": 7,
                "copy chain": 1,
                "copy contacts": 2
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which of these foods is cultivated in a paddy?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "rice"
            ],
            "lines": [
                [
                    0.65625,
                    0.0,
                    0.5513478834851779,
                    0.5774132081819774,
                    0.43641322877599725,
                    0.9265749760299082,
                    0.3372395106564529,
                    1.0,
                    0.6414728682170543,
                    0.46684963578496835,
                    -1.0
                ],
                [
                    0.0,
                    0.0,
                    0.44865211651482206,
                    0.4225761467700505,
                    0.08285032390044324,
                    0.07340980486420529,
                    0.6627567923328688,
                    0.0,
                    0.312984496124031,
                    0.44790208717143815,
                    -1.0
                ],
                [
                    0.34375,
                    1.0,
                    0.0,
                    1.0645047972069975e-05,
                    0.48073644732355947,
                    1.5219105886481584e-05,
                    3.6970106783194037e-06,
                    0.0,
                    0.045542635658914726,
                    0.08524827704359361,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "cake": 0.24511317676778588,
                "rice": 0.5593561311131536,
                "dunkaroos": 0.19553069211906043
            },
            "question": "which of these foods is cultivated in a paddy?",
            "rate_limited": false,
            "answers": [
                "rice",
                "cake",
                "dunkaroos"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "cake": 0.3536039696800638,
                "rice": 0.48995229886394875,
                "dunkaroos": 0.2222069666995656
            },
            "integer_answers": {
                "cake": 1,
                "rice": 7,
                "dunkaroos": 2
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.400548907354905,
                    1.3437062615143143,
                    0.2557448311307808
                ],
                "result_count_important_words": [
                    2070000.0,
                    164000.0,
                    34.0
                ],
                "wikipedia_search": [
                    3.0,
                    0.0,
                    0.0
                ],
                "answer_relation_to_question": [
                    1.3125,
                    0.0,
                    0.6875
                ],
                "answer_relation_to_question_bing": [
                    0.0,
                    0.0,
                    1.0
                ],
                "result_count_noun_chunks": [
                    3740000.0,
                    7350000.0,
                    41.0
                ],
                "question_answer_similarity": [
                    2.9255062341690063,
                    2.380592368543148,
                    0.0
                ],
                "result_count_bing": [
                    1280000.0,
                    243000.0,
                    1410000.0
                ],
                "word_count_appended": [
                    662.0,
                    323.0,
                    47.0
                ],
                "result_count": [
                    1790000.0,
                    1310000.0,
                    33.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which of these phrases appears in a Shakespeare play?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "in such a pickle"
            ],
            "lines": [
                [
                    0.834913112164297,
                    0.7715617715617715,
                    0.38083291225711197,
                    0.00010850205402734586,
                    0.22816901408450704,
                    0.027174699550733074,
                    0.0302151973396152,
                    0.813953488372093,
                    0.37735849056603776,
                    0.3847460067867057,
                    -1.0
                ],
                [
                    0.08649289099526067,
                    0.14335664335664336,
                    0.2622285306507105,
                    0.9998881594212333,
                    0.576056338028169,
                    0.9728220845084917,
                    0.969781184073877,
                    0.13953488372093023,
                    0.5849056603773585,
                    0.5525964287526974,
                    -1.0
                ],
                [
                    0.07859399684044234,
                    0.08508158508158509,
                    0.35693855709217753,
                    3.3385247393029493e-06,
                    0.19577464788732393,
                    3.2159407752346834e-06,
                    3.6185865077383474e-06,
                    0.046511627906976744,
                    0.03773584905660377,
                    0.06265756446059689,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "at a loss": 0.5287662803885371,
                "in such a pickle": 0.3849033194736899,
                "up a dark creek": 0.08633040013777284
            },
            "question": "which of these phrases appears in a shakespeare play?",
            "rate_limited": false,
            "answers": [
                "in such a pickle",
                "at a loss",
                "up a dark creek"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "at a loss": 0.2592526253826121,
                "in such a pickle": 0.4727941863905904,
                "up a dark creek": 0.18236501519393916
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.5389840271468227,
                    2.2103857150107897,
                    0.25063025784238757
                ],
                "result_count_important_words": [
                    16900.0,
                    605000.0,
                    2.0
                ],
                "wikipedia_search": [
                    0.813953488372093,
                    0.13953488372093023,
                    0.046511627906976744
                ],
                "answer_relation_to_question": [
                    3.339652448657188,
                    0.3459715639810427,
                    0.31437598736176936
                ],
                "answer_relation_to_question_bing": [
                    2.3146853146853146,
                    0.43006993006993005,
                    0.25524475524475526
                ],
                "result_count_noun_chunks": [
                    16700.0,
                    536000.0,
                    2.0
                ],
                "question_answer_similarity": [
                    13.143948335200548,
                    9.050473706331104,
                    12.31926601473242
                ],
                "result_count_bing": [
                    1620000.0,
                    4090000.0,
                    1390000.0
                ],
                "word_count_appended": [
                    40.0,
                    62.0,
                    4.0
                ],
                "result_count": [
                    65.0,
                    599000.0,
                    2.0
                ]
            },
            "integer_answers": {
                "at a loss": 6,
                "in such a pickle": 4,
                "up a dark creek": 0
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "J.K. Rowling\u2019s first book published in England was titled \u201cHarry Potter and the\u201d what?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "sorcerer's stone"
            ],
            "lines": [
                [
                    0.19150555187891274,
                    0.18195009396037015,
                    0.3477555735945452,
                    0.45479783016959513,
                    0.3451202263083451,
                    0.551332476906196,
                    0.5313172312275171,
                    0.0700354609929078,
                    0.4890829694323144,
                    0.46778278469722384,
                    1.0
                ],
                [
                    0.7145175483239211,
                    0.8041610171507411,
                    0.31221793421594035,
                    0.5451835188152875,
                    0.3592644978783593,
                    0.4486332900315124,
                    0.46860437770558055,
                    0.874113475177305,
                    0.4890829694323144,
                    0.4592063192604225,
                    1.0
                ],
                [
                    0.09397689979716622,
                    0.01388888888888889,
                    0.3400264921895144,
                    1.8651015117365098e-05,
                    0.2956152758132956,
                    3.423306229156119e-05,
                    7.839106690242054e-05,
                    0.05585106382978724,
                    0.021834061135371178,
                    0.07301089604235374,
                    1.0
                ]
            ],
            "fraction_answers": {
                "magician's stone": 0.08943348528406887,
                "philosopher's stone": 0.3630680199167927,
                "sorcerer's stone": 0.5474984947991384
            },
            "question": "j.k. rowling\u2019s first book published in england was titled \u201charry potter and the\u201d what?",
            "rate_limited": false,
            "answers": [
                "philosopher's stone",
                "sorcerer's stone",
                "magician's stone"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "magician's stone": 0.17184300562510132,
                "philosopher's stone": 0.4019809517034805,
                "sorcerer's stone": 0.6654640323958914
            },
            "integer_answers": {
                "magician's stone": 0,
                "philosopher's stone": 5,
                "sorcerer's stone": 5
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    3.7422622775777907,
                    3.67365055408338,
                    0.5840871683388299
                ],
                "result_count_important_words": [
                    306000.0,
                    249000.0,
                    19.0
                ],
                "wikipedia_search": [
                    0.42021276595744683,
                    5.24468085106383,
                    0.3351063829787234
                ],
                "answer_relation_to_question": [
                    1.532044415031302,
                    5.716140386591369,
                    0.7518151983773298
                ],
                "answer_relation_to_question_bing": [
                    1.0917005637622208,
                    4.824966102904446,
                    0.08333333333333333
                ],
                "result_count_noun_chunks": [
                    305000.0,
                    269000.0,
                    45.0
                ],
                "question_answer_similarity": [
                    11.789356105029583,
                    10.58458494511433,
                    11.527330418117344
                ],
                "result_count_bing": [
                    244000.0,
                    254000.0,
                    209000.0
                ],
                "result_count": [
                    317000.0,
                    380000.0,
                    13.0
                ],
                "word_count_appended": [
                    112.0,
                    112.0,
                    5.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which former NFL star does NOT have a football video game named after him?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "emmitt smith"
            ],
            "lines": [
                [
                    0.3156138534364744,
                    0.32280563928251027,
                    0.3717581617080084,
                    0.4022875816993464,
                    0.4743485342019544,
                    0.4584894498126602,
                    0.40134146341463417,
                    0.414966373785995,
                    0.3574938574938575,
                    0.3270695925242316,
                    -1.0
                ],
                [
                    0.3658201044280657,
                    0.3496404459816742,
                    0.32728874703125244,
                    0.2506535947712418,
                    0.46742671009771986,
                    0.17560638927233285,
                    0.15609756097560978,
                    0.2899205822012069,
                    0.3316953316953317,
                    0.3349235864771686,
                    -1.0
                ],
                [
                    0.3185660421354599,
                    0.3275539147358155,
                    0.3009530912607392,
                    0.34705882352941175,
                    0.05822475570032576,
                    0.3659041609150069,
                    0.4425609756097561,
                    0.2951130440127982,
                    0.3108108108108108,
                    0.3380068209985998,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "kurt warner": 0.3790495120582552,
                "brett favre": 0.3901853894136792,
                "emmitt smith": 0.23076509852806554
            },
            "question": "which former nfl star does not have a football video game named after him?",
            "rate_limited": false,
            "answers": [
                "emmitt smith",
                "brett favre",
                "kurt warner"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "kurt warner": 0.23686111344279126,
                "brett favre": 0.22274698067326112,
                "emmitt smith": 0.4870931975841423
            },
            "negative_question": true,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    2.075164889709221,
                    1.9809169622739768,
                    1.943918148016802
                ],
                "result_count_important_words": [
                    42100.0,
                    329000.0,
                    136000.0
                ],
                "wikipedia_search": [
                    1.020403514568061,
                    2.5209530135855176,
                    2.458643471846422
                ],
                "answer_relation_to_question": [
                    2.212633758762307,
                    1.6101587468632115,
                    2.177207494374481
                ],
                "answer_relation_to_question_bing": [
                    2.1263323286098768,
                    1.8043146482199095,
                    2.0693530231702137
                ],
                "result_count_noun_chunks": [
                    80900.0,
                    282000.0,
                    47100.0
                ],
                "question_answer_similarity": [
                    1.8515626415610313,
                    2.4936144711682573,
                    2.8738501026527956
                ],
                "result_count_bing": [
                    1260000.0,
                    1600000.0,
                    21700000.0
                ],
                "word_count_appended": [
                    116.0,
                    137.0,
                    154.0
                ],
                "result_count": [
                    29900.0,
                    76300.0,
                    46800.0
                ]
            },
            "integer_answers": {
                "kurt warner": 3,
                "brett favre": 4,
                "emmitt smith": 3
            }
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "How do you spell the last name of Duke University\u2019s men's basketball coach?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "krzyzewski"
            ],
            "lines": [
                [
                    0.3453817642900457,
                    0.46975114999762885,
                    0,
                    0.0001408252358822701,
                    0.29933899905571293,
                    0.0,
                    0.00015226107699335125,
                    0.0,
                    0.059748427672955975,
                    0.07709948223082082,
                    5.0
                ],
                [
                    0.31204843095671236,
                    0.4377488500023712,
                    0,
                    0.9998591747641177,
                    0.3947119924457035,
                    1.0,
                    0.9998477389230066,
                    1.0,
                    0.889937106918239,
                    0.8581695637527827,
                    5.0
                ],
                [
                    0.3425698047532419,
                    0.0925,
                    0,
                    0.0,
                    0.3059490084985836,
                    0.0,
                    0.0,
                    0.0,
                    0.050314465408805034,
                    0.06473095401639656,
                    5.0
                ]
            ],
            "fraction_answers": {
                "khzyrweski": 0.09511824807522522,
                "crzyzewski": 0.13906810106222667,
                "krzyzewski": 0.765813650862548
            },
            "question": "how do you spell the last name of duke university\u2019s men's basketball coach?",
            "rate_limited": false,
            "answers": [
                "crzyzewski",
                "krzyzewski",
                "khzyrweski"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "khzyrweski": 0.18026648472415657,
                "crzyzewski": 0.2085904161260342,
                "krzyzewski": 0.6354254300557068
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 5
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    0.4625968933849249,
                    5.149017382516696,
                    0.38838572409837935
                ],
                "result_count_important_words": [
                    0,
                    24100.0,
                    0
                ],
                "wikipedia_search": [
                    0.0,
                    5.0,
                    0.0
                ],
                "answer_relation_to_question": [
                    2.0722905857402742,
                    1.8722905857402743,
                    2.0554188285194512
                ],
                "answer_relation_to_question_bing": [
                    2.8185068999857728,
                    2.6264931000142266,
                    0.5549999999999999
                ],
                "result_count_noun_chunks": [
                    3.0,
                    19700.0,
                    0
                ],
                "question_answer_similarity": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_bing": [
                    317000.0,
                    418000.0,
                    324000.0
                ],
                "result_count": [
                    3.0,
                    21300.0,
                    0
                ],
                "word_count_appended": [
                    19.0,
                    283.0,
                    16.0
                ]
            },
            "integer_answers": {
                "khzyrweski": 0,
                "crzyzewski": 2,
                "krzyzewski": 7
            }
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Which of these consists of frozen water?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "snowflake"
            ],
            "lines": [
                [
                    0.6428571428571429,
                    0.0,
                    0.1960033110082587,
                    0.6114908553482358,
                    0.36774193548387096,
                    0.5328336320677856,
                    0.732526197985553,
                    0.6818181818181819,
                    0.5086107921928817,
                    0.4046361594798589,
                    -1.0
                ],
                [
                    0.07142857142857144,
                    1.0,
                    0.7430981882193818,
                    0.011638647699981526,
                    0.25513196480938416,
                    0.018249959263483786,
                    0.020246210194322923,
                    0.0,
                    0.04707233065442021,
                    0.2518667122754013,
                    -1.0
                ],
                [
                    0.28571428571428575,
                    0.0,
                    0.06089850077235948,
                    0.37687049695178276,
                    0.3771260997067449,
                    0.44891640866873067,
                    0.24722759182012413,
                    0.3181818181818182,
                    0.4443168771526981,
                    0.3434971282447397,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "garden rake": 0.24187325845449478,
                "snowflake": 0.4678518208241769,
                "drake": 0.2902749207213284
            },
            "question": "which of these consists of frozen water?",
            "rate_limited": false,
            "answers": [
                "snowflake",
                "garden rake",
                "drake"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "garden rake": 0.19059525444501985,
                "snowflake": 0.6693866989681225,
                "drake": 0.19230563015428742
            },
            "integer_answers": {
                "garden rake": 2,
                "snowflake": 7,
                "drake": 1
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.2139084784395768,
                    0.755600136826204,
                    1.0304913847342192
                ],
                "result_count_important_words": [
                    654000.0,
                    22400.0,
                    551000.0
                ],
                "wikipedia_search": [
                    1.3636363636363638,
                    0.0,
                    0.6363636363636364
                ],
                "answer_relation_to_question": [
                    1.2857142857142856,
                    0.14285714285714285,
                    0.5714285714285714
                ],
                "answer_relation_to_question_bing": [
                    0.0,
                    1.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    720000.0,
                    19900.0,
                    243000.0
                ],
                "question_answer_similarity": [
                    0.7907843180000782,
                    2.9980636090040207,
                    0.24569778516888618
                ],
                "result_count_bing": [
                    6270000.0,
                    4350000.0,
                    6430000.0
                ],
                "result_count": [
                    6620000.0,
                    126000.0,
                    4080000.0
                ],
                "word_count_appended": [
                    443.0,
                    41.0,
                    387.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which country did NOT have a native player selected in the first round of the 2016 NBA draft?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "haiti"
            ],
            "lines": [
                [
                    0.39855840143563936,
                    0.32161781064078243,
                    0.4334543957104662,
                    0.0008075172515049078,
                    0.33333333333333337,
                    0.4875317478642346,
                    0.37989323843416367,
                    0.3753654432396138,
                    0.322680412371134,
                    0.329482695895294,
                    -1.0
                ],
                [
                    0.29189579956843387,
                    0.3471910669860655,
                    0.38675200249967023,
                    0.49955464200068517,
                    0.33333333333333337,
                    0.043985222812283564,
                    0.33540925266903915,
                    0.2638855120163557,
                    0.33402061855670107,
                    0.3255115942230231,
                    -1.0
                ],
                [
                    0.3095457989959269,
                    0.331191122373152,
                    0.1797936017898636,
                    0.4996378407478099,
                    0.33333333333333337,
                    0.46848302932348185,
                    0.2846975088967971,
                    0.36074904474403063,
                    0.34329896907216495,
                    0.34500570988168283,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "bahamas": 0.3676921910668819,
                "brazil": 0.30885280816835137,
                "haiti": 0.3234550007647667
            },
            "question": "which country did not have a native player selected in the first round of the 2016 nba draft?",
            "rate_limited": false,
            "answers": [
                "haiti",
                "bahamas",
                "brazil"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "bahamas": 0.32934699816242863,
                "brazil": 0.49543571864651936,
                "haiti": 0.521844858405
            },
            "negative_question": true,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    2.7282768656752956,
                    2.7918144924316297,
                    2.4799086418930747
                ],
                "result_count_important_words": [
                    108000.0,
                    3950000.0,
                    273000.0
                ],
                "wikipedia_search": [
                    1.9941529081661797,
                    3.77783180773831,
                    2.2280152840955103
                ],
                "answer_relation_to_question": [
                    1.2172991827723285,
                    2.497250405178794,
                    2.2854504120488777
                ],
                "answer_relation_to_question_bing": [
                    2.497350651029046,
                    2.139325062195083,
                    2.363324286775872
                ],
                "result_count_noun_chunks": [
                    135000.0,
                    185000.0,
                    242000.0
                ],
                "question_answer_similarity": [
                    0.46972580114379525,
                    0.7993842256255448,
                    2.260242559015751
                ],
                "result_count_bing": [
                    505000.0,
                    505000.0,
                    505000.0
                ],
                "result_count": [
                    102000.0,
                    91.0,
                    74.0
                ],
                "word_count_appended": [
                    172.0,
                    161.0,
                    152.0
                ]
            },
            "integer_answers": {
                "bahamas": 4,
                "brazil": 2,
                "haiti": 4
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "What word describes joining a cause just to feel good about it?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "slacktivism"
            ],
            "lines": [
                [
                    0.2679163866705505,
                    0.09027777777777778,
                    0.0,
                    0.0033213133421901688,
                    0.3240332843857073,
                    0.0031144331731624846,
                    0.0008636788048552754,
                    0.08739837398373984,
                    0.0911062906724512,
                    0.19102723796191404,
                    1.0
                ],
                [
                    0.25670332332557516,
                    0.46388888888888885,
                    1.415706857435261,
                    0.00028468400075915733,
                    0.3392070484581498,
                    0.00026695141484249865,
                    7.002801120448179e-05,
                    0.2516759378120097,
                    0.04772234273318872,
                    0.08721450297976986,
                    1.0
                ],
                [
                    0.4753802900038742,
                    0.4458333333333333,
                    -0.415706857435261,
                    0.9963940026570507,
                    0.3367596671561429,
                    0.996618615411995,
                    0.9990662931839402,
                    0.6609256882042505,
                    0.8611713665943601,
                    0.721758259058316,
                    1.0
                ]
            ],
            "fraction_answers": {
                "slacktivism": 0.6078200658168003,
                "gung-faux": 0.28627405650596494,
                "joinerism": 0.10590587767723485
            },
            "question": "what word describes joining a cause just to feel good about it?",
            "rate_limited": false,
            "answers": [
                "joinerism",
                "gung-faux",
                "slacktivism"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "slacktivism": 0.6212557398191543,
                "gung-faux": 0.18061256259392258,
                "joinerism": 0.1868081320557263
            },
            "integer_answers": {
                "slacktivism": 7,
                "gung-faux": 3,
                "joinerism": 0
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.1461634277714843,
                    0.5232870178786192,
                    4.330549554349896
                ],
                "result_count_important_words": [
                    35.0,
                    3.0,
                    11200.0
                ],
                "wikipedia_search": [
                    0.524390243902439,
                    1.5100556268720582,
                    3.9655541292255028
                ],
                "answer_relation_to_question": [
                    1.607498320023303,
                    1.5402199399534509,
                    2.8522817400232454
                ],
                "answer_relation_to_question_bing": [
                    0.5416666666666666,
                    2.783333333333333,
                    2.675
                ],
                "result_count_noun_chunks": [
                    37.0,
                    3.0,
                    42800.0
                ],
                "question_answer_similarity": [
                    0.0,
                    4.151298344368115,
                    -1.2189834215678275
                ],
                "result_count_bing": [
                    662000.0,
                    693000.0,
                    688000.0
                ],
                "result_count": [
                    35.0,
                    3.0,
                    10500.0
                ],
                "word_count_appended": [
                    42.0,
                    22.0,
                    397.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "One of Apple\u2019s biggest flops was a product named after a man who did what?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "invented the transistor"
            ],
            "lines": [
                [
                    0.3279819139194139,
                    0.5711111111111111,
                    0.2589584497031569,
                    0.26865671641791045,
                    0.3338203067932798,
                    0.3882978723404255,
                    0.37435897435897436,
                    0.3467086834733893,
                    0.3157894736842105,
                    0.23612159095665872,
                    1.0
                ],
                [
                    0.5073975503663004,
                    0.1911111111111111,
                    0.500655128221995,
                    0.5074626865671642,
                    0.3316289262235208,
                    0.35106382978723405,
                    0.3487179487179487,
                    0.2574229691876751,
                    0.47368421052631576,
                    0.5034408498225044,
                    1.0
                ],
                [
                    0.1646205357142857,
                    0.23777777777777778,
                    0.2403864220748481,
                    0.22388059701492538,
                    0.3345507669831994,
                    0.26063829787234044,
                    0.27692307692307694,
                    0.39586834733893556,
                    0.21052631578947367,
                    0.26043755922083694,
                    1.0
                ]
            ],
            "fraction_answers": {
                "invented the transistor": 0.39725852105317694,
                "developed calculus": 0.26056096967097,
                "discovered saturn": 0.3421805092758531
            },
            "question": "one of apple\u2019s biggest flops was a product named after a man who did what?",
            "rate_limited": false,
            "answers": [
                "discovered saturn",
                "invented the transistor",
                "developed calculus"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "invented the transistor": 0.594648287837729,
                "developed calculus": 0.1299043376296558,
                "discovered saturn": 0.1310467823430267
            },
            "integer_answers": {
                "invented the transistor": 5,
                "developed calculus": 2,
                "discovered saturn": 3
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.4167295457399522,
                    3.0206450989350264,
                    1.5626253553250216
                ],
                "result_count_important_words": [
                    73.0,
                    66.0,
                    49.0
                ],
                "wikipedia_search": [
                    1.040126050420168,
                    0.7722689075630252,
                    1.1876050420168067
                ],
                "answer_relation_to_question": [
                    1.3119276556776556,
                    2.0295902014652016,
                    0.6584821428571428
                ],
                "answer_relation_to_question_bing": [
                    1.7133333333333334,
                    0.5733333333333333,
                    0.7133333333333334
                ],
                "result_count_noun_chunks": [
                    73.0,
                    68.0,
                    54.0
                ],
                "question_answer_similarity": [
                    6.830728069879115,
                    13.2061303332448,
                    6.340840713120997
                ],
                "result_count_bing": [
                    457000.0,
                    454000.0,
                    458000.0
                ],
                "word_count_appended": [
                    6.0,
                    9.0,
                    4.0
                ],
                "result_count": [
                    36.0,
                    68.0,
                    30.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "How many of the three Baltic countries border Russia?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "none"
            ],
            "lines": [
                [
                    0.38596491228070173,
                    0.3426573426573427,
                    0.35343114781032764,
                    0.4382790510655408,
                    0.05659397715472482,
                    0.3668188736681887,
                    0.4480696030451332,
                    0.02857142857142857,
                    0.46596858638743455,
                    0.3519157482721736,
                    5.0
                ],
                [
                    0.3157894736842105,
                    0.3286713286713287,
                    0.3613009743884807,
                    0.45302238305857123,
                    0.5347871235721703,
                    0.4687975646879756,
                    0.42033713974986403,
                    0.2357142857142857,
                    0.2293193717277487,
                    0.33670884381732075,
                    5.0
                ],
                [
                    0.2982456140350877,
                    0.3286713286713287,
                    0.28526787780119167,
                    0.10869856587588796,
                    0.4086188992731049,
                    0.1643835616438356,
                    0.13159325720500273,
                    0.7357142857142858,
                    0.30471204188481676,
                    0.31137540791050566,
                    5.0
                ]
            ],
            "fraction_answers": {
                "none": 0.30772808400150475,
                "three": 0.3238270670912996,
                "two": 0.3684448489071957
            },
            "question": "how many of the three baltic countries border russia?",
            "rate_limited": false,
            "answers": [
                "three",
                "two",
                "none"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "none": 0.3931173256449866,
                "three": 0.2998502181204233,
                "two": 0.2810413275686546
            },
            "integer_answers": {
                "none": 1,
                "three": 5,
                "two": 4
            },
            "categorical_data": {
                "question_type": 5
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.4076629930886944,
                    1.346835375269283,
                    1.2455016316420227
                ],
                "result_count_important_words": [
                    2410000.0,
                    3080000.0,
                    1080000.0
                ],
                "wikipedia_search": [
                    0.05714285714285714,
                    0.4714285714285714,
                    1.4714285714285715
                ],
                "answer_relation_to_question": [
                    0.38596491228070173,
                    0.3157894736842105,
                    0.2982456140350877
                ],
                "answer_relation_to_question_bing": [
                    0.6853146853146853,
                    0.6573426573426573,
                    0.6573426573426573
                ],
                "result_count_noun_chunks": [
                    8240000.0,
                    7730000.0,
                    2420000.0
                ],
                "question_answer_similarity": [
                    3.8972064778208733,
                    3.983985301107168,
                    3.1455852948129177
                ],
                "result_count_bing": [
                    109000.0,
                    1030000.0,
                    787000.0
                ],
                "result_count": [
                    3270000.0,
                    3380000.0,
                    811000.0
                ],
                "word_count_appended": [
                    445.0,
                    219.0,
                    291.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Though perhaps more famous as butter, which of these is a location in Florida?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "tillamook"
            ],
            "question": "though perhaps more famous as butter, which of these is a location in florida?",
            "answers": [
                "tillamook",
                "kerrygold",
                "land o\u2019 lakes"
            ],
            "integer_answers": {
                "tillamook": 5,
                "kerrygold": 2,
                "land o\u2019 lakes": 3
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.5236131566997848,
                    1.2218252237572023,
                    1.2545616195430127
                ],
                "result_count_important_words": [
                    878000.0,
                    781000.0,
                    65.0
                ],
                "wikipedia_search": [
                    0.38461538461538464,
                    1.0,
                    0.6153846153846154
                ],
                "answer_relation_to_question": [
                    0.7864923747276689,
                    1.299719887955182,
                    1.913787737317149
                ],
                "answer_relation_to_question_bing": [
                    0.3942857142857143,
                    0.8285714285714285,
                    1.7771428571428571
                ],
                "result_count_noun_chunks": [
                    127000.0,
                    1010000.0,
                    317000.0
                ],
                "question_answer_similarity": [
                    -1.7059812098741531,
                    0.0,
                    8.430969320237637
                ],
                "result_count_bing": [
                    2250000.0,
                    2150000.0,
                    29500.0
                ],
                "result_count": [
                    2600.0,
                    71.0,
                    66.0
                ],
                "word_count_appended": [
                    200.0,
                    128.0,
                    0.0
                ]
            },
            "negative_question": false,
            "fraction_answers": {
                "tillamook": 0.3331802994961027,
                "kerrygold": 0.34735261306950554,
                "land o\u2019 lakes": 0.3194670874343918
            },
            "lines": [
                [
                    0.19662309368191722,
                    0.13142857142857142,
                    -0.2536779518234636,
                    0.9499451954694922,
                    0.5079580088046055,
                    0.5292137438858634,
                    0.0873452544704264,
                    0.19230769230769232,
                    0.6097560975609756,
                    0.38090328917494626,
                    -1.0
                ],
                [
                    0.3249299719887955,
                    0.27619047619047615,
                    0.0,
                    0.025940811107051515,
                    0.4853820973021786,
                    0.4707470774201131,
                    0.6946354883081155,
                    0.5,
                    0.3902439024390244,
                    0.3054563059393006,
                    -1.0
                ],
                [
                    0.47844693432928725,
                    0.5923809523809523,
                    1.2536779518234635,
                    0.02411399342345634,
                    0.006659893893215939,
                    3.9178694023440914e-05,
                    0.21801925722145804,
                    0.3076923076923077,
                    0.0,
                    0.31364040488575323,
                    -1.0
                ]
            ],
            "rate_limited": false,
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "tillamook": 0.4865959614200733,
                "kerrygold": 0.23300873140631675,
                "land o\u2019 lakes": 0.33658703388823596
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which of these sharks is NOT a Lamniforme?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "goblin shark"
            ],
            "lines": [
                [
                    0.32905505952380953,
                    0.3411214953271028,
                    0.39621993430121516,
                    0.47115976927815423,
                    0.48081593006313744,
                    0.4828373277148626,
                    0.4435368928845521,
                    0.4612794612794613,
                    0.2887139107611548,
                    0.3283246875871624,
                    -1.0
                ],
                [
                    0.27771577380952384,
                    0.37850467289719625,
                    0.1984494618644107,
                    0.05199641597132776,
                    0.08839242350655657,
                    0.08344306908963217,
                    0.10311369367393924,
                    0.14814814814814814,
                    0.2992125984251969,
                    0.3377873786585338,
                    -1.0
                ],
                [
                    0.39322916666666663,
                    0.28037383177570097,
                    0.40533060383437414,
                    0.476843814750518,
                    0.430791646430306,
                    0.43371960319550523,
                    0.4533494134415086,
                    0.39057239057239057,
                    0.4120734908136483,
                    0.3338879337543038,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "goblin shark": 0.19538710625587755,
                "great white shark": 0.606647272791107,
                "hammerhead shark": 0.19796562095301556
            },
            "question": "which of these sharks is not a lamniforme?",
            "rate_limited": false,
            "answers": [
                "goblin shark",
                "great white shark",
                "hammerhead shark"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "goblin shark": 0.49843511313009786,
                "great white shark": 0.1688642384833969,
                "hammerhead shark": 0.4502546640416833
            },
            "negative_question": true,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    0.6867012496513505,
                    0.6488504853658648,
                    0.6644482649827848
                ],
                "result_count_important_words": [
                    39100.0,
                    949000.0,
                    151000.0
                ],
                "wikipedia_search": [
                    0.07744107744107744,
                    0.7037037037037037,
                    0.21885521885521886
                ],
                "answer_relation_to_question": [
                    0.6837797619047619,
                    0.8891369047619047,
                    0.4270833333333333
                ],
                "answer_relation_to_question_bing": [
                    0.3177570093457944,
                    0.24299065420560748,
                    0.4392523364485981
                ],
                "result_count_noun_chunks": [
                    103000.0,
                    724000.0,
                    85100.0
                ],
                "question_answer_similarity": [
                    2.786467866972089,
                    8.096553795039654,
                    2.5418487512506545
                ],
                "result_count_bing": [
                    158000.0,
                    3390000.0,
                    570000.0
                ],
                "word_count_appended": [
                    161.0,
                    153.0,
                    67.0
                ],
                "result_count": [
                    103000.0,
                    1600000.0,
                    82700.0
                ]
            },
            "integer_answers": {
                "goblin shark": 2,
                "great white shark": 7,
                "hammerhead shark": 1
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which Oscar-winning actress has NOT won the award for playing a real person?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "hilary swank"
            ],
            "lines": [
                [
                    0.3646559455382985,
                    0.2780276633935171,
                    0.2218545548243634,
                    0.3562231759656652,
                    0.42922564529558704,
                    0.35685483870967744,
                    0.3472727272727273,
                    0.15571548907652633,
                    0.3116883116883117,
                    0.3569262456844387,
                    -1.0
                ],
                [
                    0.3395273072846602,
                    0.3316439657903073,
                    0.50371470938339,
                    0.33476394849785407,
                    0.1315570358034971,
                    0.31854838709677424,
                    0.32545454545454544,
                    0.3973421303873431,
                    0.34632034632034636,
                    0.3328890272747137,
                    -1.0
                ],
                [
                    0.2958167471770413,
                    0.3903283708161757,
                    0.27443073579224664,
                    0.3090128755364807,
                    0.4392173189009159,
                    0.32459677419354843,
                    0.32727272727272727,
                    0.44694238053613056,
                    0.34199134199134196,
                    0.31018472704084765,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "hilary swank": 0.3080412001485088,
                "emma thompson": 0.36431108051017747,
                "susan sarandon": 0.3276477193413137
            },
            "question": "which oscar-winning actress has not won the award for playing a real person?",
            "rate_limited": false,
            "answers": [
                "emma thompson",
                "susan sarandon",
                "hilary swank"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "hilary swank": 0.5055764265678385,
                "emma thompson": 0.1715909012319304,
                "susan sarandon": 0.40439208698053436
            },
            "negative_question": true,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    2.2891800690489807,
                    2.6737755636045812,
                    3.037044367346437
                ],
                "result_count_important_words": [
                    71.0,
                    90.0,
                    87.0
                ],
                "wikipedia_search": [
                    5.508552174775579,
                    1.6425259138025097,
                    0.8489219114219113
                ],
                "answer_relation_to_question": [
                    2.1655048713872245,
                    2.5675630834454366,
                    3.2669320451673394
                ],
                "answer_relation_to_question_bing": [
                    3.1076127124907615,
                    2.3569844789356984,
                    1.5354028085735403
                ],
                "result_count_noun_chunks": [
                    84.0,
                    96.0,
                    95.0
                ],
                "question_answer_similarity": [
                    2.248649863333412,
                    -0.03003134112805128,
                    1.823600939475
                ],
                "result_count_bing": [
                    1020000.0,
                    5310000.0,
                    876000.0
                ],
                "result_count": [
                    67.0,
                    77.0,
                    89.0
                ],
                "word_count_appended": [
                    87.0,
                    71.0,
                    73.0
                ]
            },
            "integer_answers": {
                "hilary swank": 3,
                "emma thompson": 4,
                "susan sarandon": 3
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "According to Alexa, which of these is NOT one the top five most popular sports sites?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "deadspin"
            ],
            "lines": [
                [
                    0.2646123872026251,
                    0.23786407766990292,
                    0.21925303677174135,
                    0.3292682926829268,
                    0.33281637717121587,
                    0.26515151515151514,
                    0.4781810766721044,
                    0.29144171779141104,
                    0.4403846153846154,
                    0.3268110494016842,
                    -1.0
                ],
                [
                    0.31261108832376266,
                    0.28317152103559873,
                    0.22396468380442386,
                    0.3130081300813008,
                    0.33281637717121587,
                    0.398989898989899,
                    0.16863784665579118,
                    0.37903374233128834,
                    0.3634615384615385,
                    0.3200409427240916,
                    -1.0
                ],
                [
                    0.42277652447361225,
                    0.47896440129449835,
                    0.5567822794238347,
                    0.35772357723577236,
                    0.33436724565756826,
                    0.33585858585858586,
                    0.3531810766721044,
                    0.3295245398773006,
                    0.19615384615384618,
                    0.3531480078742241,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "deadspin": 0.25630398309573055,
                "sports illustrated": 0.3808528460842179,
                "yahoo sports": 0.3628431708200515
            },
            "question": "according to alexa, which of these is not one the top five most popular sports sites?",
            "rate_limited": false,
            "answers": [
                "yahoo sports",
                "sports illustrated",
                "deadspin"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "deadspin": 0.6085745625278339,
                "sports illustrated": 0.22630535152377818,
                "yahoo sports": 0.15640316880968896
            },
            "integer_answers": {
                "deadspin": 1,
                "sports illustrated": 3,
                "yahoo sports": 6
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.731889505983158,
                    1.7995905727590837,
                    1.4685199212577587
                ],
                "result_count_important_words": [
                    93.0,
                    40.0,
                    65.0
                ],
                "wikipedia_search": [
                    2.0855828220858896,
                    1.2096625766871165,
                    1.7047546012269938
                ],
                "answer_relation_to_question": [
                    1.8831009023789993,
                    1.4991112934098987,
                    0.617787804211102
                ],
                "answer_relation_to_question_bing": [
                    0.5242718446601942,
                    0.4336569579288026,
                    0.042071197411003236
                ],
                "result_count_noun_chunks": [
                    42800.0,
                    650000.0,
                    288000.0
                ],
                "question_answer_similarity": [
                    9.299221996872802,
                    9.143157435304602,
                    -1.8808075990527868
                ],
                "result_count_bing": [
                    53900000.0,
                    53900000.0,
                    53400000.0
                ],
                "result_count": [
                    84.0,
                    92.0,
                    70.0
                ],
                "word_count_appended": [
                    31.0,
                    71.0,
                    158.0
                ]
            },
            "negative_question": true
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "The best-selling book \u201cThe Chocolate War\u201d is about what?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "the rise of hershey's"
            ],
            "lines": [
                [
                    0.24277688603531306,
                    0.13748241912798873,
                    0.24969023030179077,
                    0.0,
                    0.733464309102816,
                    0.0006623697551779482,
                    0.0004692020957693611,
                    0.061224489795918366,
                    0.12,
                    0.12784885287179457,
                    1.0
                ],
                [
                    0.1699055297562888,
                    0.16778544943101906,
                    0.1743281322598069,
                    1.0,
                    0.14931237721021612,
                    0.9986497847298296,
                    0.9983577926648073,
                    0.2571428571428571,
                    0.76,
                    0.7666011685568523,
                    1.0
                ],
                [
                    0.5873175842083981,
                    0.6947321314409921,
                    0.5759816374384024,
                    0.0,
                    0.11722331368696791,
                    0.0006878455149924846,
                    0.0011730052394234027,
                    0.6816326530612244,
                    0.12,
                    0.10554997857135309,
                    1.0
                ]
            ],
            "fraction_answers": {
                "high school conformity": 0.16736187590865687,
                "the rise of hershey's": 0.2884298149161754,
                "sugar addiction": 0.5442083091751677
            },
            "question": "the best-selling book \u201cthe chocolate war\u201d is about what?",
            "rate_limited": false,
            "answers": [
                "high school conformity",
                "sugar addiction",
                "the rise of hershey's"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "high school conformity": 0.18243782457465144,
                "the rise of hershey's": 0.4727941863905904,
                "sugar addiction": 0.2326690336830119
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    0.6392442643589729,
                    3.8330058427842615,
                    0.5277498928567654
                ],
                "result_count_important_words": [
                    26.0,
                    39200.0,
                    27.0
                ],
                "wikipedia_search": [
                    0.30612244897959184,
                    1.2857142857142856,
                    3.4081632653061225
                ],
                "answer_relation_to_question": [
                    1.2138844301765652,
                    0.849527648781444,
                    2.9365879210419905
                ],
                "answer_relation_to_question_bing": [
                    0.4124472573839662,
                    0.5033563482930572,
                    2.0841963943229764
                ],
                "result_count_noun_chunks": [
                    18.0,
                    38300.0,
                    45.0
                ],
                "question_answer_similarity": [
                    9.118160897865891,
                    6.366095930337906,
                    21.03363530896604
                ],
                "result_count_bing": [
                    2240000.0,
                    456000.0,
                    358000.0
                ],
                "result_count": [
                    0,
                    86.0,
                    0
                ],
                "word_count_appended": [
                    3.0,
                    19.0,
                    3.0
                ]
            },
            "integer_answers": {
                "high school conformity": 1,
                "the rise of hershey's": 4,
                "sugar addiction": 5
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which of these celebrities has NOT been a ProActiv spokesperson?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "katy perry"
            ],
            "lines": [
                [
                    0.28260869565217395,
                    0,
                    0.334347103790002,
                    0.49957841483979765,
                    0.38707334785766156,
                    0.44337757695566227,
                    0.4561938958707361,
                    0.4431818181818182,
                    0.3211206896551724,
                    0.3046054520469156,
                    -1.0
                ],
                [
                    0.4782608695652174,
                    0,
                    0.27968802117338293,
                    0.4059865092748735,
                    0.3416848220769789,
                    0.2105337475289466,
                    0.07091561938958707,
                    0.23958333333333331,
                    0.28663793103448276,
                    0.3505256236262396,
                    -1.0
                ],
                [
                    0.2391304347826087,
                    0,
                    0.3859648750366151,
                    0.09443507588532885,
                    0.2712418300653595,
                    0.34608867551539113,
                    0.4728904847396768,
                    0.3172348484848485,
                    0.39224137931034486,
                    0.3448689243268448,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "selena gomez": 0.3635341048562182,
                "katy perry": 0.22842511225556889,
                "lindsay lohan": 0.4080407828882128
            },
            "question": "which of these celebrities has not been a proactiv spokesperson?",
            "rate_limited": false,
            "answers": [
                "katy perry",
                "lindsay lohan",
                "selena gomez"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "selena gomez": 0.28893158140911246,
                "katy perry": 0.5055600876618999,
                "lindsay lohan": 0.22440559125205273
            },
            "integer_answers": {
                "selena gomez": 3,
                "katy perry": 1,
                "lindsay lohan": 5
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.1723672877185065,
                    0.8968462582425621,
                    0.9307864540389313
                ],
                "result_count_important_words": [
                    40100.0,
                    205000.0,
                    109000.0
                ],
                "wikipedia_search": [
                    0.34090909090909094,
                    1.5625,
                    1.0965909090909092
                ],
                "answer_relation_to_question": [
                    0.43478260869565216,
                    0.043478260869565216,
                    0.5217391304347826
                ],
                "answer_relation_to_question_bing": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    24400.0,
                    239000.0,
                    15100.0
                ],
                "question_answer_similarity": [
                    1.3517169521655887,
                    1.7977315420284867,
                    0.9305192669853568
                ],
                "result_count_bing": [
                    622000.0,
                    872000.0,
                    1260000.0
                ],
                "result_count": [
                    100.0,
                    22300.0,
                    96200.0
                ],
                "word_count_appended": [
                    83.0,
                    99.0,
                    50.0
                ]
            },
            "negative_question": true
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "One symptom of argyria is turning roughly the same skin color as which cartoon character?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "garfield"
            ],
            "lines": [
                [
                    0.4454246957479542,
                    0.38765799256505573,
                    0.22209221161234527,
                    0.08548707753479125,
                    0.13428571428571429,
                    0.0196078431372549,
                    0.07894736842105263,
                    0.0347008547008547,
                    0.21176470588235294,
                    0.3164574460666479,
                    -1.0
                ],
                [
                    0.13364491855683064,
                    0.20579925650557623,
                    0.7749534690347367,
                    0.027833001988071572,
                    0.11095238095238096,
                    0.018975332068311195,
                    0.02834008097165992,
                    0.06256410256410257,
                    0.07058823529411765,
                    0.20314895407399508,
                    -1.0
                ],
                [
                    0.4209303856952152,
                    0.4065427509293681,
                    0.00295431935291795,
                    0.8866799204771372,
                    0.7547619047619047,
                    0.9614168247944339,
                    0.8927125506072875,
                    0.9027350427350427,
                    0.7176470588235294,
                    0.48039359985935703,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "garfield": 0.6426774358036195,
                "the grinch": 0.16367997320097824,
                "papa smurf": 0.1936425909954024
            },
            "question": "one symptom of argyria is turning roughly the same skin color as which cartoon character?",
            "rate_limited": false,
            "answers": [
                "papa smurf",
                "the grinch",
                "garfield"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "garfield": 0.6176644697293239,
                "the grinch": 0.17823852239844912,
                "papa smurf": 0.31446632468146535
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    2.531659568533183,
                    1.6251916325919606,
                    3.8431487988748563
                ],
                "result_count_important_words": [
                    31.0,
                    30.0,
                    1520.0
                ],
                "wikipedia_search": [
                    0.1735042735042735,
                    0.3128205128205128,
                    4.513675213675214
                ],
                "answer_relation_to_question": [
                    2.672548174487725,
                    0.8018695113409838,
                    2.525582314171291
                ],
                "answer_relation_to_question_bing": [
                    1.9382899628252788,
                    1.0289962825278811,
                    2.0327137546468403
                ],
                "result_count_noun_chunks": [
                    39.0,
                    14.0,
                    441.0
                ],
                "question_answer_similarity": [
                    2.1387014188803732,
                    7.4626393773942254,
                    0.02844947576522827
                ],
                "result_count_bing": [
                    5640.0,
                    4660.0,
                    31700.0
                ],
                "result_count": [
                    43.0,
                    14.0,
                    446.0
                ],
                "word_count_appended": [
                    18.0,
                    6.0,
                    61.0
                ]
            },
            "integer_answers": {
                "garfield": 8,
                "the grinch": 1,
                "papa smurf": 1
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which three-letter-titled movie grossed the most worldwide?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "big"
            ],
            "lines": [
                [
                    0.6214689265536723,
                    0.36111111111111116,
                    0.41395396639383125,
                    0.26964882943143814,
                    0.07765574885800369,
                    0.3051490514905149,
                    0.2695879280325015,
                    0.0,
                    0.35096774193548386,
                    0.3519237788950199,
                    -1.0
                ],
                [
                    0.031073446327683617,
                    0.5111111111111112,
                    0.17180600473033586,
                    0.2035953177257525,
                    0.4451355816891826,
                    0.2720867208672087,
                    0.2196749854904237,
                    0.0,
                    0.36516129032258066,
                    0.31411327955900487,
                    -1.0
                ],
                [
                    0.34745762711864403,
                    0.1277777777777778,
                    0.4142400288758329,
                    0.5267558528428093,
                    0.4772086694528137,
                    0.42276422764227645,
                    0.5107370864770748,
                    1.0,
                    0.2838709677419355,
                    0.3339629415459752,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "big": 0.44447751794751406,
                "saw": 0.30214670827015766,
                "ray": 0.2533757737823284
            },
            "question": "which three-letter-titled movie grossed the most worldwide?",
            "rate_limited": false,
            "answers": [
                "saw",
                "ray",
                "big"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "big": 0.5891383343073099,
                "saw": 0.279179081569283,
                "ray": 0.1990663186496085
            },
            "integer_answers": {
                "big": 6,
                "saw": 2,
                "ray": 2
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.7596188944750994,
                    1.5705663977950244,
                    1.6698147077298762
                ],
                "result_count_important_words": [
                    563000.0,
                    502000.0,
                    780000.0
                ],
                "wikipedia_search": [
                    0.0,
                    0.0,
                    1.0
                ],
                "answer_relation_to_question": [
                    1.8644067796610169,
                    0.09322033898305085,
                    1.042372881355932
                ],
                "answer_relation_to_question_bing": [
                    1.0833333333333333,
                    1.5333333333333332,
                    0.3833333333333333
                ],
                "result_count_noun_chunks": [
                    929000.0,
                    757000.0,
                    1760000.0
                ],
                "question_answer_similarity": [
                    3.4394874423742294,
                    1.4275128245353699,
                    3.4418642967939377
                ],
                "result_count_bing": [
                    7990000.0,
                    45800000.0,
                    49100000.0
                ],
                "result_count": [
                    12900000.0,
                    9740000.0,
                    25200000.0
                ],
                "word_count_appended": [
                    272.0,
                    283.0,
                    220.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Talking is discouraged on what Amtrak car?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "quiet car"
            ],
            "lines": [
                [
                    0.133674630261661,
                    0.4245614035087719,
                    0.3747164863362907,
                    0.03899721448467967,
                    0.2100302238614825,
                    0.07792207792207792,
                    0.1311049677473402,
                    0.20454545454545456,
                    0.10185185185185185,
                    0.18527429688250335,
                    1.0
                ],
                [
                    0.05497943467226744,
                    0.0456140350877193,
                    0.36944963713959095,
                    0.10027855153203342,
                    0.7427898160954869,
                    0.046753246753246755,
                    0.8628633660048588,
                    0.20454545454545456,
                    0.0,
                    0.2876852534676533,
                    1.0
                ],
                [
                    0.8113459350660716,
                    0.5298245614035088,
                    0.2558338765241184,
                    0.8607242339832869,
                    0.04717996004303058,
                    0.8753246753246753,
                    0.006031666247800955,
                    0.5909090909090909,
                    0.8981481481481481,
                    0.5270404496498434,
                    1.0
                ]
            ],
            "fraction_answers": {
                "sports argument car": 0.18826786074021137,
                "quiet car": 0.5402362597299575,
                "meet & greet car": 0.2714958795298311
            },
            "question": "talking is discouraged on what amtrak car?",
            "rate_limited": false,
            "answers": [
                "sports argument car",
                "meet & greet car",
                "quiet car"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "sports argument car": 0.14010399431059004,
                "quiet car": 0.6919434408027746,
                "meet & greet car": 0.15241427431376658
            },
            "integer_answers": {
                "sports argument car": 1,
                "quiet car": 7,
                "meet & greet car": 2
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    0.7410971875300134,
                    1.1507410138706131,
                    2.1081617985993737
                ],
                "result_count_important_words": [
                    30.0,
                    18.0,
                    337.0
                ],
                "wikipedia_search": [
                    0.4090909090909091,
                    0.4090909090909091,
                    1.1818181818181819
                ],
                "answer_relation_to_question": [
                    0.40102389078498296,
                    0.16493830401680232,
                    2.4340378051982148
                ],
                "answer_relation_to_question_bing": [
                    1.2736842105263158,
                    0.1368421052631579,
                    1.5894736842105264
                ],
                "result_count_noun_chunks": [
                    313000.0,
                    2060000.0,
                    14400.0
                ],
                "question_answer_similarity": [
                    7.02377974241972,
                    6.925056600943208,
                    4.7954143062233925
                ],
                "result_count_bing": [
                    4100000.0,
                    14500000.0,
                    921000.0
                ],
                "word_count_appended": [
                    11.0,
                    0.0,
                    97.0
                ],
                "result_count": [
                    14.0,
                    36.0,
                    309.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which of these is NOT a name of one of the Florida Keys?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "fat deer key"
            ],
            "lines": [
                [
                    0.2314108278811139,
                    0.35434065934065934,
                    0.2792305500054321,
                    0.4998364993014061,
                    0.33849765258215964,
                    0.474414623708504,
                    0.499991054224623,
                    0.33333333333333337,
                    0.42592592592592593,
                    0.38939499067291505,
                    -1.0
                ],
                [
                    0.4715552802163763,
                    0.386043956043956,
                    0.3551920914320528,
                    0.0005796842950147041,
                    0.33098591549295775,
                    0.3679464449471175,
                    0.48230292262371033,
                    0.5,
                    0.25308641975308643,
                    0.2886766913872333,
                    -1.0
                ],
                [
                    0.2970338919025098,
                    0.2596153846153846,
                    0.36557735856251505,
                    0.4995838164035792,
                    0.33051643192488267,
                    0.15763893134437856,
                    0.017706023151666694,
                    0.16666666666666669,
                    0.32098765432098764,
                    0.32192831793985166,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "pigeon key": 0.4525491046335155,
                "turtle key": 0.312726118761699,
                "fat deer key": 0.23472477660478552
            },
            "question": "which of these is not a name of one of the florida keys?",
            "rate_limited": false,
            "answers": [
                "fat deer key",
                "turtle key",
                "pigeon key"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "pigeon key": 0.25852935391123605,
                "turtle key": 0.15499666461535413,
                "fat deer key": 0.4793521318147084
            },
            "integer_answers": {
                "pigeon key": 5,
                "turtle key": 3,
                "fat deer key": 2
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    0.4424200373083398,
                    0.845293234451067,
                    0.7122867282405934
                ],
                "result_count_important_words": [
                    8370.0,
                    43200.0,
                    112000.0
                ],
                "wikipedia_search": [
                    0.3333333333333333,
                    0.0,
                    0.6666666666666666
                ],
                "answer_relation_to_question": [
                    1.0743566884755444,
                    0.11377887913449479,
                    0.8118644323899609
                ],
                "answer_relation_to_question_bing": [
                    0.5826373626373627,
                    0.4558241758241759,
                    0.9615384615384616
                ],
                "result_count_noun_chunks": [
                    23.0,
                    45500.0,
                    1240000.0
                ],
                "question_answer_similarity": [
                    11.634681515395641,
                    7.631463035941124,
                    7.084153272211552
                ],
                "result_count_bing": [
                    3440000.0,
                    3600000.0,
                    3610000.0
                ],
                "result_count": [
                    11.0,
                    33600.0,
                    28.0
                ],
                "word_count_appended": [
                    12.0,
                    40.0,
                    29.0
                ]
            },
            "negative_question": true
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Which of these verbs has two meanings that are opposites of each other?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "cleave"
            ],
            "lines": [
                [
                    0.0,
                    0.0,
                    0.5529125994186738,
                    0.14524207011686144,
                    0.22755379668562947,
                    0.5097222222222222,
                    0.27877919344365076,
                    0,
                    0.32697547683923706,
                    0.3397689390905702,
                    -1.0
                ],
                [
                    0.25,
                    0.0,
                    0.2563376711823779,
                    0.42070116861435725,
                    0.6702943358891912,
                    0.3416666666666667,
                    0.006919098054143621,
                    0,
                    0.26975476839237056,
                    0.2850138534919359,
                    -1.0
                ],
                [
                    0.75,
                    1.0,
                    0.19074972939894838,
                    0.4340567612687813,
                    0.10215186742517932,
                    0.1486111111111111,
                    0.7143017085022056,
                    0,
                    0.4032697547683924,
                    0.3752172074174939,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "cleave": 0.4575953488769014,
                "branch": 0.264550477535205,
                "jut": 0.27785417358789366
            },
            "question": "which of these verbs has two meanings that are opposites of each other?",
            "rate_limited": false,
            "answers": [
                "branch",
                "jut",
                "cleave"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "cleave": 0.36945431827667613,
                "branch": 0.1661898035518397,
                "jut": 0.1902957247480312
            },
            "integer_answers": {
                "cleave": 6,
                "branch": 2,
                "jut": 1
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.0193068172717106,
                    0.8550415604758077,
                    1.1256516222524817
                ],
                "result_count_important_words": [
                    367000.0,
                    246000.0,
                    107000.0
                ],
                "wikipedia_search": [
                    0.0,
                    0.0,
                    0.0
                ],
                "answer_relation_to_question": [
                    0.0,
                    0.5,
                    1.5
                ],
                "answer_relation_to_question_bing": [
                    0.0,
                    0.0,
                    1.0
                ],
                "result_count_noun_chunks": [
                    2490000.0,
                    61800.0,
                    6380000.0
                ],
                "question_answer_similarity": [
                    3.058261123485863,
                    1.4178507328033447,
                    1.0550717823207378
                ],
                "result_count_bing": [
                    9200000.0,
                    27100000.0,
                    4130000.0
                ],
                "word_count_appended": [
                    240.0,
                    198.0,
                    296.0
                ],
                "result_count": [
                    2610000.0,
                    7560000.0,
                    7800000.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which of these is NOT a real animal?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "wholphin"
            ],
            "lines": [
                [
                    0.3998202670318384,
                    0.32371794871794873,
                    0.21366376270780446,
                    0.27123323691822243,
                    0.33779761904761907,
                    0.33168316831683164,
                    0.33024251069900146,
                    0.16379310344827586,
                    0.319763624425476,
                    0.3542428722666374,
                    -1.0
                ],
                [
                    0.265876412187607,
                    0.28205128205128205,
                    0.2863362372921955,
                    0.2541414672626874,
                    0.3348214285714286,
                    0.25035360678925034,
                    0.2524964336661911,
                    0.39655172413793105,
                    0.2856204858831254,
                    0.329260212463038,
                    -1.0
                ],
                [
                    0.3343033207805546,
                    0.3942307692307692,
                    0.5,
                    0.4746252958190902,
                    0.3273809523809524,
                    0.41796322489391796,
                    0.4172610556348074,
                    0.4396551724137931,
                    0.39461588969139855,
                    0.31649691527032453,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "liger": 0.41249814193905265,
                "wholphin": 0.1966934807768784,
                "jackalope": 0.39080837728406886
            },
            "question": "which of these is not a real animal?",
            "rate_limited": false,
            "answers": [
                "jackalope",
                "liger",
                "wholphin"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "liger": 0.5055764265678385,
                "wholphin": 0.6335968432635589,
                "jackalope": 0.25313101268395777
            },
            "integer_answers": {
                "liger": 6,
                "wholphin": 2,
                "jackalope": 1
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    0.5830285109334502,
                    0.682959150147848,
                    0.7340123389187019
                ],
                "result_count_important_words": [
                    2380000.0,
                    3530000.0,
                    1160000.0
                ],
                "wikipedia_search": [
                    1.3448275862068966,
                    0.41379310344827586,
                    0.2413793103448276
                ],
                "answer_relation_to_question": [
                    0.40071893187264634,
                    0.936494351249572,
                    0.6627867168777816
                ],
                "answer_relation_to_question_bing": [
                    0.7051282051282051,
                    0.8717948717948718,
                    0.4230769230769231
                ],
                "result_count_noun_chunks": [
                    2380000.0,
                    3470000.0,
                    1160000.0
                ],
                "question_answer_similarity": [
                    -0.7042543757706881,
                    -0.5255137849599123,
                    0.0
                ],
                "result_count_bing": [
                    109000000.0,
                    111000000.0,
                    116000000.0
                ],
                "word_count_appended": [
                    549.0,
                    653.0,
                    321.0
                ],
                "result_count": [
                    1740000.0,
                    1870000.0,
                    193000.0
                ]
            },
            "negative_question": true
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which Hawaiian island has active volcanoes?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "maui"
            ],
            "lines": [
                [
                    0.6903289538766998,
                    0.6471787216955603,
                    0.6555825533334825,
                    0.6013745704467354,
                    0.2777777777777778,
                    0.6514476614699332,
                    0.17992240543161978,
                    0.0,
                    0.17914110429447852,
                    0.359193041855403,
                    -1.0
                ],
                [
                    0.1483112323004743,
                    0.1563705721119433,
                    0.17846040819448183,
                    0.18957617411225658,
                    0.35947712418300654,
                    0.1987750556792873,
                    0.46605237633365665,
                    0.3795045045045045,
                    0.4503067484662577,
                    0.32682346155909653,
                    -1.0
                ],
                [
                    0.16135981382282588,
                    0.1964507061924964,
                    0.1659570384720357,
                    0.20904925544100803,
                    0.3627450980392157,
                    0.14977728285077951,
                    0.35402521823472355,
                    0.6204954954954954,
                    0.37055214723926383,
                    0.31398349658550045,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "maui": 0.2853657657444965,
                "oahu": 0.29043955523733445,
                "big island": 0.42419467901816904
            },
            "question": "which hawaiian island has active volcanoes?",
            "rate_limited": false,
            "answers": [
                "big island",
                "maui",
                "oahu"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "maui": 0.47931646876622047,
                "oahu": 0.3931173256449866,
                "big island": 0.2638159626823354
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.436772167421612,
                    1.3072938462363861,
                    1.2559339863420018
                ],
                "result_count_important_words": [
                    1170000.0,
                    357000.0,
                    269000.0
                ],
                "wikipedia_search": [
                    0.0,
                    1.1385135135135136,
                    1.8614864864864864
                ],
                "answer_relation_to_question": [
                    2.761315815506799,
                    0.5932449292018972,
                    0.6454392552913035
                ],
                "answer_relation_to_question_bing": [
                    2.588714886782241,
                    0.6254822884477731,
                    0.7858028247699855
                ],
                "result_count_noun_chunks": [
                    371000.0,
                    961000.0,
                    730000.0
                ],
                "question_answer_similarity": [
                    4.776122942566872,
                    1.3001396171748638,
                    1.2090486772358418
                ],
                "result_count_bing": [
                    850000.0,
                    1100000.0,
                    1110000.0
                ],
                "result_count": [
                    1050000.0,
                    331000.0,
                    365000.0
                ],
                "word_count_appended": [
                    146.0,
                    367.0,
                    302.0
                ]
            },
            "integer_answers": {
                "maui": 2,
                "oahu": 2,
                "big island": 6
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Pixies, Bon Iver, Iron & Wine and Bauhaus were all once signed to which record label?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "4ad"
            ],
            "lines": [
                [
                    0.3428635582630429,
                    0.17461576224462824,
                    -0.0,
                    0.3275862068965517,
                    0.3333333333333333,
                    0.0037000270733688295,
                    0.395732966276669,
                    0.3812222222222222,
                    0.05,
                    0.33265188810040386,
                    -1.0
                ],
                [
                    0.5127284442361761,
                    0.48009579195146207,
                    0.5718448795319769,
                    0.33620689655172414,
                    0.3333333333333333,
                    0.8961285082573774,
                    0.20165175498967652,
                    0.6154444444444445,
                    0.9,
                    0.33367405594979804,
                    -1.0
                ],
                [
                    0.144407997500781,
                    0.3452884458039097,
                    0.42815512046802306,
                    0.33620689655172414,
                    0.3333333333333333,
                    0.10017146466925368,
                    0.4026152787336545,
                    0.0033333333333333335,
                    0.05,
                    0.33367405594979804,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "4ad": 0.5181108109245969,
                "geffen": 0.24771859263438106,
                "subpop": 0.23417059644102198
            },
            "question": "pixies, bon iver, iron & wine and bauhaus were all once signed to which record label?",
            "rate_limited": false,
            "answers": [
                "subpop",
                "4ad",
                "geffen"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "4ad": 0.5523750328022135,
                "geffen": 0.3690251074936016,
                "subpop": 0.4124352972710402
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    2.6612151048032313,
                    2.669392447598385,
                    2.669392447598385
                ],
                "result_count_important_words": [
                    41.0,
                    9930.0,
                    1110.0
                ],
                "wikipedia_search": [
                    2.287333333333333,
                    3.6926666666666668,
                    0.02
                ],
                "answer_relation_to_question": [
                    2.742908466104343,
                    4.101827553889409,
                    1.155263980006248
                ],
                "answer_relation_to_question_bing": [
                    1.2223103357123977,
                    3.3606705436602344,
                    2.417019120627368
                ],
                "result_count_noun_chunks": [
                    115000.0,
                    58600.0,
                    117000.0
                ],
                "question_answer_similarity": [
                    0.0,
                    -1.0108989626169205,
                    -0.7568863211199641
                ],
                "result_count_bing": [
                    1340000.0,
                    1340000.0,
                    1340000.0
                ],
                "result_count": [
                    38.0,
                    39.0,
                    39.0
                ],
                "word_count_appended": [
                    1.0,
                    18.0,
                    1.0
                ]
            },
            "integer_answers": {
                "4ad": 7,
                "geffen": 1,
                "subpop": 1
            }
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Which of these would an oologist study?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "ostrich egg"
            ],
            "lines": [
                [
                    0.0,
                    0,
                    0.3367300813824786,
                    0.14802065404475043,
                    0.10077896786757547,
                    0.62662681962788,
                    0.060034305317324184,
                    0.0,
                    0.19480519480519481,
                    0.24862189927336506,
                    -1.0
                ],
                [
                    1.0,
                    0,
                    0.44847547374738744,
                    0.09294320137693632,
                    0.501460564751704,
                    0.002699315530704714,
                    0.09090909090909091,
                    0.08333333333333333,
                    0.2597402597402597,
                    0.25552806314206966,
                    -1.0
                ],
                [
                    0.0,
                    0,
                    0.21479444487013397,
                    0.7590361445783133,
                    0.3977604673807206,
                    0.37067386484141523,
                    0.8490566037735849,
                    0.9166666666666666,
                    0.5454545454545454,
                    0.49585003758456525,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "ice cave": 0.19062421359095205,
                "human liver": 0.30389881139238734,
                "ostrich egg": 0.5054769750166606
            },
            "question": "which of these would an oologist study?",
            "rate_limited": false,
            "answers": [
                "ice cave",
                "human liver",
                "ostrich egg"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "ice cave": 0.1836530548343774,
                "human liver": 0.2342120360494716,
                "ostrich egg": 0.41402738296564884
            },
            "integer_answers": {
                "ice cave": 1,
                "human liver": 3,
                "ostrich egg": 5
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    0.4972437985467301,
                    0.5110561262841393,
                    0.9917000751691305
                ],
                "result_count_important_words": [
                    13000.0,
                    56.0,
                    7690.0
                ],
                "wikipedia_search": [
                    0.0,
                    0.08333333333333333,
                    0.9166666666666666
                ],
                "answer_relation_to_question": [
                    0.0,
                    1.0,
                    0.0
                ],
                "answer_relation_to_question_bing": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    35.0,
                    53.0,
                    495.0
                ],
                "question_answer_similarity": [
                    3.237850099802017,
                    4.3123452216386795,
                    2.0653700195252895
                ],
                "result_count_bing": [
                    207000.0,
                    1030000.0,
                    817000.0
                ],
                "result_count": [
                    86.0,
                    54.0,
                    441.0
                ],
                "word_count_appended": [
                    15.0,
                    20.0,
                    42.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "What book that heavily influenced \u201cThe Matrix\u201d makes a cameo in the movie?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "neuromancer"
            ],
            "lines": [
                [
                    0.6330134706402455,
                    0.5368421052631579,
                    -0.1829135133320409,
                    0.23931623931623933,
                    0.22405271828665568,
                    0.9089344121191255,
                    0.9368669817690749,
                    0.8431818181818183,
                    0.9230769230769231,
                    0.3163962981374112,
                    1.0
                ],
                [
                    0.17475945285275915,
                    0.12631578947368421,
                    0.20680081164226882,
                    0.23076923076923078,
                    0.22240527182866557,
                    0.015665346875537958,
                    0.0013082376772451047,
                    0.030303030303030304,
                    0.0,
                    0.3112126084902814,
                    1.0
                ],
                [
                    0.19222707650699536,
                    0.3368421052631579,
                    0.976112701689772,
                    0.5299145299145299,
                    0.5535420098846787,
                    0.07540024100533654,
                    0.061824780553679945,
                    0.1265151515151515,
                    0.07692307692307693,
                    0.37239109337230747,
                    1.0
                ]
            ],
            "fraction_answers": {
                "simulacra & simulation": 0.13195397799127032,
                "neuromancer": 0.537876745345861,
                "gravity's rainbow": 0.33016927666286866
            },
            "question": "what book that heavily influenced \u201cthe matrix\u201d makes a cameo in the movie?",
            "rate_limited": false,
            "answers": [
                "neuromancer",
                "simulacra & simulation",
                "gravity's rainbow"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "simulacra & simulation": 0.17153722451037362,
                "neuromancer": 0.6937718350217982,
                "gravity's rainbow": 0.23636020807929872
            },
            "integer_answers": {
                "simulacra & simulation": 0,
                "neuromancer": 6,
                "gravity's rainbow": 4
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    2.2147740869618784,
                    2.1784882594319694,
                    2.606737653606152
                ],
                "result_count_important_words": [
                    5280.0,
                    91.0,
                    438.0
                ],
                "wikipedia_search": [
                    5.0590909090909095,
                    0.18181818181818182,
                    0.759090909090909
                ],
                "answer_relation_to_question": [
                    3.1650673532012275,
                    0.8737972642637958,
                    0.9611353825349768
                ],
                "answer_relation_to_question_bing": [
                    1.0736842105263158,
                    0.25263157894736843,
                    0.6736842105263158
                ],
                "result_count_noun_chunks": [
                    44400.0,
                    62.0,
                    2930.0
                ],
                "question_answer_similarity": [
                    -2.136249199975282,
                    2.4152292544022202,
                    11.400032398290932
                ],
                "result_count_bing": [
                    27200.0,
                    27000.0,
                    67200.0
                ],
                "word_count_appended": [
                    120.0,
                    0.0,
                    10.0
                ],
                "result_count": [
                    28.0,
                    27.0,
                    62.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Who holds the record as the youngest solo artist with a Billboard #1 hit?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "michael jackson"
            ],
            "lines": [
                [
                    0.3074979372517324,
                    0.2700644231494756,
                    0.23162578867103845,
                    0.3333333333333333,
                    0.35089514066496164,
                    0.396505376344086,
                    0.3333333333333333,
                    0.3303309721762796,
                    0.42857142857142855,
                    0.3335592631213069,
                    0.0
                ],
                [
                    0.37070432482994164,
                    0.3844330063633391,
                    0.33327754450893626,
                    0.3333333333333333,
                    0.3248081841432225,
                    0.4368279569892473,
                    0.3333333333333333,
                    0.5174058722809712,
                    0.19047619047619047,
                    0.3332725060827251,
                    0.0
                ],
                [
                    0.32179773791832594,
                    0.34550257048718525,
                    0.4350966668200253,
                    0.3333333333333333,
                    0.3242966751918159,
                    0.16666666666666666,
                    0.3333333333333333,
                    0.1522631555427492,
                    0.38095238095238093,
                    0.333168230795968,
                    0.0
                ]
            ],
            "fraction_answers": {
                "justin bieber": 0.3315716996616976,
                "stevie wonder": 0.31264107510417843,
                "michael jackson": 0.35578722523412404
            },
            "question": "who holds the record as the youngest solo artist with a billboard #1 hit?",
            "rate_limited": false,
            "answers": [
                "justin bieber",
                "michael jackson",
                "stevie wonder"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "justin bieber": 0.18465451917558956,
                "stevie wonder": 0.28725776728477087,
                "michael jackson": 0.5275715604420476
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 0
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    2.6684741049704552,
                    2.6661800486618006,
                    2.665345846367744
                ],
                "result_count_important_words": [
                    118000.0,
                    130000.0,
                    49600.0
                ],
                "wikipedia_search": [
                    2.642647777410237,
                    4.13924697824777,
                    1.2181052443419935
                ],
                "answer_relation_to_question": [
                    2.152485560762127,
                    2.5949302738095916,
                    2.2525841654282814
                ],
                "answer_relation_to_question_bing": [
                    1.350322115747378,
                    1.9221650318166954,
                    1.7275128524359262
                ],
                "result_count_noun_chunks": [
                    1120000.0,
                    1120000.0,
                    1120000.0
                ],
                "question_answer_similarity": [
                    3.0850419979542494,
                    4.438949685543776,
                    5.795086540281773
                ],
                "result_count_bing": [
                    6860000.0,
                    6350000.0,
                    6340000.0
                ],
                "word_count_appended": [
                    9.0,
                    4.0,
                    8.0
                ],
                "result_count": [
                    1190000.0,
                    1190000.0,
                    1190000.0
                ]
            },
            "integer_answers": {
                "justin bieber": 5,
                "stevie wonder": 1,
                "michael jackson": 4
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which of these states does NOT touch the Mason-Dixon Line?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "west virginia"
            ],
            "lines": [
                [
                    0.4227619012903696,
                    0.30572623467880383,
                    0.1962000328379232,
                    0.4484304932735426,
                    0.2572892040977147,
                    0.36695485110470705,
                    0.1428139731657198,
                    0.3337639783124365,
                    0.4413309982486865,
                    0.3366855187238918,
                    -1.0
                ],
                [
                    0.17157906247721805,
                    0.36040943027109035,
                    0.42186295554480047,
                    0.3388452914798206,
                    0.3715524034672971,
                    0.3707973102785783,
                    0.40088238849268704,
                    0.3209575849994352,
                    0.2329246935201401,
                    0.3244289300092914,
                    -1.0
                ],
                [
                    0.40565903623241234,
                    0.33386433505010576,
                    0.3819370116172764,
                    0.21272421524663676,
                    0.37115839243498816,
                    0.2622478386167147,
                    0.45630363834159315,
                    0.3452784366881283,
                    0.3257443082311734,
                    0.3388855512668168,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "tennessee": 0.3132394472548309,
                "delaware": 0.3371519898919283,
                "west virginia": 0.34960856285324093
            },
            "question": "which of these states does not touch the mason-dixon line?",
            "rate_limited": false,
            "answers": [
                "west virginia",
                "delaware",
                "tennessee"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "tennessee": 0.38854923935537444,
                "delaware": 0.15473636765564586,
                "west virginia": 0.47063939618603196
            },
            "integer_answers": {
                "tennessee": 2,
                "delaware": 4,
                "west virginia": 4
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.6331448127610821,
                    1.7557106999070862,
                    1.611144487331832
                ],
                "result_count_important_words": [
                    277000.0,
                    269000.0,
                    495000.0
                ],
                "wikipedia_search": [
                    0.6649440867502541,
                    0.7161696600022591,
                    0.6188862532474868
                ],
                "answer_relation_to_question": [
                    0.6179047896770431,
                    2.6273675001822556,
                    0.7547277101407013
                ],
                "answer_relation_to_question_bing": [
                    1.165642591927177,
                    0.8375434183734578,
                    0.9968139896993652
                ],
                "result_count_noun_chunks": [
                    5910000.0,
                    1640000.0,
                    723000.0
                ],
                "question_answer_similarity": [
                    5.432002059184015,
                    1.3971054386347532,
                    2.110989023465663
                ],
                "result_count_bing": [
                    616000.0,
                    326000.0,
                    327000.0
                ],
                "word_count_appended": [
                    67.0,
                    305.0,
                    199.0
                ],
                "result_count": [
                    3680000.0,
                    11500000.0,
                    20500000.0
                ]
            },
            "negative_question": true
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "One of Tupac Shakur\u2019s biggest posthumous hits samples what singer?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "john mellencamp"
            ],
            "lines": [
                [
                    0.3375180375180375,
                    0.5388888888888889,
                    0.45633501858049685,
                    0.03025884068538097,
                    0.5642857142857143,
                    0.02202412165705296,
                    0.02217008797653959,
                    0.36768018018018017,
                    0.16666666666666666,
                    0.2510368333789503,
                    1.0
                ],
                [
                    0.09158249158249158,
                    0.39444444444444443,
                    0.36276600365520895,
                    0.7728764126868393,
                    0.15535714285714286,
                    0.5532249606712113,
                    0.07225806451612904,
                    0.4671546546546546,
                    0.21212121212121213,
                    0.32943729528273213,
                    1.0
                ],
                [
                    0.5708994708994709,
                    0.06666666666666667,
                    0.18089897776429417,
                    0.1968647466277798,
                    0.28035714285714286,
                    0.42475091767173573,
                    0.9055718475073313,
                    0.16516516516516516,
                    0.6212121212121212,
                    0.41952587133831765,
                    1.0
                ]
            ],
            "fraction_answers": {
                "john mellencamp": 0.3411222682472066,
                "bruce hornsby": 0.38319129277100256,
                "christopher cross": 0.27568643898179085
            },
            "question": "one of tupac shakur\u2019s biggest posthumous hits samples what singer?",
            "rate_limited": false,
            "answers": [
                "christopher cross",
                "john mellencamp",
                "bruce hornsby"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "john mellencamp": 0.4581020770693755,
                "bruce hornsby": 0.25489723292888966,
                "christopher cross": 0.3104582961742674
            },
            "integer_answers": {
                "john mellencamp": 3,
                "bruce hornsby": 4,
                "christopher cross": 3
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.7572578336526519,
                    2.3060610669791246,
                    2.936681099368223
                ],
                "result_count_important_words": [
                    84.0,
                    2110.0,
                    1620.0
                ],
                "wikipedia_search": [
                    1.1030405405405406,
                    1.4014639639639639,
                    0.4954954954954955
                ],
                "answer_relation_to_question": [
                    2.3626262626262626,
                    0.6410774410774411,
                    3.9962962962962965
                ],
                "answer_relation_to_question_bing": [
                    1.6166666666666667,
                    1.1833333333333333,
                    0.2
                ],
                "result_count_noun_chunks": [
                    9450.0,
                    30800.0,
                    386000.0
                ],
                "question_answer_similarity": [
                    3.2179248952306807,
                    2.5581068880856037,
                    1.275640265084803
                ],
                "result_count_bing": [
                    94800.0,
                    26100.0,
                    47100.0
                ],
                "result_count": [
                    83.0,
                    2120.0,
                    540.0
                ],
                "word_count_appended": [
                    11.0,
                    14.0,
                    41.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "To help first create Maps, Google acquired what company?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "where 2 technologies"
            ],
            "lines": [
                [
                    0.16853122479746327,
                    0.6449232973478982,
                    0.0041149995010338536,
                    0.10827674802716095,
                    0.3393285371702638,
                    0.039251685606660126,
                    0.37517341214789796,
                    0.10114341399718757,
                    0.36587436332767403,
                    0.3212433726003303,
                    1.0
                ],
                [
                    0.581902659784083,
                    0.2189050682545656,
                    1.0679859411524217,
                    0.04110846026793907,
                    0.32194244604316546,
                    0.014276217910164287,
                    0.0264792810181555,
                    0.7860637062877629,
                    0.06451612903225806,
                    0.3332849791658262,
                    1.0
                ],
                [
                    0.24956611541845375,
                    0.13617163439753624,
                    -0.0721009406534556,
                    0.8506147917049,
                    0.33872901678657075,
                    0.9464720964831755,
                    0.5983473068339465,
                    0.11279287971504952,
                    0.5696095076400679,
                    0.3454716482338435,
                    1.0
                ]
            ],
            "fraction_answers": {
                "mapquest": 0.24678610545235696,
                "waze": 0.40756740565600885,
                "where 2 technologies": 0.3456464888916342
            },
            "question": "to help first create maps, google acquired what company?",
            "rate_limited": false,
            "answers": [
                "mapquest",
                "where 2 technologies",
                "waze"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "mapquest": 0.3020376499742729,
                "waze": 0.2326690336830119,
                "where 2 technologies": 0.4369969593082462
            },
            "integer_answers": {
                "mapquest": 2,
                "waze": 5,
                "where 2 technologies": 3
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.9274602356019819,
                    1.9997098749949573,
                    2.072829889403061
                ],
                "result_count_important_words": [
                    124000.0,
                    45100.0,
                    2990000.0
                ],
                "wikipedia_search": [
                    0.6068604839831254,
                    4.716382237726577,
                    0.6767572782902971
                ],
                "answer_relation_to_question": [
                    1.0111873487847796,
                    3.491415958704498,
                    1.4973966925107225
                ],
                "answer_relation_to_question_bing": [
                    3.8695397840873893,
                    1.3134304095273936,
                    0.8170298063852174
                ],
                "result_count_noun_chunks": [
                    622000.0,
                    43900.0,
                    992000.0
                ],
                "question_answer_similarity": [
                    0.036335155775304884,
                    9.430240642279387,
                    -0.6366462279111147
                ],
                "result_count_bing": [
                    56600000.0,
                    53700000.0,
                    56500000.0
                ],
                "word_count_appended": [
                    431.0,
                    76.0,
                    671.0
                ],
                "result_count": [
                    118000.0,
                    44800.0,
                    927000.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "The lyrics to \u201cThe Star-Spangled Banner\u201d were written during what conflict?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "the war of 1812"
            ],
            "lines": [
                [
                    0.15319086219602066,
                    0.27777777777777773,
                    0.3798194555148806,
                    0.43755192467460535,
                    0.4516767726766489,
                    0.4601226993865031,
                    0.5505154639175258,
                    0.19607344632768361,
                    0.28888888888888886,
                    0.32667859160292084,
                    1.0
                ],
                [
                    0.09141897977564889,
                    0.15331010452961671,
                    0.17684281224940673,
                    0.3184713375796178,
                    0.4405395371859918,
                    0.32515337423312884,
                    0.3161512027491409,
                    0.0927401129943503,
                    0.22777777777777777,
                    0.305045741222694,
                    1.0
                ],
                [
                    0.7553901580283304,
                    0.5689121176926055,
                    0.4433377322357126,
                    0.2439767377457768,
                    0.10778369013735924,
                    0.2147239263803681,
                    0.13333333333333333,
                    0.7111864406779661,
                    0.48333333333333334,
                    0.36827566717438515,
                    1.0
                ]
            ],
            "fraction_answers": {
                "american revolution": 0.24474509802973737,
                "the war of 1812": 0.40302531367391703,
                "the civil war": 0.3522295882963455
            },
            "question": "the lyrics to \u201cthe star-spangled banner\u201d were written during what conflict?",
            "rate_limited": false,
            "answers": [
                "the civil war",
                "american revolution",
                "the war of 1812"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "american revolution": 0.19634688330395553,
                "the war of 1812": 0.4727941863905904,
                "the civil war": 0.250265656109275
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.9600715496175252,
                    1.830274447336164,
                    2.2096540030463108
                ],
                "result_count_important_words": [
                    225000.0,
                    159000.0,
                    105000.0
                ],
                "wikipedia_search": [
                    1.1764406779661016,
                    0.5564406779661017,
                    4.267118644067796
                ],
                "answer_relation_to_question": [
                    0.7659543109801032,
                    0.45709489887824445,
                    3.7769507901416524
                ],
                "answer_relation_to_question_bing": [
                    0.8333333333333333,
                    0.45993031358885017,
                    1.7067363530778166
                ],
                "result_count_noun_chunks": [
                    801000.0,
                    460000.0,
                    194000.0
                ],
                "question_answer_similarity": [
                    14.88093376904726,
                    6.928518638014793,
                    17.369514212419745
                ],
                "result_count_bing": [
                    365000.0,
                    356000.0,
                    87100.0
                ],
                "word_count_appended": [
                    52.0,
                    41.0,
                    87.0
                ],
                "result_count": [
                    158000.0,
                    115000.0,
                    88100.0
                ]
            },
            "integer_answers": {
                "american revolution": 0,
                "the war of 1812": 6,
                "the civil war": 4
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Where do marsupials keep their undeveloped young?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "underwater"
            ],
            "lines": [
                [
                    0.984375,
                    1.0,
                    0.4179999846109188,
                    0.004186837629203193,
                    0.7436204146730463,
                    0.00455001156782602,
                    0.06058392732537286,
                    0,
                    0.12060301507537688,
                    0.3089653000651101,
                    3.0
                ],
                [
                    0.015625,
                    0.0,
                    0.48067960832710066,
                    0.0014392254350385975,
                    0.02113237639553429,
                    0.0006169507210611552,
                    0.0003325920660488715,
                    0,
                    0.03015075376884422,
                    0.10406538681938256,
                    3.0
                ],
                [
                    0.0,
                    0.0,
                    0.10132040706198056,
                    0.9943739369357583,
                    0.23524720893141945,
                    0.9948330377111129,
                    0.9390834806085783,
                    0,
                    0.8492462311557789,
                    0.5869693131155073,
                    3.0
                ]
            ],
            "fraction_answers": {
                "in their pouches": 0.40498716566076154,
                "underwater": 0.5223415128355706,
                "in a paper bag": 0.07267132150366783
            },
            "question": "where do marsupials keep their undeveloped young?",
            "rate_limited": false,
            "answers": [
                "in their pouches",
                "in a paper bag",
                "underwater"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "in their pouches": 0.24678611114531487,
                "underwater": 0.3100083345974708,
                "in a paper bag": 0.17684493111242705
            },
            "integer_answers": {
                "in their pouches": 3,
                "underwater": 5,
                "in a paper bag": 1
            },
            "categorical_data": {
                "question_type": 3
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    0.9268959001953302,
                    0.3121961604581477,
                    1.760907939346522
                ],
                "result_count_important_words": [
                    59.0,
                    8.0,
                    12900.0
                ],
                "wikipedia_search": [
                    0.0,
                    0.0,
                    0.0
                ],
                "answer_relation_to_question": [
                    1.96875,
                    0.03125,
                    0.0
                ],
                "answer_relation_to_question_bing": [
                    3.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    9290.0,
                    51.0,
                    144000.0
                ],
                "question_answer_similarity": [
                    6.696236303076148,
                    7.700345363467932,
                    1.6231229975819588
                ],
                "result_count_bing": [
                    373000.0,
                    10600.0,
                    118000.0
                ],
                "word_count_appended": [
                    24.0,
                    6.0,
                    169.0
                ],
                "result_count": [
                    64.0,
                    22.0,
                    15200.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Catching a catfish with your bare hands is called what?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "noodling"
            ],
            "lines": [
                [
                    0.035238095238095235,
                    0.0,
                    0.8138307149619655,
                    0.07526773085471812,
                    0.33480956598759964,
                    0.0192908910046895,
                    0.017580052022602925,
                    0.06666666666666667,
                    0.17003367003367004,
                    0.28238396721277614,
                    1.0
                ],
                [
                    0.11428571428571428,
                    0.0,
                    -0.19897317461342343,
                    0.0003030915336431602,
                    0.337466784765279,
                    0.00017763251385533607,
                    0.0002690824289173917,
                    0.06666666666666667,
                    0.04040404040404041,
                    0.05649794646105577,
                    1.0
                ],
                [
                    0.8504761904761905,
                    1.0,
                    0.385142459651458,
                    0.9244291776116387,
                    0.32772364924712133,
                    0.9805314764814551,
                    0.9821508655484796,
                    0.8666666666666666,
                    0.7895622895622896,
                    0.6611180863261681,
                    1.0
                ]
            ],
            "fraction_answers": {
                "noodling": 0.7767800861571469,
                "whiskering": 0.04170977844457486,
                "strumming": 0.18151013539827834
            },
            "question": "catching a catfish with your bare hands is called what?",
            "rate_limited": false,
            "answers": [
                "strumming",
                "whiskering",
                "noodling"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "noodling": 0.6816669849388878,
                "whiskering": 0.1844517795915823,
                "strumming": 0.18591099076218698
            },
            "integer_answers": {
                "noodling": 8,
                "whiskering": 1,
                "strumming": 1
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.4119198360638807,
                    0.28248973230527885,
                    3.3055904316308404
                ],
                "result_count_important_words": [
                    543.0,
                    5.0,
                    27600.0
                ],
                "wikipedia_search": [
                    0.3333333333333333,
                    0.3333333333333333,
                    4.333333333333333
                ],
                "answer_relation_to_question": [
                    0.17619047619047618,
                    0.5714285714285714,
                    4.252380952380952
                ],
                "answer_relation_to_question_bing": [
                    0.0,
                    0.0,
                    4.0
                ],
                "result_count_noun_chunks": [
                    784.0,
                    12.0,
                    43800.0
                ],
                "question_answer_similarity": [
                    1.4455587603151798,
                    -0.35342413396574557,
                    0.6841054856777191
                ],
                "result_count_bing": [
                    3780000.0,
                    3810000.0,
                    3700000.0
                ],
                "word_count_appended": [
                    101.0,
                    24.0,
                    469.0
                ],
                "result_count": [
                    1490.0,
                    6.0,
                    18300.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which verb describes the sound minerals make when they are heated?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "decrepitate"
            ],
            "lines": [
                [
                    0.9044715447154471,
                    1.0,
                    0,
                    1.0,
                    0.33766233766233766,
                    1.0,
                    1.0,
                    1.0,
                    0.7288135593220338,
                    0.7324606012045752,
                    2.0
                ],
                [
                    0.006097560975609756,
                    0.0,
                    0,
                    0.0,
                    0.3354978354978355,
                    0.0,
                    0.0,
                    0.0,
                    0.13559322033898305,
                    0.13376969939771235,
                    2.0
                ],
                [
                    0.08943089430894309,
                    0.0,
                    0,
                    0.0,
                    0.3268398268398268,
                    0.0,
                    0.0,
                    0.0,
                    0.13559322033898305,
                    0.13376969939771235,
                    2.0
                ]
            ],
            "fraction_answers": {
                "frangelle": 0.06788425735668231,
                "decrepitate": 0.8559342269893773,
                "recleft": 0.0761815156539406
            },
            "question": "which verb describes the sound minerals make when they are heated?",
            "rate_limited": false,
            "answers": [
                "decrepitate",
                "frangelle",
                "recleft"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "frangelle": 0.1844517795915823,
                "decrepitate": 0.6800759067258717,
                "recleft": 0.1844517795915823
            },
            "integer_answers": {
                "frangelle": 0,
                "decrepitate": 9,
                "recleft": 0
            },
            "categorical_data": {
                "question_type": 2
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    3.662303006022876,
                    0.6688484969885617,
                    0.6688484969885617
                ],
                "result_count_important_words": [
                    4420.0,
                    0,
                    0
                ],
                "wikipedia_search": [
                    2.0,
                    0.0,
                    0.0
                ],
                "answer_relation_to_question": [
                    3.6178861788617884,
                    0.024390243902439025,
                    0.35772357723577236
                ],
                "answer_relation_to_question_bing": [
                    4.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    4610.0,
                    0,
                    0
                ],
                "question_answer_similarity": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_bing": [
                    156000.0,
                    155000.0,
                    151000.0
                ],
                "word_count_appended": [
                    86.0,
                    16.0,
                    16.0
                ],
                "result_count": [
                    4360.0,
                    0,
                    0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Before a performance, an orchestra usually tunes to what instrument?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "oboe"
            ],
            "lines": [
                [
                    0.38541666666666663,
                    0.31901709401709405,
                    0.2088085995985237,
                    0.15192926045016078,
                    0.36225823314166233,
                    0.27220902612826603,
                    0.35472370766488415,
                    0.23219795418965544,
                    0.46490218642117376,
                    0.3421658380039939,
                    1.0
                ],
                [
                    0.2861280487804878,
                    0.3754273504273504,
                    0.6277283574065281,
                    0.06430868167202572,
                    0.3230527966544694,
                    0.08646080760095012,
                    0.13725490196078433,
                    0.41594850516012344,
                    0.10586881472957423,
                    0.3287761529830922,
                    1.0
                ],
                [
                    0.3284552845528455,
                    0.3055555555555555,
                    0.16346304299494818,
                    0.7837620578778135,
                    0.31468897020386827,
                    0.6413301662707839,
                    0.5080213903743316,
                    0.3518535406502211,
                    0.42922899884925203,
                    0.329058009012914,
                    1.0
                ]
            ],
            "fraction_answers": {
                "french horn": 0.2750954417375385,
                "bassoon": 0.41554170163425336,
                "oboe": 0.30936285662820806
            },
            "question": "before a performance, an orchestra usually tunes to what instrument?",
            "rate_limited": false,
            "answers": [
                "oboe",
                "french horn",
                "bassoon"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "french horn": 0.4074284557948611,
                "bassoon": 0.20653181992713215,
                "oboe": 0.5003754507103342
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.7108291900199695,
                    1.643880764915461,
                    1.64529004506457
                ],
                "result_count_important_words": [
                    573000.0,
                    182000.0,
                    1350000.0
                ],
                "wikipedia_search": [
                    0.9287918167586218,
                    1.6637940206404938,
                    1.4074141626008845
                ],
                "answer_relation_to_question": [
                    1.5416666666666665,
                    1.1445121951219512,
                    1.313821138211382
                ],
                "answer_relation_to_question_bing": [
                    1.2760683760683762,
                    1.5017094017094017,
                    1.222222222222222
                ],
                "result_count_noun_chunks": [
                    796000.0,
                    308000.0,
                    1140000.0
                ],
                "question_answer_similarity": [
                    1.648685345891863,
                    4.956340620294213,
                    1.2906514583155513
                ],
                "result_count_bing": [
                    693000.0,
                    618000.0,
                    602000.0
                ],
                "result_count": [
                    378000.0,
                    160000.0,
                    1950000.0
                ],
                "word_count_appended": [
                    404.0,
                    92.0,
                    373.0
                ]
            },
            "integer_answers": {
                "french horn": 3,
                "bassoon": 3,
                "oboe": 4
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which two countries have almost perfectly identical flags?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "luxembourg / russia"
            ],
            "lines": [
                [
                    0.08176100628930817,
                    0.25,
                    0.16941492720506374,
                    0.21475054229934923,
                    0.03233564938535542,
                    0.7175472928897586,
                    0.4333038869257951,
                    0.00315955766192733,
                    0.21052631578947367,
                    0.3608257267531461,
                    -1.0
                ],
                [
                    0.09433962264150943,
                    0.08333333333333333,
                    0.48353237953530304,
                    0.6550976138828634,
                    0.8204168893639765,
                    0.2420091324200913,
                    0.5477031802120141,
                    0.00315955766192733,
                    0.15789473684210525,
                    0.35248653797040896,
                    -1.0
                ],
                [
                    0.8238993710691824,
                    0.6666666666666666,
                    0.3470526932596332,
                    0.1301518438177874,
                    0.1472474612506681,
                    0.04044357469015003,
                    0.018992932862190812,
                    0.9936808846761452,
                    0.631578947368421,
                    0.286687735276445,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "luxembourg / russia": 0.3439972983863533,
                "indonesia / monaco": 0.408640211093729,
                "armenia / romania": 0.24736249051991774
            },
            "question": "which two countries have almost perfectly identical flags?",
            "rate_limited": false,
            "answers": [
                "armenia / romania",
                "luxembourg / russia",
                "indonesia / monaco"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "luxembourg / russia": 0.36638889182243195,
                "indonesia / monaco": 0.21932500723434808,
                "armenia / romania": 0.33029567661057535
            },
            "integer_answers": {
                "luxembourg / russia": 4,
                "indonesia / monaco": 4,
                "armenia / romania": 2
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.4433029070125845,
                    1.4099461518816359,
                    1.14675094110578
                ],
                "result_count_important_words": [
                    1100.0,
                    371.0,
                    62.0
                ],
                "wikipedia_search": [
                    0.009478672985781991,
                    0.009478672985781991,
                    2.9810426540284363
                ],
                "answer_relation_to_question": [
                    0.24528301886792453,
                    0.2830188679245283,
                    2.4716981132075473
                ],
                "answer_relation_to_question_bing": [
                    0.75,
                    0.25,
                    2.0
                ],
                "result_count_noun_chunks": [
                    981.0,
                    1240.0,
                    43.0
                ],
                "question_answer_similarity": [
                    0.5158121178392321,
                    1.4721953067928553,
                    1.0566600456368178
                ],
                "result_count_bing": [
                    12100.0,
                    307000.0,
                    55100.0
                ],
                "word_count_appended": [
                    4.0,
                    3.0,
                    12.0
                ],
                "result_count": [
                    99.0,
                    302.0,
                    60.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "The \u201cAmerican Craftsman\u201d style of house was an architectural reaction to what?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "industrial revolution"
            ],
            "lines": [
                [
                    0.156112906701142,
                    0.2867102396514161,
                    0.37899132670912994,
                    0.0010361431096483208,
                    0.4172244533690317,
                    0.48214285714285715,
                    0.2660702451954937,
                    0.4564468553992202,
                    0.22962962962962963,
                    0.289339492927176,
                    1.0
                ],
                [
                    0.4005932629462041,
                    0.46644880174291936,
                    0.20377879766972998,
                    0.9980496129700738,
                    0.3614457831325301,
                    0.4126984126984127,
                    0.5798542080848244,
                    0.3703102220715375,
                    0.5481481481481482,
                    0.47053564622502164,
                    1.0
                ],
                [
                    0.4432938303526539,
                    0.2468409586056645,
                    0.4172298756211401,
                    0.0009142439202779302,
                    0.2213297634984382,
                    0.10515873015873016,
                    0.1540755467196819,
                    0.17324292252924223,
                    0.2222222222222222,
                    0.2401248608478023,
                    1.0
                ]
            ],
            "fraction_answers": {
                "world war i": 0.29637041498347444,
                "industrial revolution": 0.48118628956894016,
                "the great depression": 0.22244329544758532
            },
            "question": "the \u201camerican craftsman\u201d style of house was an architectural reaction to what?",
            "rate_limited": false,
            "answers": [
                "world war i",
                "industrial revolution",
                "the great depression"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "world war i": 0.13542796211556482,
                "industrial revolution": 0.6360642849927717,
                "the great depression": 0.18087186047961695
            },
            "integer_answers": {
                "world war i": 3,
                "industrial revolution": 5,
                "the great depression": 2
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.7360369575630559,
                    2.82321387735013,
                    1.4407491650868138
                ],
                "result_count_important_words": [
                    72900.0,
                    62400.0,
                    15900.0
                ],
                "wikipedia_search": [
                    2.282234276996101,
                    1.8515511103576876,
                    0.8662146126462111
                ],
                "answer_relation_to_question": [
                    0.78056453350571,
                    2.0029663147310206,
                    2.2164691517632695
                ],
                "answer_relation_to_question_bing": [
                    0.8601307189542484,
                    1.399346405228758,
                    0.7405228758169935
                ],
                "result_count_noun_chunks": [
                    8030.0,
                    17500.0,
                    4650.0
                ],
                "question_answer_similarity": [
                    13.826534636318684,
                    7.434351146221161,
                    15.22157083824277
                ],
                "result_count_bing": [
                    187000.0,
                    162000.0,
                    99200.0
                ],
                "result_count": [
                    68.0,
                    65500.0,
                    60.0
                ],
                "word_count_appended": [
                    31.0,
                    74.0,
                    30.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "In the original NES \u201cMike Tyson\u2019s Punch-Out!!\u201d, who does Little Mac face right before the final opponent?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "super macho man"
            ],
            "lines": [
                [
                    0.33498243973073366,
                    0.2006267889669529,
                    0.393206579596363,
                    0.45757737459978653,
                    0.2668112798264642,
                    0.5018888289260658,
                    0.24844167408726625,
                    0.0104775828460039,
                    0.37606837606837606,
                    0.3229822631759514,
                    0.0
                ],
                [
                    0.5098930923818935,
                    0.4120573119958365,
                    0.3606642667217029,
                    0.12620064034151549,
                    0.2668112798264642,
                    0.0124123043712898,
                    0.2736717126743841,
                    0.91973858256753,
                    0.3076923076923077,
                    0.3552433147239244,
                    0.0
                ],
                [
                    0.15512446788737286,
                    0.38731589903721053,
                    0.2461291536819341,
                    0.41622198505869795,
                    0.46637744034707157,
                    0.48569886670264434,
                    0.47788661323834963,
                    0.06978383458646617,
                    0.3162393162393162,
                    0.32177442210012425,
                    0.0
                ]
            ],
            "fraction_answers": {
                "super macho man": 0.35443848132968486,
                "mr. dream": 0.31130631878239634,
                "mr. sandman": 0.3342551998879188
            },
            "question": "in the original nes \u201cmike tyson\u2019s punch-out!!\u201d, who does little mac face right before the final opponent?",
            "rate_limited": false,
            "answers": [
                "mr. dream",
                "super macho man",
                "mr. sandman"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "super macho man": 0.4727941863905904,
                "mr. dream": 0.14661766669363183,
                "mr. sandman": 0.2686608587011491
            },
            "integer_answers": {
                "super macho man": 4,
                "mr. dream": 4,
                "mr. sandman": 2
            },
            "categorical_data": {
                "question_type": 0
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    3.552804894935466,
                    3.907676461963168,
                    3.539518643101367
                ],
                "result_count_important_words": [
                    3720.0,
                    92.0,
                    3600.0
                ],
                "wikipedia_search": [
                    0.09429824561403508,
                    8.277647243107769,
                    0.6280545112781954
                ],
                "answer_relation_to_question": [
                    3.6848068370380704,
                    5.6088240162008285,
                    1.7063691467611013
                ],
                "answer_relation_to_question_bing": [
                    2.006267889669529,
                    4.120573119958365,
                    3.8731589903721053
                ],
                "result_count_noun_chunks": [
                    8370.0,
                    9220.0,
                    16100.0
                ],
                "question_answer_similarity": [
                    20.357109935488552,
                    18.672327749431133,
                    12.74261037283577
                ],
                "result_count_bing": [
                    123000.0,
                    123000.0,
                    215000.0
                ],
                "result_count": [
                    3430.0,
                    946.0,
                    3120.0
                ],
                "word_count_appended": [
                    44.0,
                    36.0,
                    37.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Which of these do NOT have flippers?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "new yorkers"
            ],
            "lines": [
                [
                    0.5,
                    0,
                    0.299061207536534,
                    0.33082077051926295,
                    0.4106914796569969,
                    0.4443565400843882,
                    0.4443565400843882,
                    0.5,
                    0.4391711229946524,
                    0.36771300448430494,
                    -1.0
                ],
                [
                    0.5,
                    0,
                    0.3917375172628791,
                    0.24371859296482412,
                    0.14604999087757708,
                    0.19672995780590719,
                    0.19672995780590719,
                    0.4,
                    0.12232620320855614,
                    0.3318385650224215,
                    -1.0
                ],
                [
                    0.0,
                    0,
                    0.30920127520058693,
                    0.4254606365159129,
                    0.443258529465426,
                    0.35891350210970463,
                    0.35891350210970463,
                    0.09999999999999998,
                    0.4385026737967914,
                    0.3004484304932735,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "new yorkers": 0.169739852142105,
                "pinball machines": 0.39228921117968885,
                "dolphins": 0.4379709366782062
            },
            "question": "which of these do not have flippers?",
            "rate_limited": false,
            "answers": [
                "new yorkers",
                "dolphins",
                "pinball machines"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "new yorkers": 0.6001961100467188,
                "pinball machines": 0.15562764747283997,
                "dolphins": 0.3937950996202099
            },
            "integer_answers": {
                "new yorkers": 1,
                "pinball machines": 3,
                "dolphins": 5
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    0.2645739910313901,
                    0.336322869955157,
                    0.3991031390134529
                ],
                "result_count_important_words": [
                    42200.0,
                    230000.0,
                    107000.0
                ],
                "wikipedia_search": [
                    0.0,
                    0.2,
                    0.8
                ],
                "answer_relation_to_question": [
                    0.0,
                    0.0,
                    1.0
                ],
                "answer_relation_to_question_bing": [
                    0.0,
                    0.0,
                    0.0
                ],
                "result_count_noun_chunks": [
                    42200.0,
                    230000.0,
                    107000.0
                ],
                "question_answer_similarity": [
                    2.8958178497850895,
                    1.5602185428142548,
                    2.7496848478913307
                ],
                "result_count_bing": [
                    9790000.0,
                    38800000.0,
                    6220000.0
                ],
                "result_count": [
                    101000.0,
                    153000.0,
                    44500.0
                ],
                "word_count_appended": [
                    91.0,
                    565.0,
                    92.0
                ]
            },
            "negative_question": true
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "In \u201cPeanuts,\u201d what breed of dog is Snoopy?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "beagle"
            ],
            "lines": [
                [
                    0.2191409399155878,
                    0.3210526315789474,
                    0.5113000362162664,
                    9.972530212233575e-05,
                    0.849609375,
                    0.27466570292735815,
                    6.486444412252461e-06,
                    0.5347605109704354,
                    0.11124845488257108,
                    0.310720542870603,
                    1.0
                ],
                [
                    0.07743633518281406,
                    0.22631578947368422,
                    0.21743359478926708,
                    5.6985886927049e-05,
                    0.05810546875,
                    0.00012046741356463077,
                    0.4864833309189346,
                    0.007907335556916934,
                    0.11248454882571075,
                    0.17793240181838213,
                    1.0
                ],
                [
                    0.7034227249015981,
                    0.45263157894736844,
                    0.27126636899446643,
                    0.9998432888109506,
                    0.09228515625,
                    0.7252138296590772,
                    0.5135101826366532,
                    0.45733215347264766,
                    0.7762669962917181,
                    0.5113470553110149,
                    1.0
                ]
            ],
            "fraction_answers": {
                "beagle": 0.5503119335275495,
                "pitbull": 0.13642762586162013,
                "border collie": 0.3132604406108304
            },
            "question": "in \u201cpeanuts,\u201d what breed of dog is snoopy?",
            "rate_limited": false,
            "answers": [
                "border collie",
                "pitbull",
                "beagle"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "beagle": 0.6989401585088912,
                "pitbull": 0.3541025853490388,
                "border collie": 0.40857738184796016
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.242882171482412,
                    0.7117296072735285,
                    2.0453882212440595
                ],
                "result_count_important_words": [
                    114000.0,
                    50.0,
                    301000.0
                ],
                "wikipedia_search": [
                    1.0695210219408708,
                    0.01581467111383387,
                    0.9146643069452953
                ],
                "answer_relation_to_question": [
                    0.8765637596623512,
                    0.30974534073125626,
                    2.8136908996063923
                ],
                "answer_relation_to_question_bing": [
                    0.6421052631578947,
                    0.4526315789473684,
                    0.9052631578947368
                ],
                "result_count_noun_chunks": [
                    24.0,
                    1800000.0,
                    1900000.0
                ],
                "question_answer_similarity": [
                    3.995528713800013,
                    1.6991240167990327,
                    2.1197975545364898
                ],
                "result_count_bing": [
                    1740000.0,
                    119000.0,
                    189000.0
                ],
                "result_count": [
                    77.0,
                    44.0,
                    772000.0
                ],
                "word_count_appended": [
                    90.0,
                    91.0,
                    628.0
                ]
            },
            "integer_answers": {
                "beagle": 7,
                "pitbull": 0,
                "border collie": 3
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "Which of the following is a dice-based game?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "quirkle"
            ],
            "lines": [
                [
                    0.38711415815003386,
                    0.4512012012012012,
                    -0.0,
                    0.9978308026030369,
                    0.023897677549646584,
                    0.997839568535414,
                    0.9974871291983329,
                    0.0,
                    0.22544642857142858,
                    0.3651384464112932,
                    -1.0
                ],
                [
                    0.008593396653098146,
                    0.0,
                    -13.448183182848236,
                    0.0011620700340873877,
                    0.6428811847862672,
                    0.0009636456892398079,
                    0.0012104682520225547,
                    0.0,
                    0.3203125,
                    0.3249692011585715,
                    -1.0
                ],
                [
                    0.604292445196868,
                    0.5487987987987988,
                    14.448183182848236,
                    0.001007127362875736,
                    0.3332211376640862,
                    0.001196785775346213,
                    0.0013024025496445207,
                    1.0,
                    0.45424107142857145,
                    0.30989235243013535,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "sparkle": -1.2148090716274949,
                "quirkle": 0.44459554122203865,
                "farkle": 1.7702135304054563
            },
            "question": "which of the following is a dice-based game?",
            "rate_limited": false,
            "answers": [
                "quirkle",
                "sparkle",
                "farkle"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "sparkle": 0.293883475133595,
                "quirkle": 0.5831583047511493,
                "farkle": 0.2706364793675059
            },
            "integer_answers": {
                "sparkle": 2,
                "quirkle": 4,
                "farkle": 4
            },
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.460553785645173,
                    1.299876804634286,
                    1.2395694097205414
                ],
                "result_count_important_words": [
                    64200.0,
                    62.0,
                    77.0
                ],
                "wikipedia_search": [
                    0.0,
                    0.0,
                    4.0
                ],
                "answer_relation_to_question": [
                    1.1613424744501015,
                    0.025780189959294438,
                    1.812877335590604
                ],
                "answer_relation_to_question_bing": [
                    1.3536036036036037,
                    0.0,
                    1.6463963963963963
                ],
                "result_count_noun_chunks": [
                    65100.0,
                    79.0,
                    85.0
                ],
                "question_answer_similarity": [
                    0.0,
                    1.0122998552396894,
                    -1.087573952972889
                ],
                "result_count_bing": [
                    142000.0,
                    3820000.0,
                    1980000.0
                ],
                "word_count_appended": [
                    202.0,
                    287.0,
                    407.0
                ],
                "result_count": [
                    64400.0,
                    75.0,
                    65.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "What was the first popular home video game?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "pong"
            ],
            "lines": [
                [
                    0.41141519219494593,
                    0.2090682948891904,
                    0.15572708926335596,
                    0.034710537196042425,
                    0.3223767383059418,
                    0.018308152956503853,
                    0.019464720194647202,
                    0.09539914521327161,
                    0.16526610644257703,
                    0.29465504283920324,
                    1.0
                ],
                [
                    0.3531454352760782,
                    0.22953414744459522,
                    0.10277820441426974,
                    0.9586261934751882,
                    0.3438685208596713,
                    0.9348357751822816,
                    0.9618815896188159,
                    0.7075650244795225,
                    0.6974789915966386,
                    0.4497125015108621,
                    1.0
                ],
                [
                    0.23543937252897584,
                    0.5613975576662144,
                    0.7414947063223744,
                    0.006663269328769363,
                    0.33375474083438683,
                    0.0468560718612146,
                    0.0186536901865369,
                    0.19703583030720578,
                    0.13725490196078433,
                    0.2556324556499347,
                    1.0
                ]
            ],
            "fraction_answers": {
                "tekken 2": 0.17263910194956797,
                "pong": 0.5739426383857923,
                "half-life 3": 0.25341825966463977
            },
            "question": "what was the first popular home video game?",
            "rate_limited": false,
            "answers": [
                "tekken 2",
                "pong",
                "half-life 3"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "tekken 2": 0.2416961322931678,
                "pong": 0.6871476592945055,
                "half-life 3": 0.19414123001326766
            },
            "integer_answers": {
                "tekken 2": 1,
                "pong": 7,
                "half-life 3": 2
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.178620171356813,
                    1.7988500060434485,
                    1.0225298225997388
                ],
                "result_count_important_words": [
                    80100.0,
                    4090000.0,
                    205000.0
                ],
                "wikipedia_search": [
                    0.38159658085308645,
                    2.83026009791809,
                    0.7881433212288231
                ],
                "answer_relation_to_question": [
                    1.6456607687797837,
                    1.412581741104313,
                    0.9417574901159034
                ],
                "answer_relation_to_question_bing": [
                    0.8362731795567616,
                    0.9181365897783809,
                    2.2455902306648574
                ],
                "result_count_noun_chunks": [
                    120000.0,
                    5930000.0,
                    115000.0
                ],
                "question_answer_similarity": [
                    2.11887746816501,
                    1.3984363451600075,
                    10.089037388563156
                ],
                "result_count_bing": [
                    51000000.0,
                    54400000.0,
                    52800000.0
                ],
                "word_count_appended": [
                    118.0,
                    498.0,
                    98.0
                ],
                "result_count": [
                    361000.0,
                    9970000.0,
                    69300.0
                ]
            },
            "negative_question": false
        },
        "right_answer": [
            0,
            1,
            0
        ]
    },
    "Featuring 20 scoops of ice cream, the Vermonster is found on what chain's menu?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "ben & jerry's"
            ],
            "lines": [
                [
                    0.650351066332298,
                    0.6728449676919631,
                    0.10819974874763372,
                    0.16339869281045752,
                    0.3333333333333333,
                    0.005690252350321623,
                    0.007161857990587273,
                    0.15921843066037847,
                    0.7051282051282052,
                    0.2185590015323421,
                    1.0
                ],
                [
                    0.22246940107820576,
                    0.17090958299139683,
                    0.31262316818317987,
                    0.1830065359477124,
                    0.3333333333333333,
                    0.007174666006927264,
                    0.010640474728872518,
                    0.36529698691253404,
                    0.2948717948717949,
                    0.22506365203856232,
                    1.0
                ],
                [
                    0.12717953258949627,
                    0.15624544931664006,
                    0.5791770830691864,
                    0.6535947712418301,
                    0.3333333333333333,
                    0.9871350816427511,
                    0.9821976672805403,
                    0.47548458242708747,
                    0.0,
                    0.5563773464290956,
                    1.0
                ]
            ],
            "fraction_answers": {
                "ben & jerry's": 0.5218710870230854,
                "dairy queen": 0.22866260482098824,
                "baskin-robbins": 0.24946630815592635
            },
            "question": "featuring 20 scoops of ice cream, the vermonster is found on what chain's menu?",
            "rate_limited": false,
            "answers": [
                "baskin-robbins",
                "dairy queen",
                "ben & jerry's"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "ben & jerry's": 0.6686223491779206,
                "dairy queen": 0.3931173256449866,
                "baskin-robbins": 0.3120071030637619
            },
            "negative_question": false,
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.967031013791079,
                    2.025572868347061,
                    5.007396117861861
                ],
                "result_count_important_words": [
                    23.0,
                    29.0,
                    3990.0
                ],
                "wikipedia_search": [
                    1.2737474452830277,
                    2.9223758953002723,
                    3.8038766594166997
                ],
                "answer_relation_to_question": [
                    5.202808530658384,
                    1.779755208625646,
                    1.0174362607159702
                ],
                "answer_relation_to_question_bing": [
                    4.709914773843742,
                    1.196367080939778,
                    1.0937181452164806
                ],
                "result_count_noun_chunks": [
                    35.0,
                    52.0,
                    4800.0
                ],
                "question_answer_similarity": [
                    2.0412506726570427,
                    5.897816397249699,
                    10.926509757060558
                ],
                "result_count_bing": [
                    1680000.0,
                    1680000.0,
                    1680000.0
                ],
                "word_count_appended": [
                    55.0,
                    23.0,
                    0.0
                ],
                "result_count": [
                    25.0,
                    28.0,
                    100.0
                ]
            },
            "integer_answers": {
                "ben & jerry's": 6,
                "dairy queen": 0,
                "baskin-robbins": 4
            }
        },
        "right_answer": [
            0,
            0,
            1
        ]
    },
    "The U.S. has never had a Miss America from what state?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "new mexico"
            ],
            "lines": [
                [
                    0.3556163486719042,
                    0.32658783783783785,
                    0.24551597015623117,
                    0.39857015192135836,
                    0.40775220040622884,
                    0.39426100628930816,
                    0.2169811320754717,
                    0.318804923840329,
                    0.4236526946107784,
                    0.33445899364761666,
                    1.0
                ],
                [
                    0.3319467826412271,
                    0.3894594594594595,
                    0.3169507826414436,
                    0.3614834673815907,
                    0.3376777251184834,
                    0.33215408805031443,
                    0.3971468016566958,
                    0.2949478392633389,
                    0.36227544910179643,
                    0.32639577623727883,
                    1.0
                ],
                [
                    0.3124368686868687,
                    0.2839527027027027,
                    0.4375332472023252,
                    0.23994638069705093,
                    0.25457007447528773,
                    0.27358490566037735,
                    0.3858720662678325,
                    0.3862472368963321,
                    0.21407185628742514,
                    0.3391452301151045,
                    1.0
                ]
            ],
            "fraction_answers": {
                "nebraska": 0.3745278862017386,
                "new mexico": 0.3155597481085871,
                "north dakota": 0.3099123656896743
            },
            "question": "the u.s. has never had a miss america from what state?",
            "rate_limited": false,
            "answers": [
                "new mexico",
                "north dakota",
                "nebraska"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "nebraska": 0.3094065610240718,
                "new mexico": 0.4633030882014168,
                "north dakota": 0.137683616274745
            },
            "integer_answers": {
                "nebraska": 6,
                "new mexico": 2,
                "north dakota": 2
            },
            "categorical_data": {
                "question_type": 1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    1.3243280508190667,
                    1.3888337901017693,
                    1.286838159079164
                ],
                "result_count_important_words": [
                    2690000.0,
                    4270000.0,
                    5760000.0
                ],
                "wikipedia_search": [
                    1.0871704569580258,
                    1.2303129644199668,
                    0.6825165786220073
                ],
                "answer_relation_to_question": [
                    1.1550692106247662,
                    1.3444257388701832,
                    1.5005050505050503
                ],
                "answer_relation_to_question_bing": [
                    1.3872972972972972,
                    0.8843243243243243,
                    1.7283783783783784
                ],
                "result_count_noun_chunks": [
                    12300000.0,
                    4470000.0,
                    4960000.0
                ],
                "question_answer_similarity": [
                    7.735453888773918,
                    5.564077168703079,
                    1.8987780339084566
                ],
                "result_count_bing": [
                    54500000.0,
                    95900000.0,
                    145000000.0
                ],
                "result_count": [
                    2270000.0,
                    3100000.0,
                    5820000.0
                ],
                "word_count_appended": [
                    102.0,
                    184.0,
                    382.0
                ]
            },
            "negative_question": true
        },
        "right_answer": [
            1,
            0,
            0
        ]
    },
    "Which of these do adverbs NOT typically modify?": {
        "raw_data": {
            "z-best_answer_by_ml": [
                "pronoun"
            ],
            "lines": [
                [
                    0.49691358024691357,
                    0.5,
                    0.32544746535615543,
                    0.23434237995824636,
                    0.24296799224054316,
                    0.33585858585858586,
                    0.21779699590350476,
                    0.5,
                    0.41733067729083667,
                    0.3602445474342625,
                    -1.0
                ],
                [
                    0.1388037462750107,
                    0.08683378500451672,
                    0.3791113996727453,
                    0.3423799582463466,
                    0.4165858389912706,
                    0.33964646464646464,
                    0.4244424214838416,
                    0.1739750445632799,
                    0.21762948207171312,
                    0.31756989586637363,
                    -1.0
                ],
                [
                    0.36428267347807575,
                    0.4131662149954833,
                    0.29544113497109925,
                    0.4232776617954071,
                    0.34044616876818623,
                    0.3244949494949495,
                    0.35776058261265364,
                    0.32602495543672017,
                    0.3650398406374502,
                    0.3221855566993639,
                    -1.0
                ]
            ],
            "fraction_answers": {
                "adjective": 0.2935760522221222,
                "adverb": 0.4326043926356875,
                "pronoun": 0.27381955514219036
            },
            "question": "which of these do adverbs not typically modify?",
            "rate_limited": false,
            "answers": [
                "pronoun",
                "adverb",
                "adjective"
            ],
            "columns_in_order": [
                "answer_relation_to_question",
                "answer_relation_to_question_bing",
                "question_answer_similarity",
                "result_count",
                "result_count_bing",
                "result_count_important_words",
                "result_count_noun_chunks",
                "wikipedia_search",
                "word_count_appended",
                "word_count_appended_relation_to_question",
                "question_type"
            ],
            "ml_answers": {
                "adjective": 0.14425554293871565,
                "adverb": 0.11570650891993323,
                "pronoun": 0.7062640391302258
            },
            "negative_question": true,
            "categorical_data": {
                "question_type": -1
            },
            "data": {
                "word_count_appended_relation_to_question": [
                    0.8385327153944249,
                    1.0945806248017584,
                    1.066886659803817
                ],
                "result_count_important_words": [
                    130000.0,
                    127000.0,
                    139000.0
                ],
                "wikipedia_search": [
                    0.0,
                    1.9561497326203208,
                    1.0438502673796792
                ],
                "answer_relation_to_question": [
                    0.018518518518518517,
                    2.167177522349936,
                    0.8143039591315453
                ],
                "answer_relation_to_question_bing": [
                    0.0,
                    2.4789972899728996,
                    0.5210027100271002
                ],
                "result_count_noun_chunks": [
                    2480000.0,
                    664000.0,
                    1250000.0
                ],
                "question_answer_similarity": [
                    1.4027007594704628,
                    0.9714584313333035,
                    1.643831044435501
                ],
                "result_count_bing": [
                    15900000.0,
                    5160000.0,
                    9870000.0
                ],
                "word_count_appended": [
                    332.0,
                    1134.0,
                    542.0
                ],
                "result_count": [
                    509000.0,
                    302000.0,
                    147000.0
                ]
            },
            "integer_answers": {
                "adjective": 2,
                "adverb": 5,
                "pronoun": 3
            }
        },
        "right_answer": [
            1,
            0,
            0
        ]
    }
}